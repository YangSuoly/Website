<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/blog-logo-32px.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/blog-logo-16px.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="manifest" href="/images/manifest.json">
  <meta name="msapplication-config" content="/images/browserconfig.xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yangsuoly.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1. Introduction 1.1 Job description 本项目为企查查注册企业信息爬取，项目来源是别人的实验需求。故本博客会对项目的具体数据进行脱敏处理，其中涉及的 1168 个链接本文不进行提供，也不提供成品数据。">
<meta property="og:type" content="article">
<meta property="og:title" content="Crawler-qcc">
<meta property="og:url" content="http://yangsuoly.com/2021/10/02/Crawler-qcc/index.html">
<meta property="og:site_name" content="独孤诗人的学习驿站">
<meta property="og:description" content="1. Introduction 1.1 Job description 本项目为企查查注册企业信息爬取，项目来源是别人的实验需求。故本博客会对项目的具体数据进行脱敏处理，其中涉及的 1168 个链接本文不进行提供，也不提供成品数据。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-10-02T06:37:24.000Z">
<meta property="article:modified_time" content="2021-10-02T09:39:12.711Z">
<meta property="article:author" content="YangSu">
<meta property="article:tag" content="Crawler">
<meta property="article:tag" content="Project">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yangsuoly.com/2021/10/02/Crawler-qcc/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Crawler-qcc | 独孤诗人的学习驿站</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f59f5fb59d32ec3903088b0f976956d1";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">独孤诗人的学习驿站</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">生活就是一半烟火，一半诗意。手执烟火谋生活，心怀诗意谋未来……</p>
      <a>
        <img class="custom-logo-image" src="/images/logo@2x.png" alt="独孤诗人的学习驿站">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/Tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/Categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/YangSuoly" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yangsuoly.com/2021/10/02/Crawler-qcc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/YangSu.jpg">
      <meta itemprop="name" content="YangSu">
      <meta itemprop="description" content="A blog for recording learning notes...">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="独孤诗人的学习驿站">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Crawler-qcc
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-10-02 14:37:24 / Modified: 17:39:12" itemprop="dateCreated datePublished" datetime="2021-10-02T14:37:24+08:00">2021-10-02</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/Categories/Project/" itemprop="url" rel="index"><span itemprop="name">Project</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/Categories/Project/Crawler/" itemprop="url" rel="index"><span itemprop="name">Crawler</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>48k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>43 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="introduction">1. Introduction</h1>
<h2 id="job-description">1.1 Job description</h2>
<p>本项目为企查查注册企业信息爬取，项目来源是别人的实验需求。故本博客会对项目的具体数据进行脱敏处理，其中涉及的
1168 个链接本文不进行提供，也不提供成品数据。</p>
<a id="more"></a>
<p>读者如需类似信息，可以借助本博客提供的方法自行爬取。注：部分公司和企业家信息需要
VIP 账户方能进行爬取。</p>
<p>免责声明：本文仅供参考和交流，仅记录数据爬取过程中所使用的方法和问题的解决方法，如有侵权，请联系
<code>e-mail:yangsuoly@qq.com</code>。</p>
<p>任务爬取所需工具：</p>
<ol type="1">
<li>企查查 VIP 账户</li>
<li>Python 3.8</li>
</ol>
<h2 id="task-requirements">1.2 Task requirements</h2>
<p>网站：企查查（共1168个链接-Excel表），链接样例：
https://www.qcc.com/pl/p43ce90f8f80f49f4089ab2e9040dece.html</p>
<h3 id="企业家信息">1.2.1 企业家信息</h3>
<ul>
<li><p>所有企业表</p>
<p>抓取企业家在哪些企业有股份(即他的所有企业表，如下图所示)：抓取的内容包括序号、企业名称、企业名称对应的url(第二个任务会用到)以及其余的整个表的内容。</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCMXq.png' style="zoom:80%;" /></p>
<center>
<p>Fig. 1 所有企业表</p>
</center></li>
<li><p>在外任职表</p>
<p>抓取企业家在哪些企业有管理职位(在外任职表，如下图所示)：同样的抓取的内容包括序号、企业名称以及对应的url、以及职位等表格内容。</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCln0.png' style="zoom:80%;" /></p>
<center>
<p>Fig. 2 在外任职表</p>
</center></li>
</ul>
<h3 id="公司信息">1.2.2 公司信息</h3>
<p>爬取企业家旗下每一家企业信息(即他的所有企业表中的所有公司的信息，如
Fig.1 所示)的信息：</p>
<ul>
<li><p>营业执照信息</p>
<p>企业的基本注册信息</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCu1s.png' style="zoom:80%;" /></p>
<center>
<p>Fig. 3 营业执照信息</p>
</center></li>
<li><p>股东信息</p>
<p>企业的股东信息(点击url显示如下表)，包括：每一位股东的名字 + 股份 +
每一位股东的URL</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bC37T.png' style="zoom:80%;" /></p>
<center>
<p>Fig. 4 公司股东信息</p>
</center></li>
<li><p>主要人员</p>
<p>企业管理者信息，包括：名字 + 股份(if applicable) + 职务
+每一位管理者的URL</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCKcn.png' style="zoom:80%;" /></p>
<center>
<p>Fig. 5 主要人员信息</p>
</center></li>
</ul>
<h3 id="公司知识产权信息">1.2.3 公司知识产权信息</h3>
<p>企业的知识产权信息(点击相同url后，点击知识产权)</p>
<ul>
<li><p>专利信息</p>
<p>包含专利信息一栏的所有信息</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCGAU.png' style="zoom:80%;" /></p>
<center>
<p>Fig. 6 专利信息</p>
</center></li>
<li><p>软件著作权</p>
<p>包含软件著作权一栏的所有信息</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCJNF.png' style="zoom:80%;" /></p></li>
<li><p>其他</p>
<p>如资质证书、作品著作权。</p></li>
</ul>
<h1 id="static-crawler">2 Static crawler</h1>
<p>在爬取之前，对需要爬取的链接进行初步地分析，我们发现，索要爬取的信息存在如下特点：</p>
<ol type="1">
<li>大多数内容数量少于 10
条，少部分公司的词条（如专利证书）数量会大于10。</li>
<li>高管的 <code>url</code> 链接都以 <code>pl</code>
开头，公司的基本信息的 <code>url</code> 以 <code>cbase</code>
开头，而知识产权信息以 <code>cassets</code> 开头。</li>
<li>各项信息在网页中（如果存在该词条）存在都有规律，且存在一直的
<code>id</code> 节点，因此可以通过 <code>id</code>
对元素进行定位（<code>id</code> 是页面中唯一的标识）</li>
<li>企查查的反爬虫机制较为严格，需要适用虚拟 <code>ip</code>
和控制请求的时间来规避反爬虫，本文只是用最简单的控制请求的时间来规避爬虫机制。</li>
</ol>
<p>得到上述信息之后，我们考虑先用静态爬虫来进行信息的提取，之后适用动态爬虫来补充遗漏的数据。同时，文中也会附上
<code>ip</code> 代理池的生成方法，感兴趣的可以自行适用代理池进行虚拟
<code>ip</code> 的设置。</p>
<h2 id="configuration">2.1 Configuration</h2>
<ul>
<li><p>Import modules</p>
<p>首先导入如下模块，如果没有的，自行适用
<code>pip install module_name</code> 进行安装。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> swifter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br></pre></td></tr></table></figure></li>
<li><p>Set request headers</p>
<p>设置请求头：</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> headers = &#123;</span><br><span class="line">  <span class="string">&#x27;Host&#x27;</span>:<span class="string">&#x27;www.qcc.com&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Accept&#x27;</span>:<span class="string">r&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;X-Requested-With&#x27;</span>: <span class="string">&#x27;XMLHttpRequest&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.164 Safari/537.36&quot;</span>,</span><br><span class="line">  <span class="string">&#x27;Accept-Encoding&#x27;</span>:<span class="string">&#x27;gzip, deflate, br&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Accept-Language&#x27;</span>:<span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Cookie&#x27;</span>:<span class="string">&quot;QCCSESSID= ; qcc_did= ; zg_did= ; acw_tc= ; zg_294c2ba1ecc244809c552f8f6fd2a440= &quot;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>由于爬取过程中需要 <code>VIP</code>
账户的权限，因此我们适用了本地浏览器的 <code>Cookie</code>，此处已经对
<code>Cookie</code> 信息进行脱敏，读者自行载入自己浏览器的
<code>Cookie</code> 信息，本文全程适用
<code>Google Chrome 92.0.4515.107</code> 进行数据爬取，此处以
<code>Chrome</code> 浏览器为例，其他浏览器 <code>Cookie</code>
信息载入方法大同小异。</p>
<p>进入企查查官网，并进行登录，只有有两种方式得到
<code>Cookie</code>，分别法如下：</p>
<ol type="1">
<li><p>利用设置</p>
<p>打开 <code>all cookies and site data</code> 界面 <a
href="chrome://settings/siteData">chrome://settings/siteData</a>，搜查
<code>qcc</code> 将搜过结果对应字段的值粘贴到上述 <code>Cookie</code>
中等号的右边（如<code>QCCSESSID</code>）</p>
<p>搜索结果如下图所示：</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCYh4.png' style="zoom:80%;" /></p></li>
<li><p>利用开发者模式</p>
<p>进入企查查官网，登录之后，按 <code>F12</code> 或右键
<code>审视</code> 打开开发者模式，依次点击
<code>Network</code>，<code>Fetch/XHR</code>，之后算便点击其中一个链接，找到
<code>Headers</code> 中的 <code>cookie</code>
字段的信息，进行复制。如下图所示：</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bC1BV.png' style="zoom:80%;" /></p></li>
</ol></li>
<li><p>Set data path and load data</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pl_root_dir = <span class="string">r&#x27;D:\Demo\work\XMU\Data_Collection\Results\Results/&#x27;</span></span><br><span class="line">pd_firm = pd.read_csv(<span class="string">&#x27;./FirmList.csv&#x27;</span>, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>其中，<code>FirmList.csv</code> 仅包含1168条公司 <code>url</code>
信息，由于涉及他人实验和论文信息，本文不进行公开，仅提供 5
个样本供学习交流。读者可自行寻找一些公司的 <code>url</code>
进行尝试。</p>
<p><a id="download" href="https://www.aliyundrive.com/s/2pB62oUL4sv" target="_blank"><i class="fa fa-download"></i><span>
Download FirmList </span> </a></p></li>
</ul>
<h2 id="自定义函数">2.2 自定义函数</h2>
<p>接下来，对所需要爬取的各项数据进行拆解和爬取。</p>
<h3 id="企业家所属信息">2.2.1 企业家所属信息</h3>
<p>通过 <code>id</code> 我们可以定位许多信息，如</p>
<ul>
<li><code>allcompanylist</code>: 所有企业信息;</li>
<li><code>postofficelist</code>: 在外任职信息；</li>
<li><code>legallist</code>: 担任法定代表人信息;</li>
<li><code>holdcolist</code>: 控制企业</li>
</ul>
<p>由于本项目的任务只需要前两个，故设置 <code>n_info</code> 为
<code>2</code> 爬取前两个信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_pl_data</span>(<span class="params">soup</span>):</span></span><br><span class="line">    list_ids = [<span class="string">&#x27;allcompanylist&#x27;</span>, <span class="comment"># 他的所有企业表</span></span><br><span class="line">                 <span class="string">&#x27;postofficelist&#x27;</span>, <span class="comment"># 在外任职表</span></span><br><span class="line">                 <span class="string">&#x27;legallist&#x27;</span>, <span class="comment"># 担任法定代表人</span></span><br><span class="line">                 <span class="string">&#x27;holdcolist&#x27;</span> <span class="comment"># 控制企业    </span></span><br><span class="line">                ]</span><br><span class="line"></span><br><span class="line">    n_info = <span class="number">2</span> <span class="comment"># 爬取他的所有企业和在外任职信息</span></span><br><span class="line">    list_pd = []</span><br><span class="line">    <span class="keyword">for</span> com_id <span class="keyword">in</span> list_ids[:n_info]:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            html_table = soup.find_all(<span class="string">&#x27;div&#x27;</span>, <span class="built_in">id</span> = com_id)[<span class="number">0</span>] <span class="comment"># 他的所有企业表</span></span><br><span class="line"></span><br><span class="line">            pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(html_table.table)))[<span class="number">0</span>] <span class="comment"># 得到公司信息</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                html_table = soup.find_all(<span class="string">&#x27;div&#x27;</span>, <span class="built_in">id</span> = <span class="string">&#x27;his&#x27;</span> + com_id)[<span class="number">0</span>] <span class="comment"># 他的所有企业表</span></span><br><span class="line">                pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(html_table.table)))[<span class="number">0</span>] <span class="comment"># 得到公司信息</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                pd_comp = pd.DataFrame()</span><br><span class="line">        hyper_comps = html_table.find_all(<span class="string">&#x27;a&#x27;</span>, class_ = <span class="string">&#x27;text-blue&#x27;</span>)</span><br><span class="line">        dict_comps = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> hyper_comps:</span><br><span class="line">            <span class="keyword">if</span> h.text <span class="keyword">in</span> dict_comps.keys():</span><br><span class="line">                dict_comps[h.text + <span class="string">&#x27;1&#x27;</span>] = h[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dict_comps[h.text] = h[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> ix <span class="keyword">in</span> <span class="built_in">range</span>(pd_comp.shape[<span class="number">0</span>], <span class="built_in">len</span>(dict_comps.keys())):</span><br><span class="line">            pd_comp.loc[ix, <span class="string">&#x27;Name&#x27;</span>] = np.nan</span><br><span class="line"></span><br><span class="line">        pd_comp[<span class="string">&#x27;Name&#x27;</span>] = dict_comps.keys()</span><br><span class="line">        pd_comp[<span class="string">&#x27;url&#x27;</span>] = dict_comps.values()</span><br><span class="line">        pd_comp[<span class="string">&#x27;url&#x27;</span>] = pd_comp[<span class="string">&#x27;url&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="string">&#x27;https://www.qcc.com&#x27;</span> + x)</span><br><span class="line"></span><br><span class="line">        list_pd.append(pd_comp)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> list_pd[<span class="number">0</span>], list_pd[<span class="number">1</span>] <span class="comment"># 输出到 n_info-1</span></span><br></pre></td></tr></table></figure>
<h3 id="公司所属信息">2.2.2 公司所属信息</h3>
<p>类似的，可以通过 <code>id</code> 定位公司信息：</p>
<ul>
<li><code>cominfo</code>: 营业执照信息；</li>
<li><code>partner</code>: 股东信息；</li>
<li><code>mainmember</code>: 主要人员；</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_firm_data</span>(<span class="params">name_urls, sep, pl_dir</span>):</span></span><br><span class="line">    list_ids = [<span class="string">&#x27;cominfo&#x27;</span>, <span class="comment"># 营业执照信息</span></span><br><span class="line">                 <span class="string">&#x27;partner&#x27;</span>, <span class="comment"># 股东信息</span></span><br><span class="line">                 <span class="string">&#x27;mainmember&#x27;</span>, <span class="comment">#  主要人员</span></span><br><span class="line">                ]</span><br><span class="line"></span><br><span class="line">    num_partner_id = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    part_keys = [<span class="string">&#x27;股东信息&#x27;</span>, <span class="string">&#x27;主要人员&#x27;</span>]</span><br><span class="line">    part_numbers = [<span class="number">0</span>, <span class="number">0</span>] <span class="comment"># 所述块的位置</span></span><br><span class="line">    dic_partners = <span class="built_in">dict</span>(<span class="built_in">zip</span>(part_keys, part_numbers))</span><br><span class="line"></span><br><span class="line">    csv_names = [<span class="string">&#x27;营业执照信息&#x27;</span>, <span class="string">&#x27;股东信息&#x27;</span>, <span class="string">&#x27;主要人员&#x27;</span>]</span><br><span class="line">    name = name_urls.split(sep)[<span class="number">0</span>] <span class="comment"># 得到公司名字，用来作为存储的文件名</span></span><br><span class="line">    url = name_urls.split(sep)[<span class="number">1</span>] <span class="comment"># 得到公司 url 并转化为基本信息链接</span></span><br><span class="line">    firm_url = url.split(<span class="string">&#x27;firm&#x27;</span>)</span><br><span class="line">    url = firm_url[<span class="number">0</span>] + <span class="string">&#x27;cbase&#x27;</span> + firm_url[<span class="number">1</span>] <span class="comment"># 进入公司基本信息界面</span></span><br><span class="line"></span><br><span class="line">    html = requests.get(url, headers = headers).text</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    list_pd = []</span><br><span class="line">    <span class="keyword">for</span> i, com_id <span class="keyword">in</span> <span class="built_in">enumerate</span>(list_ids):</span><br><span class="line">        html_table = soup.find_all(<span class="string">&#x27;section&#x27;</span>, <span class="built_in">id</span> = com_id)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                html_table = html_table[<span class="number">0</span>]</span><br><span class="line">                pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(html_table.table)))[<span class="number">0</span>] <span class="comment"># 得到公司信息</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(html_table) &gt; <span class="number">0</span>:</span><br><span class="line">                html_table = html_table[<span class="number">0</span>]</span><br><span class="line">                pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(html_table.table)))[<span class="number">0</span>]</span><br><span class="line">                hyper_comps = html_table.find_all(<span class="string">&#x27;a&#x27;</span>, target = <span class="string">&#x27;_blank&#x27;</span>)</span><br><span class="line">                dict_comps = <span class="built_in">dict</span>()</span><br><span class="line">                <span class="keyword">for</span> h <span class="keyword">in</span> hyper_comps:</span><br><span class="line">                    dict_comps[h.text] = h[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line"></span><br><span class="line">                num_partners = html_table.find_all(<span class="string">&#x27;span&#x27;</span>, class_ = <span class="string">&#x27;tbadge&#x27;</span>)</span><br><span class="line">                part_numbers[i-<span class="number">1</span>] = num_partners[num_partner_id[i-<span class="number">1</span>]].text</span><br><span class="line">                dic_partners[part_keys[i-<span class="number">1</span>]] = part_numbers[i-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> dic_partners[part_keys[i-<span class="number">1</span>]] == <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">                    dic_partners[part_keys[i-<span class="number">1</span>]] = pd_comp.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> pd_comp.shape[<span class="number">0</span>] &lt;= <span class="built_in">len</span>(dict_comps.keys()):</span><br><span class="line">                    <span class="keyword">for</span> ix <span class="keyword">in</span> <span class="built_in">range</span>(pd_comp.shape[<span class="number">0</span>], <span class="built_in">len</span>(dict_comps.keys())):</span><br><span class="line">                        pd_comp.loc[ix, <span class="string">&#x27;Name&#x27;</span>] = np.nan</span><br><span class="line"></span><br><span class="line">                    pd_comp[<span class="string">&#x27;Name&#x27;</span>] = dict_comps.keys()</span><br><span class="line">                    pd_comp[<span class="string">&#x27;url&#x27;</span>] = dict_comps.values()</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">len</span>(dict_comps.keys()) != <span class="number">0</span>:</span><br><span class="line">                        pd_comp.loc[<span class="number">0</span>:<span class="built_in">len</span>(dict_comps.keys())-<span class="number">1</span>, <span class="string">&#x27;Name&#x27;</span>] = dict_comps.keys()</span><br><span class="line">                        pd_comp.loc[<span class="number">0</span>:<span class="built_in">len</span>(dict_comps.keys())-<span class="number">1</span>, <span class="string">&#x27;url&#x27;</span>] = dict_comps.values()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dic_partners[part_keys[i-<span class="number">1</span>]] = <span class="literal">None</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        firm_path = pl_dir +  <span class="string">&#x27;/&#x27;</span> + name</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(firm_path):</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            os.makedirs(firm_path)</span><br><span class="line">        firm_dir = firm_path + <span class="string">&#x27;/&#x27;</span> + csv_names[i] + <span class="string">&#x27;.csv&#x27;</span></span><br><span class="line">        pd_comp.to_csv(firm_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">10</span>) <span class="comment"># 休眠 10 s</span></span><br><span class="line">    <span class="keyword">return</span> dic_partners</span><br></pre></td></tr></table></figure>
<h3 id="公司专利信息">2.2.3 公司专利信息</h3>
<p><code>zhuanlilist</code>: 专利信息; <code>zhengshulist</code>:
资质证书; <code>rjzzqlist</code>: 软件著作权; <code>zzqlist</code>:
作品著作权</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_casset_data</span>(<span class="params">name_urls, sep, pl_dir</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;专利信息：zhuanlilist</span></span><br><span class="line"><span class="string">        资质证书：zhengshulist</span></span><br><span class="line"><span class="string">        软件著作权：rjzzqlist</span></span><br><span class="line"><span class="string">        作品著作权：zzqlist</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    list_ids = [<span class="string">&#x27;zhuanlilist&#x27;</span>, <span class="string">&#x27;zhengshulist&#x27;</span>, <span class="string">&#x27;rjzzqlist&#x27;</span>, <span class="string">&#x27;zzqlist&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    cas_keys = [<span class="string">&#x27;专利信息&#x27;</span>, <span class="string">&#x27;资质证书&#x27;</span>, <span class="string">&#x27;软件著作权&#x27;</span>, <span class="string">&#x27;作品著作权&#x27;</span>]</span><br><span class="line">    cas_numbers = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    dic_cassets = <span class="built_in">dict</span>(<span class="built_in">zip</span>(cas_keys, cas_numbers))</span><br><span class="line"></span><br><span class="line">    name = name_urls.split(sep)[<span class="number">0</span>]</span><br><span class="line">    casset_path = pl_dir +  <span class="string">&#x27;/&#x27;</span> + name</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(casset_path):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        os.makedirs(casset_path)</span><br><span class="line"></span><br><span class="line">    url = name_urls.split(sep)[<span class="number">1</span>]</span><br><span class="line">    firm_url = url.split(<span class="string">&#x27;firm&#x27;</span>)</span><br><span class="line">    url = firm_url[<span class="number">0</span>] + <span class="string">&#x27;cassets&#x27;</span> + firm_url[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    html = requests.get(url, headers = headers).text</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    list_pd = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, com_id <span class="keyword">in</span> <span class="built_in">enumerate</span>(list_ids):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            html_table = soup.find_all(<span class="string">&#x27;section&#x27;</span>, <span class="built_in">id</span> = com_id)[<span class="number">0</span>] <span class="comment"># 专利信息</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                txt = html_table.find(<span class="string">&#x27;div&#x27;</span>, class_ = <span class="string">&#x27;app-ntable&#x27;</span>)</span><br><span class="line">                pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(txt)))[<span class="number">0</span>] <span class="comment"># 专利信息</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(html_table.table)))[<span class="number">0</span>] <span class="comment"># 得到公司信息</span></span><br><span class="line"></span><br><span class="line">            casset_dir = casset_path + <span class="string">&#x27;/&#x27;</span> + cas_keys[i] + <span class="string">&#x27;.csv&#x27;</span></span><br><span class="line">            pd_comp.to_csv(casset_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            cas_numbers[i] = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            html_table = soup.find_all(<span class="string">&#x27;section&#x27;</span>, <span class="built_in">id</span> = com_id)[<span class="number">0</span>] <span class="comment"># 专利信息</span></span><br><span class="line">            casset_infos = html_table.find_all(<span class="string">&#x27;div&#x27;</span>, class_ = <span class="string">&#x27;tcaption&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(casset_infos) == <span class="number">0</span>:</span><br><span class="line">                cas_numbers[i] = <span class="literal">None</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">len</span>(casset_infos) == <span class="number">1</span>:</span><br><span class="line">                cassets = casset_infos[<span class="number">0</span>]</span><br><span class="line">                title = BeautifulSoup(<span class="built_in">str</span>(casset_infos[<span class="number">0</span>]), <span class="string">&#x27;lxml&#x27;</span>).find_all(<span class="string">&#x27;h3&#x27;</span>, class_ = <span class="string">&#x27;title&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> title[<span class="number">0</span>].text == cas_keys[i]:</span><br><span class="line">                    cas_numbers[i] = BeautifulSoup(<span class="built_in">str</span>(casset_infos[<span class="number">0</span>]), <span class="string">&#x27;lxml&#x27;</span>).find_all(<span class="string">&#x27;span&#x27;</span>, class_ = <span class="string">&#x27;tbadge&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">len</span>(casset_infos) &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">for</span> cassets <span class="keyword">in</span> casset_infos:</span><br><span class="line">                    cassets = casset_infos[<span class="number">0</span>]</span><br><span class="line">                    title = BeautifulSoup(<span class="built_in">str</span>(casset_infos[<span class="number">0</span>]), <span class="string">&#x27;lxml&#x27;</span>).find_all(<span class="string">&#x27;h3&#x27;</span>, class_ = <span class="string">&#x27;title&#x27;</span>)</span><br><span class="line">                    <span class="keyword">if</span> title[<span class="number">0</span>].text == cas_keys[i]:</span><br><span class="line">                        cas_numbers[i] = BeautifulSoup(<span class="built_in">str</span>(casset_infos[<span class="number">0</span>]), <span class="string">&#x27;lxml&#x27;</span>).find_all(<span class="string">&#x27;span&#x27;</span>, class_ = <span class="string">&#x27;tbadge&#x27;</span>)[<span class="number">0</span>].text</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">&gt;         <span class="keyword">except</span>:</span><br><span class="line">            cas_numbers[i] = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        dic_cassets[cas_keys[i]] = cas_numbers[i]</span><br><span class="line">    time.sleep(<span class="number">20</span>)</span><br><span class="line">    <span class="keyword">return</span> dic_cassets</span><br></pre></td></tr></table></figure>
<h3 id="建立-ip-池">2.2.4 建立 IP 池</h3>
<p>可以通过如下的程序来建立个人的免费代理 <code>IP</code> 池子。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立属于自己的开放代理IP池</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IpPool</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 测试ip是否可用url</span></span><br><span class="line">        self.test_url = <span class="string">&#x27;http://httpbin.org/get&#x27;</span></span><br><span class="line">        <span class="comment"># 获取IP的 目标url</span></span><br><span class="line">        self.url = <span class="string">&#x27;https://www.89ip.cn/index_&#123;&#125;.html&#x27;</span></span><br><span class="line"></span><br><span class="line">        self.headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: UserAgent().random&#125;</span><br><span class="line">        <span class="comment"># 存储可用ip</span></span><br><span class="line">        self.file = <span class="built_in">open</span>(<span class="string">&#x27;ip_pool.txt&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_html</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;获取页面&#x27;&#x27;&#x27;</span></span><br><span class="line">        html = requests.get(url=url, headers=self.headers).text</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_proxy</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;数据处理  获取ip 和端口&#x27;&#x27;&#x27;</span></span><br><span class="line">        html = self.get_html(url=url)</span><br><span class="line">        <span class="comment"># print(html)</span></span><br><span class="line"></span><br><span class="line">        elemt = etree.HTML(html)</span><br><span class="line"></span><br><span class="line">        ips_list = elemt.xpath(<span class="string">&#x27;//table/tbody/tr/td[1]/text()&#x27;</span>)</span><br><span class="line">        ports_list = elemt.xpath(<span class="string">&#x27;//table/tbody/tr/td[2]/text()&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> ip, port <span class="keyword">in</span> <span class="built_in">zip</span>(ips_list, ports_list):</span><br><span class="line">            <span class="comment"># 拼接ip与port</span></span><br><span class="line">            proxy = ip.strip() + <span class="string">&quot;:&quot;</span> + port.strip()</span><br><span class="line">            <span class="comment"># print(proxy)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 175.44.109.195:9999</span></span><br><span class="line">            self.test_proxy(proxy)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_proxy</span>(<span class="params">self, proxy</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;测试代理IP是否可用&#x27;&#x27;&#x27;</span></span><br><span class="line">        proxies = &#123;</span><br><span class="line">            <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(proxy),</span><br><span class="line">            <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;https://&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(proxy),</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 参数类型</span></span><br><span class="line">        <span class="comment"># proxies</span></span><br><span class="line">        <span class="comment"># proxies = &#123;&#x27;协议&#x27;: &#x27;协议://IP:端口号&#x27;&#125;</span></span><br><span class="line">        <span class="comment"># timeout 超时设置 网页响应时间3秒 超过时间会抛出异常</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            resp = requests.get(url=self.test_url, proxies=proxies, headers=self.headers, timeout=<span class="number">3</span>)</span><br><span class="line">           <span class="comment"># 获取 状态码为200</span></span><br><span class="line">            <span class="keyword">if</span> resp.status_code == <span class="number">200</span>:</span><br><span class="line">                print(proxy, <span class="string">&#x27;\033[31m可用\033[0m&#x27;</span>)</span><br><span class="line">                <span class="comment"># 可以的IP 写入文本以便后续使用</span></span><br><span class="line">                self.file.write(proxy)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(proxy, <span class="string">&#x27;不可用&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(proxy, <span class="string">&#x27;不可用&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">crawl</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;执行函数&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 快代理每页url 的区别</span></span><br><span class="line">        <span class="comment"># https://www.kuaidaili.com/free/inha/1/</span></span><br><span class="line">        <span class="comment"># https://www.kuaidaili.com/free/inha/2/</span></span><br><span class="line">        <span class="comment"># .......</span></span><br><span class="line">        <span class="comment"># 提供的免费ip太多</span></span><br><span class="line">        <span class="comment"># 这里只获取前100页提供的免费代理IP测试</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">101</span>):</span><br><span class="line">            <span class="comment"># 拼接完整的url</span></span><br><span class="line">            page_url = self.url.<span class="built_in">format</span>(i)</span><br><span class="line">            <span class="comment"># 注意抓取控制频率</span></span><br><span class="line">            time.sleep(random.randint(<span class="number">1</span>, <span class="number">4</span>))</span><br><span class="line">            self.get_proxy(url=page_url)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 执行完毕关闭文本</span></span><br><span class="line">        self.file.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    ip = IpPool()</span><br><span class="line">    ip.crawl()</span><br></pre></td></tr></table></figure>
<h2 id="start-program">2.3 Start program</h2>
<p>考虑到程序可能会由于异常情况而终止，我们设置了起始点，只需要对
<code>start</code> 的值进行更改，便可在上一次的基础上进行爬取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">start = <span class="number">0</span> <span class="comment"># 接着上次爬取的序号</span></span><br><span class="line"><span class="keyword">for</span> ix, url <span class="keyword">in</span> <span class="built_in">enumerate</span>(pd_firm[<span class="string">&#x27;url&#x27;</span>].values[start:]):</span><br><span class="line">    i = start + ix <span class="comment"># 更改 index 值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置代理 ip</span></span><br><span class="line">    proxies = &#123;</span><br><span class="line">            <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;47.98.179.39:8080&#x27;</span>),</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    html = requests.get(url, headers = headers, proxies = proxies).text</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    name = soup.find_all(<span class="string">&#x27;h1&#x27;</span>, class_ = <span class="string">&#x27;row title jk-tip&#x27;</span>)[<span class="number">0</span>].text.strip() <span class="comment"># 得到企业家的名字</span></span><br><span class="line"></span><br><span class="line">    pl_dir = pl_root_dir + <span class="string">f&#x27;<span class="subst">&#123;i&#125;</span>.<span class="subst">&#123;name&#125;</span>&#x27;</span> <span class="comment"># 以企业家的名字作为文件夹的名字保存信息</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(pl_dir):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        os.makedirs(pl_dir) <span class="comment"># 如果该文件目录不存在，则新建文件夹</span></span><br><span class="line"></span><br><span class="line">    all_comp, post_of_comp = get_pl_data(soup) <span class="comment"># 调用 2.2.1 节的 get_pl_data 函数</span></span><br><span class="line"></span><br><span class="line">    post_of_comp_path = pl_dir + <span class="string">f&#x27;/<span class="subst">&#123;name&#125;</span>-在外任职表.csv&#x27;</span> <span class="comment"># 保存路径</span></span><br><span class="line">    post_of_comp.to_csv(post_of_comp_path, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>) <span class="comment"># 保存在外任职表</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将名字和路径保存至 pd_firm 中</span></span><br><span class="line">    pd_firm.loc[i, <span class="string">&#x27;企业家名字&#x27;</span>] = name  </span><br><span class="line">    pd_firm.loc[i, <span class="string">&#x27;在外任职目录&#x27;</span>] = post_of_comp_path</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 借助apply函数爬取所有企业信息</span></span><br><span class="line">    sep = <span class="string">&#x27;&lt;break&gt;&#x27;</span></span><br><span class="line">    all_comp[<span class="string">&#x27;Name_com&#x27;</span>] = all_comp[<span class="string">&#x27;企业名称&#x27;</span>] + sep + (all_comp[<span class="string">&#x27;url&#x27;</span>])</span><br><span class="line">    all_comp[<span class="string">&#x27;Firm_info&#x27;</span>] = all_comp[<span class="string">&#x27;Name_com&#x27;</span>].apply(<span class="keyword">lambda</span> x: get_firm_data(x, sep, pl_dir))</span><br><span class="line">    all_comp[<span class="string">&#x27;Casset_info&#x27;</span>] = all_comp[<span class="string">&#x27;Name_com&#x27;</span>].apply(<span class="keyword">lambda</span> x: get_casset_data(x, sep, pl_dir))</span><br><span class="line"></span><br><span class="line">    all_comp[<span class="string">&#x27;股东数&#x27;</span>] = all_comp[<span class="string">&#x27;Firm_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="built_in">list</span>(x.keys())[<span class="number">0</span>]])</span><br><span class="line">    all_comp[<span class="string">&#x27;主要人员数&#x27;</span>] = all_comp[<span class="string">&#x27;Firm_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="built_in">list</span>(x.keys())[<span class="number">1</span>]])</span><br><span class="line">    all_comp[<span class="string">&#x27;专利信息数&#x27;</span>] = all_comp[<span class="string">&#x27;Casset_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="built_in">list</span>(x.keys())[<span class="number">0</span>]])</span><br><span class="line">    all_comp[<span class="string">&#x27;资质证书数&#x27;</span>] = all_comp[<span class="string">&#x27;Casset_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="built_in">list</span>(x.keys())[<span class="number">1</span>]])</span><br><span class="line">    all_comp[<span class="string">&#x27;软件著作权数&#x27;</span>] = all_comp[<span class="string">&#x27;Casset_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="built_in">list</span>(x.keys())[<span class="number">2</span>]])</span><br><span class="line">    all_comp[<span class="string">&#x27;作品著作权数&#x27;</span>] = all_comp[<span class="string">&#x27;Casset_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="built_in">list</span>(x.keys())[<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存所有企业信息</span></span><br><span class="line">    all_comp_path = pl_dir + <span class="string">f&#x27;/<span class="subst">&#123;name&#125;</span>-所有企业表.csv&#x27;</span></span><br><span class="line">    pd_firm.loc[i, <span class="string">&#x27;所有企业目录&#x27;</span>] = all_comp_path</span><br><span class="line">    all_comp.drop(<span class="string">&#x27;Name_com&#x27;</span>, axis = <span class="number">1</span>).to_csv(all_comp_path, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">f&#x27;已经爬取<span class="subst">&#123;i&#125;</span>个企业家名单...&#x27;</span>)</span><br><span class="line">    pd_firm.to_csv(<span class="string">&#x27;FirmList.csv&#x27;</span>, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>) <span class="comment"># 每次爬取一个企业家之后进行保存</span></span><br><span class="line">    time.sleep(<span class="number">20</span>) <span class="comment"># 休眠，反爬虫</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<pre><code>已经爬取0个企业家名单...
已经爬取1个企业家名单...
已经爬取2个企业家名单...
已经爬取3个企业家名单...
已经爬取4个企业家名单...
...</code></pre>
<h2 id="data-cleaning">2.4 Data cleaning</h2>
<h3 id="更正公司数量信息">2.4.1 更正公司数量信息</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_current_dir</span>(<span class="params">file_dir, all_comp_path</span>):</span></span><br><span class="line">    cur_dir = file_dir</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> all_comp_path.split(<span class="string">&#x27;/&#x27;</span>)[:-<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">if</span> i == file_dir:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cur_dir = cur_dir + <span class="string">&#x27;/&#x27;</span> + i</span><br><span class="line"></span><br><span class="line">    cur_dir = cur_dir + <span class="string">&#x27;/&#x27;</span>  </span><br><span class="line">    <span class="keyword">return</span> cur_dir</span><br></pre></td></tr></table></figure>
<ul>
<li><p>产看数和表格中的记录数是否相同</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">file_dir = <span class="string">&#x27;D:\\Demo\\work\\XMU\\Data_Collection\\Results&#x27;</span></span><br><span class="line">sep = <span class="string">&#x27;&lt;break&gt;&#x27;</span></span><br><span class="line">error_idx = []</span><br><span class="line"><span class="keyword">for</span> i, relat_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(pd_firm[<span class="string">&#x27;所有企业目录&#x27;</span>].values):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        name = relat_path.split(<span class="string">&#x27;/&#x27;</span>)[<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        error_idx.append(i)</span><br><span class="line">        print(i, relat_path, sep = <span class="string">&#x27;\t | \t&#x27;</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    all_comp_path = file_dir + relat_path</span><br><span class="line">    all_comp = pd.read_csv(all_comp_path, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    cur_dir = get_current_dir(file_dir, all_comp_path)</span><br><span class="line">    sub_dirs = os.listdir(cur_dir)</span><br><span class="line"></span><br><span class="line">    records_len = all_comp.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(sub_dirs) - <span class="number">2</span> != records_len):</span><br><span class="line">        error_idx.append(i)</span><br><span class="line">        print(i, relat_path, sep = <span class="string">&#x27;\t | \t&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<pre><code>  683  |  nan
  747  |  /Results/747.朱俊/朱俊-所有企业表.csv
  868  |  /Results/868.杨大伟/杨大伟-所有企业表.csv
  991  |  /Results/991.刘学高/刘学高-所有企业表.csv</code></pre>
<p>可以发现有4个数据表格中的企业数和爬取的不同。</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd_firm.loc[error_idx, <span class="string">&#x27;url&#x27;</span>].values</span><br></pre></td></tr></table></figure></p>
<p>Results:</p>
<pre><code>  array([&#39;https://www.qcc.com/pl/pr06c1505288f0c2021d813c9e7f332f.html&#39;,
         &#39;https://www.qcc.com/pl/pc73f5a2f9eb17be99d0ef4cf0f0991b.html&#39;,
         &#39;https://www.qcc.com/pl/pa26bc685636ad55bc1a11b5b7d42828.html&#39;,
         &#39;https://www.qcc.com/pl/p12d778b91113fa1209cdb2394bb4a65.html&#39;],
          dtype=object)</code></pre>
<p>进一步查看发现：</p>
<ul>
<li>683 孙月洋 信息缺失</li>
<li>747 朱俊 旗下两家公司信息重叠</li>
<li>868 杨大伟 旗下两家公司信息重叠</li>
<li>991 刘学高 旗下两家公司信息重叠</li>
</ul>
<p>因此对后面三家进行重新爬取</p></li>
<li><p>重新爬取三个企业家的信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">file_dir = <span class="string">&#x27;D:\\Demo\\work\\XMU\\Data_Collection\\Results&#x27;</span></span><br><span class="line">sep = <span class="string">&#x27;&lt;break&gt;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> i, relat_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(pd_firm[<span class="string">&#x27;所有企业目录&#x27;</span>].values[error_idx[<span class="number">2</span>:]]):</span><br><span class="line">    name = relat_path.split(<span class="string">&#x27;/&#x27;</span>)[<span class="number">2</span>]</span><br><span class="line">    all_comp_path = file_dir + relat_path</span><br><span class="line">    all_comp = pd.read_csv(all_comp_path, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    pl_dir = file_dir+<span class="string">&#x27;/Results/&#x27;</span> + name</span><br><span class="line">    <span class="comment"># 爬取所有企业信息</span></span><br><span class="line">    all_comp[<span class="string">&#x27;Name_com&#x27;</span>] = all_comp[<span class="string">&#x27;企业名称&#x27;</span>] + sep + (all_comp[<span class="string">&#x27;url&#x27;</span>])</span><br><span class="line">    cur_dir = get_current_dir(file_dir, all_comp_path)</span><br><span class="line">    sub_dirs = os.listdir(cur_dir)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> j, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(all_comp[<span class="string">&#x27;Name_com&#x27;</span>].values):</span><br><span class="line">        <span class="keyword">if</span> x.split(sep)[<span class="number">0</span>] <span class="keyword">in</span> sub_dirs:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            all_comp.loc[j, <span class="string">&#x27;Firm_info&#x27;</span>] = <span class="built_in">str</span>(get_firm_data(x, sep, pl_dir))</span><br><span class="line">            all_comp.loc[j, <span class="string">&#x27;Casset_info&#x27;</span>] = <span class="built_in">str</span>(get_casset_data(x, sep, pl_dir))</span><br><span class="line"></span><br><span class="line">    all_comp[<span class="string">&#x27;股东数&#x27;</span>] = all_comp[<span class="string">&#x27;Firm_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">eval</span>(x)[<span class="built_in">list</span>(<span class="built_in">eval</span>(x).keys())[<span class="number">0</span>]])</span><br><span class="line">    all_comp[<span class="string">&#x27;主要人员数&#x27;</span>] = all_comp[<span class="string">&#x27;Firm_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">eval</span>(x)[<span class="built_in">list</span>(<span class="built_in">eval</span>(x).keys())[<span class="number">1</span>]])</span><br><span class="line">    all_comp[<span class="string">&#x27;专利信息数&#x27;</span>] = all_comp[<span class="string">&#x27;Casset_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">eval</span>(x)[<span class="built_in">list</span>(<span class="built_in">eval</span>(x).keys())[<span class="number">0</span>]])</span><br><span class="line">    all_comp[<span class="string">&#x27;资质证书数&#x27;</span>] = all_comp[<span class="string">&#x27;Casset_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">eval</span>(x)[<span class="built_in">list</span>(<span class="built_in">eval</span>(x).keys())[<span class="number">1</span>]])</span><br><span class="line">    all_comp[<span class="string">&#x27;软件著作权数&#x27;</span>] = all_comp[<span class="string">&#x27;Casset_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">eval</span>(x)[<span class="built_in">list</span>(<span class="built_in">eval</span>(x).keys())[<span class="number">2</span>]])</span><br><span class="line">    all_comp[<span class="string">&#x27;作品著作权数&#x27;</span>] = all_comp[<span class="string">&#x27;Casset_info&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">eval</span>(x)[<span class="built_in">list</span>(<span class="built_in">eval</span>(x).keys())[<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">    all_comp_path = pl_dir + <span class="string">f&#x27;/<span class="subst">&#123;name&#125;</span>-所有企业表.csv&#x27;</span></span><br><span class="line">    all_comp.drop(<span class="string">&#x27;Name_com&#x27;</span>, axis = <span class="number">1</span>).to_csv(all_comp_path, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="数据规范化">2.4.2 数据规范化</h3>
<p>查看数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd_firm.sample(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
url
</th>
<th>
企业家名字
</th>
<th>
在外任职目录
</th>
<th>
所有企业目录
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
454
</th>
<td>
https://www.qcc.com/pl/pc0bf5ac0db3ac3833528e9...
</td>
<td>
徐诵舜
</td>
<td>
/Results/454.徐诵舜/徐诵舜-在外任职表.csv
</td>
<td>
/Results/454.徐诵舜/徐诵舜-所有企业表.csv
</td>
</tr>
<tr>
<th>
444
</th>
<td>
https://www.qcc.com/pl/pe9f1e4541b32c30c40c4f1...
</td>
<td>
刘键
</td>
<td>
/Results/444.刘键/刘键-在外任职表.csv
</td>
<td>
/Results/444.刘键/刘键-所有企业表.csv
</td>
</tr>
<tr>
<th>
244
</th>
<td>
https://www.qcc.com/pl/p103fd20dc779066987fd98...
</td>
<td>
刘兵
</td>
<td>
/Results/244.刘兵/刘兵-在外任职表.csv
</td>
<td>
/Results/244.刘兵/刘兵-所有企业表.csv
</td>
</tr>
<tr>
<th>
610
</th>
<td>
https://www.qcc.com/pl/p4f922b492f237793f8e240...
</td>
<td>
刘云辉
</td>
<td>
/Results/610.刘云辉/刘云辉-在外任职表.csv
</td>
<td>
/Results/610.刘云辉/刘云辉-所有企业表.csv
</td>
</tr>
<tr>
<th>
1146
</th>
<td>
https://www.qcc.com/pl/p98067b26718f4c7b0b9e69...
</td>
<td>
李骁淳
</td>
<td>
/Results/1146.李骁淳/李骁淳-在外任职表.csv
</td>
<td>
/Results/1146.李骁淳/李骁淳-所有企业表.csv
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ignore_index = pd_firm[pd_firm[<span class="string">&#x27;企业家名字&#x27;</span>].isnull()].index</span><br><span class="line">pd_firm.loc[ignore_index, :].values</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<pre><code>array([], shape=(0, 4), dtype=object)</code></pre>
<p>可以发现，数据爬取基本成功，接下来对文件目录进行标准化，方便迁移分析。</p>
<ul>
<li><p>Modify file path</p>
<p>将文件路径的绝对路劲转换为相对路径。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mode_path</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(path, <span class="built_in">float</span>):</span><br><span class="line">        <span class="keyword">return</span> path</span><br><span class="line">    <span class="keyword">if</span> path.startswith(<span class="string">&#x27;.&#x27;</span>):</span><br><span class="line">        modify_path = path[<span class="number">1</span>:]</span><br><span class="line">    <span class="keyword">elif</span> path.startswith(<span class="string">&#x27;D:\\&#x27;</span>):</span><br><span class="line">        path_split = path.split(<span class="string">&#x27;D:\\Demo\\work\\XMU\\Data_Collection\\Results\\&#x27;</span>)</span><br><span class="line">        modify_path = <span class="string">&#x27;/&#x27;</span> + path_split[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">elif</span> path.startswith(<span class="string">&#x27;/&#x27;</span>):</span><br><span class="line">        modify_path = path</span><br><span class="line">    <span class="keyword">return</span> modify_path</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> swifter <span class="comment"># 加速apply</span></span><br><span class="line">pd_firm[<span class="string">&#x27;在外任职目录&#x27;</span>] = pd_firm[<span class="string">&#x27;在外任职目录&#x27;</span>].swifter.apply(mode_path)</span><br><span class="line">pd_firm[<span class="string">&#x27;所有企业目录&#x27;</span>] = pd_firm[<span class="string">&#x27;所有企业目录&#x27;</span>].swifter.apply(mode_path)</span><br></pre></td></tr></table></figure></li>
<li><p>Recheck</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">file_dir = <span class="string">&#x27;D:\\Demo\\work\\XMU\\Data_Collection\\Results&#x27;</span></span><br><span class="line">sep = <span class="string">&#x27;&lt;break&gt;&#x27;</span></span><br><span class="line">error_idx = []</span><br><span class="line"><span class="keyword">for</span> i, relat_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(pd_firm[<span class="string">&#x27;所有企业目录&#x27;</span>].values):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        name = relat_path.split(<span class="string">&#x27;/&#x27;</span>)[<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        error_idx.append(i)</span><br><span class="line">        print(i, relat_path, sep = <span class="string">&#x27;\t | \t&#x27;</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    all_comp_path = file_dir + relat_path</span><br><span class="line">    all_comp = pd.read_csv(all_comp_path, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    cur_dir = get_current_dir(file_dir, all_comp_path)</span><br><span class="line">    sub_dirs = os.listdir(cur_dir)</span><br><span class="line"></span><br><span class="line">    records_len = all_comp.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(sub_dirs) - <span class="number">2</span> != records_len): <span class="comment"># 文件夹中还包含所有企业表和在外任职表，所以 -2</span></span><br><span class="line">        error_idx.append(i)</span><br><span class="line">        print(i, relat_path, sep = <span class="string">&#x27;\t | \t&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<pre><code>683  |  nan</code></pre>
<p>至此处理完毕，公司数和表格中的记录数能对上。其中683为失效链接，后续直接去掉:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd_firm = pd_firm.drop(<span class="number">683</span>, axis = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="更新专利信息">2.4.3 更新专利信息</h3>
<h4 id="更新所有数量信息">更新所有数量信息</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">file_dir = <span class="string">&#x27;D:\\Demo\\work\\XMU\\Data_Collection\\Results&#x27;</span></span><br><span class="line">sep = <span class="string">&#x27;&lt;break&gt;&#x27;</span></span><br><span class="line"></span><br><span class="line">pd_all_firm = pd_firm.copy()</span><br><span class="line">pd_pl_comp = pd.DataFrame()</span><br><span class="line"></span><br><span class="line">columns = [<span class="string">&#x27;企业表&#x27;</span>, <span class="string">&#x27;公司地址&#x27;</span>, <span class="string">&#x27;公司url&#x27;</span>, <span class="string">&#x27;股东信息&#x27;</span>,  <span class="string">&#x27;NUM_股东信息&#x27;</span>, <span class="string">&#x27;主要人员&#x27;</span>, <span class="string">&#x27;NUM_主要人员&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;专利信息&#x27;</span>, <span class="string">&#x27;NUM_专利信息&#x27;</span>, <span class="string">&#x27;资质证书&#x27;</span>, <span class="string">&#x27;NUM_资质证书&#x27;</span>, <span class="string">&#x27;软件著作权&#x27;</span>, <span class="string">&#x27;NUM_软件著作权&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;股东信息&#x27;</span>, <span class="string">&#x27;NUM_股东信息&#x27;</span>]</span><br><span class="line">pd_record = pd.DataFrame(columns = columns)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, relat_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(pd_firm[<span class="string">&#x27;所有企业目录&#x27;</span>].values):</span><br><span class="line">    name = relat_path.split(<span class="string">&#x27;/&#x27;</span>)[<span class="number">2</span>]</span><br><span class="line">    all_comp_path = file_dir + relat_path</span><br><span class="line">    all_comp = pd.read_csv(all_comp_path, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line">    all_comp[<span class="string">&#x27;企业家名字&#x27;</span>] = [name]*all_comp.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    pl_dir = file_dir+<span class="string">&#x27;/Results/&#x27;</span> + name</span><br><span class="line">    <span class="comment"># 爬取所有企业信息</span></span><br><span class="line">    all_comp[<span class="string">&#x27;Name_com&#x27;</span>] = all_comp[<span class="string">&#x27;企业名称&#x27;</span>] + sep + (all_comp[<span class="string">&#x27;url&#x27;</span>])</span><br><span class="line">    cur_dir = get_current_dir(file_dir, all_comp_path)</span><br><span class="line">    sub_dirs = os.listdir(cur_dir)</span><br><span class="line">    <span class="keyword">for</span> j, nam <span class="keyword">in</span> <span class="built_in">enumerate</span>(all_comp[<span class="string">&#x27;企业名称&#x27;</span>].values):</span><br><span class="line">        url = all_comp.loc[j, <span class="string">&#x27;url&#x27;</span>]</span><br><span class="line">        comp_dir = cur_dir + nam + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">        all_comp.loc[j, <span class="string">&#x27;公司目录&#x27;</span>] = comp_dir</span><br><span class="line">        file_list = os.listdir(comp_dir)</span><br><span class="line">        cas_keys = [<span class="string">&#x27;股东信息&#x27;</span>, <span class="string">&#x27;主要人员&#x27;</span>, <span class="string">&#x27;专利信息&#x27;</span>, <span class="string">&#x27;资质证书&#x27;</span>, <span class="string">&#x27;软件著作权&#x27;</span>, <span class="string">&#x27;作品著作权&#x27;</span>]</span><br><span class="line">        <span class="keyword">for</span> k, cas <span class="keyword">in</span> <span class="built_in">enumerate</span>(cas_keys):</span><br><span class="line">            file_path = cas+<span class="string">&#x27;.csv&#x27;</span></span><br><span class="line">            pd_cols = [<span class="string">&#x27;股东数&#x27;</span>, <span class="string">&#x27;主要人员数&#x27;</span>, <span class="string">&#x27;专利信息数&#x27;</span>, <span class="string">&#x27;资质证书数&#x27;</span>, <span class="string">&#x27;软件著作权数&#x27;</span>,<span class="string">&#x27;作品著作权数&#x27;</span>]</span><br><span class="line">            <span class="keyword">if</span> file_path <span class="keyword">not</span> <span class="keyword">in</span> file_list:</span><br><span class="line">                all_comp.loc[j, pd_cols[k]] = np.nan</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cas_file_dir = comp_dir+file_path</span><br><span class="line">                casset = pd.read_csv(cas_file_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line">                number = casset.shape[<span class="number">0</span>]</span><br><span class="line">                all_comp.loc[j, pd_cols[k]] = number</span><br><span class="line">    save_col = [<span class="string">&#x27;序号&#x27;</span>, <span class="string">&#x27;企业家名字&#x27;</span>, <span class="string">&#x27;企业名称&#x27;</span>, <span class="string">&#x27;角色&#x27;</span>, <span class="string">&#x27;注册资本&#x27;</span>, <span class="string">&#x27;成立日期&#x27;</span>, <span class="string">&#x27;地区&#x27;</span>, <span class="string">&#x27;状态&#x27;</span>, <span class="string">&#x27;url&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;股东数&#x27;</span>, <span class="string">&#x27;主要人员数&#x27;</span>, <span class="string">&#x27;专利信息数&#x27;</span>, <span class="string">&#x27;资质证书数&#x27;</span>, <span class="string">&#x27;软件著作权数&#x27;</span>, <span class="string">&#x27;作品著作权数&#x27;</span>]</span><br><span class="line">    mod_path = all_comp_path.split(<span class="string">&#x27;.csv&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;_mod.csv&#x27;</span></span><br><span class="line">    all_comp[save_col].to_csv(mod_path, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line">    pd_pl_comp = pd.concat([pd_pl_comp, all_comp], axis = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Modify path</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mod_name</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;.&#x27;</span> <span class="keyword">in</span> x:</span><br><span class="line">        name = x.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        name = x</span><br><span class="line">    <span class="keyword">return</span> name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mode_path</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(path, <span class="built_in">float</span>):</span><br><span class="line">        <span class="keyword">return</span> path</span><br><span class="line">    <span class="keyword">if</span> path.startswith(<span class="string">&#x27;.&#x27;</span>):</span><br><span class="line">        modify_path = path[<span class="number">1</span>:]</span><br><span class="line">    <span class="keyword">elif</span> path.startswith(<span class="string">&#x27;D:&#x27;</span>):</span><br><span class="line">        path_split = path.split(<span class="string">&#x27;D:\Demo\work\XMU\Data_Collection\Results/&#x27;</span>)</span><br><span class="line">        modify_path = <span class="string">&#x27;/&#x27;</span> + path_split[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">elif</span> path.startswith(<span class="string">&#x27;/&#x27;</span>):</span><br><span class="line">        modify_path = path</span><br><span class="line">    <span class="keyword">return</span> modify_path</span><br><span class="line"></span><br><span class="line">pd_pl_comp[<span class="string">&#x27;企业家名字&#x27;</span>] = pd_pl_comp[<span class="string">&#x27;企业家名字&#x27;</span>].apply(mod_name)</span><br><span class="line">pd_pl_comp[<span class="string">&#x27;公司目录&#x27;</span>] = pd_pl_comp[<span class="string">&#x27;公司目录&#x27;</span>].swifter.apply(mod_name)</span><br><span class="line">pd_pl_comp.rename(columns=&#123;<span class="string">&#x27;url&#x27;</span>:<span class="string">&#x27;Com_url&#x27;</span>,<span class="string">&#x27;b&#x27;</span>:<span class="string">&#x27;B&#x27;</span>&#125;, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>Merge</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd_all_firm = pd_firm.copy()</span><br><span class="line">pd_all_firm = pd.merge(pd_all_firm, pd_pl_comp, on = <span class="string">&#x27;企业家名字&#x27;</span>, how = <span class="string">&#x27;outer&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="核对数量">核对数量</h4>
<ul>
<li><p>产看所有信息指标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd_all_firm.columns</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>Index([&#39;url&#39;, &#39;企业家名字&#39;, &#39;在外任职目录&#39;, &#39;所有企业目录&#39;, &#39;序号&#39;, &#39;企业名称&#39;, &#39;角色&#39;, &#39;注册资本&#39;, &#39;成立日期&#39;,
       &#39;地区&#39;, &#39;状态&#39;, &#39;Com_url&#39;, &#39;Firm_info&#39;, &#39;Casset_info&#39;, &#39;股东数&#39;, &#39;主要人员数&#39;,
       &#39;专利信息数&#39;, &#39;资质证书数&#39;, &#39;软件著作权数&#39;, &#39;作品著作权数&#39;, &#39;Name_com&#39;, &#39;公司目录&#39;, &#39;Name&#39;],
       dtype=&#39;object&#39;)</code></pre></li>
<li><p>Check</p>
<p>由于静态爬取仅能爬取页面中加载的第一页信息，共十条，因此对所爬取的信息数量进行核对，对所爬取的
<code>csv</code> 表格中信息数为 10 的进行动态爬取，补充信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">check_names = [ <span class="string">&#x27;股东数&#x27;</span>, <span class="string">&#x27;主要人员数&#x27;</span>, <span class="string">&#x27;专利信息数&#x27;</span>, <span class="string">&#x27;资质证书数&#x27;</span>, <span class="string">&#x27;软件著作权数&#x27;</span>, <span class="string">&#x27;作品著作权数&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> check_names:</span><br><span class="line">    col_shape = pd_all_firm[pd_all_firm[col]&gt;=<span class="number">10</span>].shape</span><br><span class="line">    print(col, col_shape, sep = <span class="string">&#x27; | &#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> check_names:</span><br><span class="line">    col_shape = pd_all_firm[pd_all_firm[col]&gt;<span class="number">10</span>].shape</span><br><span class="line">    print(col, col_shape, sep = <span class="string">&#x27; | &#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<pre><code>股东数 | (658, 23)
主要人员数 | (225, 23)
专利信息数 | (1009, 23)
资质证书数 | (411, 23)
软件著作权数 | (576, 23)
作品著作权数 | (15, 23)
股东数 | (585, 23)
主要人员数 | (162, 23)
专利信息数 | (0, 23)
资质证书数 | (0, 23)
软件著作权数 | (0, 23)
作品著作权数 | (0, 23)</code></pre>
<p>可以发现资产信息的四个指标的数量基本都是10个，这些都需要进行重新爬取。接下来需要适用动态爬虫来对这些信息进行补充。</p></li>
<li><p>Save</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd_all_firm.to_csv(<span class="string">&#x27;./All_pd_firm.csv&#x27;</span>, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="dynamic-crawler">3. Dynamic crawler</h1>
<h2 id="problem-description">3.1 Problem description</h2>
<p>尽管上述静态爬虫能爬取绝大多数的信息，但还是存在诸多问题，如：所有企业表中：以
高<em>波 为例，北京 </em>***
科技有限责任公司为例，所有企业表中的专利数等信息存在错误。<所有企业表>
中的专利信息数和资质证书数都错了。</p>
<p>经过分析，发现造成这些原因是因为静态爬虫不能得到页面内动态加载的信息（指同一个
url 中点击按钮后会加载不同的信息），因此在本节中，我们考虑用
<code>selenium</code>
来进行动态爬取资产信息，补充第二节中静态爬虫未能完整爬取的信息。</p>
<h2 id="configuration-1">3.2 Configuration</h2>
<p>由于本人使用的是 <code>Google Chrome</code> 浏览器，其版本是
<code>92.0.4515.107</code>。因此在本节中，我们借助 <code>selenium</code>
库中的 <code>webdriver</code>
驱动进行动态爬取，使用该工具需要下载相应的驱动，其各版本的驱动可以通过
<a target="_blank" rel="noopener" href="https://mirrors.huaweicloud.com/chromedriver/">华为镜像</a>
进行下载，需要注意的是要下载自己浏览器对应的驱动版本，同时将该文件所保存的地址传给
<code>executable_path</code> 参数，如本人的存储地址为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files (x86)\Google\Chrome\Application\chromedriver.exe</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Import modules</p>
<p>同上，若未安装对应的库，可使用 <code>pip install module_name</code>
进行安装。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time  <span class="comment"># 提供延时功能</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver  <span class="comment"># 浏览器操作库</span></span><br></pre></td></tr></table></figure></li>
<li><p>Launch driver</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">option = webdriver.ChromeOptions()</span><br><span class="line">option.add_argument(</span><br><span class="line">    <span class="string">&#x27;--user-agent=&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36&quot;&#x27;</span>)</span><br><span class="line">driver = webdriver.Chrome(</span><br><span class="line">      options=option, executable_path=<span class="string">&#x27;C:\Program Files (x86)\Google\Chrome\Application\chromedriver.exe&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开登录页面</span></span><br><span class="line">driver.get(<span class="string">&#x27;https://www.qcc.com/&#x27;</span>)</span><br><span class="line">time.sleep(<span class="number">20</span>)  <span class="comment"># 等待20s，完成手动登录操作</span></span><br><span class="line">driver.refresh()</span><br></pre></td></tr></table></figure>
<p>可以注意到在这里我们休眠了 20 s，这个过程是为了手动用企查查
<code>APP</code> 进行扫码登录，虽然也可以传入 <code>cookie</code>
进行登录，不过本人在传入 <code>cookie</code>
过程中并未成功，因此使用该简便方式进行登录。</p></li>
<li><p>Load data</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pl_root_dir = <span class="string">r&#x27;D:\Demo\work\XMU\Data_Collection\Results/&#x27;</span></span><br><span class="line"></span><br><span class="line">pd_all_firm = pd.read_csv(<span class="string">&#x27;./All_pd_firm.csv&#x27;</span>, encoding=<span class="string">&#x27;ansi&#x27;</span>, index_col = <span class="number">0</span>)</span><br><span class="line">pd_firm = pd.read_csv(<span class="string">&#x27;FirmList.csv&#x27;</span>, encoding=<span class="string">&#x27;ansi&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="data-complementary">3.3 Data complementary</h2>
<p>对数量不对的进行再次爬取，先获取数量不对的条目的index</p>
<ul>
<li><p>得到需要重新爬取的数据索引</p>
<p>得到需要重新爬取的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">check_names = [<span class="string">&#x27;股东数&#x27;</span>, <span class="string">&#x27;主要人员数&#x27;</span>, <span class="string">&#x27;专利信息数&#x27;</span>, <span class="string">&#x27;资质证书数&#x27;</span>, <span class="string">&#x27;软件著作权数&#x27;</span>, <span class="string">&#x27;作品著作权数&#x27;</span>]</span><br><span class="line"></span><br><span class="line">recheck_index = pd.Index([])</span><br><span class="line">recheck_type_index = []</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> check_names[<span class="number">2</span>:]:</span><br><span class="line">    check_idx = pd_all_firm[pd_all_firm[col] &gt;= <span class="number">10</span>].index</span><br><span class="line">    recheck_index = recheck_index.append(check_idx)</span><br><span class="line">    recheck_type_index.append(check_idx)</span><br><span class="line"></span><br><span class="line">recheck_index = <span class="built_in">list</span>(<span class="built_in">set</span>(recheck_index))</span><br></pre></td></tr></table></figure></li>
<li><p>判断当前节点是否存在</p>
<p>由于有些信息节点并不是所有企业都有（如知识产权），因此我们需要判断该节点是否存在，以防程序报错而终止运行。</p>
<p>我们可以通过 <code>type_input</code> 来控制传入的节点的类型，如
<code>xpath</code>, <code>tag</code> 等，也可以自行扩充。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">NodeExists</span>(<span class="params">drievr, input_code, type_input</span>):</span></span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">      <span class="keyword">if</span> type_input == <span class="string">&#x27;xpath&#x27;</span>:</span><br><span class="line">          driver.find_element_by_xpath(input_code)</span><br><span class="line">      <span class="keyword">elif</span> type_input == <span class="string">&#x27;tag&#x27;</span>:</span><br><span class="line">          driver.find_element_by_tag_name(input_code)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">   <span class="keyword">except</span>:</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure></li>
<li><p>判断四个信息中哪些信息需要重新爬取</p>
<p>通过筛选之后，我们发现在外任职表和所有企业表的信息基本准确，因此，主要针对专利信息、资质证书、软件著作权和作品著作权进行更新。</p>
<p>此外，我们需要判断四个节点中有哪些节点是需要更新的，因为并不是所有的节点都需要更新，全部更新的话颇为耗时，且有报错的可能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_idx</span>(<span class="params">pd_data, idx, recheck_cols</span>):</span></span><br><span class="line">    ret_idx = []</span><br><span class="line">    <span class="keyword">for</span> i, col <span class="keyword">in</span> <span class="built_in">enumerate</span>(recheck_cols):</span><br><span class="line">        <span class="keyword">if</span> pd_data.loc[idx, col] &gt;= <span class="number">10</span>:</span><br><span class="line">            ret_idx.append(i)</span><br><span class="line">    <span class="keyword">return</span> ret_idx</span><br></pre></td></tr></table></figure></li>
<li><p>开始更新数据</p>
<p>得到需要更新的数据的索引 <code>recheck_index</code>
之后，我们对这些数据进行遍历和爬取。由于不同节点的 <code>xpath</code>
地址不同，我们使用 <code>if ... else ...</code>
语句进行区分对待。最后将更新好的数据保存至
<code>All_pd_firm-mod.csv</code> 文件中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line">start_pos = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> idx, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(recheck_index[start_pos:]):</span><br><span class="line">  name = pd_all_firm.loc[i, <span class="string">&#x27;企业名称&#x27;</span>]</span><br><span class="line">  casset_path = pd_all_firm.loc[i, <span class="string">&#x27;公司目录&#x27;</span>]</span><br><span class="line">  url = pd_all_firm.loc[i, <span class="string">&#x27;Com_url&#x27;</span>]</span><br><span class="line">  firm_url = url.split(<span class="string">&#x27;firm&#x27;</span>)</span><br><span class="line">  url = firm_url[<span class="number">0</span>] + <span class="string">&#x27;cassets&#x27;</span> + firm_url[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  <span class="comment"># requests.get(url=url, cookies=cookies, headers=headers, timeout=5).text</span></span><br><span class="line"></span><br><span class="line">  driver.get(url)</span><br><span class="line">  time.sleep(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">  <span class="string">&#x27;&#x27;&#x27;专利信息：zhuanlilist</span></span><br><span class="line"><span class="string">      资质证书：zhengshulist</span></span><br><span class="line"><span class="string">      软件著作权：rjzzqlist</span></span><br><span class="line"><span class="string">      作品著作权：zzqlist</span></span><br><span class="line"><span class="string">  &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">  list_ids = [<span class="string">&#x27;zhuanlilist&#x27;</span>, <span class="string">&#x27;zhengshulist&#x27;</span>, <span class="string">&#x27;rjzzqlist&#x27;</span>, <span class="string">&#x27;zzqlist&#x27;</span>]</span><br><span class="line">  num_cassets_id = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">  cas_keys = [<span class="string">&#x27;专利信息&#x27;</span>, <span class="string">&#x27;资质证书&#x27;</span>, <span class="string">&#x27;软件著作权&#x27;</span>, <span class="string">&#x27;作品著作权&#x27;</span>] <span class="comment"># csv表名称</span></span><br><span class="line">  recheck_cols = [<span class="string">&#x27;专利信息数&#x27;</span>, <span class="string">&#x27;资质证书数&#x27;</span>, <span class="string">&#x27;软件著作权数&#x27;</span>, <span class="string">&#x27;作品著作权数&#x27;</span>] <span class="comment"># 数量</span></span><br><span class="line">  cas_numbers = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">  dic_cassets = <span class="built_in">dict</span>(<span class="built_in">zip</span>(cas_keys, cas_numbers))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># if os.path.exists(pl_root_dir+casset_path):</span></span><br><span class="line">  <span class="comment">#     pass</span></span><br><span class="line">  <span class="comment"># else:</span></span><br><span class="line">  <span class="comment">#     os.makedirs(casset_path)</span></span><br><span class="line"></span><br><span class="line">  recheck_col_idx = check_idx(pd_all_firm, i, recheck_cols)</span><br><span class="line">  <span class="comment"># pd_all_firm.loc[i, recheck_cols]</span></span><br><span class="line">  <span class="keyword">for</span> j <span class="keyword">in</span> recheck_col_idx:</span><br><span class="line">      com_id = list_ids[j]</span><br><span class="line">      casset_dir = pl_root_dir + casset_path + cas_keys[j] + <span class="string">&#x27;.csv&#x27;</span></span><br><span class="line">      <span class="comment"># try:</span></span><br><span class="line">      html_table = driver.find_element_by_id(com_id).get_attribute(<span class="string">&quot;innerHTML&quot;</span>)   <span class="comment"># 专利信息</span></span><br><span class="line">      soup = BeautifulSoup(html_table, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">      <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">          <span class="comment"># 专利信息</span></span><br><span class="line">          txt = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;app-ntable&#x27;</span>)</span><br><span class="line">          pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(txt)))[<span class="number">0</span>]  <span class="comment"># 专利信息</span></span><br><span class="line"></span><br><span class="line">          number_xpath = <span class="string">&#x27;//*[@id=&quot;zhuanlilist&quot;]/div[4]/nav/ul&#x27;</span></span><br><span class="line">          <span class="keyword">if</span> NodeExists(driver, number_xpath, <span class="string">&#x27;xpath&#x27;</span>):                    </span><br><span class="line">              <span class="keyword">while</span> <span class="number">1</span> :</span><br><span class="line">                  <span class="keyword">try</span>:</span><br><span class="line">                      list_str_list = driver.find_element_by_xpath(number_xpath).text</span><br><span class="line">                      bt_text = list_str_list.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                      bt_next_index = bt_text.index(<span class="string">&#x27;&gt;&#x27;</span>) + <span class="number">1</span></span><br><span class="line">                  <span class="keyword">except</span>:</span><br><span class="line">                      <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                  bt_xpath = <span class="string">f&#x27;//*[@id=&quot;zhuanlilist&quot;]/div[4]/nav/ul/li[<span class="subst">&#123;bt_next_index&#125;</span>]&#x27;</span></span><br><span class="line">                  driver.find_element_by_xpath(bt_xpath).click()</span><br><span class="line">                  time.sleep(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">                  html_table = driver.find_element_by_id(com_id).get_attribute(<span class="string">&quot;innerHTML&quot;</span>)   <span class="comment"># 专利信息</span></span><br><span class="line">                  soup = BeautifulSoup(html_table, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">                  tmp_txt = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;app-ntable&#x27;</span>)</span><br><span class="line">                  tmp_pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(tmp_txt)))[<span class="number">0</span>]  <span class="comment"># 专利信息</span></span><br><span class="line">                  pd_comp = pd.concat([pd_comp, tmp_pd_comp], axis = <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">elif</span> j == <span class="number">1</span>:</span><br><span class="line">          pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(html_table)))[<span class="number">0</span>]  <span class="comment"># 得到公司信息</span></span><br><span class="line"></span><br><span class="line">          casset_driver = driver.find_element_by_id(com_id)</span><br><span class="line">          table_cas = casset_driver.find_element_by_class_name(<span class="string">&#x27;app-ntable&#x27;</span>)</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> NodeExists(table_cas, <span class="string">&#x27;nav&#x27;</span>, <span class="string">&#x27;tag&#x27;</span>):</span><br><span class="line">              <span class="keyword">while</span> <span class="number">1</span> :</span><br><span class="line">                  <span class="keyword">try</span>:</span><br><span class="line">                      number_xpath = <span class="string">&#x27;//*[@id=&quot;zhengshulist&quot;]/div[4]/div[2]/nav/ul&#x27;</span></span><br><span class="line">                      <span class="comment"># list_str_list = table_cas.find_element_by_xpath(number_xpath).text</span></span><br><span class="line">                      list_str_list = table_cas.find_element_by_tag_name(<span class="string">&#x27;nav&#x27;</span>).text</span><br><span class="line">                      bt_text = list_str_list.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                      bt_next_index = bt_text.index(<span class="string">&#x27;&gt;&#x27;</span>) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                  <span class="keyword">except</span>:</span><br><span class="line">                      <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                  bt_xpath = <span class="string">f&#x27;//*[@id=&quot;zhengshulist&quot;]/div[4]/div[2]/nav/ul/li[<span class="subst">&#123;bt_next_index&#125;</span>]&#x27;</span></span><br><span class="line">                  table_cas.find_element_by_xpath(bt_xpath).click()</span><br><span class="line">                  time.sleep(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">                  html_table = driver.find_element_by_id(com_id).get_attribute(<span class="string">&quot;innerHTML&quot;</span>)   <span class="comment"># 专利信息</span></span><br><span class="line">                  soup = BeautifulSoup(html_table, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">                  tmp_txt = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;app-ntable&#x27;</span>)</span><br><span class="line">                  tmp_pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(tmp_txt)))[<span class="number">0</span>]  <span class="comment"># 专利信息</span></span><br><span class="line">                  pd_comp = pd.concat([pd_comp, tmp_pd_comp], axis = <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">elif</span> j == <span class="number">2</span>:</span><br><span class="line">          pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(html_table)))[<span class="number">0</span>]  <span class="comment"># 得到公司信息</span></span><br><span class="line"></span><br><span class="line">          casset_driver = driver.find_element_by_id(com_id)</span><br><span class="line">          table_cas = casset_driver.find_element_by_class_name(<span class="string">&#x27;app-ntable&#x27;</span>)</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> NodeExists(table_cas, <span class="string">&#x27;nav&#x27;</span>, <span class="string">&#x27;tag&#x27;</span>):</span><br><span class="line">              <span class="keyword">while</span> <span class="number">1</span> :</span><br><span class="line">                  <span class="keyword">try</span>:</span><br><span class="line">                      number_xpath = <span class="string">&#x27;//*[@id=&quot;rjzzqlist&quot;]/div[2]/nav/ul&#x27;</span></span><br><span class="line">                      <span class="comment"># list_str_list = table_cas.find_element_by_xpath(number_xpath).text</span></span><br><span class="line">                      list_str_list = table_cas.find_element_by_tag_name(<span class="string">&#x27;nav&#x27;</span>).text</span><br><span class="line">                      bt_text = list_str_list.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                      bt_next_index = bt_text.index(<span class="string">&#x27;&gt;&#x27;</span>) + <span class="number">1</span></span><br><span class="line">                  <span class="keyword">except</span>:</span><br><span class="line">                      <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                  bt_xpath = <span class="string">f&#x27;//*[@id=&quot;rjzzqlist&quot;]/div[2]/nav/ul/li[<span class="subst">&#123;bt_next_index&#125;</span>]&#x27;</span></span><br><span class="line">                  table_cas.find_element_by_xpath(bt_xpath).click()</span><br><span class="line">                  time.sleep(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">                  html_table = driver.find_element_by_id(com_id).get_attribute(<span class="string">&quot;innerHTML&quot;</span>)   <span class="comment"># 专利信息</span></span><br><span class="line">                  soup = BeautifulSoup(html_table, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">                  tmp_txt = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;app-ntable&#x27;</span>)</span><br><span class="line">                  tmp_pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(tmp_txt)))[<span class="number">0</span>]  <span class="comment"># 专利信息</span></span><br><span class="line">                  pd_comp = pd.concat([pd_comp, tmp_pd_comp], axis = <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">elif</span> j == <span class="number">3</span>:</span><br><span class="line">          pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(html_table)))[<span class="number">0</span>]  <span class="comment"># 得到公司信息</span></span><br><span class="line"></span><br><span class="line">          casset_driver = driver.find_element_by_id(com_id)</span><br><span class="line">          table_cas = casset_driver.find_element_by_class_name(<span class="string">&#x27;app-ntable&#x27;</span>)</span><br><span class="line">          <span class="keyword">if</span> NodeExists(table_cas, <span class="string">&#x27;nav&#x27;</span>, <span class="string">&#x27;tag&#x27;</span>):</span><br><span class="line">              <span class="keyword">while</span> <span class="number">1</span> :</span><br><span class="line">                  <span class="keyword">try</span>:</span><br><span class="line">                      number_xpath = <span class="string">&#x27;//*[@id=&quot;zzqlist&quot;]/div[2]/nav/ul&#x27;</span></span><br><span class="line">                      <span class="comment"># list_str_list = table_cas.find_element_by_xpath(number_xpath).text</span></span><br><span class="line">                      list_str_list = table_cas.find_element_by_tag_name(<span class="string">&#x27;nav&#x27;</span>).text</span><br><span class="line">                      bt_text = list_str_list.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                      bt_next_index = bt_text.index(<span class="string">&#x27;&gt;&#x27;</span>) + <span class="number">1</span></span><br><span class="line">                  <span class="keyword">except</span>:</span><br><span class="line">                      <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                  bt_xpath = <span class="string">f&#x27;//*[@id=&quot;zzqlist&quot;]/div[2]/nav/ul/li[<span class="subst">&#123;bt_next_index&#125;</span>]&#x27;</span></span><br><span class="line">                  table_cas.find_element_by_xpath(bt_xpath).click()</span><br><span class="line">                  time.sleep(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">                  html_table = driver.find_element_by_id(com_id).get_attribute(<span class="string">&quot;innerHTML&quot;</span>)   <span class="comment"># 专利信息</span></span><br><span class="line">                  soup = BeautifulSoup(html_table, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">                  tmp_txt = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;app-ntable&#x27;</span>)</span><br><span class="line">                  tmp_pd_comp = pd.read_html(StringIO(<span class="built_in">str</span>(tmp_txt)))[<span class="number">0</span>]  <span class="comment"># 专利信息</span></span><br><span class="line">                  pd_comp = pd.concat([pd_comp, tmp_pd_comp], axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">      pd_all_firm.loc[i, recheck_cols[j]] = pd_comp.shape[<span class="number">0</span>]</span><br><span class="line">      pd_comp.to_csv(casset_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>, errors = <span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line">      time.sleep(<span class="number">2</span>)</span><br><span class="line">  print(<span class="string">f&#x27;第<span class="subst">&#123;idx+start_pos&#125;</span>个条目已经重新整理完毕！&#x27;</span>)</span><br><span class="line"></span><br><span class="line">pd_all_firm.to_csv(<span class="string">&#x27;./All_pd_firm-mod.csv&#x27;</span>, encoding=<span class="string">&#x27;ansi&#x27;</span>, errors = <span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">driver.close()</span><br></pre></td></tr></table></figure></li>
</ul>
<p>至此，数量信息更新完毕，由于 <code>selenium</code>
是通过动态爬取，其结果很大程度上具有可信性。</p>
<h1 id="data-preprocess">4 Data Preprocess</h1>
<h2 id="job-description-1">4.1 Job description</h2>
<p>经过动态爬取之后，为了方便做研究，甲方认为数据仍然存在些许需要改善的地方，因此本节的主要目的是对得到的数据进行数据预处理。</p>
<p>甲方提出需求如下：</p>
<ol type="1">
<li><p>所有企业表和在外任职表：仅需要企业的url，但是把法定代表人的url也给搞下来了，造成表格较乱（处理方法两种，要不把法人url给删除了，要不把法人url给对齐，推荐后者）。如下图所示：</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCU39.md.png' style="zoom:80%;" /></p>
<center>
<p>Fig. 7 在外任职表样例</p>
</center></li>
<li><p>营业执照信息表：企业名称、经营范围、英文名以及注册地址存在重复；法定代表人处存在重复的首字（注：该问题存在的原因是因为我们直接借助
<code>pd.read_html</code>
进行页面表格的提取，而这种方式对于合并单元的处理并不友好。）。如下图所示：</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCacR.png' style="zoom:80%;" /></p>
<center>
<p>Fig. 8 营业执照信息样例</p>
</center>
<p>如果可行，把表头方第一行，内容方第二行吧（此外，营业执照信息表里中D2单元格-有关企业名称拿里有多余”复制”两个字，需要进行剔除）。</p></li>
<li><p>股东信息表和主要人员表：B列和C列重复，把C列中”关联?加企业”单独分出一列。</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCdj1.png' style="zoom:80%;" /></p>
<center>
<p>Fig. 9 营业执照信息样例</p>
</center></li>
<li><p>所有企业表中，需要载爬取一个数据：当企业状态为注销或吊销时，需要再爬取注销的时间，如下图所示。</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bCN9J.png' style="zoom:80%;" /></p>
<center>
<p>Fig. 10 注销时间样例</p>
</center></li>
</ol>
<h2 id="preprocess">4.2 Preprocess</h2>
<p>在本节中，我们针对甲方提出的问题对所得到的数据进行一个个处理。</p>
<h3 id="task-1">4.2.1 Task 1</h3>
<p>首先我们定义一些函数，方便处理。</p>
<ul>
<li><p>得到精确的高管名字</p>
<p>通过 Fig.7
我们可以发现，直接从网页上爬取的企业（家）名称并不一定精确，所以需要对这些信息进行标准化处理。</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mod_plname</span>(<span class="params">pl_name</span>):</span></span><br><span class="line">    pl_list = pl_name.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(pl_list[<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> pl_list[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">len</span>(pl_list[<span class="number">0</span>]) &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> pl_list[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p></li>
<li><p>用字典存储企业及其 url</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updata_names</span>(<span class="params">dict_url</span>):</span></span><br><span class="line">  en_keys = <span class="built_in">dict</span>()</span><br><span class="line">  keys = dict_url.keys()</span><br><span class="line">  <span class="keyword">for</span> ky <span class="keyword">in</span> keys:</span><br><span class="line">      ky_split = ky.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">      <span class="keyword">if</span> <span class="built_in">len</span>(ky_split) &gt; <span class="number">1</span>:</span><br><span class="line">          en_keys[ky_split[<span class="number">0</span>]] = ky</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          en_keys[ky] = ky</span><br><span class="line">  <span class="keyword">return</span> en_keys</span><br></pre></td></tr></table></figure></li>
<li><p>更新名称和url</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mod_url</span>(<span class="params">name, dict_url</span>):</span></span><br><span class="line">      <span class="keyword">if</span> name <span class="keyword">in</span> dict_url.keys():</span><br><span class="line">        <span class="keyword">return</span> dict_url[name]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> np.nan</span><br></pre></td></tr></table></figure></li>
<li><p>得到关联信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mod_connec</span>(<span class="params">name</span>):</span></span><br><span class="line">    ky_split = name.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(ky_split) &gt; <span class="number">1</span>:</span><br><span class="line">        connect = ky_split[-<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">if</span> connect.startswith(<span class="string">&#x27;关联&#x27;</span>):</span><br><span class="line">            <span class="keyword">return</span> connect</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> np.nan</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> np.nan</span><br></pre></td></tr></table></figure></li>
</ul>
<ol type="1">
<li><p>处理股东信息</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">start = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i, u_idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(pd_all_firm.index[start:]):</span><br><span class="line">    i = i + start</span><br><span class="line">    name = pd_all_firm.loc[u_idx, <span class="string">&#x27;企业名称&#x27;</span>]</span><br><span class="line">    people_path = pd_all_firm.loc[u_idx, <span class="string">&#x27;公司目录&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    read_people_path = <span class="string">&#x27;Results - Copy&#x27;</span> + people_path.split(<span class="string">&#x27;/Results&#x27;</span>)[<span class="number">1</span>]</span><br><span class="line">    out_people_path = people_path</span><br><span class="line"></span><br><span class="line">    pl_csv = <span class="string">&#x27;股东信息.csv&#x27;</span></span><br><span class="line">    people_dir = pl_root_dir + read_people_path + pl_csv</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    columns:</span></span><br><span class="line"><span class="string">        [&#x27;序号&#x27;, &#x27;股东名称&#x27;, &#x27;股东名称.1&#x27;, &#x27;持股比例&#x27;,</span></span><br><span class="line"><span class="string">         &#x27;持股数(股)&#x27;, &#x27;关联产品/机构&#x27;, &#x27;Name&#x27;, &#x27;url&#x27;]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> pd_all_firm.loc[u_idx, <span class="string">&#x27;股东数&#x27;</span>] == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        pd_people = pd.read_csv(people_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    numbers = pd_people[<span class="string">&#x27;序号&#x27;</span>].notnull().<span class="built_in">sum</span>()</span><br><span class="line">    columns = pd_people.columns</span><br><span class="line">    pd_pl_mod = pd_people.loc[:numbers-<span class="number">1</span>, columns[:-<span class="number">2</span>]]</span><br><span class="line">    pd_pl_mod[columns[<span class="number">1</span>]] = pd_pl_mod[columns[<span class="number">2</span>]].apply(mod_plname)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;Name&#x27;</span> <span class="keyword">in</span> pd_people.columns:</span><br><span class="line">        dict_url = <span class="built_in">dict</span>(<span class="built_in">zip</span>(pd_people[<span class="string">&#x27;Name&#x27;</span>].values, pd_people[<span class="string">&#x27;url&#x27;</span>].values))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            pd_pl_mod[<span class="string">&#x27;url&#x27;</span>] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x: dict_url[x])</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                dict_names = updata_names(dict_url)</span><br><span class="line">                pd_pl_mod[columns[<span class="number">1</span>]] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x: dict_names[x] <span class="keyword">if</span> x <span class="keyword">in</span> dict_names.keys() <span class="keyword">else</span> x)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                keys = pd_people[<span class="string">&#x27;Name&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">                beg_idx = keys.index(<span class="string">&#x27;[&#x27;</span>)</span><br><span class="line">                end_idx = keys.index(<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">                keys = <span class="built_in">eval</span>(keys[beg_idx:end_idx+<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">                values = pd_people[<span class="string">&#x27;url&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">                beg_idx = values.index(<span class="string">&#x27;[&#x27;</span>)</span><br><span class="line">                end_idx = values.index(<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">                values = <span class="built_in">eval</span>(values[beg_idx:end_idx+<span class="number">1</span>])</span><br><span class="line">                dict_url = dict_url = <span class="built_in">dict</span>(<span class="built_in">zip</span>(keys, values))</span><br><span class="line"></span><br><span class="line">            pd_pl_mod[<span class="string">&#x27;url&#x27;</span>] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x:  mod_url(x, dict_url))</span><br><span class="line"></span><br><span class="line">        pd_pl_mod[<span class="string">&#x27;关联信息&#x27;</span>] = pd_pl_mod[(columns[<span class="number">2</span>])].apply(mod_connec)</span><br><span class="line">        pd_pl_mod.drop(columns[<span class="number">2</span>], axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">        people_mod_dir = pl_root_dir + out_people_path + pl_csv.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;-mod.csv&#x27;</span></span><br><span class="line">        pd_pl_mod.to_csv(people_mod_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">f&#x27;第<span class="subst">&#123;i&#125;</span>条人员信息已处理完毕&#x27;</span>)</span><br></pre></td></tr></table></figure></p></li>
<li><p>处理在外任职表</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">start = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i, u_idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(pd_firm.index[start:]):</span><br><span class="line">    i = i + start</span><br><span class="line">    out_dir = pd_firm.loc[u_idx, <span class="string">&#x27;在外任职目录&#x27;</span>]</span><br><span class="line">    out_path = pl_root_dir + out_dir</span><br><span class="line">    pd_people = pd.read_csv(out_path, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pd_people.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    numbers = pd_people[<span class="string">&#x27;序号&#x27;</span>].notnull().<span class="built_in">sum</span>()</span><br><span class="line">    columns = pd_people.columns</span><br><span class="line">    pd_pl_mod = pd_people.loc[:numbers-<span class="number">1</span>, columns[:-<span class="number">2</span>]]</span><br><span class="line">    pd_pl_mod[columns[<span class="number">1</span>]] = pd_pl_mod[columns[<span class="number">1</span>]].apply(mod_plname)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;Name&#x27;</span> <span class="keyword">in</span> pd_people.columns:</span><br><span class="line">        dict_url = <span class="built_in">dict</span>(<span class="built_in">zip</span>(pd_people[<span class="string">&#x27;Name&#x27;</span>].values, pd_people[<span class="string">&#x27;url&#x27;</span>].values))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            pd_pl_mod[<span class="string">&#x27;url&#x27;</span>] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x: dict_url[x])</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                dict_names = updata_names(dict_url)</span><br><span class="line">                pd_pl_mod[columns[<span class="number">1</span>]] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x: dict_names[x] <span class="keyword">if</span> x <span class="keyword">in</span> dict_names.keys() <span class="keyword">else</span> x)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                keys = pd_people[<span class="string">&#x27;Name&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">                beg_idx = keys.index(<span class="string">&#x27;[&#x27;</span>)</span><br><span class="line">                end_idx = keys.index(<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">                keys = <span class="built_in">eval</span>(keys[beg_idx:end_idx+<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">                values = pd_people[<span class="string">&#x27;url&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">                beg_idx = values.index(<span class="string">&#x27;[&#x27;</span>)</span><br><span class="line">                end_idx = values.index(<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">                values = <span class="built_in">eval</span>(values[beg_idx:end_idx+<span class="number">1</span>])</span><br><span class="line">                dict_url = dict_url = <span class="built_in">dict</span>(<span class="built_in">zip</span>(keys, values))</span><br><span class="line"></span><br><span class="line">            pd_pl_mod[<span class="string">&#x27;url&#x27;</span>] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x:  mod_url(x, dict_url))</span><br><span class="line"></span><br><span class="line">        pd_pl_mod.drop(columns[<span class="number">2</span>], axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">        people_mod_dir = out_path.split(<span class="string">&#x27;.csv&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;-mod.csv&#x27;</span></span><br><span class="line">        pd_pl_mod.to_csv(people_mod_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># break</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">f&#x27;第<span class="subst">&#123;i&#125;</span>条人员信息已处理完毕&#x27;</span>)</span><br></pre></td></tr></table></figure></p></li>
</ol>
<h3 id="工商信息处理">4.2.2 工商信息处理</h3>
<ul>
<li><p>标准化名字</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_mod_plname</span>(<span class="params">pl_name</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(pl_name, <span class="built_in">str</span>):</span><br><span class="line">        pl_list = pl_name.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(pl_list[<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> pl_list[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">len</span>(pl_list[<span class="number">0</span>]) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> pl_list[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> pl_name</span><br></pre></td></tr></table></figure></li>
<li><p>update</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">start = <span class="number">366</span></span><br><span class="line"><span class="keyword">for</span> i, u_idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(pd_all_firm.index[start:]):</span><br><span class="line">    i = i + start</span><br><span class="line">    name = pd_all_firm.loc[u_idx, <span class="string">&#x27;企业名称&#x27;</span>]</span><br><span class="line">    people_path = pd_all_firm.loc[u_idx, <span class="string">&#x27;公司目录&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    pl_csv = <span class="string">&#x27;营业执照信息.csv&#x27;</span></span><br><span class="line">    people_dir = pl_root_dir + people_path + pl_csv</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    columns:</span></span><br><span class="line"><span class="string">        [&#x27;序号&#x27;, &#x27;股东名称&#x27;, &#x27;股东名称.1&#x27;, &#x27;持股比例&#x27;,</span></span><br><span class="line"><span class="string">         &#x27;持股数(股)&#x27;, &#x27;关联产品/机构&#x27;, &#x27;Name&#x27;, &#x27;url&#x27;]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        pd_people = pd.read_csv(people_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pd_people.shape[<span class="number">0</span>] == <span class="number">10</span>:</span><br><span class="line">        columns = pd_people.iloc[:, <span class="number">0</span>].values.tolist()</span><br><span class="line">        columns.extend(pd_people.iloc[:, <span class="number">2</span>].values[:<span class="number">7</span>].tolist())</span><br><span class="line">        columns.extend(pd_people.iloc[:, <span class="number">4</span>].values[<span class="number">1</span>:<span class="number">8</span>].tolist())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第二列</span></span><br><span class="line">        idx = pd_people.iloc[:, <span class="number">1</span>].values[<span class="number">0</span>].split(<span class="string">&#x27;复制&#x27;</span>)[<span class="number">0</span>].strip()</span><br><span class="line">        name = new_mod_plname(pd_people.iloc[:, <span class="number">1</span>].values[<span class="number">1</span>])</span><br><span class="line">        dollar = pd_people.iloc[:, <span class="number">1</span>].values[<span class="number">2</span>]</span><br><span class="line">        org_id = pd_people.iloc[:, <span class="number">1</span>].values[<span class="number">3</span>].split(<span class="string">&#x27;复制&#x27;</span>)[<span class="number">0</span>].strip()</span><br><span class="line">        values = [idx, name, dollar, org_id] <span class="comment"># id</span></span><br><span class="line">        values.extend(pd_people.iloc[:, <span class="number">1</span>].values[<span class="number">4</span>:].tolist())</span><br><span class="line"></span><br><span class="line">        values.append(pd_people.iloc[:, <span class="number">3</span>].values[<span class="number">0</span>].split(<span class="string">&#x27;复制&#x27;</span>)[<span class="number">0</span>].strip())</span><br><span class="line">        values.extend(pd_people.iloc[:, <span class="number">3</span>].values[<span class="number">1</span>:<span class="number">3</span>].tolist())</span><br><span class="line">        values.append(pd_people.iloc[:, <span class="number">3</span>].values[<span class="number">3</span>].split(<span class="string">&#x27;复制&#x27;</span>)[<span class="number">0</span>].strip())</span><br><span class="line">        values.extend(pd_people.iloc[:, <span class="number">3</span>].values[<span class="number">4</span>:<span class="number">7</span>].tolist())</span><br><span class="line"></span><br><span class="line">        values.extend(pd_people.iloc[:, <span class="number">5</span>].values[<span class="number">1</span>:<span class="number">3</span>].tolist())</span><br><span class="line">        values.append(pd_people.iloc[:, <span class="number">5</span>].values[<span class="number">3</span>].split(<span class="string">&#x27;复制&#x27;</span>)[<span class="number">0</span>].strip())</span><br><span class="line">        values.extend(pd_people.iloc[:, <span class="number">5</span>].values[<span class="number">4</span>:<span class="number">8</span>].tolist())</span><br><span class="line"></span><br><span class="line">        pd_pl_mod.drop(columns[<span class="number">2</span>], axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">        people_mod_dir = pl_root_dir + people_path + pl_csv.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;-mod.csv&#x27;</span></span><br><span class="line">        pd_pl_mod.to_csv(people_mod_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        pd_pl_mod = pd.DataFrame(np.array(values).reshape(<span class="number">1</span>,-<span class="number">1</span>), columns = columns)</span><br><span class="line">    <span class="keyword">elif</span> pd_people.shape[<span class="number">0</span>] == <span class="number">11</span>:</span><br><span class="line">        columns = pd_people.iloc[:, <span class="number">0</span>].values.tolist()</span><br><span class="line">        columns.extend(pd_people.iloc[:, <span class="number">2</span>].values[:<span class="number">7</span>].tolist())</span><br><span class="line">        columns.extend(pd_people.iloc[:, <span class="number">4</span>].values[<span class="number">1</span>:<span class="number">8</span>].tolist())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第二列</span></span><br><span class="line">        idx = pd_people.iloc[:, <span class="number">1</span>].values[<span class="number">0</span>].split(<span class="string">&#x27;复制&#x27;</span>)[<span class="number">0</span>].strip()</span><br><span class="line">        name = new_mod_plname(pd_people.iloc[:, <span class="number">1</span>].values[<span class="number">1</span>])</span><br><span class="line">        dollar = pd_people.iloc[:, <span class="number">1</span>].values[<span class="number">2</span>]</span><br><span class="line">        org_id = pd_people.iloc[:, <span class="number">1</span>].values[<span class="number">3</span>].split(<span class="string">&#x27;复制&#x27;</span>)[<span class="number">0</span>].strip()</span><br><span class="line">        values = [idx, name, dollar, org_id] <span class="comment"># id</span></span><br><span class="line">        values.extend(pd_people.iloc[:, <span class="number">1</span>].values[<span class="number">4</span>:].tolist())</span><br><span class="line"></span><br><span class="line">        values.append(pd_people.iloc[:, <span class="number">3</span>].values[<span class="number">0</span>].split(<span class="string">&#x27;复制&#x27;</span>)[<span class="number">0</span>].strip())</span><br><span class="line">        values.extend(pd_people.iloc[:, <span class="number">3</span>].values[<span class="number">1</span>:<span class="number">3</span>].tolist())</span><br><span class="line">        values.append(pd_people.iloc[:, <span class="number">3</span>].values[<span class="number">3</span>].split(<span class="string">&#x27;复制&#x27;</span>)[<span class="number">0</span>].strip())</span><br><span class="line">        values.extend(pd_people.iloc[:, <span class="number">3</span>].values[<span class="number">4</span>:<span class="number">7</span>].tolist())</span><br><span class="line"></span><br><span class="line">        values.extend(pd_people.iloc[:, <span class="number">5</span>].values[<span class="number">1</span>:<span class="number">3</span>].tolist())</span><br><span class="line">        values.append(pd_people.iloc[:, <span class="number">5</span>].values[<span class="number">3</span>].split(<span class="string">&#x27;复制&#x27;</span>)[<span class="number">0</span>].strip())</span><br><span class="line">        values.extend(pd_people.iloc[:, <span class="number">5</span>].values[<span class="number">4</span>:<span class="number">8</span>].tolist())</span><br><span class="line"></span><br><span class="line">        pd_pl_mod.drop(columns[<span class="number">2</span>], axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">        people_mod_dir = pl_root_dir + people_path + pl_csv.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;-mod.csv&#x27;</span></span><br><span class="line">        pd_pl_mod.to_csv(people_mod_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        pd_pl_mod = pd.DataFrame(np.array(values).reshape(<span class="number">1</span>,-<span class="number">1</span>), columns = columns)</span><br><span class="line"></span><br><span class="line">    people_mod_dir = people_dir.split(<span class="string">&#x27;.csv&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;-mod.csv&#x27;</span></span><br><span class="line">    pd_pl_mod.to_csv(people_mod_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># break</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">f&#x27;第<span class="subst">&#123;i&#125;</span>条人员信息已处理完毕&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="股东和主要人员url匹配">4.2.3 股东和主要人员url匹配</h3>
<p>从 Fig.9 可以发现，股东名字和 url
并没有很好地对应，因此对该记录进行校正，删除多余的信息，仅保留与前面合伙人一直的url信息，如果不能匹配则填充为空值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mod_plname</span>(<span class="params">pl_name</span>):</span></span><br><span class="line">    pl_list = pl_name.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(pl_list[<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> pl_list[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">len</span>(pl_list[<span class="number">0</span>]) &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> pl_list[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updata_names</span>(<span class="params">dict_url</span>):</span></span><br><span class="line">    en_keys = <span class="built_in">dict</span>()</span><br><span class="line">    keys = dict_url.keys()</span><br><span class="line">    <span class="keyword">for</span> ky <span class="keyword">in</span> keys:</span><br><span class="line">        ky_split = ky.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(ky_split) &gt; <span class="number">1</span>:</span><br><span class="line">            en_keys[ky_split[<span class="number">0</span>]] = ky</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            en_keys[ky] = ky</span><br><span class="line">    <span class="keyword">return</span> en_keys</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mod_url</span>(<span class="params">name, dict_url</span>):</span></span><br><span class="line">    <span class="keyword">if</span> name <span class="keyword">in</span> dict_url.keys():</span><br><span class="line">        <span class="keyword">return</span> dict_url[name]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> np.nan</span><br><span class="line"></span><br><span class="line">people_csvs = [<span class="string">&#x27;股东信息.csv&#x27;</span>, <span class="string">&#x27;主要人员.csv&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1212, 2115</span></span><br><span class="line">start = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i, u_idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(pd_all_firm.index[start:]):</span><br><span class="line">    i = i + start</span><br><span class="line">    name = pd_all_firm.loc[u_idx, <span class="string">&#x27;企业名称&#x27;</span>]</span><br><span class="line">    people_path = pd_all_firm.loc[u_idx, <span class="string">&#x27;公司目录&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> j, pl_csv <span class="keyword">in</span> <span class="built_in">enumerate</span>(people_csvs):</span><br><span class="line">        people_dir = pl_root_dir + people_path + pl_csv</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            columns:</span></span><br><span class="line"><span class="string">                [&#x27;序号&#x27;, &#x27;股东名称&#x27;, &#x27;股东名称.1&#x27;, &#x27;持股比例&#x27;,</span></span><br><span class="line"><span class="string">                 &#x27;持股数(股)&#x27;, &#x27;关联产品/机构&#x27;, &#x27;Name&#x27;, &#x27;url&#x27;]</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">            <span class="keyword">if</span> pd_all_firm.loc[u_idx, <span class="string">&#x27;股东数&#x27;</span>] == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            pd_people = pd.read_csv(people_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line">            numbers = pd_people[<span class="string">&#x27;序号&#x27;</span>].notnull().<span class="built_in">sum</span>()</span><br><span class="line">            columns = pd_people.columns</span><br><span class="line">            pd_pl_mod = pd_people.loc[:numbers-<span class="number">1</span>, columns[:-<span class="number">2</span>]]</span><br><span class="line">            pd_pl_mod[columns[<span class="number">1</span>]] = pd_pl_mod[columns[<span class="number">2</span>]].apply(mod_plname)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;Name&#x27;</span> <span class="keyword">in</span> pd_people.columns:</span><br><span class="line">                dict_url = <span class="built_in">dict</span>(<span class="built_in">zip</span>(pd_people[<span class="string">&#x27;Name&#x27;</span>].values, pd_people[<span class="string">&#x27;url&#x27;</span>].values))</span><br><span class="line"></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    pd_pl_mod[<span class="string">&#x27;url&#x27;</span>] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x: dict_url[x])</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">try</span>:</span><br><span class="line">                        dict_names = updata_names(dict_url)</span><br><span class="line">                        pd_pl_mod[columns[<span class="number">1</span>]] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x: dict_names[x] <span class="keyword">if</span> x <span class="keyword">in</span> dict_names.keys() <span class="keyword">else</span> x)</span><br><span class="line">                    <span class="keyword">except</span>:</span><br><span class="line">                        keys = pd_people[<span class="string">&#x27;Name&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">                        beg_idx = keys.index(<span class="string">&#x27;[&#x27;</span>)</span><br><span class="line">                        end_idx = keys.index(<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">                        keys = <span class="built_in">eval</span>(keys[beg_idx:end_idx+<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">                        values = pd_people[<span class="string">&#x27;url&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">                        beg_idx = values.index(<span class="string">&#x27;[&#x27;</span>)</span><br><span class="line">                        end_idx = values.index(<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">                        values = <span class="built_in">eval</span>(values[beg_idx:end_idx+<span class="number">1</span>])</span><br><span class="line">                        dict_url = dict_url = <span class="built_in">dict</span>(<span class="built_in">zip</span>(keys, values))</span><br><span class="line"></span><br><span class="line">                    pd_pl_mod[<span class="string">&#x27;url&#x27;</span>] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x:  mod_url(x, dict_url))</span><br><span class="line"></span><br><span class="line">                pd_pl_mod.drop(columns[<span class="number">2</span>], axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">                people_mod_dir = pl_root_dir + people_path + pl_csv.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;-mod.csv&#x27;</span></span><br><span class="line">                pd_pl_mod.to_csv(people_mod_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> pd_all_firm.loc[u_idx, <span class="string">&#x27;主要人员数&#x27;</span>] == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            pd_people = pd.read_csv(people_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line">            numbers = pd_people[<span class="string">&#x27;序号&#x27;</span>].notnull().<span class="built_in">sum</span>()</span><br><span class="line">            columns = pd_people.columns</span><br><span class="line">            pd_pl_mod = pd_people.loc[:numbers-<span class="number">1</span>, columns[:-<span class="number">2</span>]]</span><br><span class="line">            pd_pl_mod[columns[<span class="number">1</span>]] = pd_pl_mod[columns[<span class="number">1</span>]].apply(mod_plname)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;Name&#x27;</span> <span class="keyword">in</span> pd_people.columns:</span><br><span class="line">                dict_url = <span class="built_in">dict</span>(<span class="built_in">zip</span>(pd_people[<span class="string">&#x27;Name&#x27;</span>].values, pd_people[<span class="string">&#x27;url&#x27;</span>].values))</span><br><span class="line"></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    pd_pl_mod[<span class="string">&#x27;url&#x27;</span>] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x: dict_url[x])</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">try</span>:</span><br><span class="line">                        dict_names = updata_names(dict_url)</span><br><span class="line">                        pd_pl_mod[columns[<span class="number">1</span>]] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x: dict_names[x] <span class="keyword">if</span> x <span class="keyword">in</span> dict_names.keys() <span class="keyword">else</span> x)</span><br><span class="line">                    <span class="keyword">except</span>:</span><br><span class="line">                        keys = pd_people[<span class="string">&#x27;Name&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">                        beg_idx = keys.index(<span class="string">&#x27;[&#x27;</span>)</span><br><span class="line">                        end_idx = keys.index(<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">                        keys = <span class="built_in">eval</span>(keys[beg_idx:end_idx+<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">                        values = pd_people[<span class="string">&#x27;url&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">                        beg_idx = values.index(<span class="string">&#x27;[&#x27;</span>)</span><br><span class="line">                        end_idx = values.index(<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">                        values = <span class="built_in">eval</span>(values[beg_idx:end_idx+<span class="number">1</span>])</span><br><span class="line">                        dict_url = dict_url = <span class="built_in">dict</span>(<span class="built_in">zip</span>(keys, values))     </span><br><span class="line"></span><br><span class="line">                    pd_pl_mod[<span class="string">&#x27;url&#x27;</span>] = pd_pl_mod[columns[<span class="number">1</span>]].apply(<span class="keyword">lambda</span> x: mod_url(x, dict_url))                </span><br><span class="line"></span><br><span class="line">            people_mod_dir = pl_root_dir + people_path + pl_csv.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;-mod.csv&#x27;</span></span><br><span class="line">            pd_pl_mod.to_csv(people_mod_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>, index = <span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># break</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">f&#x27;第<span class="subst">&#123;i&#125;</span>条人员信息已处理完毕&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="得到注销时间">4.2.4 得到注销时间</h3>
<p>此处，我们仍然使用动态爬虫的方式爬取注销时间，通过分析页面可以发现，注销的实践存储在
<code>xpath</code> 值为
<code>/html/body/div[3]/div/div/div[2]/table/tr[2]/td[3]</code>
的节点下，不过需要点击方可显示该节点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">pd_all_firm = pd.read_csv(<span class="string">&#x27;./All_pd_firm-mod.csv&#x27;</span>, encoding=<span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">NodeExists</span>(<span class="params">drievr, input_code</span>):</span></span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">      driver.find_element_by_xpath(input_code)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">   <span class="keyword">except</span>:</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">start_pos = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i, idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(browser_index):</span><br><span class="line">    i = i + start_pos</span><br><span class="line">    url = pd_all_firm.loc[idx, <span class="string">&#x27;Com_url&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    driver.get(url)</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    expire_bt_xpath = <span class="string">&#x27;/html/body/div[1]/div[2]/div/div/a&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> NodeExists(driver, expire_bt_xpath):</span><br><span class="line">        driver.find_element_by_xpath(<span class="string">&#x27;/html/body/div[1]/div[2]/div/div/a&#x27;</span>).click()</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        date = driver.find_element_by_xpath(<span class="string">&#x27;/html/body/div[3]/div/div/div[2]/table/tr[2]/td[3]&#x27;</span>).text</span><br><span class="line">        pd_all_firm.loc[idx, <span class="string">&#x27;吊销时间&#x27;</span>] = date</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">f&#x27;第<span class="subst">&#123;idx&#125;</span>个条目已经重新整理完毕！&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="更新所有数量信息-1">4.2.5 更新所有数量信息</h3>
<p>至此，我们已经对四个任务处理完毕，接下来，我们更新表格的的数量信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">columns = [<span class="string">&#x27;企业表&#x27;</span>, <span class="string">&#x27;公司地址&#x27;</span>, <span class="string">&#x27;公司url&#x27;</span>, <span class="string">&#x27;股东信息&#x27;</span>,  <span class="string">&#x27;NUM_股东信息&#x27;</span>, <span class="string">&#x27;主要人员&#x27;</span>, <span class="string">&#x27;NUM_主要人员&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;专利信息&#x27;</span>, <span class="string">&#x27;NUM_专利信息&#x27;</span>, <span class="string">&#x27;资质证书&#x27;</span>, <span class="string">&#x27;NUM_资质证书&#x27;</span>, <span class="string">&#x27;软件著作权&#x27;</span>, <span class="string">&#x27;NUM_软件著作权&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;股东信息&#x27;</span>, <span class="string">&#x27;NUM_股东信息&#x27;</span>]</span><br><span class="line">pd_record = pd.DataFrame(columns = columns)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mod_check_idx</span>(<span class="params">pd_data, idx, recheck_cols</span>):</span></span><br><span class="line">    ret_idx = []</span><br><span class="line">    <span class="keyword">for</span> i, col <span class="keyword">in</span> <span class="built_in">enumerate</span>(recheck_cols):</span><br><span class="line">        <span class="keyword">if</span> pd_data.loc[idx, col] == <span class="number">10</span>:</span><br><span class="line">            ret_idx.append(i)</span><br><span class="line">    <span class="keyword">return</span> ret_idx</span><br><span class="line"></span><br><span class="line">pd_all_pri_firm = pd.read_csv(<span class="string">&#x27;./All_pd_firm.csv&#x27;</span>, encoding=<span class="string">&#x27;ansi&#x27;</span>, index_col = <span class="number">0</span>)</span><br><span class="line">start_pos = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> idx, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(recheck_index[start_pos:]):</span><br><span class="line">    name = pd_all_firm.loc[i, <span class="string">&#x27;企业名称&#x27;</span>]</span><br><span class="line">    casset_path = pd_all_firm.loc[i, <span class="string">&#x27;公司目录&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;专利信息：zhuanlilist</span></span><br><span class="line"><span class="string">        资质证书：zhengshulist</span></span><br><span class="line"><span class="string">        软件著作权：rjzzqlist</span></span><br><span class="line"><span class="string">        作品著作权：zzqlist</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    cas_keys = [<span class="string">&#x27;专利信息&#x27;</span>, <span class="string">&#x27;资质证书&#x27;</span>, <span class="string">&#x27;软件著作权&#x27;</span>, <span class="string">&#x27;作品著作权&#x27;</span>] <span class="comment"># csv表名称</span></span><br><span class="line">    recheck_cols = [<span class="string">&#x27;专利信息数&#x27;</span>, <span class="string">&#x27;资质证书数&#x27;</span>, <span class="string">&#x27;软件著作权数&#x27;</span>, <span class="string">&#x27;作品著作权数&#x27;</span>] <span class="comment"># 数量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># if os.path.exists(pl_root_dir+casset_path):</span></span><br><span class="line">    <span class="comment">#     pass</span></span><br><span class="line">    <span class="comment"># else:</span></span><br><span class="line">    <span class="comment">#     os.makedirs(casset_path)</span></span><br><span class="line"></span><br><span class="line">    recheck_col_idx = mod_check_idx(pd_all_pri_firm, i, recheck_cols)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pd_all_firm.loc[i, recheck_cols]</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> recheck_col_idx:</span><br><span class="line">        casset_dir = pl_root_dir + casset_path + cas_keys[j] + <span class="string">&#x27;.csv&#x27;</span></span><br><span class="line">        pd_comp = pd.read_csv(casset_dir, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        col = recheck_cols[j]</span><br><span class="line"></span><br><span class="line">        pd_all_firm.loc[i, col] = pd_comp.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> idx % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">f&#x27;第<span class="subst">&#123;idx+start_pos&#125;</span>个条目已经重新整理完毕！&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pd_all_firm.to_csv(<span class="string">&#x27;./All_pd_firm-mod.csv&#x27;</span>, encoding=<span class="string">&#x27;ansi&#x27;</span>, errors = <span class="string">&#x27;ignore&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="删除旧的信息">4.2.6 删除旧的信息</h3>
<p>由于在处理数据过程中，以防万一我们都用 <code>-mod</code>
的后缀处理得到的所有信息，因此，再甲方确认处理完的信息无误之后，我们需要对旧信息进行删除，这里需要用到文件夹操作，具体代码如下：</p>
<ul>
<li><p>删除旧的公司信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">remove_name = [<span class="string">&#x27;股东信息.csv&#x27;</span>, <span class="string">&#x27;主要人员.csv&#x27;</span>, <span class="string">&#x27;营业执照信息.csv&#x27;</span>]</span><br><span class="line">keep_name = [<span class="string">&#x27;股东信息-mod.csv&#x27;</span>, <span class="string">&#x27;主要人员-mod.csv&#x27;</span>, <span class="string">&#x27;营业执照信息-mod.csv&#x27;</span>]</span><br><span class="line"></span><br><span class="line">start = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i, u_idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(pd_all_firm.index[start:]):</span><br><span class="line">    i = i + start</span><br><span class="line">    name = pd_all_firm.loc[u_idx, <span class="string">&#x27;企业名称&#x27;</span>]</span><br><span class="line">    people_path = pd_all_firm.loc[u_idx, <span class="string">&#x27;公司目录&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    remove_name = [<span class="string">&#x27;股东信息.csv&#x27;</span>, <span class="string">&#x27;主要人员.csv&#x27;</span>, <span class="string">&#x27;营业执照信息.csv&#x27;</span>]</span><br><span class="line">    keep_name = [<span class="string">&#x27;股东信息-mod.csv&#x27;</span>, <span class="string">&#x27;主要人员-mod.csv&#x27;</span>, <span class="string">&#x27;营业执照信息-mod.csv&#x27;</span>]</span><br><span class="line">    people_dir = pl_root_dir + people_path</span><br><span class="line">    have_file_lists = os.listdir(people_dir)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        <span class="keyword">if</span> remove_name[j] <span class="keyword">in</span> have_file_lists <span class="keyword">and</span> keep_name[j] <span class="keyword">in</span> have_file_lists:</span><br><span class="line">            os.remove(os.path.join(people_dir, remove_name[j]))</span><br></pre></td></tr></table></figure></li>
<li><p>删除多余的任职表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">pl_root_dir_new = pl_root_dir + <span class="string">&#x27;Results/&#x27;</span></span><br><span class="line">pl_dirs = os.listdir(pl_root_dir_new)</span><br><span class="line"></span><br><span class="line">remove_name = [<span class="string">&#x27;在外任职表.csv&#x27;</span>, <span class="string">&#x27;所有企业表.csv&#x27;</span>]</span><br><span class="line">keep_name = [<span class="string">&#x27;在外任职表-mod.csv&#x27;</span>, <span class="string">&#x27;所有企业表_mod.csv&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, tmp_dir <span class="keyword">in</span> <span class="built_in">enumerate</span>(pl_dirs):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;.&#x27;</span> <span class="keyword">in</span> tmp_dir:</span><br><span class="line">        name = tmp_dir.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        name = tmp_dir</span><br><span class="line">    pl_dir = pl_root_dir_new + tmp_dir</span><br><span class="line">    have_file_lists = os.listdir(pl_dir)</span><br><span class="line"></span><br><span class="line">    remove_names = [name+<span class="string">&#x27;-&#x27;</span>+table <span class="keyword">for</span> table <span class="keyword">in</span> remove_name]</span><br><span class="line">    keep_names = [name+<span class="string">&#x27;-&#x27;</span>+table <span class="keyword">for</span> table <span class="keyword">in</span> keep_name]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        <span class="keyword">if</span> remove_names[j] <span class="keyword">in</span> have_file_lists <span class="keyword">and</span> keep_names[j] <span class="keyword">in</span> have_file_lists:</span><br><span class="line">            os.remove(os.path.join(pl_dir, remove_names[j]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">f&#x27;第<span class="subst">&#123;i&#125;</span>个条目已经重新整理完毕！&#x27;</span>)  </span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="conclusion">5 Conclusion</h1>
<p>至此，所有信息处理完毕，甲方也十分满意。最后附上成品图。</p>
<p><img src = 'https://z3.ax1x.com/2021/10/02/4bC0nx.png' style="zoom:80%;" /></p>
<center>
Fig. 11 成果样例
</center>
<p>由于是别人的研究，本文不提供更详细的数据，代码已基本附上。所获取的数据仅用于研究，不做他用，展示数据已经过脱敏处理。图片皆为个人爬取后的数据截图，如有侵权，可联系邮箱进行删除。</p>
<p>申明：本文的代码均为个人原创，本文仅供学习和交流，请珍惜作者劳动成果，勿用作商业用途，如需商业用途或业务交流可联系邮箱
<code>e-mail:yangsuoly@qq.com</code> 进行进一步交流。</p>

    </div>

    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">
            -------------This blog is over!
            <i class="fa fa-eye"></i>
            Thanks for your reading-------------
        </div>
    
</div>
      
    </div>
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>YangSu
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="http://yangsuoly.com/2021/10/02/Crawler-qcc/" title="Crawler-qcc">http://yangsuoly.com/2021/10/02/Crawler-qcc/</a>
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/Tags/Crawler/" rel="tag"><i class="fa fa-tag"></i> Crawler</a>
              <a href="/Tags/Project/" rel="tag"><i class="fa fa-tag"></i> Project</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/09/01/test/" rel="prev" title="test">
      <i class="fa fa-chevron-left"></i> test
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/10/02/Crawler-JD/" rel="next" title="Crawler-JD">
      Crawler-JD <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div id="music163player">
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1317956275&auto=0&height=66"></iframe>
      </iframe>
    </div>
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#introduction"><span class="nav-text">1. Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#job-description"><span class="nav-text">1.1 Job description</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#task-requirements"><span class="nav-text">1.2 Task requirements</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%81%E4%B8%9A%E5%AE%B6%E4%BF%A1%E6%81%AF"><span class="nav-text">1.2.1 企业家信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AC%E5%8F%B8%E4%BF%A1%E6%81%AF"><span class="nav-text">1.2.2 公司信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AC%E5%8F%B8%E7%9F%A5%E8%AF%86%E4%BA%A7%E6%9D%83%E4%BF%A1%E6%81%AF"><span class="nav-text">1.2.3 公司知识产权信息</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#static-crawler"><span class="nav-text">2 Static crawler</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#configuration"><span class="nav-text">2.1 Configuration</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0"><span class="nav-text">2.2 自定义函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%81%E4%B8%9A%E5%AE%B6%E6%89%80%E5%B1%9E%E4%BF%A1%E6%81%AF"><span class="nav-text">2.2.1 企业家所属信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AC%E5%8F%B8%E6%89%80%E5%B1%9E%E4%BF%A1%E6%81%AF"><span class="nav-text">2.2.2 公司所属信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AC%E5%8F%B8%E4%B8%93%E5%88%A9%E4%BF%A1%E6%81%AF"><span class="nav-text">2.2.3 公司专利信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B-ip-%E6%B1%A0"><span class="nav-text">2.2.4 建立 IP 池</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#start-program"><span class="nav-text">2.3 Start program</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#data-cleaning"><span class="nav-text">2.4 Data cleaning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%B4%E6%AD%A3%E5%85%AC%E5%8F%B8%E6%95%B0%E9%87%8F%E4%BF%A1%E6%81%AF"><span class="nav-text">2.4.1 更正公司数量信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%84%E8%8C%83%E5%8C%96"><span class="nav-text">2.4.2 数据规范化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%B4%E6%96%B0%E4%B8%93%E5%88%A9%E4%BF%A1%E6%81%AF"><span class="nav-text">2.4.3 更新专利信息</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9B%B4%E6%96%B0%E6%89%80%E6%9C%89%E6%95%B0%E9%87%8F%E4%BF%A1%E6%81%AF"><span class="nav-text">更新所有数量信息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A0%B8%E5%AF%B9%E6%95%B0%E9%87%8F"><span class="nav-text">核对数量</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#dynamic-crawler"><span class="nav-text">3. Dynamic crawler</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#problem-description"><span class="nav-text">3.1 Problem description</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#configuration-1"><span class="nav-text">3.2 Configuration</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#data-complementary"><span class="nav-text">3.3 Data complementary</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#data-preprocess"><span class="nav-text">4 Data Preprocess</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#job-description-1"><span class="nav-text">4.1 Job description</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#preprocess"><span class="nav-text">4.2 Preprocess</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#task-1"><span class="nav-text">4.2.1 Task 1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B7%A5%E5%95%86%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86"><span class="nav-text">4.2.2 工商信息处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%82%A1%E4%B8%9C%E5%92%8C%E4%B8%BB%E8%A6%81%E4%BA%BA%E5%91%98url%E5%8C%B9%E9%85%8D"><span class="nav-text">4.2.3 股东和主要人员url匹配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%97%E5%88%B0%E6%B3%A8%E9%94%80%E6%97%B6%E9%97%B4"><span class="nav-text">4.2.4 得到注销时间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%B4%E6%96%B0%E6%89%80%E6%9C%89%E6%95%B0%E9%87%8F%E4%BF%A1%E6%81%AF-1"><span class="nav-text">4.2.5 更新所有数量信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A0%E9%99%A4%E6%97%A7%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="nav-text">4.2.6 删除旧的信息</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#conclusion"><span class="nav-text">5 Conclusion</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="YangSu"
      src="/images/YangSu.jpg">
  <p class="site-author-name" itemprop="name">YangSu</p>
  <div class="site-description" itemprop="description">A blog for recording learning notes...</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">56</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/Categories/">
          
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/Tags/">
          
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/YangSuoly" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;YangSuoly" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://gitee.com/yangsuoly" title="Gitee → https:&#x2F;&#x2F;gitee.com&#x2F;yangsuoly" rel="noopener" target="_blank"><i class="fab fa-github-square fa-fw"></i>Gitee</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/64518717" title="B 站 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;64518717" rel="noopener" target="_blank"><i class="fa fa-play-circle fa-fw"></i>B 站</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Related links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.58pic.com/u/19637930/" title="https:&#x2F;&#x2F;www.58pic.com&#x2F;u&#x2F;19637930&#x2F;" rel="noopener" target="_blank">千图网</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YangSu</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'http://yangsuoly.com/2021/10/02/Crawler-qcc/',]
      });
      });
  </script>

  
  <script id="ribbon" src="js/canvas-ribbon.js"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/22.2017.cba-normal.model.json"},"display":{"position":"right","width":300,"height":450},"mobile":{"show":false},"react":{"opacity":0.7},"log":false});</script></body>
</html>
