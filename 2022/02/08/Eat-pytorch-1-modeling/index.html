<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/blog-logo-32px.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/blog-logo-16px.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="manifest" href="/images/manifest.json">
  <meta name="msapplication-config" content="/images/browserconfig.xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yangsuoly.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1. Introduction 1.1 Preface 本系列博文是和鲸社区的活动《20天吃掉那只PyTorch》学习的笔记，本篇为系列笔记的第一篇—— Pytorch 的建模流程。该专栏是 Github 上 2.8K 星的项目，在学习该书的过程中可以参考阅读《Python深度学习》一书的第一部分&quot;深度学习基础&quot;内容。">
<meta property="og:type" content="article">
<meta property="og:title" content="Eat-pytorch-1-modeling">
<meta property="og:url" content="http://yangsuoly.com/2022/02/08/Eat-pytorch-1-modeling/index.html">
<meta property="og:site_name" content="独孤诗人的学习驿站">
<meta property="og:description" content="1. Introduction 1.1 Preface 本系列博文是和鲸社区的活动《20天吃掉那只PyTorch》学习的笔记，本篇为系列笔记的第一篇—— Pytorch 的建模流程。该专栏是 Github 上 2.8K 星的项目，在学习该书的过程中可以参考阅读《Python深度学习》一书的第一部分&quot;深度学习基础&quot;内容。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-02-08T04:12:45.000Z">
<meta property="article:modified_time" content="2022-02-08T05:06:56.465Z">
<meta property="article:author" content="YangSu">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Pytorch">
<meta property="article:tag" content="Deep learning">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yangsuoly.com/2022/02/08/Eat-pytorch-1-modeling/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Eat-pytorch-1-modeling | 独孤诗人的学习驿站</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f59f5fb59d32ec3903088b0f976956d1";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">独孤诗人的学习驿站</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">生活就是一半烟火，一半诗意。手执烟火谋生活，心怀诗意谋未来……</p>
      <a>
        <img class="custom-logo-image" src="/images/logo@2x.png" alt="独孤诗人的学习驿站">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/Tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/Categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/YangSuoly" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yangsuoly.com/2022/02/08/Eat-pytorch-1-modeling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/YangSu.jpg">
      <meta itemprop="name" content="YangSu">
      <meta itemprop="description" content="A blog for recording learning notes...">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="独孤诗人的学习驿站">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Eat-pytorch-1-modeling
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-02-08 12:12:45 / Modified: 13:06:56" itemprop="dateCreated datePublished" datetime="2022-02-08T12:12:45+08:00">2022-02-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/Categories/Notes/" itemprop="url" rel="index"><span itemprop="name">Notes</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/Categories/Notes/Eat-pytorch-in-20-days/" itemprop="url" rel="index"><span itemprop="name">Eat pytorch in 20 days</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>49k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>45 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="introduction">1. Introduction</h1>
<h2 id="preface">1.1 Preface</h2>
<p>本系列博文是和鲸社区的活动《20天吃掉那只PyTorch》学习的笔记，本篇为系列笔记的第一篇——
<code>Pytorch</code> 的建模流程。该专栏是 <code>Github</code> 上
<code>2.8K</code>
星的项目，在学习该书的过程中可以参考阅读《Python深度学习》一书的第一部分"深度学习基础"内容。</p>
<a id="more"></a>
<p>《Python深度学习》这本书是 <code>Keras</code> 之父
<code>Francois Chollet</code>
所著，该书假定读者无任何机器学习知识，以<code>Keras</code>
为工具，使用丰富的范例示范深度学习的最佳实践，该书通俗易懂，全书没有一个数学公式，注重培养读者的深度学习直觉。</p>
<p>《Python深度学习》一书的第一部分的 <code>4</code>
个章节内容如下，预计读者可以在 <code>20</code> 小时之内学完。</p>
<ol type="1">
<li>什么是深度学习</li>
<li>神经网络的数学基础</li>
<li>神经网络入门</li>
<li>机器学习基础</li>
</ol>
<p>本系列博文的大纲如下：</p>
<ul>
<li>一、PyTorch的建模流程</li>
<li>二、PyTorch的核心概念</li>
<li>三、PyTorch的层次结构</li>
<li>四、PyTorch的低阶API</li>
<li>五、PyTorch的中阶API</li>
<li>六、PyTorch的高阶API</li>
</ul>
<p>最后，本博文提供所使用的全部数据，读者可以从下述连接中下载数据：</p>
<p><a id="download" href="https://www.heywhale.com/mw/dataset/61ffa75e7a7c9a0017c2e189/file" target="_blank"><i class="fa fa-download"></i><span>
Download Now </span> </a></p>
<h2 id="pytoch-的建模流程">1.2 Pytoch 的建模流程</h2>
<p>使用 <code>Pytorch</code> 实现神经网络模型的一般流程包括：</p>
<ol type="1">
<li>准备数据</li>
<li>定义模型</li>
<li>训练模型</li>
<li>评估模型</li>
<li>使用模型</li>
<li>保存模型</li>
</ol>
<p>接下来的学习将分别以 <code>titanic</code> 生存 <strong>预测</strong>
问题，<code>cifar2</code> 图片 <strong>分类</strong>
问题，<code>imdb</code> 电影评论分类问题，国内新冠疫情结束
<strong>时间预测</strong> 问题为例，演示应用 <code>Pytorch</code>
对这四类数据的建模方法。</p>
<h1 id="structured-numeric-classication">2. Structured numeric
classication</h1>
<h2 id="data">2.1 Data</h2>
<h3 id="load-data">2.1.1 Load data</h3>
<p><code>titanic</code> 数据集的目标是根据乘客信息预测他们在
<code>Titanic</code>
号撞击冰山沉没后能否生存。结构化数据一般会使用<code>Pandas</code> 中的
<code>DataFrame</code> 进行预处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader,TensorDataset</span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&#x27;../data/&#x27;</span></span><br><span class="line"></span><br><span class="line">dftrain_raw = pd.read_csv(data_dir + <span class="string">&#x27;titanic/train.csv&#x27;</span>)</span><br><span class="line">dftest_raw = pd.read_csv(data_dir + <span class="string">&#x27;titanic/test.csv&#x27;</span>)</span><br><span class="line">dftrain_raw.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
493
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Molson, Mr. Harry Markland
</td>
<td>
male
</td>
<td>
55.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
113787
</td>
<td>
30.5000
</td>
<td>
C30
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
53
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Harper, Mrs. Henry Sleeper (Myna Haxtun)
</td>
<td>
female
</td>
<td>
49.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17572
</td>
<td>
76.7292
</td>
<td>
D33
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
388
</td>
<td>
1
</td>
<td>
2
</td>
<td>
Buss, Miss. Kate
</td>
<td>
female
</td>
<td>
36.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
27849
</td>
<td>
13.0000
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
192
</td>
<td>
0
</td>
<td>
2
</td>
<td>
Carbines, Mr. William
</td>
<td>
male
</td>
<td>
19.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
28424
</td>
<td>
13.0000
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
687
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Panula, Mr. Jaako Arnold
</td>
<td>
male
</td>
<td>
14.0
</td>
<td>
4
</td>
<td>
1
</td>
<td>
3101295
</td>
<td>
39.6875
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
5
</th>
<td>
16
</td>
<td>
1
</td>
<td>
2
</td>
<td>
Hewlett, Mrs. (Mary D Kingcome)
</td>
<td>
female
</td>
<td>
55.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
248706
</td>
<td>
16.0000
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
6
</th>
<td>
228
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Lovell, Mr. John Hall ("Henry")
</td>
<td>
male
</td>
<td>
20.5
</td>
<td>
0
</td>
<td>
0
</td>
<td>
A/5 21173
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
7
</th>
<td>
884
</td>
<td>
0
</td>
<td>
2
</td>
<td>
Banfield, Mr. Frederick James
</td>
<td>
male
</td>
<td>
28.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
C.A./SOTON 34068
</td>
<td>
10.5000
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
8
</th>
<td>
168
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Skoog, Mrs. William (Anna Bernhardina Karlsson)
</td>
<td>
female
</td>
<td>
45.0
</td>
<td>
1
</td>
<td>
4
</td>
<td>
347088
</td>
<td>
27.9000
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
9
</th>
<td>
752
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Moor, Master. Meier
</td>
<td>
male
</td>
<td>
6.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
392096
</td>
<td>
12.4750
</td>
<td>
E121
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p><strong>Information</strong>:</p>
<ul>
<li>PassengerId：乘客 <code>ID</code></li>
<li>Survived：<code>0</code> 代表死亡，<code>1</code>
代表存活【y标签】</li>
<li>Pclass：乘客所持票类，有三种值(1,2,3) 【转换成onehot编码】</li>
<li>Name：乘客姓名 【舍去】</li>
<li>Sex：乘客性别 【转换成bool特征】</li>
<li>Age：乘客年龄(有缺失)
【数值特征，添加“年龄是否缺失”作为辅助特征】</li>
<li>SibSp：乘客兄弟姐妹/配偶的个数(整数值) 【数值特征】</li>
<li>Parch：乘客父母/孩子的个数(整数值)【数值特征】</li>
<li>Ticket：票号(字符串)【舍去】</li>
<li>Fare：乘客所持票的价格(浮点数，0-500不等) 【数值特征】</li>
<li>Cabin：乘客所在船舱(有缺失)
【添加“所在船舱是否缺失”作为辅助特征】</li>
<li>Embarked：乘客登船港口:S、C、Q(有缺失)【转换成onehot编码，四维度
S,C,Q,nan】</li>
</ul>
<h3 id="eda">2.1.2 EDA</h3>
<p>利用 <code>Pandas</code>
的数据可视化功能我们可以简单地进行探索性数据分析
<code>EDA</code>（Exploratory Data Analysis）</p>
<ul>
<li><p>Label 分布</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">&#x27;png&#x27;</span></span><br><span class="line">ax = dftrain_raw[<span class="string">&#x27;Survived&#x27;</span>].value_counts().plot(kind = <span class="string">&#x27;bar&#x27;</span>,</span><br><span class="line">     figsize = (<span class="number">12</span>,<span class="number">8</span>),fontsize=<span class="number">15</span>,rot = <span class="number">0</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Counts&#x27;</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Survived&#x27;</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSw7t.png' style = "zoom:80%"></p></li>
<li><p>年龄</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ax = dftrain_raw[<span class="string">&#x27;Age&#x27;</span>].plot(kind = <span class="string">&#x27;hist&#x27;</span>,bins = <span class="number">20</span>,color= <span class="string">&#x27;purple&#x27;</span>,</span><br><span class="line">                    figsize = (<span class="number">12</span>,<span class="number">8</span>),fontsize=<span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Frequency&#x27;</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Age&#x27;</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSBAP.md.png' style = "zoom:80%"></p></li>
<li><p>年龄和 <code>label</code> 的相关性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ax = dftrain_raw.query(<span class="string">&#x27;Survived == 0&#x27;</span>)[<span class="string">&#x27;Age&#x27;</span>].plot(kind = <span class="string">&#x27;density&#x27;</span>,</span><br><span class="line">                      figsize = (<span class="number">12</span>,<span class="number">8</span>),fontsize=<span class="number">15</span>)</span><br><span class="line">dftrain_raw.query(<span class="string">&#x27;Survived == 1&#x27;</span>)[<span class="string">&#x27;Age&#x27;</span>].plot(kind = <span class="string">&#x27;density&#x27;</span>,</span><br><span class="line">                      figsize = (<span class="number">12</span>,<span class="number">8</span>),fontsize=<span class="number">15</span>)</span><br><span class="line">ax.legend([<span class="string">&#x27;Survived==0&#x27;</span>,<span class="string">&#x27;Survived==1&#x27;</span>],fontsize = <span class="number">12</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Density&#x27;</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Age&#x27;</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSDtf.png' style = "zoom:80%"></p></li>
</ul>
<h2 id="preprocessing">2.2 Preprocessing</h2>
<h3 id="预处理">2.2.1 预处理</h3>
<p>定义数据预处理的函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocessing</span>(<span class="params">dfdata</span>):</span></span><br><span class="line"></span><br><span class="line">    dfresult= pd.DataFrame()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Pclass</span></span><br><span class="line">    dfPclass = pd.get_dummies(dfdata[<span class="string">&#x27;Pclass&#x27;</span>])</span><br><span class="line">    dfPclass.columns = [<span class="string">&#x27;Pclass_&#x27;</span> +<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> dfPclass.columns ]</span><br><span class="line">    dfresult = pd.concat([dfresult,dfPclass],axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Sex</span></span><br><span class="line">    dfSex = pd.get_dummies(dfdata[<span class="string">&#x27;Sex&#x27;</span>])</span><br><span class="line">    dfresult = pd.concat([dfresult,dfSex],axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Age</span></span><br><span class="line">    dfresult[<span class="string">&#x27;Age&#x27;</span>] = dfdata[<span class="string">&#x27;Age&#x27;</span>].fillna(<span class="number">0</span>)</span><br><span class="line">    dfresult[<span class="string">&#x27;Age_null&#x27;</span>] = pd.isna(dfdata[<span class="string">&#x27;Age&#x27;</span>]).astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#SibSp,Parch,Fare</span></span><br><span class="line">    dfresult[<span class="string">&#x27;SibSp&#x27;</span>] = dfdata[<span class="string">&#x27;SibSp&#x27;</span>]</span><br><span class="line">    dfresult[<span class="string">&#x27;Parch&#x27;</span>] = dfdata[<span class="string">&#x27;Parch&#x27;</span>]</span><br><span class="line">    dfresult[<span class="string">&#x27;Fare&#x27;</span>] = dfdata[<span class="string">&#x27;Fare&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Carbin</span></span><br><span class="line">    dfresult[<span class="string">&#x27;Cabin_null&#x27;</span>] =  pd.isna(dfdata[<span class="string">&#x27;Cabin&#x27;</span>]).astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Embarked</span></span><br><span class="line">    dfEmbarked = pd.get_dummies(dfdata[<span class="string">&#x27;Embarked&#x27;</span>],dummy_na=<span class="literal">True</span>)</span><br><span class="line">    dfEmbarked.columns = [<span class="string">&#x27;Embarked_&#x27;</span> + <span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> dfEmbarked.columns]</span><br><span class="line">    dfresult = pd.concat([dfresult,dfEmbarked],axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>(dfresult)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x_train = preprocessing(dftrain_raw).values</span><br><span class="line">y_train = dftrain_raw[[<span class="string">&#x27;Survived&#x27;</span>]].values</span><br><span class="line"></span><br><span class="line">x_test = preprocessing(dftest_raw).values</span><br><span class="line">y_test = dftest_raw[[<span class="string">&#x27;Survived&#x27;</span>]].values</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;x_train.shape =&quot;</span>, x_train.shape )</span><br><span class="line">print(<span class="string">&quot;x_test.shape =&quot;</span>, x_test.shape )</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;y_train.shape =&quot;</span>, y_train.shape )</span><br><span class="line">print(<span class="string">&quot;y_test.shape =&quot;</span>, y_test.shape )</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>x_train.shape = (712, 15)
x_test.shape = (179, 15)
y_train.shape = (712, 1)
y_test.shape = (179, 1)</code></pre>
<h3 id="dataloader">2.2.2 Dataloader</h3>
<ul>
<li><p>用 Dataloader 和 TensorDataset 封装</p>
<p>进一步使用DataLoader和TensorDataset封装成可以迭代的数据管道。</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dl_train = DataLoader(TensorDataset(torch.tensor(x_train).<span class="built_in">float</span>(),torch.tensor(y_train).<span class="built_in">float</span>()),</span><br><span class="line">                     shuffle = <span class="literal">True</span>, batch_size = <span class="number">8</span>)</span><br><span class="line">dl_valid = DataLoader(TensorDataset(torch.tensor(x_test).<span class="built_in">float</span>(),torch.tensor(y_test).<span class="built_in">float</span>()),</span><br><span class="line">                     shuffle = <span class="literal">False</span>, batch_size = <span class="number">8</span>)</span><br></pre></td></tr></table></figure></p></li>
<li><p>测试数据管道</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试数据管道</span></span><br><span class="line"><span class="keyword">for</span> features,labels <span class="keyword">in</span> dl_train:</span><br><span class="line">    print(features,labels)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">tensor([[  1.0000,   0.0000,   0.0000,   1.0000,   0.0000,  31.0000,   0.0000,</span><br><span class="line">           0.0000,   2.0000, 164.8667,   0.0000,   0.0000,   0.0000,   1.0000,</span><br><span class="line">           0.0000],</span><br><span class="line">        [  0.0000,   0.0000,   1.0000,   0.0000,   1.0000,  29.0000,   0.0000,</span><br><span class="line">           0.0000,   0.0000,   9.4833,   1.0000,   0.0000,   0.0000,   1.0000,</span><br><span class="line">           0.0000],</span><br><span class="line">        [  0.0000,   1.0000,   0.0000,   0.0000,   1.0000,  54.0000,   0.0000,</span><br><span class="line">           0.0000,   0.0000,  26.0000,   1.0000,   0.0000,   0.0000,   1.0000,</span><br><span class="line">           0.0000],</span><br><span class="line">        [  0.0000,   0.0000,   1.0000,   0.0000,   1.0000,  18.0000,   0.0000,</span><br><span class="line">           0.0000,   0.0000,   8.0500,   1.0000,   0.0000,   0.0000,   1.0000,</span><br><span class="line">           0.0000],</span><br><span class="line">        [  0.0000,   0.0000,   1.0000,   0.0000,   1.0000,  36.0000,   0.0000,</span><br><span class="line">           1.0000,   0.0000,  15.5500,   1.0000,   0.0000,   0.0000,   1.0000,</span><br><span class="line">           0.0000],</span><br><span class="line">        [  0.0000,   0.0000,   1.0000,   1.0000,   0.0000,  39.0000,   0.0000,</span><br><span class="line">           0.0000,   5.0000,  29.1250,   1.0000,   0.0000,   1.0000,   0.0000,</span><br><span class="line">           0.0000],</span><br><span class="line">        [  0.0000,   0.0000,   1.0000,   0.0000,   1.0000,  19.0000,   0.0000,</span><br><span class="line">           0.0000,   0.0000,   8.0500,   1.0000,   0.0000,   0.0000,   1.0000,</span><br><span class="line">           0.0000],</span><br><span class="line">        [  0.0000,   1.0000,   0.0000,   1.0000,   0.0000,  22.0000,   0.0000,</span><br><span class="line">           1.0000,   2.0000,  41.5792,   1.0000,   1.0000,   0.0000,   0.0000,</span><br><span class="line">           0.0000]]) tensor([[1.],</span><br><span class="line">        [0.],</span><br><span class="line">        [0.],</span><br><span class="line">        [1.],</span><br><span class="line">        [0.],</span><br><span class="line">        [0.],</span><br><span class="line">        [1.],</span><br><span class="line">        [1.]])</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="model">2.3 Model</h2>
<h3 id="define-model">2.3.1 Define model</h3>
<p>使用 <code>Pytorch</code> 通常有三种方式构建模型：</p>
<ul>
<li>使用 <code>nn.Sequential</code> 按层顺序构建模型；</li>
<li>继承 <code>nn.Module</code> 基类构建自定义模型；</li>
<li>继承 <code>nn.Module</code>
基类构建模型并辅助应用模型容器进行封装。</li>
</ul>
<p>此处选择使用最简单的 <code>nn.Sequential</code>，按层顺序模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_net</span>():</span></span><br><span class="line">    net = nn.Sequential()</span><br><span class="line">    net.add_module(<span class="string">&quot;linear1&quot;</span>,nn.Linear(<span class="number">15</span>,<span class="number">20</span>))</span><br><span class="line">    net.add_module(<span class="string">&quot;relu1&quot;</span>,nn.ReLU())</span><br><span class="line">    net.add_module(<span class="string">&quot;linear2&quot;</span>,nn.Linear(<span class="number">20</span>,<span class="number">15</span>))</span><br><span class="line">    net.add_module(<span class="string">&quot;relu2&quot;</span>,nn.ReLU())</span><br><span class="line">    net.add_module(<span class="string">&quot;linear3&quot;</span>,nn.Linear(<span class="number">15</span>,<span class="number">1</span>))</span><br><span class="line">    net.add_module(<span class="string">&quot;sigmoid&quot;</span>,nn.Sigmoid())</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line">net = create_net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>Sequential(
  (linear1): Linear(in_features=15, out_features=20, bias=True)
  (relu1): ReLU()
  (linear2): Linear(in_features=20, out_features=15, bias=True)
  (relu2): ReLU()
  (linear3): Linear(in_features=15, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)</code></pre>
<ul>
<li><p>Install <code>torchkeras</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install torchkeras</span><br></pre></td></tr></table></figure></li>
<li><p>查看模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchkeras <span class="keyword">import</span> summary</span><br><span class="line">summary(net,input_shape=(<span class="number">15</span>,))</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">----------------------------------------------------------------</span><br><span class="line">        Layer (type)               Output Shape         Param #</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">            Linear-1                   [-1, 20]             320</span><br><span class="line">              ReLU-2                   [-1, 20]               0</span><br><span class="line">            Linear-3                   [-1, 15]             315</span><br><span class="line">              ReLU-4                   [-1, 15]               0</span><br><span class="line">            Linear-5                    [-1, 1]              16</span><br><span class="line">           Sigmoid-6                    [-1, 1]               0</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 651</span><br><span class="line">Trainable params: 651</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Input size (MB): 0.000057</span><br><span class="line">Forward&#x2F;backward pass size (MB): 0.000549</span><br><span class="line">Params size (MB): 0.002483</span><br><span class="line">Estimated Total Size (MB): 0.003090</span><br><span class="line">----------------------------------------------------------------</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="training-model">2.3.2 Training model</h3>
<p><code>Pytorch</code>
通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。</p>
<p>有 <code>3</code> 类典型的训练循环代码风格：</p>
<ul>
<li>脚本形式训练循环；</li>
<li>函数形式训练循环；</li>
<li>类形式训练循环。</li>
</ul>
<p>此处介绍一种较通用的脚本形式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">loss_func = nn.BCELoss()</span><br><span class="line">optimizer = torch.optim.Adam(params=net.parameters(),lr = <span class="number">0.01</span>)</span><br><span class="line">metric_func = <span class="keyword">lambda</span> y_pred,y_true: accuracy_score(y_true.data.numpy(),y_pred.data.numpy()&gt;<span class="number">0.5</span>)</span><br><span class="line">metric_name = <span class="string">&quot;accuracy&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">log_step_freq = <span class="number">30</span></span><br><span class="line"></span><br><span class="line">dfhistory = pd.DataFrame(columns = [<span class="string">&quot;epoch&quot;</span>,<span class="string">&quot;loss&quot;</span>,metric_name,<span class="string">&quot;val_loss&quot;</span>,<span class="string">&quot;val_&quot;</span>+metric_name])</span><br><span class="line">print(<span class="string">&quot;Start Training...&quot;</span>)</span><br><span class="line">nowtime = datetime.datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)</span><br><span class="line">print(<span class="string">&quot;==========&quot;</span>*<span class="number">8</span> + <span class="string">&quot;%s&quot;</span>%nowtime)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,epochs+<span class="number">1</span>):  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1，训练循环-------------------------------------------------</span></span><br><span class="line">    net.train()</span><br><span class="line">    loss_sum = <span class="number">0.0</span></span><br><span class="line">    metric_sum = <span class="number">0.0</span></span><br><span class="line">    step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step, (features,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl_train, <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 正向传播求损失</span></span><br><span class="line">        predictions = net(features)</span><br><span class="line">        loss = loss_func(predictions,labels)</span><br><span class="line">        metric = metric_func(predictions,labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反向传播求梯度</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印batch级别日志</span></span><br><span class="line">        loss_sum += loss.item()</span><br><span class="line">        metric_sum += metric.item()</span><br><span class="line">        <span class="keyword">if</span> step%log_step_freq == <span class="number">0</span>:   </span><br><span class="line">            print((<span class="string">&quot;[step = %d] loss: %.3f, &quot;</span>+metric_name+<span class="string">&quot;: %.3f&quot;</span>) %</span><br><span class="line">                  (step, loss_sum/step, metric_sum/step))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2，验证循环-------------------------------------------------</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    val_loss_sum = <span class="number">0.0</span></span><br><span class="line">    val_metric_sum = <span class="number">0.0</span></span><br><span class="line">    val_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> val_step, (features,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl_valid, <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 关闭梯度计算</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            predictions = net(features)</span><br><span class="line">            val_loss = loss_func(predictions,labels)</span><br><span class="line">            val_metric = metric_func(predictions,labels)</span><br><span class="line">        val_loss_sum += val_loss.item()</span><br><span class="line">        val_metric_sum += val_metric.item()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3，记录日志-------------------------------------------------</span></span><br><span class="line">    info = (epoch, loss_sum/step, metric_sum/step,</span><br><span class="line">            val_loss_sum/val_step, val_metric_sum/val_step)</span><br><span class="line">    dfhistory.loc[epoch-<span class="number">1</span>] = info</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印epoch级别日志</span></span><br><span class="line">    print((<span class="string">&quot;\nEPOCH = %d, loss = %.3f,&quot;</span>+ metric_name + \</span><br><span class="line">          <span class="string">&quot;  = %.3f, val_loss = %.3f, &quot;</span>+<span class="string">&quot;val_&quot;</span>+ metric_name+<span class="string">&quot; = %.3f&quot;</span>)</span><br><span class="line">          %info)</span><br><span class="line">    nowtime = datetime.datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)</span><br><span class="line">    print(<span class="string">&quot;\n&quot;</span>+<span class="string">&quot;==========&quot;</span>*<span class="number">8</span> + <span class="string">&quot;%s&quot;</span>%nowtime)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Finished Training...&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>Start Training...
================================================================================2022-02-06 13:01:43
[step = 30] loss: 0.394, accuracy: 0.846
[step = 60] loss: 0.411, accuracy: 0.823

EPOCH = 1, loss = 0.452,accuracy  = 0.803, val_loss = 0.442, val_accuracy = 0.783

...

================================================================================2022-02-06 13:01:46
[step = 30] loss: 0.408, accuracy: 0.808
[step = 60] loss: 0.418, accuracy: 0.812

EPOCH = 10, loss = 0.425,accuracy  = 0.808, val_loss = 0.413, val_accuracy = 0.810

================================================================================2022-02-06 13:01:46
Finished Training...</code></pre>
<h3 id="evaluate-model">2.3.3 Evaluate model</h3>
<p>我们首先评估一下模型在训练集和验证集上的效果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfhistory</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
epoch
</th>
<th>
loss
</th>
<th>
accuracy
</th>
<th>
val_loss
</th>
<th>
val_accuracy
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1.0
</td>
<td>
0.452268
</td>
<td>
0.803371
</td>
<td>
0.442081
</td>
<td>
0.782609
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2.0
</td>
<td>
0.443471
</td>
<td>
0.790730
</td>
<td>
0.427079
</td>
<td>
0.809783
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3.0
</td>
<td>
0.442639
</td>
<td>
0.806180
</td>
<td>
0.412987
</td>
<td>
0.793478
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4.0
</td>
<td>
0.438777
</td>
<td>
0.807584
</td>
<td>
0.408850
</td>
<td>
0.809783
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5.0
</td>
<td>
0.440705
</td>
<td>
0.803371
</td>
<td>
0.420241
</td>
<td>
0.798913
</td>
</tr>
<tr>
<th>
5
</th>
<td>
6.0
</td>
<td>
0.449405
</td>
<td>
0.799157
</td>
<td>
0.395391
</td>
<td>
0.804348
</td>
</tr>
<tr>
<th>
6
</th>
<td>
7.0
</td>
<td>
0.425921
</td>
<td>
0.801966
</td>
<td>
0.434522
</td>
<td>
0.782609
</td>
</tr>
<tr>
<th>
7
</th>
<td>
8.0
</td>
<td>
0.436438
</td>
<td>
0.800562
</td>
<td>
0.398559
</td>
<td>
0.782609
</td>
</tr>
<tr>
<th>
8
</th>
<td>
9.0
</td>
<td>
0.436541
</td>
<td>
0.797753
</td>
<td>
0.384473
</td>
<td>
0.809783
</td>
</tr>
<tr>
<th>
9
</th>
<td>
10.0
</td>
<td>
0.424680
</td>
<td>
0.807584
</td>
<td>
0.413394
</td>
<td>
0.809783
</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Visualization</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_metric</span>(<span class="params">dfhistory, metric</span>):</span></span><br><span class="line">    train_metrics = dfhistory[metric]</span><br><span class="line">    val_metrics = dfhistory[<span class="string">&#x27;val_&#x27;</span>+metric]</span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(train_metrics) + <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_metrics, <span class="string">&#x27;bo--&#x27;</span>)</span><br><span class="line">    plt.plot(epochs, val_metrics, <span class="string">&#x27;ro-&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Training and validation &#x27;</span>+ metric)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">    plt.ylabel(metric)</span><br><span class="line">    plt.legend([<span class="string">&quot;train_&quot;</span>+metric, <span class="string">&#x27;val_&#x27;</span>+metric])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_metric(dfhistory,<span class="string">&quot;loss&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSrh8.png' style = "zoom:80%"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_metric(dfhistory,<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSy9S.png' style = "zoom:80%"></p></li>
</ul>
<h3 id="predict">2.3.4 Predict</h3>
<ul>
<li><p>Probability</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred_probs = net(torch.tensor(x_test[<span class="number">0</span>:<span class="number">10</span>]).<span class="built_in">float</span>()).data</span><br><span class="line">y_pred_probs</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.0503],</span><br><span class="line">        [0.6572],</span><br><span class="line">        [0.3338],</span><br><span class="line">        [0.8437],</span><br><span class="line">        [0.5118],</span><br><span class="line">        [0.9191],</span><br><span class="line">        [0.1300],</span><br><span class="line">        [0.9312],</span><br><span class="line">        [0.5218],</span><br><span class="line">        [0.2221]])</span><br></pre></td></tr></table></figure></li>
<li><p>Classification</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_pred = torch.where(y_pred_probs&gt;<span class="number">0.5</span>,</span><br><span class="line">        torch.ones_like(y_pred_probs),torch.zeros_like(y_pred_probs))</span><br><span class="line">y_pred</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.],</span><br><span class="line">        [1.],</span><br><span class="line">        [0.],</span><br><span class="line">        [1.],</span><br><span class="line">        [1.],</span><br><span class="line">        [1.],</span><br><span class="line">        [0.],</span><br><span class="line">        [1.],</span><br><span class="line">        [1.],</span><br><span class="line">        [0.]])</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="save-model">2.3.5 Save model</h3>
<p><code>Pytorch</code> 有两种保存模型的方式，都是通过调用
<code>pickle</code> 序列化方法实现的。</p>
<ol type="1">
<li>只保存模型参数；</li>
<li>保存完整模型。</li>
</ol>
<p>推荐使用第一种，第二种方法可能在切换设备和目录的时候出现各种问题。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(net.state_dict().keys())</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">odict_keys([&#39;linear1.weight&#39;, &#39;linear1.bias&#39;, &#39;linear2.weight&#39;, &#39;linear2.bias&#39;, &#39;linear3.weight&#39;, &#39;linear3.bias&#39;])</span><br></pre></td></tr></table></figure>
<ul>
<li><p>保存模型参数（<span
class="math inline">\(\star\star\star\)</span>）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型参数</span></span><br><span class="line">torch.save(net.state_dict(), data_dir + <span class="string">&quot;net_parameter.pkl&quot;</span>)</span><br><span class="line"></span><br><span class="line">net_clone = create_net()</span><br><span class="line">net_clone.load_state_dict(torch.load(data_dir + <span class="string">&quot;net_parameter.pkl&quot;</span>))</span><br><span class="line"></span><br><span class="line">net_clone.forward(torch.tensor(x_test[<span class="number">0</span>:<span class="number">10</span>]).<span class="built_in">float</span>()).data</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.0503],</span><br><span class="line">        [0.6572],</span><br><span class="line">        [0.3338],</span><br><span class="line">        [0.8437],</span><br><span class="line">        [0.5118],</span><br><span class="line">        [0.9191],</span><br><span class="line">        [0.1300],</span><br><span class="line">        [0.9312],</span><br><span class="line">        [0.5218],</span><br><span class="line">        [0.2221]])</span><br></pre></td></tr></table></figure></li>
<li><p>保存完整模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.save(net, data_dir + <span class="string">&#x27;net_model.pkl&#x27;</span>)</span><br><span class="line">net_loaded = torch.load(data_dir + <span class="string">&#x27;net_model.pkl&#x27;</span>)</span><br><span class="line">net_loaded(torch.tensor(x_test[<span class="number">0</span>:<span class="number">10</span>]).<span class="built_in">float</span>()).data</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.0503],</span><br><span class="line">        [0.6572],</span><br><span class="line">        [0.3338],</span><br><span class="line">        [0.8437],</span><br><span class="line">        [0.5118],</span><br><span class="line">        [0.9191],</span><br><span class="line">        [0.1300],</span><br><span class="line">        [0.9312],</span><br><span class="line">        [0.5218],</span><br><span class="line">        [0.2221]])</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="image-classification">3. Image classification</h1>
<h2 id="data-1">3.1 Data</h2>
<h3 id="prepare-data">3.1.1 Prepare data</h3>
<p><code>cifar2</code> 数据集为 <code>cifar10</code>
数据集的子集，只包括前两种类别 <code>airplane</code> 和
<code>automobile</code>。</p>
<p>训练集有 <code>airplane</code> 和 <code>automobile</code> 图片各
<code>5000</code> 张，测试集有 <code>airplane</code> 和
<code>automobile</code> 图片各 <code>1000</code> 张。</p>
<p><code>cifar2</code> 任务的目标是训练一个模型来对飞机
<code>airplane</code> 和机动车 <code>automobile</code>
两种图片进行分类。</p>
<p>我们准备的 <code>Cifar2</code> 数据集的文件结构如下所示。</p>
<p><img src = 'https://s4.ax1x.com/2022/02/08/Hl6bDI.png' style = "zoom:80%"></p>
<p>在 <code>Pytorch</code> 中构建图片数据管道通常有两种方法。</p>
<ol type="1">
<li><p>使用 <code>torchvision</code> 中的
<code>datasets.ImageFolder</code> 来读取图片然后用
<code>DataLoader</code> 来并行加载。</p></li>
<li><p>通过继承 <code>torch.utils.data.Dataset</code>
实现用户自定义读取逻辑然后用 <code>DataLoader</code>
来并行加载。</p></li>
</ol>
<p>第二种方法是读取用户自定义数据集的通用方法，既可以读取图片数据集，也可以读取文本数据集。</p>
<p>本篇我们介绍第一种方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms,datasets</span><br><span class="line"></span><br><span class="line">transform_train = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor()])</span><br><span class="line">transform_valid = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor()])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trasform_target</span>(<span class="params">t</span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.tensor([t]).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&#x27;../data/&#x27;</span></span><br><span class="line">ds_train = datasets.ImageFolder(data_dir + <span class="string">&quot;cifar2/train/&quot;</span>,</span><br><span class="line">            transform = transform_train)</span><br><span class="line">ds_valid = datasets.ImageFolder(data_dir + <span class="string">&quot;cifar2/test/&quot;</span>,</span><br><span class="line">            transform = transform_train)</span><br><span class="line"></span><br><span class="line">print(ds_train.class_to_idx)</span><br><span class="line"></span><br><span class="line">dl_train = DataLoader(ds_train, batch_size = <span class="number">50</span>, shuffle = <span class="literal">True</span>, num_workers=<span class="number">3</span>)</span><br><span class="line">dl_valid = DataLoader(ds_valid, batch_size = <span class="number">50</span>, shuffle = <span class="literal">True</span>, num_workers=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>&#123;&#39;0_airplane&#39;: 0, &#39;1_automobile&#39;: 1&#125;</code></pre>
<p><strong>Note</strong>: 原始的代码中，<code>target_transform</code>
使用了匿名函数
<code>lambda</code>：<code>target_transform= lambda t:torch.tensor([t]).float()</code>，虽然在此处不会报错，但在后面的迭代过程中会报
<code>PicklingError</code> 错误，错误信息如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PicklingError: Can<span class="string">&#x27;t pickle &lt;function &lt;lambda&gt; at 0x000001D42D136310&gt;: attribute lookup &lt;lambda&gt; on __main__ failed</span></span><br></pre></td></tr></table></figure>
<p>为了解决该问题，此处选择将该参数去掉，并手动对后面的
<code>feature</code> 和 <code>labels</code> 进行处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">features = features.<span class="built_in">float</span>()</span><br><span class="line">labels = labels.<span class="built_in">float</span>().view(-<span class="number">1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看部分样本</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):</span><br><span class="line">    img,label = ds_train[i]</span><br><span class="line">    img = img.permute(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)</span><br><span class="line">    ax=plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    ax.imshow(img.numpy())</span><br><span class="line">    ax.set_title(<span class="string">&quot;label = %d&quot;</span>%label) <span class="comment"># 此处去掉 .item()</span></span><br><span class="line">    ax.set_xticks([])</span><br><span class="line">    ax.set_yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlS61g.png' style = "zoom:80%"></p>
<p><code>Pytorch</code> 的图片默认顺序是 <code>Batch</code>,
<code>Channel</code>, <code>Width</code>, <code>Height</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Pytorch的图片默认顺序是 Batch,Channel,Width,Height</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> dl_train:</span><br><span class="line">    print(x.shape,y.shape)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>torch.Size([50, 3, 32, 32]) torch.Size([50])</code></pre>
<h2 id="model-1">3.2 Model</h2>
<h3 id="define-model-1">3.2.1 Define model</h3>
<p>上一章提到 <code>Pytroch</code>
通常有三种方式构建模型，此处选择通过继承 <code>nn.Module</code>
基类构建自定义模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#测试AdaptiveMaxPool2d的效果</span></span><br><span class="line">pool = nn.AdaptiveMaxPool2d((<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">t = torch.randn(<span class="number">10</span>,<span class="number">8</span>,<span class="number">32</span>,<span class="number">32</span>)</span><br><span class="line">pool(t).shape</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>torch.Size([10, 8, 1, 1])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">3</span>,out_channels=<span class="number">32</span>,kernel_size = <span class="number">3</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(kernel_size = <span class="number">2</span>,stride = <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=<span class="number">32</span>,out_channels=<span class="number">64</span>,kernel_size = <span class="number">5</span>)</span><br><span class="line">        self.dropout = nn.Dropout2d(p = <span class="number">0.1</span>)</span><br><span class="line">        self.adaptive_pool = nn.AdaptiveMaxPool2d((<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.linear1 = nn.Linear(<span class="number">64</span>,<span class="number">32</span>)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.linear2 = nn.Linear(<span class="number">32</span>,<span class="number">1</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x = self.adaptive_pool(x)</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.linear1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.linear2(x)</span><br><span class="line">        y = self.sigmoid(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>Net(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)</code></pre>
<ul>
<li><p>产看模型概述</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchkeras</span><br><span class="line">torchkeras.summary(net,input_shape= (<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">----------------------------------------------------------------</span><br><span class="line">        Layer (type)               Output Shape         Param #</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">            Conv2d-1           [-1, 32, 30, 30]             896</span><br><span class="line">         MaxPool2d-2           [-1, 32, 15, 15]               0</span><br><span class="line">            Conv2d-3           [-1, 64, 11, 11]          51,264</span><br><span class="line">         MaxPool2d-4             [-1, 64, 5, 5]               0</span><br><span class="line">         Dropout2d-5             [-1, 64, 5, 5]               0</span><br><span class="line"> AdaptiveMaxPool2d-6             [-1, 64, 1, 1]               0</span><br><span class="line">           Flatten-7                   [-1, 64]               0</span><br><span class="line">            Linear-8                   [-1, 32]           2,080</span><br><span class="line">              ReLU-9                   [-1, 32]               0</span><br><span class="line">           Linear-10                    [-1, 1]              33</span><br><span class="line">          Sigmoid-11                    [-1, 1]               0</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 54,273</span><br><span class="line">Trainable params: 54,273</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Input size (MB): 0.011719</span><br><span class="line">Forward&#x2F;backward pass size (MB): 0.359634</span><br><span class="line">Params size (MB): 0.207035</span><br><span class="line">Estimated Total Size (MB): 0.578388</span><br><span class="line">----------------------------------------------------------------</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="train-model">3.2.2 Train model</h3>
<p><code>Pytorch</code>
通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。</p>
<p>同样地，有 <code>3</code> 类典型的训练循环代码风格：</p>
<ul>
<li>脚本形式训练循环；</li>
<li>函数形式训练循环；</li>
<li>类形式训练循环。</li>
</ul>
<p>此处介绍一种较通用的函数形式训练循环。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"></span><br><span class="line">model = net</span><br><span class="line">model.optimizer = torch.optim.SGD(model.parameters(),lr = <span class="number">0.01</span>)</span><br><span class="line">model.loss_func = torch.nn.BCELoss()</span><br><span class="line">model.metric_func = <span class="keyword">lambda</span> y_pred,y_true: roc_auc_score(y_true.data.numpy(),y_pred.data.numpy())</span><br><span class="line">model.metric_name = <span class="string">&quot;auc&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>定义训练循环的函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(dl_train)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>200</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span>(<span class="params">model,features,labels</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练模式，dropout层发生作用</span></span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 梯度清零</span></span><br><span class="line">    model.optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 正向传播求损失</span></span><br><span class="line">    predictions = model(features)</span><br><span class="line">    loss = model.loss_func(predictions,labels)</span><br><span class="line">    metric = model.metric_func(predictions,labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播求梯度</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    model.optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss.item(),metric.item()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">valid_step</span>(<span class="params">model,features,labels</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测模式，dropout层不发生作用</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="comment"># 关闭梯度计算</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        predictions = model(features)</span><br><span class="line">        loss = model.loss_func(predictions,labels)</span><br><span class="line">        metric = model.metric_func(predictions,labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss.item(), metric.item()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试train_step效果</span></span><br><span class="line">features,labels = <span class="built_in">next</span>(<span class="built_in">iter</span>(dl_train))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动对 features 和 labels 进行处理</span></span><br><span class="line">features = features.<span class="built_in">float</span>()</span><br><span class="line">labels = labels.<span class="built_in">float</span>().view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">train_step(model,features,labels)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(0.7002284526824951, 0.6288998357963875)</span><br></pre></td></tr></table></figure></li>
<li><p>Training</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>(<span class="params">model,epochs,dl_train,dl_valid,log_step_freq</span>):</span></span><br><span class="line"></span><br><span class="line">    metric_name = model.metric_name</span><br><span class="line">    dfhistory = pd.DataFrame(columns = [<span class="string">&quot;epoch&quot;</span>,<span class="string">&quot;loss&quot;</span>,metric_name,<span class="string">&quot;val_loss&quot;</span>,<span class="string">&quot;val_&quot;</span>+metric_name])</span><br><span class="line">    print(<span class="string">&quot;Start Training...&quot;</span>)</span><br><span class="line">    nowtime = datetime.datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)</span><br><span class="line">    print(<span class="string">&quot;==========&quot;</span>*<span class="number">8</span> + <span class="string">&quot;%s&quot;</span>%nowtime)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,epochs+<span class="number">1</span>):  </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1，训练循环-------------------------------------------------</span></span><br><span class="line">        loss_sum = <span class="number">0.0</span></span><br><span class="line">        metric_sum = <span class="number">0.0</span></span><br><span class="line">        step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step, (features,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl_train, <span class="number">1</span>):</span><br><span class="line">            features = features.<span class="built_in">float</span>()</span><br><span class="line">            labels = labels.<span class="built_in">float</span>().view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            loss,metric = train_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 打印batch级别日志</span></span><br><span class="line">            loss_sum += loss</span><br><span class="line">            metric_sum += metric</span><br><span class="line">            <span class="keyword">if</span> step%log_step_freq == <span class="number">0</span>:   </span><br><span class="line">                print((<span class="string">&quot;[step = %d] loss: %.3f, &quot;</span>+metric_name+<span class="string">&quot;: %.3f&quot;</span>) %</span><br><span class="line">                      (step, loss_sum/step, metric_sum/step))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2，验证循环-------------------------------------------------</span></span><br><span class="line">        val_loss_sum = <span class="number">0.0</span></span><br><span class="line">        val_metric_sum = <span class="number">0.0</span></span><br><span class="line">        val_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> val_step, (features,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl_valid, <span class="number">1</span>):</span><br><span class="line">            features = features.<span class="built_in">float</span>()</span><br><span class="line">            labels = labels.<span class="built_in">float</span>().view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            val_loss,val_metric = valid_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">            val_loss_sum += val_loss</span><br><span class="line">            val_metric_sum += val_metric</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3，记录日志-------------------------------------------------</span></span><br><span class="line">        info = (epoch, loss_sum/step, metric_sum/step,</span><br><span class="line">                val_loss_sum/val_step, val_metric_sum/val_step)</span><br><span class="line">        dfhistory.loc[epoch-<span class="number">1</span>] = info</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印epoch级别日志</span></span><br><span class="line">        print((<span class="string">&quot;\nEPOCH = %d, loss = %.3f,&quot;</span>+ metric_name + \</span><br><span class="line">              <span class="string">&quot;  = %.3f, val_loss = %.3f, &quot;</span>+<span class="string">&quot;val_&quot;</span>+ metric_name+<span class="string">&quot; = %.3f&quot;</span>)</span><br><span class="line">              %info)</span><br><span class="line">        nowtime = datetime.datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)</span><br><span class="line">        print(<span class="string">&quot;\n&quot;</span>+<span class="string">&quot;==========&quot;</span>*<span class="number">8</span> + <span class="string">&quot;%s&quot;</span>%nowtime)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;Finished Training...&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dfhistory</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line">epochs = <span class="number">20</span></span><br><span class="line">dfhistory = train_model(model,epochs,dl_train,dl_valid,log_step_freq = <span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Start Training...</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;2022-02-06 15:29:25</span><br><span class="line">[step &#x3D; 50] loss: 0.689, auc: 0.684</span><br><span class="line">[step &#x3D; 100] loss: 0.687, auc: 0.702</span><br><span class="line">[step &#x3D; 150] loss: 0.685, auc: 0.719</span><br><span class="line">[step &#x3D; 200] loss: 0.682, auc: 0.731</span><br><span class="line"></span><br><span class="line">EPOCH &#x3D; 1, loss &#x3D; 0.682,auc  &#x3D; 0.731, val_loss &#x3D; 0.669, val_auc &#x3D; 0.798</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">EPOCH &#x3D; 20, loss &#x3D; 0.392,auc  &#x3D; 0.919, val_loss &#x3D; 0.430, val_auc &#x3D; 0.936</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;2022-02-06 15:44:33</span><br><span class="line">Finished Training...</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="evaluate-model-1">3.2.3 Evaluate model</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfhistory</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
epoch
</th>
<th>
loss
</th>
<th>
auc
</th>
<th>
val_loss
</th>
<th>
val_auc
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1.0
</td>
<td>
0.681958
</td>
<td>
0.731338
</td>
<td>
0.668862
</td>
<td>
0.797954
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2.0
</td>
<td>
0.654892
</td>
<td>
0.771506
</td>
<td>
0.627371
</td>
<td>
0.806149
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3.0
</td>
<td>
0.608822
</td>
<td>
0.772492
</td>
<td>
0.569101
</td>
<td>
0.806107
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4.0
</td>
<td>
0.569133
</td>
<td>
0.782751
</td>
<td>
0.537821
</td>
<td>
0.812113
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5.0
</td>
<td>
0.547803
</td>
<td>
0.795203
</td>
<td>
0.516346
</td>
<td>
0.828602
</td>
</tr>
<tr>
<th>
5
</th>
<td>
6.0
</td>
<td>
0.535204
</td>
<td>
0.804953
</td>
<td>
0.501350
</td>
<td>
0.836900
</td>
</tr>
<tr>
<th>
6
</th>
<td>
7.0
</td>
<td>
0.524705
</td>
<td>
0.815323
</td>
<td>
0.501829
</td>
<td>
0.844522
</td>
</tr>
<tr>
<th>
7
</th>
<td>
8.0
</td>
<td>
0.516900
</td>
<td>
0.820933
</td>
<td>
0.484164
</td>
<td>
0.849198
</td>
</tr>
<tr>
<th>
8
</th>
<td>
9.0
</td>
<td>
0.507156
</td>
<td>
0.831129
</td>
<td>
0.473935
</td>
<td>
0.852870
</td>
</tr>
<tr>
<th>
9
</th>
<td>
10.0
</td>
<td>
0.501035
</td>
<td>
0.836087
</td>
<td>
0.494572
</td>
<td>
0.859365
</td>
</tr>
<tr>
<th>
10
</th>
<td>
11.0
</td>
<td>
0.490484
</td>
<td>
0.845260
</td>
<td>
0.458230
</td>
<td>
0.871329
</td>
</tr>
<tr>
<th>
11
</th>
<td>
12.0
</td>
<td>
0.481249
</td>
<td>
0.848306
</td>
<td>
0.447633
</td>
<td>
0.877395
</td>
</tr>
<tr>
<th>
12
</th>
<td>
13.0
</td>
<td>
0.470961
</td>
<td>
0.857883
</td>
<td>
0.467264
</td>
<td>
0.879283
</td>
</tr>
<tr>
<th>
13
</th>
<td>
14.0
</td>
<td>
0.458891
</td>
<td>
0.870709
</td>
<td>
0.420090
</td>
<td>
0.891266
</td>
</tr>
<tr>
<th>
14
</th>
<td>
15.0
</td>
<td>
0.447952
</td>
<td>
0.879920
</td>
<td>
0.426877
</td>
<td>
0.896159
</td>
</tr>
<tr>
<th>
15
</th>
<td>
16.0
</td>
<td>
0.439210
</td>
<td>
0.889682
</td>
<td>
0.392666
</td>
<td>
0.910185
</td>
</tr>
<tr>
<th>
16
</th>
<td>
17.0
</td>
<td>
0.424930
</td>
<td>
0.897675
</td>
<td>
0.459186
</td>
<td>
0.912733
</td>
</tr>
<tr>
<th>
17
</th>
<td>
18.0
</td>
<td>
0.416532
</td>
<td>
0.906937
</td>
<td>
0.426213
</td>
<td>
0.923270
</td>
</tr>
<tr>
<th>
18
</th>
<td>
19.0
</td>
<td>
0.406580
</td>
<td>
0.912283
</td>
<td>
0.377994
</td>
<td>
0.926940
</td>
</tr>
<tr>
<th>
19
</th>
<td>
20.0
</td>
<td>
0.392066
</td>
<td>
0.919133
</td>
<td>
0.429610
</td>
<td>
0.936487
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_metric</span>(<span class="params">dfhistory, metric</span>):</span></span><br><span class="line">    train_metrics = dfhistory[metric]</span><br><span class="line">    val_metrics = dfhistory[<span class="string">&#x27;val_&#x27;</span>+metric]</span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(train_metrics) + <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_metrics, <span class="string">&#x27;bo--&#x27;</span>)</span><br><span class="line">    plt.plot(epochs, val_metrics, <span class="string">&#x27;ro-&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Training and validation &#x27;</span>+ metric)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">    plt.ylabel(metric)</span><br><span class="line">    plt.legend([<span class="string">&quot;train_&quot;</span>+metric, <span class="string">&#x27;val_&#x27;</span>+metric])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_metric(dfhistory,<span class="string">&quot;loss&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSNXd.png' style = "zoom:80%"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_metric(dfhistory,<span class="string">&quot;auc&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSJpD.png' style = "zoom:80%"></p>
<h3 id="predict-1">3.2.4 Predict</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">model,dl</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        result = torch.cat([model.forward(t[<span class="number">0</span>]) <span class="keyword">for</span> t <span class="keyword">in</span> dl])</span><br><span class="line">    <span class="keyword">return</span>(result.data)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Probability</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred_probs = predict(model,dl_valid)</span><br><span class="line">y_pred_probs</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.9675],</span><br><span class="line">        [0.6920],</span><br><span class="line">        [0.1920],</span><br><span class="line">        ...,</span><br><span class="line">        [0.9491],</span><br><span class="line">        [0.8573],</span><br><span class="line">        [0.9429]])</span><br></pre></td></tr></table></figure></li>
<li><p>Classification</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.ones_like(y_pred_probs),torch.zeros_like(y_pred_probs)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[1.],</span><br><span class="line">         [1.],</span><br><span class="line">         [1.],</span><br><span class="line">         ...,</span><br><span class="line">         [1.],</span><br><span class="line">         [1.],</span><br><span class="line">         [1.]]),</span><br><span class="line"> tensor([[0.],</span><br><span class="line">         [0.],</span><br><span class="line">         [0.],</span><br><span class="line">         ...,</span><br><span class="line">         [0.],</span><br><span class="line">         [0.],</span><br><span class="line">         [0.]]))</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="save-model-1">3.2.5 Save model</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(model.state_dict().keys())</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>odict_keys([&#39;conv1.weight&#39;, &#39;conv1.bias&#39;, &#39;conv2.weight&#39;, &#39;conv2.bias&#39;,
 &#39;linear1.weight&#39;, &#39;linear1.bias&#39;, &#39;linear2.weight&#39;, &#39;linear2.bias&#39;])</code></pre>
<ul>
<li><p>Save parameters</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型参数</span></span><br><span class="line"></span><br><span class="line">torch.save(model.state_dict(), data_dir + <span class="string">&quot;model_parameter.pkl&quot;</span>)</span><br><span class="line"></span><br><span class="line">net_clone = Net()</span><br><span class="line">net_clone.load_state_dict(torch.load(data_dir + <span class="string">&quot;model_parameter.pkl&quot;</span>))</span><br><span class="line"></span><br><span class="line">predict(net_clone,dl_valid)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.6056],</span><br><span class="line">        [0.9186],</span><br><span class="line">        [0.9777],</span><br><span class="line">        ...,</span><br><span class="line">        [0.9546],</span><br><span class="line">        [0.2568],</span><br><span class="line">        [0.9221]])</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="text-classification">4. Text classification</h1>
<h2 id="data-2">4.1 Data</h2>
<h3 id="prepare-data-1">4.1.1 Prepare data</h3>
<p><code>imdb</code>
数据集的目标是根据电影评论的文本内容预测评论的情感标签。</p>
<p>训练集有 <code>20000</code>
条电影评论文本，测试集有5000条电影评论文本，其中正面评论和负面评论都各占一半。</p>
<p>文本数据预处理较为繁琐，包括中文切词（本示例不涉及），构建词典，编码转换，序列填充，构建数据管道等等。</p>
<p>在 <code>torch</code> 中预处理文本数据一般使用 <code>torchtext</code>
或者自定义 <code>Dataset</code>，<code>torchtext</code>
功能非常强大，可以构建文本分类，序列标注，问答模型，机器翻译等
<code>NLP</code> 任务的数据集。</p>
<p>下面仅演示使用它来构建文本分类数据集的方法。</p>
<p>较完整的教程可以参考以下知乎文章：<a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/65833208">《<code>pytorch</code>学习笔记—<code>Torchtext</code>》</a></p>
<ul>
<li><p><code>torchtext</code> 常见 <code>API</code> 一览</p>
<ul>
<li><code>torchtext.data.Example</code> :
用来表示一个样本，数据和标签</li>
<li><code>torchtext.vocab.Vocab</code>:
词汇表，可以导入一些预训练词向量</li>
<li><code>torchtext.data.Datasets</code>:
数据集类，<code>__getitem__</code>返回 <code>Example</code>实例,
<code>torchtext.data.TabularDataset</code> 是其子类。</li>
<li><code>torchtext.data.Field</code> :
用来定义字段的处理方法（文本字段，标签字段）创建 <code>Example</code>
时的 预处理，batch 时的一些处理操作。</li>
<li><code>torchtext.data.Iterator</code>: 迭代器，用来生成
<code>batch</code></li>
<li><code>torchtext.datasets</code>: 包含了常见的数据集。</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> string,re</span><br><span class="line"><span class="keyword">import</span> torchtext</span><br><span class="line"></span><br><span class="line">MAX_WORDS = <span class="number">10000</span>  <span class="comment"># 仅考虑最高频的10000个词</span></span><br><span class="line">MAX_LEN = <span class="number">200</span>  <span class="comment"># 每个样本保留200个词的长度</span></span><br><span class="line">BATCH_SIZE = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#分词方法</span></span><br><span class="line">tokenizer = <span class="keyword">lambda</span> x:re.sub(<span class="string">&#x27;[%s]&#x27;</span>%string.punctuation,<span class="string">&quot;&quot;</span>,x).split(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#过滤掉低频词</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filterLowFreqWords</span>(<span class="params">arr,vocab</span>):</span></span><br><span class="line">    arr = [[x <span class="keyword">if</span> x&lt;MAX_WORDS <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> example]</span><br><span class="line">           <span class="keyword">for</span> example <span class="keyword">in</span> arr]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line"><span class="comment">#1,定义各个字段的预处理方法</span></span><br><span class="line">TEXT = torchtext.legacy.data.Field(sequential=<span class="literal">True</span>, tokenize=tokenizer, lower=<span class="literal">True</span>,</span><br><span class="line">                  fix_length=MAX_LEN,postprocessing = filterLowFreqWords)</span><br><span class="line"></span><br><span class="line">LABEL = torchtext.legacy.data.Field(sequential=<span class="literal">False</span>, use_vocab=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#2,构建表格型dataset</span></span><br><span class="line"><span class="comment">#torchtext.data.TabularDataset可读取csv,tsv,json等格式</span></span><br><span class="line">ds_train, ds_valid = torchtext.legacy.data.TabularDataset.splits(</span><br><span class="line">        path= data_dir + <span class="string">&#x27;imdb&#x27;</span>, train=<span class="string">&#x27;train.tsv&#x27;</span>,test=<span class="string">&#x27;test.tsv&#x27;</span>, <span class="built_in">format</span>=<span class="string">&#x27;tsv&#x27;</span>,</span><br><span class="line">        fields=[(<span class="string">&#x27;label&#x27;</span>, LABEL), (<span class="string">&#x27;text&#x27;</span>, TEXT)],skip_header = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#3,构建词典</span></span><br><span class="line">TEXT.build_vocab(ds_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4,构建数据管道迭代器</span></span><br><span class="line">train_iter, valid_iter = torchtext.legacy.data.Iterator.splits(</span><br><span class="line">        (ds_train, ds_valid),  sort_within_batch=<span class="literal">True</span>,sort_key=<span class="keyword">lambda</span> x: <span class="built_in">len</span>(x.text),</span><br><span class="line">        batch_sizes=(BATCH_SIZE,BATCH_SIZE))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>Note</strong>：<code>TabularDataset</code> 和
<code>Field</code> 在新版的 <code>TorchText</code> 中不再位于
<code>torchtext.data</code>，而是在 <code>torchtext.legacy.data</code>
中。</p>
<ul>
<li><p>查看 <code>example</code> 信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看example信息</span></span><br><span class="line">print(ds_train[<span class="number">0</span>].text)</span><br><span class="line">print(ds_train[<span class="number">0</span>].label)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[&#39;it&#39;, &#39;really&#39;, &#39;boggles&#39;, &#39;my&#39;, &#39;mind&#39;, &#39;when&#39;, &#39;someone&#39;, &#39;comes&#39;,</span><br><span class="line">&#39;across&#39;, &#39;a&#39;, &#39;movie&#39;, &#39;like&#39;, &#39;this&#39;, &#39;and&#39;, &#39;claims&#39;, &#39;it&#39;, &#39;to&#39;,</span><br><span class="line">&#39;be&#39;, &#39;one&#39;, &#39;of&#39;, &#39;the&#39;, &#39;worst&#39;, &#39;slasher&#39;, &#39;films&#39;, &#39;out&#39;, &#39;there&#39;,</span><br><span class="line">&#39;this&#39;, &#39;is&#39;, &#39;by&#39;, &#39;far&#39;, &#39;not&#39;, &#39;one&#39;, &#39;of&#39;, &#39;the&#39;, &#39;worst&#39;, &#39;out&#39;,</span><br><span class="line">&#39;there&#39;, &#39;still&#39;, &#39;not&#39;, &#39;a&#39;, &#39;good&#39;, &#39;movie&#39;, &#39;but&#39;, &#39;not&#39;, &#39;the&#39;,</span><br><span class="line">&#39;worst&#39;, &#39;nonetheless&#39;, &#39;go&#39;, &#39;see&#39;, &#39;something&#39;, &#39;like&#39;, &#39;death&#39;,</span><br><span class="line">&#39;nurse&#39;, &#39;or&#39;, &#39;blood&#39;, &#39;lake&#39;, &#39;and&#39;, &#39;then&#39;, &#39;come&#39;, &#39;back&#39;, &#39;to&#39;,</span><br><span class="line">&#39;me&#39;, &#39;and&#39;, &#39;tell&#39;, &#39;me&#39;, &#39;if&#39;, &#39;you&#39;, &#39;think&#39;, &#39;the&#39;, &#39;night&#39;,</span><br><span class="line">&#39;brings&#39;, &#39;charlie&#39;, &#39;is&#39;, &#39;the&#39;, &#39;worst&#39;, &#39;the&#39;, &#39;film&#39;, &#39;has&#39;,</span><br><span class="line">&#39;decent&#39;, &#39;camera&#39;, &#39;work&#39;, &#39;and&#39;, &#39;editing&#39;, &#39;which&#39;, &#39;is&#39;, &#39;way&#39;,</span><br><span class="line">&#39;more&#39;, &#39;than&#39;, &#39;i&#39;, &#39;can&#39;, &#39;say&#39;, &#39;for&#39;, &#39;many&#39;, &#39;more&#39;, &#39;extremely&#39;,</span><br><span class="line">&#39;obscure&#39;, &#39;slasher&#39;, &#39;filmsbr&#39;, &#39;br&#39;, &#39;the&#39;, &#39;film&#39;, &#39;doesnt&#39;,</span><br><span class="line">&#39;deliver&#39;, &#39;on&#39;, &#39;the&#39;, &#39;onscreen&#39;, &#39;deaths&#39;, &#39;theres&#39;, &#39;one&#39;, &#39;death&#39;,</span><br><span class="line">&#39;where&#39;, &#39;you&#39;, &#39;see&#39;, &#39;his&#39;, &#39;pruning&#39;, &#39;saw&#39;, &#39;rip&#39;, &#39;into&#39;, &#39;a&#39;,</span><br><span class="line">&#39;neck&#39;, &#39;but&#39;, &#39;all&#39;, &#39;other&#39;, &#39;deaths&#39;, &#39;are&#39;, &#39;hardly&#39;, &#39;interesting&#39;,</span><br><span class="line">&#39;but&#39;, &#39;the&#39;, &#39;lack&#39;, &#39;of&#39;, &#39;onscreen&#39;, &#39;graphic&#39;, &#39;violence&#39;, &#39;doesnt&#39;,</span><br><span class="line">&#39;mean&#39;, &#39;this&#39;, &#39;isnt&#39;, &#39;a&#39;, &#39;slasher&#39;, &#39;film&#39;, &#39;just&#39;, &#39;a&#39;, &#39;bad&#39;,</span><br><span class="line">&#39;onebr&#39;, &#39;br&#39;, &#39;the&#39;, &#39;film&#39;, &#39;was&#39;, &#39;obviously&#39;, &#39;intended&#39;, &#39;not&#39;,</span><br><span class="line">&#39;to&#39;, &#39;be&#39;, &#39;taken&#39;, &#39;too&#39;, &#39;seriously&#39;, &#39;the&#39;, &#39;film&#39;, &#39;came&#39;, &#39;in&#39;,</span><br><span class="line">&#39;at&#39;, &#39;the&#39;, &#39;end&#39;, &#39;of&#39;, &#39;the&#39;, &#39;second&#39;, &#39;slasher&#39;, &#39;cycle&#39;, &#39;so&#39;,</span><br><span class="line">&#39;it&#39;, &#39;certainly&#39;, &#39;was&#39;, &#39;a&#39;, &#39;reflection&#39;, &#39;on&#39;, &#39;traditional&#39;,</span><br><span class="line">&#39;slasher&#39;, &#39;elements&#39;, &#39;done&#39;, &#39;in&#39;, &#39;a&#39;, &#39;tongue&#39;, &#39;in&#39;, &#39;cheek&#39;, &#39;way&#39;,</span><br><span class="line">&#39;for&#39;, &#39;example&#39;, &#39;after&#39;, &#39;a&#39;, &#39;kill&#39;, &#39;charlie&#39;, &#39;goes&#39;, &#39;to&#39;, &#39;the&#39;,</span><br><span class="line">&#39;towns&#39;, &#39;welcome&#39;, &#39;sign&#39;, &#39;and&#39;, &#39;marks&#39;, &#39;the&#39;, &#39;population&#39;, &#39;down&#39;,</span><br><span class="line">&#39;one&#39;, &#39;less&#39;, &#39;this&#39;, &#39;is&#39;, &#39;something&#39;, &#39;that&#39;, &#39;can&#39;, &#39;only&#39;, &#39;get&#39;,</span><br><span class="line">&#39;a&#39;, &#39;laughbr&#39;, &#39;br&#39;, &#39;if&#39;, &#39;youre&#39;, &#39;into&#39;, &#39;slasher&#39;, &#39;films&#39;,</span><br><span class="line">&#39;definitely&#39;, &#39;give&#39;, &#39;this&#39;, &#39;film&#39;, &#39;a&#39;, &#39;watch&#39;, &#39;it&#39;, &#39;is&#39;,</span><br><span class="line">&#39;slightly&#39;, &#39;different&#39;, &#39;than&#39;, &#39;your&#39;, &#39;usual&#39;, &#39;slasher&#39;, &#39;film&#39;,</span><br><span class="line">&#39;with&#39;, &#39;possibility&#39;, &#39;of&#39;, &#39;two&#39;, &#39;killers&#39;, &#39;but&#39;, &#39;not&#39;, &#39;by&#39;,</span><br><span class="line">&#39;much&#39;, &#39;the&#39;, &#39;comedy&#39;, &#39;of&#39;, &#39;the&#39;, &#39;movie&#39;, &#39;is&#39;, &#39;pretty&#39;, &#39;much&#39;,</span><br><span class="line">&#39;telling&#39;, &#39;the&#39;, &#39;audience&#39;, &#39;to&#39;, &#39;relax&#39;, &#39;and&#39;, &#39;not&#39;, &#39;take&#39;, &#39;the&#39;,</span><br><span class="line">&#39;movie&#39;, &#39;so&#39;, &#39;god&#39;, &#39;darn&#39;, &#39;serious&#39;, &#39;you&#39;, &#39;may&#39;, &#39;forget&#39;, &#39;the&#39;,</span><br><span class="line">&#39;movie&#39;, &#39;you&#39;, &#39;may&#39;, &#39;remember&#39;, &#39;it&#39;, &#39;ill&#39;, &#39;remember&#39;, &#39;it&#39;,</span><br><span class="line">&#39;because&#39;, &#39;i&#39;, &#39;love&#39;, &#39;the&#39;, &#39;name&#39;]</span><br><span class="line">0</span><br></pre></td></tr></table></figure></li>
<li><p>查看词典信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="built_in">len</span>(TEXT.vocab))</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">108197</span><br></pre></td></tr></table></figure></li>
<li><p>itos: index to string</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># itos: index to string</span></span><br><span class="line">print(TEXT.vocab.itos[<span class="number">0</span>])</span><br><span class="line">print(TEXT.vocab.itos[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;unk&gt;</span><br><span class="line">&lt;pad&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>stoi: string to index</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># stoi: string to index</span></span><br><span class="line">print(TEXT.vocab.stoi[<span class="string">&#x27;&lt;unk&gt;&#x27;</span>]) <span class="comment">#unknown 未知词</span></span><br><span class="line">print(TEXT.vocab.stoi[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]) <span class="comment">#padding  填充</span></span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0</span><br><span class="line">1</span><br></pre></td></tr></table></figure></li>
<li><p>词频</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># freqs: 词频</span></span><br><span class="line">print(TEXT.vocab.freqs[<span class="string">&#x27;&lt;unk&gt;&#x27;</span>])</span><br><span class="line">print(TEXT.vocab.freqs[<span class="string">&#x27;a&#x27;</span>])</span><br><span class="line">print(TEXT.vocab.freqs[<span class="string">&#x27;good&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">0</span><br><span class="line">129453</span><br><span class="line">11457</span><br></pre></td></tr></table></figure></li>
<li><p>查看数据管道信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数据管道信息</span></span><br><span class="line"><span class="comment"># 注意有坑：text第0维是句子长度</span></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_iter:</span><br><span class="line">    features = batch.text</span><br><span class="line">    labels = batch.label</span><br><span class="line">    print(features)</span><br><span class="line">    print(features.shape)</span><br><span class="line">    print(labels)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tensor([[   9,   11,    9,  ...,   10,    2,   10],</span><br><span class="line">        [ 921,    7,    7,  ...,  628,  902,  283],</span><br><span class="line">        [  15,   29, 1651,  ...,    6,  172,   11],</span><br><span class="line">        ...,</span><br><span class="line">        [   7,  522,  461,  ...,    1,    1,    1],</span><br><span class="line">        [ 205,    8,  108,  ...,    1,    1,    1],</span><br><span class="line">        [   0,   11,    4,  ...,    1,    1,    1]])</span><br><span class="line">torch.Size([200, 20])</span><br><span class="line">tensor([1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1])</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="数据管道转换">4.1.2 数据管道转换</h3>
<p>将数据管道组织成 <code>torch.utils.data.DataLoader</code> 相似的
<code>features</code>, <code>label</code> 输出形式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将数据管道组织成torch.utils.data.DataLoader相似的features,label输出形式</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataLoader</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,data_iter</span>):</span></span><br><span class="line">        self.data_iter = data_iter</span><br><span class="line">        self.length = <span class="built_in">len</span>(data_iter)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.length</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 注意：此处调整features为 batch first，并调整label的shape和dtype</span></span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> self.data_iter:</span><br><span class="line">            <span class="keyword">yield</span>(torch.transpose(batch.text,<span class="number">0</span>,<span class="number">1</span>),</span><br><span class="line">                  torch.unsqueeze(batch.label.<span class="built_in">float</span>(),dim = <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">dl_train = DataLoader(train_iter)</span><br><span class="line">dl_valid = DataLoader(valid_iter)</span><br></pre></td></tr></table></figure>
<h2 id="model-2">4.2 Model</h2>
<h3 id="define-model-2">4.2.1 Define model</h3>
<p>第二章提到使用 <code>Pytorch</code>
通常有三种方式构建模型，此处选择使用第三种方式进行构建。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torchkeras <span class="keyword">import</span> LightModel,summary</span><br><span class="line"></span><br><span class="line">torch.random.seed()</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#设置padding_idx参数后将在训练过程中将填充的token始终赋值为0向量</span></span><br><span class="line">        self.embedding = nn.Embedding(num_embeddings = MAX_WORDS,embedding_dim = <span class="number">3</span>,padding_idx = <span class="number">1</span>)</span><br><span class="line">        self.conv = nn.Sequential()</span><br><span class="line">        self.conv.add_module(<span class="string">&quot;conv_1&quot;</span>,nn.Conv1d(in_channels = <span class="number">3</span>,out_channels = <span class="number">16</span>,kernel_size = <span class="number">5</span>))</span><br><span class="line">        self.conv.add_module(<span class="string">&quot;pool_1&quot;</span>,nn.MaxPool1d(kernel_size = <span class="number">2</span>))</span><br><span class="line">        self.conv.add_module(<span class="string">&quot;relu_1&quot;</span>,nn.ReLU())</span><br><span class="line">        self.conv.add_module(<span class="string">&quot;conv_2&quot;</span>,nn.Conv1d(in_channels = <span class="number">16</span>,out_channels = <span class="number">128</span>,kernel_size = <span class="number">2</span>))</span><br><span class="line">        self.conv.add_module(<span class="string">&quot;pool_2&quot;</span>,nn.MaxPool1d(kernel_size = <span class="number">2</span>))</span><br><span class="line">        self.conv.add_module(<span class="string">&quot;relu_2&quot;</span>,nn.ReLU())</span><br><span class="line"></span><br><span class="line">        self.dense = nn.Sequential()</span><br><span class="line">        self.dense.add_module(<span class="string">&quot;flatten&quot;</span>,nn.Flatten())</span><br><span class="line">        self.dense.add_module(<span class="string">&quot;linear&quot;</span>,nn.Linear(<span class="number">6144</span>,<span class="number">1</span>))</span><br><span class="line">        self.dense.add_module(<span class="string">&quot;sigmoid&quot;</span>,nn.Sigmoid())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.embedding(x).transpose(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        y = self.dense(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br><span class="line"></span><br><span class="line">summary(net, input_shape = (<span class="number">200</span>,),input_dtype = torch.LongTensor)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>Net(
  (embedding): Embedding(10000, 3, padding_idx=1)
  (conv): Sequential(
    (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (relu_1): ReLU()
    (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
    (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (relu_2): ReLU()
  )
  (dense): Sequential(
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (linear): Linear(in_features=6144, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
         Embedding-1               [-1, 200, 3]          30,000
            Conv1d-2              [-1, 16, 196]             256
         MaxPool1d-3               [-1, 16, 98]               0
              ReLU-4               [-1, 16, 98]               0
            Conv1d-5              [-1, 128, 97]           4,224
         MaxPool1d-6              [-1, 128, 48]               0
              ReLU-7              [-1, 128, 48]               0
           Flatten-8                 [-1, 6144]               0
            Linear-9                    [-1, 1]           6,145
          Sigmoid-10                    [-1, 1]               0
================================================================
Total params: 40,625
Trainable params: 40,625
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.000763
Forward/backward pass size (MB): 0.287796
Params size (MB): 0.154972
Estimated Total Size (MB): 0.443531
----------------------------------------------------------------</code></pre>
<h3 id="training-model-1">4.2.2 Training model</h3>
<p>训练 <code>Pytorch</code>
通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。</p>
<p>有 <code>3</code>
类典型的训练循环代码风格：脚本形式训练循环，函数形式训练循环，类形式训练循环。</p>
<p>此处介绍一种类形式的训练循环。</p>
<p>我们利用 <code>Pytorch-Lightning</code> 定义了一个高阶的模型接口
<code>LightModel</code>, 封装在 <code>torchkeras</code> 中,
可以非常方便地训练模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pytorch_lightning <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">from</span> torchkeras <span class="keyword">import</span> LightModel</span><br><span class="line"><span class="keyword">import</span> torchmetrics <span class="keyword">as</span> metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params">LightModel</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss,and optional metrics</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shared_step</span>(<span class="params">self,batch</span>)-&gt;dict:</span></span><br><span class="line">        x, y = batch</span><br><span class="line">        prediction = self(x)</span><br><span class="line">        loss = nn.BCELoss()(prediction,y)</span><br><span class="line">        preds = torch.where(prediction&gt;<span class="number">0.5</span>,torch.ones_like(prediction),torch.zeros_like(prediction))</span><br><span class="line">        acc = metrics.functional.accuracy(preds.<span class="built_in">int</span>(), y.<span class="built_in">int</span>())</span><br><span class="line">        dic = &#123;<span class="string">&quot;loss&quot;</span>:loss,<span class="string">&quot;accuracy&quot;</span>:acc&#125;</span><br><span class="line">        <span class="keyword">return</span> dic</span><br><span class="line"></span><br><span class="line">    <span class="comment">#optimizer,and optional lr_scheduler</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">configure_optimizers</span>(<span class="params">self</span>):</span></span><br><span class="line">        optimizer= torch.optim.Adagrad(self.parameters(),lr = <span class="number">0.02</span>)</span><br><span class="line">        <span class="keyword">return</span> optimizer</span><br></pre></td></tr></table></figure>
<p><strong>Note</strong>：第六行中原始的 <code>metrics</code> 为
<code>pl.metrics</code>，但最新的版本中 <code>metrics</code>
已经被移到新的包<code>torchmetrics</code> 。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pl.seed_everything(<span class="number">1234</span>)</span><br><span class="line">net = Net()</span><br><span class="line">model = Model(net)</span><br><span class="line"></span><br><span class="line">ckpt_cb = pl.callbacks.ModelCheckpoint(monitor=<span class="string">&#x27;val_loss&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set gpus=0 will use cpu，</span></span><br><span class="line"><span class="comment"># set gpus=1 will use 1 gpu</span></span><br><span class="line"><span class="comment"># set gpus=2 will use 2gpus</span></span><br><span class="line"><span class="comment"># set gpus = -1 will use all gpus</span></span><br><span class="line"><span class="comment"># you can also set gpus = [0,1] to use the  given gpus</span></span><br><span class="line"><span class="comment"># you can even set tpu_cores=2 to use two tpus</span></span><br><span class="line"></span><br><span class="line">trainer = pl.Trainer(max_epochs=<span class="number">20</span>,gpus = <span class="number">0</span>, callbacks=[ckpt_cb])</span><br><span class="line">trainer.fit(model,dl_train,dl_valid)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">Global seed set to 1234</span><br><span class="line">GPU available: False, used: False</span><br><span class="line">TPU available: False, using: 0 TPU cores</span><br><span class="line">IPU available: False, using: 0 IPUs</span><br><span class="line"></span><br><span class="line">  | Name | Type | Params</span><br><span class="line">------------------------------</span><br><span class="line">0 | net  | Net  | 40.6 K</span><br><span class="line">------------------------------</span><br><span class="line">40.6 K    Trainable params</span><br><span class="line">0         Non-trainable params</span><br><span class="line">40.6 K    Total params</span><br><span class="line">0.163     Total estimated model params size (MB)</span><br><span class="line"></span><br><span class="line">Validation sanity check: 0it [00:00, ?it&#x2F;s]</span><br><span class="line"></span><br><span class="line">Global seed set to 1234</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;2022-02-06 17:27:40</span><br><span class="line">epoch &#x3D;  0</span><br><span class="line">&#123;&#39;val_loss&#39;: 0.6898235082626343, &#39;val_accuracy&#39;: 0.6499999761581421&#125;</span><br><span class="line"></span><br><span class="line">Training: 0it [00:00, ?it&#x2F;s]</span><br><span class="line"></span><br><span class="line">Validating: 0it [00:00, ?it&#x2F;s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;2022-02-06 17:28:29</span><br><span class="line">epoch &#x3D;  0</span><br><span class="line">&#123;&#39;val_loss&#39;: 0.6681257486343384, &#39;val_accuracy&#39;: 0.586999773979187&#125;</span><br><span class="line">&#123;&#39;loss&#39;: 0.6940434575080872, &#39;accuracy&#39;: 0.5381003022193909&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Validating: 0it [00:00, ?it&#x2F;s]</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;2022-02-06 17:42:56</span><br><span class="line">epoch &#x3D;  19</span><br><span class="line">&#123;&#39;val_loss&#39;: 0.5400923490524292, &#39;val_accuracy&#39;: 0.7785999178886414&#125;</span><br><span class="line">&#123;&#39;loss&#39;: 0.20424380898475647, &#39;accuracy&#39;: 0.9274038672447205&#125;</span><br></pre></td></tr></table></figure>
<h3 id="evaluate-model-2">4.2.3 Evaluate model</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">history = model.history</span><br><span class="line">dfhistory = pd.DataFrame(history)</span><br><span class="line">dfhistory</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
val_loss
</th>
<th>
val_accuracy
</th>
<th>
loss
</th>
<th>
accuracy
</th>
<th>
epoch
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0.668126
</td>
<td>
0.5870
</td>
<td>
0.694043
</td>
<td>
0.538100
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
0.622295
</td>
<td>
0.6486
</td>
<td>
0.619329
</td>
<td>
0.653051
</td>
<td>
1
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0.543876
</td>
<td>
0.7202
</td>
<td>
0.539137
</td>
<td>
0.725501
</td>
<td>
2
</td>
</tr>
<tr>
<th>
3
</th>
<td>
0.516527
</td>
<td>
0.7420
</td>
<td>
0.485453
</td>
<td>
0.765250
</td>
<td>
3
</td>
</tr>
<tr>
<th>
4
</th>
<td>
0.501172
</td>
<td>
0.7566
</td>
<td>
0.446320
</td>
<td>
0.791349
</td>
<td>
4
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0.493917
</td>
<td>
0.7606
</td>
<td>
0.416267
</td>
<td>
0.810600
</td>
<td>
5
</td>
</tr>
<tr>
<th>
6
</th>
<td>
0.491973
</td>
<td>
0.7642
</td>
<td>
0.390249
</td>
<td>
0.828950
</td>
<td>
6
</td>
</tr>
<tr>
<th>
7
</th>
<td>
0.485185
</td>
<td>
0.7702
</td>
<td>
0.367199
</td>
<td>
0.839549
</td>
<td>
7
</td>
</tr>
<tr>
<th>
8
</th>
<td>
0.486927
</td>
<td>
0.7722
</td>
<td>
0.348247
</td>
<td>
0.851001
</td>
<td>
8
</td>
</tr>
<tr>
<th>
9
</th>
<td>
0.487843
</td>
<td>
0.7724
</td>
<td>
0.329982
</td>
<td>
0.862001
</td>
<td>
9
</td>
</tr>
<tr>
<th>
10
</th>
<td>
0.490562
</td>
<td>
0.7718
</td>
<td>
0.312720
</td>
<td>
0.870900
</td>
<td>
10
</td>
</tr>
<tr>
<th>
11
</th>
<td>
0.506245
</td>
<td>
0.7718
</td>
<td>
0.297354
</td>
<td>
0.881451
</td>
<td>
11
</td>
</tr>
<tr>
<th>
12
</th>
<td>
0.498210
</td>
<td>
0.7748
</td>
<td>
0.283493
</td>
<td>
0.886551
</td>
<td>
12
</td>
</tr>
<tr>
<th>
13
</th>
<td>
0.501044
</td>
<td>
0.7758
</td>
<td>
0.270271
</td>
<td>
0.893802
</td>
<td>
13
</td>
</tr>
<tr>
<th>
14
</th>
<td>
0.519616
</td>
<td>
0.7736
</td>
<td>
0.257364
</td>
<td>
0.901002
</td>
<td>
14
</td>
</tr>
<tr>
<th>
15
</th>
<td>
0.517258
</td>
<td>
0.7760
</td>
<td>
0.245659
</td>
<td>
0.907853
</td>
<td>
15
</td>
</tr>
<tr>
<th>
16
</th>
<td>
0.522427
</td>
<td>
0.7788
</td>
<td>
0.234360
</td>
<td>
0.911853
</td>
<td>
16
</td>
</tr>
<tr>
<th>
17
</th>
<td>
0.525286
</td>
<td>
0.7750
</td>
<td>
0.223529
</td>
<td>
0.918153
</td>
<td>
17
</td>
</tr>
<tr>
<th>
18
</th>
<td>
0.533164
</td>
<td>
0.7780
</td>
<td>
0.213193
</td>
<td>
0.923954
</td>
<td>
18
</td>
</tr>
<tr>
<th>
19
</th>
<td>
0.540092
</td>
<td>
0.7786
</td>
<td>
0.204244
</td>
<td>
0.927404
</td>
<td>
19
</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Visualization</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_metric</span>(<span class="params">dfhistory, metric</span>):</span></span><br><span class="line">    train_metrics = dfhistory[metric]</span><br><span class="line">    val_metrics = dfhistory[<span class="string">&#x27;val_&#x27;</span>+metric]</span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(train_metrics) + <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_metrics, <span class="string">&#x27;bo--&#x27;</span>)</span><br><span class="line">    plt.plot(epochs, val_metrics, <span class="string">&#x27;ro-&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Training and validation &#x27;</span>+ metric)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">    plt.ylabel(metric)</span><br><span class="line">    plt.legend([<span class="string">&quot;train_&quot;</span>+metric, <span class="string">&#x27;val_&#x27;</span>+metric])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_metric(dfhistory,<span class="string">&quot;loss&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSY1e.png' style = "zoom:80%"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_metric(dfhistory,<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlS8fO.png' style = "zoom:80%"></p></li>
<li><p>Evaluate</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 评估</span></span><br><span class="line">results = trainer.test(model, test_dataloaders=dl_valid, verbose = <span class="literal">False</span>)</span><br><span class="line">print(results[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Testing: 0it [00:00, ?it&#x2F;s]</span><br><span class="line"></span><br><span class="line">&#123;&#39;test_loss&#39;: 0.5400923490524292, &#39;test_accuracy&#39;: 0.7785999774932861&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="predict-2">4.2.4 Predict</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">model,dl</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    result = torch.cat([model.forward(t[<span class="number">0</span>].to(model.device)) <span class="keyword">for</span> t <span class="keyword">in</span> dl])</span><br><span class="line">    <span class="keyword">return</span>(result.data)</span><br><span class="line"></span><br><span class="line">result = predict(model,dl_valid)</span><br><span class="line">result</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[0.0053],
        [0.9006],
        [0.1638],
        ...,
        [0.9836],
        [0.5532],
        [0.0018]])</code></pre>
<h3 id="save-model-2">4.2.5 Save model</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">print(ckpt_cb.best_model_score)</span><br><span class="line">model.load_from_checkpoint(ckpt_cb.best_model_path)</span><br><span class="line"></span><br><span class="line">best_net  = model.net</span><br><span class="line">torch.save(best_net.state_dict(),data_dir + <span class="string">&quot;/net.pt&quot;</span>)</span><br><span class="line"></span><br><span class="line">net_clone = Net()</span><br><span class="line">net_clone.load_state_dict(torch.load(data_dir + <span class="string">&quot;net.pt&quot;</span>))</span><br><span class="line">model_clone = Model(net_clone)</span><br><span class="line">trainer = pl.Trainer()</span><br><span class="line">result = trainer.test(model_clone,test_dataloaders=dl_valid, verbose = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tensor(0.4852)</span><br><span class="line"></span><br><span class="line">GPU available: False, used: False</span><br><span class="line">TPU available: False, using: 0 TPU cores</span><br><span class="line">IPU available: False, using: 0 IPUs</span><br><span class="line"></span><br><span class="line">Testing: 0it [00:00, ?it&#x2F;s]</span><br><span class="line"></span><br><span class="line">[&#123;&#39;test_loss&#39;: 0.5400923490524292, &#39;test_accuracy&#39;: 0.7785999774932861&#125;]</span><br></pre></td></tr></table></figure>
<h1 id="time-series-regression">5. Time series regression</h1>
<h2 id="introduction-1">5.1 Introduction</h2>
<p><code>2020年</code>
发生的新冠肺炎疫情灾难给各国人民的生活造成了诸多方面的影响。</p>
<p>有的同学是收入上的，有的同学是感情上的，有的同学是心理上的，还有的同学是体重上的。</p>
<p>本文基于中国 <code>2020</code> 年 <code>3</code>
月之前的疫情数据，建立时间序列 <code>RNN</code>
模型，对中国的新冠肺炎疫情结束时间进行预测。</p>
<h2 id="data-3">5.2 Data</h2>
<h3 id="prepare-data-2">5.2.1 Prepare data</h3>
<p>本文的数据集取自tushare，获取该数据集的方法参考了以下文章。</p>
<p>《https://zhuanlan.zhihu.com/p/109556102》</p>
<p><img src = 'https://s4.ax1x.com/2022/02/08/HlceGF.png' style = "zoom:80%"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_dir = <span class="string">&#x27;../data/&#x27;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>总数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(data_dir + <span class="string">&quot;covid-19.csv&quot;</span>,sep = <span class="string">&quot;\t&quot;</span>)</span><br><span class="line">df.plot(x = <span class="string">&quot;date&quot;</span>,y = [<span class="string">&quot;confirmed_num&quot;</span>,<span class="string">&quot;cured_num&quot;</span>,<span class="string">&quot;dead_num&quot;</span>],figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.xticks(rotation=<span class="number">60</span>);</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSt6H.png' style = "zoom:80%"></p></li>
<li><p>新增</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dfdata = df.set_index(<span class="string">&quot;date&quot;</span>)</span><br><span class="line">dfdiff = dfdata.diff(periods=<span class="number">1</span>).dropna()</span><br><span class="line">dfdiff = dfdiff.reset_index(<span class="string">&quot;date&quot;</span>)</span><br><span class="line"></span><br><span class="line">dfdiff.plot(x = <span class="string">&quot;date&quot;</span>,y = [<span class="string">&quot;confirmed_num&quot;</span>,<span class="string">&quot;cured_num&quot;</span>,<span class="string">&quot;dead_num&quot;</span>],figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.xticks(rotation=<span class="number">60</span>)</span><br><span class="line">dfdiff = dfdiff.drop(<span class="string">&quot;date&quot;</span>,axis = <span class="number">1</span>).astype(<span class="string">&quot;float32&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSd0I.png' style = "zoom:80%"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfdiff.head()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>confirmed_num</p>
</th>
<th>
<p>cured_num</p>
</th>
<th>
<p>dead_num</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>457.0</p>
</td>
<td>
<p>4.0</p>
</td>
<td>
<p>16.0</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>688.0</p>
</td>
<td>
<p>11.0</p>
</td>
<td>
<p>15.0</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>769.0</p>
</td>
<td>
<p>2.0</p>
</td>
<td>
<p>24.0</p>
</td>
</tr>
<tr>
<th>
<p>3</p>
</th>
<td>
<p>1771.0</p>
</td>
<td>
<p>9.0</p>
</td>
<td>
<p>26.0</p>
</td>
</tr>
<tr>
<th>
<p>4</p>
</th>
<td>
<p>1459.0</p>
</td>
<td>
<p>43.0</p>
</td>
<td>
<p>26.0</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<h3 id="dataloader-1">5.2.2 Dataloader</h3>
<p>下面我们通过继承 <code>torch.utils.data.Dataset</code>
实现自定义时间序列数据集。</p>
<p><code>torch.utils.data.Dataset</code>
是一个抽象类，用户想要加载自定义的数据只需要继承这个类，并且覆写其中的两个方法即可：</p>
<ul>
<li><code>__len__</code>：实现len(dataset)返回整个数据集的大小。</li>
<li><code>__getitem__</code>：用来获取一些索引的数据，使
<code>dataset[i]</code> 返回数据集中第i个样本。</li>
</ul>
<p>不覆写这两个方法会直接返回错误。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader,TensorDataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#用某日前8天窗口数据作为输入预测该日数据</span></span><br><span class="line">WINDOW_SIZE = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Covid19Dataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(dfdiff) - WINDOW_SIZE</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self,i</span>):</span></span><br><span class="line">        x = dfdiff.loc[i:i+WINDOW_SIZE-<span class="number">1</span>,:]</span><br><span class="line">        feature = torch.tensor(x.values)</span><br><span class="line">        y = dfdiff.loc[i+WINDOW_SIZE,:]</span><br><span class="line">        label = torch.tensor(y.values)</span><br><span class="line">        <span class="keyword">return</span> (feature,label)</span><br><span class="line"></span><br><span class="line">ds_train = Covid19Dataset()</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据较小，可以将全部训练数据放入到一个batch中，提升性能</span></span><br><span class="line">dl_train = DataLoader(ds_train,batch_size = <span class="number">38</span>)</span><br></pre></td></tr></table></figure>
<h2 id="model-3">5.3 Model</h2>
<h3 id="define-model-3">5.3.1 Define model</h3>
<p>前面提到使用 <code>Pytorch</code> 通常有三种方式构建模型：</p>
<ul>
<li>使用 <code>nn.Sequential</code> 按层顺序构建模型；</li>
<li>继承 <code>nn.Module</code> 基类构建自定义模型；</li>
<li>继承nn.Module基类构建模型并辅助应用模型容器进行封装。</li>
</ul>
<p>此处选择第二种方式构建模型。</p>
<p>由于接下来使用类形式的训练循环，我们进一步将模型封装成
<code>torchkeras</code> 中的 <code>Model</code> 类来获得类似
<code>Keras</code> 中高阶模型接口的功能。<code>Model</code>
类实际上继承自 <code>nn.Module</code> 类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> importlib</span><br><span class="line"><span class="keyword">import</span> torchkeras</span><br><span class="line"></span><br><span class="line">torch.random.seed()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Block,self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x,x_input</span>):</span></span><br><span class="line">        x_out = torch.<span class="built_in">max</span>((<span class="number">1</span>+x)*x_input[:,-<span class="number">1</span>,:],torch.tensor(<span class="number">0.0</span>))</span><br><span class="line">        <span class="keyword">return</span> x_out</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 3层lstm</span></span><br><span class="line">        self.lstm = nn.LSTM(input_size = <span class="number">3</span>,hidden_size = <span class="number">3</span>,num_layers = <span class="number">5</span>,batch_first = <span class="literal">True</span>)</span><br><span class="line">        self.linear = nn.Linear(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">        self.block = Block()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x_input</span>):</span></span><br><span class="line">        x = self.lstm(x_input)[<span class="number">0</span>][:,-<span class="number">1</span>,:]</span><br><span class="line">        x = self.linear(x)</span><br><span class="line">        y = self.block(x,x_input)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">model = torchkeras.Model(net)</span><br><span class="line">print(model)</span><br><span class="line"></span><br><span class="line">model.summary(input_shape=(<span class="number">8</span>,<span class="number">3</span>),input_dtype = torch.FloatTensor)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>Model(
  (net): Net(
    (lstm): LSTM(3, 3, num_layers=5, batch_first=True)
    (linear): Linear(in_features=3, out_features=3, bias=True)
    (block): Block()
  )
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
              LSTM-1                 [-1, 8, 3]             480
            Linear-2                    [-1, 3]              12
             Block-3                    [-1, 3]               0
================================================================
Total params: 492
Trainable params: 492
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.000092
Forward/backward pass size (MB): 0.000229
Params size (MB): 0.001877
Estimated Total Size (MB): 0.002197
----------------------------------------------------------------</code></pre>
<h3 id="training-model-2">5.3.2 Training model</h3>
<p>训练 <code>Pytorch</code>
通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。</p>
<p>有 <code>3</code> 类典型的训练循环代码风格：</p>
<ul>
<li>脚本形式训练循环；</li>
<li>函数形式训练循环；</li>
<li>类形式训练循环。</li>
</ul>
<p>此处介绍一种类形式的训练循环。</p>
<p>我们仿照 <code>Keras</code> 定义了一个高阶的模型接口
<code>Model</code>, 实现 <code>fit</code>,
<code>validate</code>，<code>predict</code>, <code>summary</code>
方法，相当于用户自定义高阶API。</p>
<p>注：循环神经网络调试较为困难，需要设置多个不同的学习率多次尝试，以取得较好的效果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mspe</span>(<span class="params">y_pred,y_true</span>):</span></span><br><span class="line">    err_percent = (y_true - y_pred)**<span class="number">2</span>/(torch.<span class="built_in">max</span>(y_true**<span class="number">2</span>,torch.tensor(<span class="number">1e-7</span>)))</span><br><span class="line">    <span class="keyword">return</span> torch.mean(err_percent)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss_func = mspe,optimizer = torch.optim.Adagrad(model.parameters(),lr = <span class="number">0.1</span>))</span><br><span class="line">dfhistory = model.fit(<span class="number">100</span>,dl_train,log_step_freq=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>Resulst:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Start Training ...</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;2022-02-06 18:24:32</span><br><span class="line">&#123;&#39;step&#39;: 1, &#39;loss&#39;: 0.237&#125;</span><br><span class="line"></span><br><span class="line"> +-------+-------+</span><br><span class="line">| epoch |  loss |</span><br><span class="line">+-------+-------+</span><br><span class="line">|   1   | 0.237 |</span><br><span class="line">+-------+-------+</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;2022-02-06 18:24:35</span><br><span class="line">&#123;&#39;step&#39;: 1, &#39;loss&#39;: 0.233&#125;</span><br><span class="line"></span><br><span class="line"> +-------+-------+</span><br><span class="line">| epoch |  loss |</span><br><span class="line">+-------+-------+</span><br><span class="line">|  100  | 0.233 |</span><br><span class="line">+-------+-------+</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;2022-02-06 18:24:35</span><br><span class="line">Finished Training...</span><br></pre></td></tr></table></figure>
<h3 id="evaluate-model-3">5.3.3 Evaluate model</h3>
<p>评估模型一般要设置验证集或者测试集，由于此例数据较少，我们仅仅可视化损失函数在训练集上的迭代情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_metric</span>(<span class="params">dfhistory, metric</span>):</span></span><br><span class="line">    train_metrics = dfhistory[metric]</span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(train_metrics) + <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_metrics, <span class="string">&#x27;bo--&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Training &#x27;</span>+ metric)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">    plt.ylabel(metric)</span><br><span class="line">    plt.legend([<span class="string">&quot;train_&quot;</span>+metric])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_metric(dfhistory,<span class="string">&quot;loss&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src = 'https://s4.ax1x.com/2022/02/07/HlSanA.png' style = "zoom:80%"></p>
<h3 id="predict-3">5.3.4 Predict</h3>
<p>此处我们使用模型预测疫情结束时间，即新增确诊病例为 <code>0</code>
的时间。</p>
<ul>
<li><p>使用 <code>dfresult</code> 记录现有数据以及此后预测的疫情数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用dfresult记录现有数据以及此后预测的疫情数据</span></span><br><span class="line">dfresult = dfdiff[[<span class="string">&quot;confirmed_num&quot;</span>,<span class="string">&quot;cured_num&quot;</span>,<span class="string">&quot;dead_num&quot;</span>]].copy()</span><br><span class="line">dfresult.tail()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>confirmed_num</p>
</th>
<th>
<p>cured_num</p>
</th>
<th>
<p>dead_num</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>41</p>
</th>
<td>
<p>143.0</p>
</td>
<td>
<p>1681.0</p>
</td>
<td>
<p>30.0</p>
</td>
</tr>
<tr>
<th>
<p>42</p>
</th>
<td>
<p>99.0</p>
</td>
<td>
<p>1678.0</p>
</td>
<td>
<p>28.0</p>
</td>
</tr>
<tr>
<th>
<p>43</p>
</th>
<td>
<p>44.0</p>
</td>
<td>
<p>1661.0</p>
</td>
<td>
<p>27.0</p>
</td>
</tr>
<tr>
<th>
<p>44</p>
</th>
<td>
<p>40.0</p>
</td>
<td>
<p>1535.0</p>
</td>
<td>
<p>22.0</p>
</td>
</tr>
<tr>
<th>
<p>45</p>
</th>
<td>
<p>19.0</p>
</td>
<td>
<p>1297.0</p>
</td>
<td>
<p>17.0</p>
</td>
</tr>
</tbody>
</table></li>
<li><p>预测此后 <code>200</code> 天的新增走势,将其结果添加到
<code>dfresult</code> 中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#预测此后200天的新增走势,将其结果添加到dfresult中</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    arr_input = torch.unsqueeze(torch.from_numpy(dfresult.values[-<span class="number">38</span>:,:]),axis=<span class="number">0</span>)</span><br><span class="line">    arr_predict = model.forward(arr_input)</span><br><span class="line"></span><br><span class="line">    dfpredict = pd.DataFrame(torch.floor(arr_predict).data.numpy(),</span><br><span class="line">                columns = dfresult.columns)</span><br><span class="line">    dfresult = dfresult.append(dfpredict,ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>查询新增确诊为零的日期</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfresult.query(<span class="string">&quot;confirmed_num==0&quot;</span>).head()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>confirmed_num</p>
</th>
<th>
<p>cured_num</p>
</th>
<th>
<p>dead_num</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>50</p>
</th>
<td>
<p>0.0</p>
</td>
<td>
<p>1006.0</p>
</td>
<td>
<p>3.0</p>
</td>
</tr>
<tr>
<th>
<p>51</p>
</th>
<td>
<p>0.0</p>
</td>
<td>
<p>956.0</p>
</td>
<td>
<p>2.0</p>
</td>
</tr>
<tr>
<th>
<p>52</p>
</th>
<td>
<p>0.0</p>
</td>
<td>
<p>909.0</p>
</td>
<td>
<p>1.0</p>
</td>
</tr>
<tr>
<th>
<p>53</p>
</th>
<td>
<p>0.0</p>
</td>
<td>
<p>864.0</p>
</td>
<td>
<p>0.0</p>
</td>
</tr>
<tr>
<th>
<p>54</p>
</th>
<td>
<p>0.0</p>
</td>
<td>
<p>821.0</p>
</td>
<td>
<p>0.0</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<p>第 <code>50</code> 天开始新增确诊降为 <code>0</code>，第
<code>45</code> 天对应 <code>3</code> 月 <code>10</code> 日，也就是
<code>5</code> 天后，即预计 <code>3</code> 月 <code>15</code>
日新增确诊降为 <code>0</code>。</p>
<p><strong>注</strong>：该预测偏乐观。</p>
<ul>
<li><p>新增治愈人数为零</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfresult.query(<span class="string">&quot;cured_num==0&quot;</span>).head()</span><br></pre></td></tr></table></figure>
<p>Results：</p>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>confirmed_num</p>
</th>
<th>
<p>cured_num</p>
</th>
<th>
<p>dead_num</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>140</p>
</th>
<td>
<p>0.0</p>
</td>
<td>
<p>0.0</p>
</td>
<td>
<p>0.0</p>
</td>
</tr>
<tr>
<th>
<p>141</p>
</th>
<td>
<p>0.0</p>
</td>
<td>
<p>0.0</p>
</td>
<td>
<p>0.0</p>
</td>
</tr>
<tr>
<th>
<p>142</p>
</th>
<td>
<p>0.0</p>
</td>
<td>
<p>0.0</p>
</td>
<td>
<p>0.0</p>
</td>
</tr>
<tr>
<th>
<p>143</p>
</th>
<td>
<p>0.0</p>
</td>
<td>
<p>0.0</p>
</td>
<td>
<p>0.0</p>
</td>
</tr>
<tr>
<th>
<p>144</p>
</th>
<td>
<p>0.0</p>
</td>
<td>
<p>0.0</p>
</td>
<td>
<p>0.0</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<p>第 <code>132</code> 天开始新增治愈降为 <code>0</code>，第
<code>45</code> 天对应 <code>3</code> 月 <code>10</code> 日，也就是大概
<code>3</code> 个月后，即 <code>6</code> 月 <code>10</code>
日左右全部治愈。</p>
<p><strong>注</strong>:
该预测偏悲观，并且存在问题，如果将每天新增治愈人数加起来，将超过累计确诊人数。</p>
<h3 id="save-model-3">5.3.5 Save model</h3>
<p>推荐使用保存参数方式保存模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型参数</span></span><br><span class="line"></span><br><span class="line">torch.save(model.net.state_dict(), data_dir + <span class="string">&quot;model_parameter.pkl&quot;</span>)</span><br><span class="line"></span><br><span class="line">net_clone = Net()</span><br><span class="line">net_clone.load_state_dict(torch.load(data_dir + <span class="string">&quot;model_parameter.pkl&quot;</span>))</span><br><span class="line">model_clone = torchkeras.Model(net_clone)</span><br><span class="line">model_clone.<span class="built_in">compile</span>(loss_func = mspe)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">model_clone.evaluate(dl_train)</span><br></pre></td></tr></table></figure>
<p>Results：</p>
<pre><code>&#123;&#39;val_loss&#39;: 0.23351764678955078&#125;</code></pre>

    </div>

    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">
            -------------This blog is over!
            <i class="fa fa-eye"></i>
            Thanks for your reading-------------
        </div>
    
</div>
      
    </div>
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>YangSu
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="http://yangsuoly.com/2022/02/08/Eat-pytorch-1-modeling/" title="Eat-pytorch-1-modeling">http://yangsuoly.com/2022/02/08/Eat-pytorch-1-modeling/</a>
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/Tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
              <a href="/Tags/Pytorch/" rel="tag"><i class="fa fa-tag"></i> Pytorch</a>
              <a href="/Tags/Deep-learning/" rel="tag"><i class="fa fa-tag"></i> Deep learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/02/07/Eat-pytorch-6-hyperAPI/" rel="prev" title="Eat-pytorch-6-hyperAPI">
      <i class="fa fa-chevron-left"></i> Eat-pytorch-6-hyperAPI
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/03/15/Tianchi-nlp/" rel="next" title="Tianchi-nlp">
      Tianchi-nlp <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div id="music163player">
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1317956275&auto=0&height=66"></iframe>
      </iframe>
    </div>
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#introduction"><span class="nav-text">1. Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#preface"><span class="nav-text">1.1 Preface</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pytoch-%E7%9A%84%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B"><span class="nav-text">1.2 Pytoch 的建模流程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#structured-numeric-classication"><span class="nav-text">2. Structured numeric
classication</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#data"><span class="nav-text">2.1 Data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#load-data"><span class="nav-text">2.1.1 Load data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eda"><span class="nav-text">2.1.2 EDA</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#preprocessing"><span class="nav-text">2.2 Preprocessing</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-text">2.2.1 预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dataloader"><span class="nav-text">2.2.2 Dataloader</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#model"><span class="nav-text">2.3 Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#define-model"><span class="nav-text">2.3.1 Define model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#training-model"><span class="nav-text">2.3.2 Training model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#evaluate-model"><span class="nav-text">2.3.3 Evaluate model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#predict"><span class="nav-text">2.3.4 Predict</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#save-model"><span class="nav-text">2.3.5 Save model</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#image-classification"><span class="nav-text">3. Image classification</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#data-1"><span class="nav-text">3.1 Data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#prepare-data"><span class="nav-text">3.1.1 Prepare data</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#model-1"><span class="nav-text">3.2 Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#define-model-1"><span class="nav-text">3.2.1 Define model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#train-model"><span class="nav-text">3.2.2 Train model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#evaluate-model-1"><span class="nav-text">3.2.3 Evaluate model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#predict-1"><span class="nav-text">3.2.4 Predict</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#save-model-1"><span class="nav-text">3.2.5 Save model</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#text-classification"><span class="nav-text">4. Text classification</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#data-2"><span class="nav-text">4.1 Data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#prepare-data-1"><span class="nav-text">4.1.1 Prepare data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93%E8%BD%AC%E6%8D%A2"><span class="nav-text">4.1.2 数据管道转换</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#model-2"><span class="nav-text">4.2 Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#define-model-2"><span class="nav-text">4.2.1 Define model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#training-model-1"><span class="nav-text">4.2.2 Training model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#evaluate-model-2"><span class="nav-text">4.2.3 Evaluate model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#predict-2"><span class="nav-text">4.2.4 Predict</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#save-model-2"><span class="nav-text">4.2.5 Save model</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#time-series-regression"><span class="nav-text">5. Time series regression</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#introduction-1"><span class="nav-text">5.1 Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#data-3"><span class="nav-text">5.2 Data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#prepare-data-2"><span class="nav-text">5.2.1 Prepare data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dataloader-1"><span class="nav-text">5.2.2 Dataloader</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#model-3"><span class="nav-text">5.3 Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#define-model-3"><span class="nav-text">5.3.1 Define model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#training-model-2"><span class="nav-text">5.3.2 Training model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#evaluate-model-3"><span class="nav-text">5.3.3 Evaluate model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#predict-3"><span class="nav-text">5.3.4 Predict</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#save-model-3"><span class="nav-text">5.3.5 Save model</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="YangSu"
      src="/images/YangSu.jpg">
  <p class="site-author-name" itemprop="name">YangSu</p>
  <div class="site-description" itemprop="description">A blog for recording learning notes...</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">58</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/Categories/">
          
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/Tags/">
          
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/YangSuoly" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;YangSuoly" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://gitee.com/yangsuoly" title="Gitee → https:&#x2F;&#x2F;gitee.com&#x2F;yangsuoly" rel="noopener" target="_blank"><i class="fab fa-github-square fa-fw"></i>Gitee</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/64518717" title="B 站 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;64518717" rel="noopener" target="_blank"><i class="fa fa-play-circle fa-fw"></i>B 站</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Related links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.58pic.com/u/19637930/" title="https:&#x2F;&#x2F;www.58pic.com&#x2F;u&#x2F;19637930&#x2F;" rel="noopener" target="_blank">千图网</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YangSu</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'http://yangsuoly.com/2022/02/08/Eat-pytorch-1-modeling/',]
      });
      });
  </script>

  
  <script id="ribbon" src="js/canvas-ribbon.js"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/22.2017.cba-normal.model.json"},"display":{"position":"right","width":300,"height":450},"mobile":{"show":false},"react":{"opacity":0.7},"log":false});</script></body>
</html>
