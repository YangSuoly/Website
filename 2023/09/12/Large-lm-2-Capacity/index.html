<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/blog-logo-32px.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/blog-logo-16px.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="manifest" href="/images/manifest.json">
  <meta name="msapplication-config" content="/images/browserconfig.xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yangsuoly.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="2. 大预言模型的能力 在本次课程中，我们将深入探讨 GPT-3 大预言模型的能力。我们的研究主要是基于 GPT-3论文 中的基准测试，这些测试包括：  标准的自然语言处理（NLP）基准测试，例如问题回答； 一些特殊的一次性演示，例如在句子中使用新词。">
<meta property="og:type" content="article">
<meta property="og:title" content="Large-lm-2-Capacity">
<meta property="og:url" content="http://yangsuoly.com/2023/09/12/Large-lm-2-Capacity/index.html">
<meta property="og:site_name" content="独孤诗人的学习驿站">
<meta property="og:description" content="2. 大预言模型的能力 在本次课程中，我们将深入探讨 GPT-3 大预言模型的能力。我们的研究主要是基于 GPT-3论文 中的基准测试，这些测试包括：  标准的自然语言处理（NLP）基准测试，例如问题回答； 一些特殊的一次性演示，例如在句子中使用新词。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/YangSuoly/Images/Large-LM/202309121256229.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/YangSuoly/Images/Large-LM/202309121304667.png">
<meta property="article:published_time" content="2023-09-12T00:42:57.000Z">
<meta property="article:modified_time" content="2023-09-12T05:09:37.770Z">
<meta property="article:author" content="YangSu">
<meta property="article:tag" content="LM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/YangSuoly/Images/Large-LM/202309121256229.png">

<link rel="canonical" href="http://yangsuoly.com/2023/09/12/Large-lm-2-Capacity/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Large-lm-2-Capacity | 独孤诗人的学习驿站</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f59f5fb59d32ec3903088b0f976956d1";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">独孤诗人的学习驿站</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">生活就是一半烟火，一半诗意。手执烟火谋生活，心怀诗意谋未来……</p>
      <a>
        <img class="custom-logo-image" src="/images/logo@2x.png" alt="独孤诗人的学习驿站">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/Tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/Categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/YangSuoly" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yangsuoly.com/2023/09/12/Large-lm-2-Capacity/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/YangSu.jpg">
      <meta itemprop="name" content="YangSu">
      <meta itemprop="description" content="A blog for recording learning notes...">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="独孤诗人的学习驿站">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Large-lm-2-Capacity
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-09-12 08:42:57 / Modified: 13:09:37" itemprop="dateCreated datePublished" datetime="2023-09-12T08:42:57+08:00">2023-09-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/Categories/DataWhale/" itemprop="url" rel="index"><span itemprop="name">DataWhale</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/Categories/DataWhale/Large-LM/" itemprop="url" rel="index"><span itemprop="name">Large LM</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>10k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>9 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="大预言模型的能力">2. 大预言模型的能力</h1>
<h6
id="在本次课程中我们将深入探讨-gpt-3-大预言模型的能力我们的研究主要是基于-gpt-3论文-中的基准测试这些测试包括">在本次课程中，我们将深入探讨
GPT-3 大预言模型的能力。我们的研究主要是基于 <a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2005.14165.pdf">GPT-3论文</a>
中的基准测试，这些测试包括：</h6>
<ul>
<li>标准的自然语言处理（NLP）基准测试，例如问题回答；</li>
<li>一些特殊的一次性演示，例如在句子中使用新词。</li>
</ul>
<a id="more"></a>
<p>对比每个任务的最新技术成果，发现模型的结果参差不齐：</p>
<ul>
<li><p>在某些任务上，比如语言建模，<code>GPT-3</code>
大幅度超越了现有技术的最高水平；</p></li>
<li><p>在其他任务上，<code>GPT-3</code>
与训练有素、拥有大量标签数据的系统竞争时，却明显落后。</p></li>
</ul>
<p>理解这些结果呢？</p>
<ul>
<li><p>首先，<code>GPT-3</code>
并未明确针对这些任务进行训练，它只是作为一个语言模型，被训练来预测下一个词。平均来看，它仍然可以在广泛的
<code>NLP</code> 任务中做得不错。</p></li>
<li><p>由于 <code>GPT-3</code>
并未特别针对任何这些任务进行训练，因此它并未过度拟合，意味着它有很大的潜力在许多其他任务上表现良好（就像在一次性任务上的表现一样）。</p></li>
</ul>
<p>此外，如果你希望在任何特定任务（例如问题回答）上表现良好，原则上你应能够利用大量的标签数据来适应<code>GPT-3</code>，并超越当前的技术水平。</p>
<h2 id="语言模型的适应性">2.1 语言模型的适应性</h2>
<p>在自然语言处理中，语言模型 <span class="math inline">\(p\)</span>
是对 <code>token</code> 序列 <span
class="math inline">\(x_{1:L}\)</span> 的分布。这样的模型能够用于：</p>
<ul>
<li>评估序列，如：<span
class="math inline">\(p(\text{𝗍𝗁𝖾,𝗆𝗈𝗎𝗌𝖾,𝖺𝗍𝖾,𝗍𝗁𝖾,𝖼𝗁𝖾𝖾𝗌𝖾})\)</span>。</li>
<li>给定提示的条件下生成完成的序列，如： <span
class="math inline">\(\text{𝗍𝗁𝖾 𝗆𝗈𝗎𝗌𝖾 𝖺𝗍𝖾}⇝\text{𝗍𝗁𝖾
𝖼𝗁𝖾𝖾𝗌𝖾}\)</span>。</li>
</ul>
<p>此处，任务被定义为从输入映射到输出。以问答为例，我们可能有如下的任务：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：What school did Burne Hogarth establish?</span><br><span class="line">输出：School of Visual Arts</span><br></pre></td></tr></table></figure>
<p>我们使用“适应（Adaptation）”一词来指代将语言模型转化为任务模型的过程。这个过程需要以下两个输入：</p>
<ol type="1">
<li>任务的自然语言描述</li>
<li>一组训练实例（输入-输出对）</li>
</ol>
<p>我们主要有两种方式来进行这种适应：</p>
<ul>
<li><p>训练（标准的有监督学习）：训练一个新模型，使其能将输入映射到输出。这可以通过创建一个新模型并利用语言模型作为特征（探针法），或者从现有的语言模型出发，根据训练实例进行更新（微调），或者在这两者之间找到平衡（轻量级的微调）。</p></li>
<li><p>提示（上下文学习）：根据描述和训练实例构建一个或一组提示，将其输入到语言模型中以获取完成的序列。</p></li>
</ul>
<p>根据训练实例的数量，我们还可以进一步细分：</p>
<ul>
<li>零样本学习(Zero-shot)：训练样本为<code>0</code></li>
<li>单样本学习(One-shot)：训练样本为 <code>1</code></li>
<li>少样本学习(Few-shot)：训练样本为少数</li>
</ul>
<p>在这个选择过程中，训练可能会面临过拟合问题。（例如，用 5
个案例微调一个 1750
亿参数的模型）。如何有效进行训练将会在后续内容中进行讨论。现在，我们将先满足于使用提示进行
<code>GPT-3</code> 的适应。</p>
<p><strong>注</strong>：提示的局限性在于我们只能利用少量的训练实例（最多只能塞进一个提示的数量）。这种输入的局限性由于Transformer自身的局限性导致的，其中提示和完成都必须适应
<code>2048</code> 个tokens。</p>
<p>在GPT-3的论文中，作者们评估了 <code>GPT-3</code>
在大量任务上的表现。我们将选择其中的一部分，对于每个任务，我们会讨论以下几点：</p>
<ul>
<li>定义：任务是什么，以及其动机？</li>
<li>适应：我们如何通过提示将任务简化为语言模型？</li>
<li>结果：与任务特定的最先进模型相比，数量性能如何？</li>
</ul>
<p>模型的大小和训练样本的数量都很重要。默认情况下，结果将基于：</p>
<ul>
<li>完整的 <code>GPT-3</code> 模型（davinci），其拥有1750亿参数</li>
<li>使用尽可能多的训练实例进行上下文学习，这些实例都可以塞进提示。</li>
</ul>
<p>在此过程中，我们将进行消融实验，以查看模型的大小和上下文训练实例的数量是否真的重要。而结果告诉我们，答案是肯定的，更多总是更好。我们选择的任务如下：</p>
<ul>
<li>Language modeling</li>
<li>Question answering</li>
<li>Translation</li>
<li>Arithmetic</li>
<li>News article generation</li>
<li>Novel tasks</li>
</ul>
<h3 id="language-modeling">2.2 Language Modeling</h3>
<p>回顾 <a
target="_blank" rel="noopener" href="https://www.yangsuoly.com/2023/09/11/Large-lm-1-Introduction/#more">上一章</a>
中提到的语言模型的内容，语言模型 <span class="math inline">\(p\)</span>
是关于词汇序列的概率分布。假设有一段文本 <span
class="math inline">\(x_{1:L}\)</span>，例如： <span
class="math display">\[
\text{𝗍𝗁𝖾 𝗆𝗈𝗎𝗌𝖾 𝖺𝗍𝖾 𝗍𝗁𝖾 𝖼𝗁𝖾𝖾𝗌𝖾}
\]</span>
我们知道，联合概率可以通过链式规则分解为每个令牌的条件概率的乘积： <span
class="math display">\[
p(x_{1:L}) = \prod_{i=1}^L p(x_i \mid x_{1:i-1}).
\]</span>
这里我们介绍一下困惑度（Perplexity）的概念。困惑度是自然语言处理和语言模型中的一个重要指，用于衡量语言模型的性能。它可以理解为模型在预测下一个词时的平均不确定性。</p>
<p>简单来说，如果一个模型的困惑度较低，那么它在预测下一个词的时候就会更加准确。对于给定的语言模型和一个测试数据集，困惑度被定义为：
<span class="math display">\[
P(X) = P(x_1,x_2,...,x_N)^{(-1/N)}
\]</span> 其中，<span
class="math inline">\(X=x_{1},x_{2},...,x_{N}\)</span>
是测试集中的词序列，<span class="math inline">\(N\)</span>
是测试集中的总词数。困惑度与语言模型的质量紧密相关，一个优秀的语言模型应能准确预测测试数据中的词序列，因此它的困惑度应较低。相反，如果语言模型经常做出错误的预测，那么它的困惑度将较高。</p>
<p>一个序列的联合概率取决于其长度，并且随着长度的增长，其值趋近于零，这使得困惑度变得难以追踪。直观上，我们希望对每个词标记（token）的概率
<span class="math inline">\(p(x_{i}∣x_{1:i−1})\)</span> 进行平均。这里的
<span class="math inline">\(p(x_i∣x_{1:i−1})\)</span>
表示给定之前的词序列 <span class="math inline">\(x_{1:i−1}\)</span>
后，下一个词 <span class="math inline">\(x_{i}\)</span> 出现的概率。</p>
<p>我们不希望采取算术平均，因为如果给一个词标记分配了 <code>0</code>
的概率，即模型认为这个词在特定的上下文中不可能出现。然而，算术平均简单地将所有词标记的概率加在一起，然后除以总数，此时低概率可能会被其他较高的概率抵消。</p>
<p>因此，困惑度（perplexity）最终采用了几何平均。在几何平均中，每个词标记的概率都被同等看待，并且一个极低的概率（如
<code>0</code>
）将会导致整个几何平均大幅度下降。因此，借助几何平均可以更好地衡量模型在处理所有可能的词标记时的性能，特别是在处理模型可能会出错的情况：
<span class="math display">\[
\operatorname{perplexity}_p\left(x_{1: L}\right)=\exp \left(\frac{1}{L}
\sum_{i=1}^L \log \frac{1}{p\left(x_i \mid x_{1: i-1}\right)}\right)
\text {. }
\]</span></p>
<p>困惑度可以被理解为每个标记（token）的平均"分支因子（branching
factor）"。这里的"分支因子"，可以理解为在每个特定的词或标记出现后，语言模型预测下一个可能出现的词或标记的平均数量。因此，它实际上是度量模型预测的多样性和不确定性的一种方式。</p>
<p>这个理解与公式中的 <span class="math inline">\(\log
\frac{1}{p\left(x_i \mid x_{1: i-1}\right)}\)</span>
密切相关，这个表达式代表了编码长度。我们在计算的是平均编码长度，这个长度反映了给定当前词或标记后，下一个词或标记可能的选择数量。因此，通过对平均编码长度取指数，我们可以得到可能的选择数量，这也就是"分支因子"。</p>
<p>为了更好地理解，我们可以考虑一个均匀分布的例子：一个长度为
<code>3</code> 的二进制字符串可以编码 <span
class="math inline">\(2^3=8\)</span>
个可能的字符串。类比到大语言模型：在给定特定词或标记后，模型需要从多个可能的选项中预测下一个词或标记。如果选择的可能性多，模型的预测任务就更为复杂，相应的困惑度就会更高。</p>
<p><strong>两类错误</strong>：语言模型可能会犯两种类型的错误，而困惑度对这两种错误的处理方式并不对称：</p>
<ul>
<li><p>召回错误：语言模型未能正确地为某个词符分配概率值。</p>
<p>如果模型为词组 <code>𝖺𝗍𝖾</code> 在 <code>𝗍𝗁𝖾, 𝗆𝗈𝗎𝗌𝖾</code>
后出现的预测概率接近 0，则对应的困惑度值将趋近于无穷大。</p></li>
</ul>
<p><span class="math display">\[
p(\text{ate} \mid \text{the}, \text{mouse}) \to 0 \quad\Rightarrow\quad
\text{perplexity}_p(\text{the, mouse, ate, the, cheese}) \to \infty
\]</span></p>
<ul>
<li><p>精确度错误：语言模型为某些错误的词序列过度分配了概率值。</p>
<p>在这种情况下，困惑度会进行适度的惩罚。给定语言模型
p，假设将一些垃圾分布 <span class="math inline">\(r\)</span> 按照概率
<span class="math inline">\(ϵ\)</span> 混入：</p></li>
</ul>
<p><span class="math display">\[
q(x_i \mid x_{1:i-1}) = (1-\epsilon) p(x_i \mid x_{1:i-1}) + \epsilon
r(x_i \mid x_{1:i-1}).
\]</span></p>
<p>那么，我们可以计算在 <span class="math inline">\(q\)</span> 下的
<span class="math inline">\(x_{1:L}\)</span> 的困惑度： <span
class="math display">\[
\text{perplexity}_q(x_{1:L}) \le \frac{1}{1 - \epsilon}
\text{perplexity}_p(x_{1:L}) \approxeq (1 + \epsilon)
\text{perplexity}_p(x_{1:L}),
\]</span> 其中，最后一个近似等式在 <span
class="math inline">\(ϵ\)</span> 的值较小时成立。如果我们混入<span
class="math inline">\(5\%\)</span> 的垃圾信息，那么困惑度只增加 <span
class="math inline">\(5\%\)</span>。需要注意的是，这样生成的语言结果会非常糟糕，因为平均每
20 个词符就会生成一个无意义的词符。</p>
<h3 id="penn-tree-bank">2.2.1 Penn Tree Bank</h3>
<p><a target="_blank" rel="noopener" href="https://catalog.ldc.upenn.edu/LDC99T42">Penn Tree Bank
(PTB)</a>
是自然语言处理中的一个经典数据集，最初是为了进行句法解析而标注的。从 <a
target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=1325968">Emami
&amp; Jelinek (2004)</a> 和 <a
target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6424228">Mikolov
&amp; Zweig (2012)</a>
开始，一个只包含华尔街日报文章的版本被用作语言模型评估。需要注意的是，<code>PTB</code>
语言模型基准测试涉及对原始数据集的一些重要预处理。</p>
<ul>
<li>适应性测试。将整个文本作为提示输入到 <code>GPT-3</code>
中，并评估其困惑度（示例）："</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pierre Vinken, 61 years old, will join the board as a nonexecutive director Nov. 29. Mr. Vinken is chairman of Elsevier N.V., the Dutch publishing group.</span><br></pre></td></tr></table></figure>
<p><strong>结果：</strong>
GPT-3大幅度的超过了目前的最好结果（state-of-the-art）</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Perplexity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GPT-3</td>
<td style="text-align: center;"><strong>20.5</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">BERT-Large-CAs1</td>
<td style="text-align: center;">31.3</td>
</tr>
</tbody>
</table>
<p>那这个结果是否存在训练/测试泄露问题呢？作者没有在一些数据集上进行评估，例如
WikiText-103。我们知道<code>GPT-3</code>
是在维基百科上进行训练的，因此在这方面 <code>PTB</code>
是具有优势的，因为它早于互联网，并且只能通过付费许可获得，或许泄露问题会有所缓解。</p>
<p>但是我们也要知道，数据泄露是当前大型数据集的另一个复杂问题：很难检查你的测试数据是否出现在你的训练数据中，并被记忆下来。</p>
<h3 id="lambada">2.2.2 <a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1606.06031.pdf">LAMBADA</a></h3>
<ul>
<li>任务：预测句子的最后一个词。</li>
<li>动机：解决这个任务需要对较长的内容进行建模，并对较长的内容具有一定的依赖。</li>
</ul>
<p>由于 <code>LAMBADA</code>
本身就是一个语言模型任务，所以可以直接要求语言模型完成句子的最后一个词。但是语言模型本身并不知道它需要生成句子的最后一个词。</p>
<p>因此，为了解决这个委托方，需要更明确地将其构建为输入-输出映射，并使用额外的示例进行上下文学习：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Fill in blank:  </span><br><span class="line">  </span><br><span class="line">Alice was friends with Bob. Alice went to visit her friend ___. -&gt; Bob  </span><br><span class="line">  </span><br><span class="line">She held the torch in front of her.  </span><br><span class="line">She caught her breath.  </span><br><span class="line">“Chris? There’s a step.”  </span><br><span class="line">“What?”  </span><br><span class="line">“A step. Cut in the rock. About fifty feet ahead.” She moved faster. They both moved faster. “In fact,” she said, raising the torch higher, “there’s more than a ___. -&gt; step</span><br></pre></td></tr></table></figure>
<p>结果：**GPT-3超过了v之前的最好结果（GPT-2）</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Perplexity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">GPT-3 (few-shot)</td>
<td style="text-align: center;"><strong>1.92</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">SOTA</td>
<td style="text-align: center;">8.63</td>
</tr>
</tbody>
</table>
<h3 id="hellaswag">2.2.3 <a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.07830.pdf">HellaSwag</a></h3>
<ul>
<li><p>动机：评估模型进行常识推理的能力</p></li>
<li><p>任务：从一系列选择中选出最适合完成句子的选项</p></li>
</ul>
<p>该数据是多项选择任务，所以最自然的做法是用语言模型为每个候选答案打分，并预测“最佳”答案：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Making a cake: Several cake pops are shown on a display. A woman and girl are shown making the cake pops in a kitchen. They $&#123;answer&#125;</span><br></pre></td></tr></table></figure>
<p>其中 <span class="math inline">\({answer}\)</span>
是以下选项之一：</p>
<ol type="1">
<li><em>bake them, then frost and decorate.</em></li>
<li><em>taste them as they place them on plates.</em></li>
<li><em>put the frosting on the cake as they pan it.</em></li>
<li><em>come out and begin decorating the cake as well.</em></li>
</ol>
<p>给定一个问题 <span class="math inline">\(x\)</span>，你如何对候选答案
<span class="math inline">\(y\)</span>
进行评分呢？没有明确的答案，但这里有一些启发式方法：</p>
<ul>
<li>未归一化的概率 (Unnormalized probability)：<span
class="math inline">\(score(x,y)=p(x,y)\)</span>。未归一化概率的问题是它倾向于短答案。</li>
<li>长度归一化概率 (Length-normalized probability)：<span
class="math inline">\(score(x,y)=p(x,y)/num-tokens(y)\)</span>。这修正了长度偏见。然而，对于长度相同的两个答案，模型仍可能偏好更受欢迎的实体。</li>
<li>频率归一化概率(Frequency-normalized probability)：<span
class="math inline">\(score(x,y)=p(y∣x)/p(y∣x_{0})\)</span>，其中 <span
class="math inline">\(x_{0}\)</span>
是一个中立的字符串，如'Answer:'。这降低了恰巧很常见的答案（例如，“John”）的得分。</li>
</ul>
<p><strong>结果：</strong>GPT-3接近但没有超过最先进的水平：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">SOTA</td>
<td style="text-align: center;"><strong>85.6</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">GPT-3</td>
<td style="text-align: center;">79.3</td>
</tr>
</tbody>
</table>
<p>我需要知道的是，<code>SOTA</code>
结果是在该数据集的训练集中微调得到的结果，因此 <code>GPT-3</code>
在完全不在该数据集训练的情况下获得了接近的结果是很令人惊喜的。</p>
<h2 id="question-answering">2.3 Question answering</h2>
<p>我们现在考虑（闭卷）问答题，其中输入是一个问题，输出是一个答案。语言模型必须以某种方式“知道”答案，而无需在数据库或一组文档中查找信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: What school did burne hogarth establish?  </span><br><span class="line">Output: School of Visual Art</span><br></pre></td></tr></table></figure>
<h3 id="triviaqa">2.3.1 <a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1705.03551.pdf">TriviaQA</a></h3>
<ul>
<li>任务：给定一问题后生成答案</li>
</ul>
<p><strong>PS</strong>:
原始数据集是由业余爱好者收集的，并被用作开放式阅读理解的挑战，但我们用它来进行（闭卷）问题回答。我们根据训练实例和问题定义一个提示，并将完成的内容作为预测的答案：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Q: ‘Nude Descending A Staircase’ is perhaps the most famous painting by which  </span><br><span class="line">20th century artist?  </span><br><span class="line">A: Marcel Duchamp</span><br></pre></td></tr></table></figure>
<p><strong>结果：</strong></p>
<table>
<colgroup>
<col style="width: 88%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Model</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">RAG</td>
<td>68.0</td>
</tr>
<tr class="even">
<td style="text-align: center;">GPT-3 (zero-shot)</td>
<td>64.3</td>
</tr>
<tr class="odd">
<td style="text-align: center;">GPT-3 (few-shot)</td>
<td><strong>71.2</strong></td>
</tr>
</tbody>
</table>
<p>我们也看到，增加模型大小和增加in-context
training实例都有助于提高性能：</p>
<p><img src="https://cdn.jsdelivr.net/gh/YangSuoly/Images/Large-LM/202309121256229.png" style="zoom:75%;" /></p>
<h2 id="webquestions">2.3.2 <a
target="_blank" rel="noopener" href="https://aclanthology.org/D13-1160.pdf">WebQuestions</a></h2>
<ul>
<li>任务：和 <code>TriviaQA</code> 类似是问答任务</li>
<li>数据集从 <code>Google</code>
搜索查询中收集，最初用于对知识库的问题回答。我们定义一个提示，就如
<code>TriviaQA</code> 一样：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Q: What school did burne hogarth establish?  </span><br><span class="line">A: School of Visual Arts</span><br></pre></td></tr></table></figure>
<p><strong>结果：</strong></p>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>RAG</td>
<td><strong>45.5</strong></td>
</tr>
<tr class="even">
<td>GPT-3 (zero-shot)</td>
<td>14.4</td>
</tr>
<tr class="odd">
<td>GPT-3 (few-shot)</td>
<td>41.5</td>
</tr>
</tbody>
</table>
<h3 id="naturalquestions">2.3.3 NaturalQuestions</h3>
<ul>
<li>任务：回答问题</li>
<li>从 <code>Google</code>
搜索查询中收集的数据集（区别在于答案的长度较长），同上，定义一个提示：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Q: Who played tess on touched by an angel?  </span><br><span class="line">A: Delloreese Patricia Early (July 6, 1931 - November 19, 2017), known professionally as Della Reese.</span><br></pre></td></tr></table></figure>
<p><strong>结果：</strong></p>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>RAG</td>
<td><strong>44.5</strong></td>
</tr>
<tr class="even">
<td>GPT-3 (zero-shot)</td>
<td>14.6</td>
</tr>
<tr class="odd">
<td>GPT-3 (few-shot)</td>
<td>29.9</td>
</tr>
</tbody>
</table>
<h2 id="translation">2.4 Translation</h2>
<ul>
<li>任务描述：翻译任务是将源语言（例如，德语）中的句子翻译成目标语言（例如，英语）中的句子。</li>
</ul>
<p>自1960年代以来，机器翻译一直是NLP的长期任务，2000年代开始，在
<code>NLP</code>
领域中，统计机器翻译开始飞速发展，紧随其后的是2010年代中期的神经机器翻译。由于存在人类翻译者，因此它一直是一个数据丰富的领域。</p>
<p>标准的评估数据集比如是 <code>WMT’14</code> 和 <code>WMT’16</code>
数据集。由于存在多种可能的翻译，所以（自动）评估指标是BLEU（它捕获了
<code>n-gram</code> 重叠的概念）。对于 <code>Few-shot</code>
的情况，我们构造了一个包含输入-输出训练实例以及输入的提示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Mein Haus liegt auf dem Hügel. &#x3D; My house is on the hill.  </span><br><span class="line">Keinesfalls dürfen diese für den kommerziellen Gebrauch verwendet werden. &#x3D; In no case may they be used for commercial purposes.</span><br></pre></td></tr></table></figure>
<p><strong>结果：</strong>这里是从德语到英语的结果：</p>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SOTA (supervised)</td>
<td>40.2</td>
</tr>
<tr class="even">
<td>GPT-3 (zero-shot)</td>
<td>27.2</td>
</tr>
<tr class="odd">
<td>GPT-3 (few-shot)</td>
<td>40.6</td>
</tr>
</tbody>
</table>
<ul>
<li>即使没有监督训练数据，GPT-3也能达到全监督系统的最新技术水平！</li>
<li>这为机器翻译的性能设定了一个下限；因为肯定会想利用大量的平行语料库（对齐的输入-输出对）。</li>
<li>法语和罗马尼亚语的结果类似。</li>
<li>从英语到外语的结果要差得多，这是可以预料的，因为GPT-3主要是一个英语模型。</li>
</ul>
<h2 id="arithmetic">2.5 Arithmetic</h2>
<p>GPT-3是一个语言模型（主要是英语），但我们可以在一系列更“抽象推理”的任务上评估它，以评估GPT-3作为更通用模型的性能。</p>
<p>这里的Arithmetic任务是做算术题（2-5位数的加法，减法，乘法）你没有实际的理由要解决这个问题；这只是一个诊断任务，满足我们的科学好奇心。我们将问题提出为问题回答：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Q: What is 556 plus 497?  </span><br><span class="line">A: 1053</span><br></pre></td></tr></table></figure>
<p><strong>结果：</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/YangSuoly/Images/Large-LM/202309121304667.png" style="zoom:75%;" /></p>
<p>从实验结果看起来，虽说不能认为 <code>GPT-3</code>
获得很好的结果，但是还是让我们惊艳，并对未来充满想象。</p>
<h2 id="news-article-generation">2.6 News article generation</h2>
<ul>
<li>任务：给定标题和副标题，生成新闻文章。</li>
<li>数据集：标题/副标题取自 <a
target="_blank" rel="noopener" href="https://stanford-cs324.github.io/winter2022/lectures/capabilities/newser.com">newser.com</a>。</li>
</ul>
<p>我们设立了一个评估标准，人类根据文章可能由机器编写的可能性对文章进行评分。我们在上下文学习中给模型提供提示样本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Title: United Methodists Agree to Historic Split  </span><br><span class="line">Subtitle: Those who oppose gay marriage will form their own denomination  </span><br><span class="line">Article: After two days of intense debate, the United Methodist Church has agreed to a historic split - one that is expected to end in the creation of a new denomination, one that will be &quot;theologically and socially conservative,&quot; according to The Washington Post. The majority of delegates attending the church&#39;s annual General Conference in May voted to strengthen a ban on the ordination of LGBTQ clergy and to write new rules that will &quot;discipline&quot; clergy who officiate at same-sex weddings. But those who opposed these measures have a new plan: They say they will form a separate denomination by 2020, calling their church the Christian Methodist denomination...</span><br></pre></td></tr></table></figure>
<p><strong>结果：</strong>人类只有52%的时间能够正确地分类“人类”与“机器”（几乎只是随机机会）。</p>
<h2 id="novel-tasks">2.7 Novel tasks</h2>
<h3 id="使用新词">2.7.1 使用新词</h3>
<ul>
<li>任务：给定一个新造的词和定义，生成使用该词的句子。</li>
</ul>
<p>我们依旧只需在提示中描述任务：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">To “screeg” something is to swing a sword at it. An example of a sentence that uses the word screeg is: We screeged the tree with our swords.</span><br></pre></td></tr></table></figure>
<h3 id="纠正英语语法">2.7.2 纠正英语语法</h3>
<ul>
<li>任务：给定一个不合语法的句子，生成其合语法的版本。</li>
</ul>
<p>我们通过给出提示来描述任务（提示是有输入和输入对组成的）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Poor English input: I eated the purple berries.  </span><br><span class="line">Good English output: I ate the purple berries.  </span><br><span class="line">Poor English input: Thank you for picking me as your designer. I’d appreciate it.  </span><br><span class="line">Good English output: Thank you for choosing me as your designer. I appreciate it.  </span><br><span class="line">Poor English input: The mentioned changes have done. or I did the alteration that you  </span><br><span class="line">requested. or I changed things you wanted and did the modifications.  </span><br><span class="line">Good English output: The requested changes have been made. or I made the alteration that you  </span><br><span class="line">requested. or I changed things you wanted and made the modifications.  </span><br><span class="line">Poor English input: I’d be more than happy to work with you in another project.  </span><br><span class="line">Good English output: I would be happy to work with you on another project.</span><br></pre></td></tr></table></figure>
<h2 id="other-tasks">2.8 Other tasks</h2>
<p>自原始论文以来，GPT-3已应用于许多更多的任务，包括基准数据集(Benchmark)和一次性的演示(one-off
deoms)。以下是一个不详尽的列表: <strong>Benchmarks：</strong></p>
<ul>
<li><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.04102.pdf">SWORDS</a>：词汇替换，目标是在句子的上下文中预测同义词。</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2009.03300.pdf">Massive Multitask
Language
Understanding</a>：包括数学，美国历史，计算机科学，法律等57个多选问题。</li>
<li><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2109.07958.pdf">TruthfulQA</a>：人类由于误解而错误回答的问答数据集。
<strong>结果：</strong>虽说GPT-3在这些Benchmark数据集中的表现平庸，但是考虑到我们只使用了few-shot的情况，或许不算太差。</li>
</ul>
<p><strong>one-off Demos：</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://beta.openai.com/examples/">Examples from the OpenAI
website</a></li>
<li><a target="_blank" rel="noopener" href="https://gpt3demo.com/">Examples from gpt3demo.com</a>
这些演示既创新又有趣，但很难判断它们的可靠性如何。</li>
</ul>
<h2 id="总结">2.9 总结</h2>
<ul>
<li>GPT-3在广泛的标准NLP基准测试和一次性任务上进行了评估。</li>
<li>GPT-3可以表现得极好或者非常普通。</li>
<li>增加模型的大小和示例的数量都有助于提高性能。</li>
<li>有一些启发式的方法可以将语言模型适应到感兴趣的任务。</li>
<li>但是为什么会有这样表现，没有人知道。</li>
</ul>
<h2 id="reference">2.10 Reference</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2005.14165.pdf">Language Models are
Few-Shot Learners</a>. <em>Tom B. Brown, Benjamin Mann, Nick Ryder,
Melanie Subbiah, J. Kaplan, Prafulla Dhariwal, Arvind Neelakantan,
Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel
Herbert-Voss, Gretchen Krueger, T. Henighan, R. Child, A. Ramesh, Daniel
M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,
Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario
Amodei</em>. NeurIPS 2020.</li>
<li>[Blog post explaining perplexity](</li>
</ul>

    </div>

    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">
            -------------This blog is over!
            <i class="fa fa-eye"></i>
            Thanks for your reading-------------
        </div>
    
</div>
      
    </div>
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>YangSu
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="http://yangsuoly.com/2023/09/12/Large-lm-2-Capacity/" title="Large-lm-2-Capacity">http://yangsuoly.com/2023/09/12/Large-lm-2-Capacity/</a>
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/Tags/LM/" rel="tag"><i class="fa fa-tag"></i> LM</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/09/11/Large-lm-1-Introduction/" rel="prev" title="Large-lm-1-Introduction">
      <i class="fa fa-chevron-left"></i> Large-lm-1-Introduction
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div id="music163player">
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1317956275&auto=0&height=66"></iframe>
      </iframe>
    </div>
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%A7%E9%A2%84%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%83%BD%E5%8A%9B"><span class="nav-text">2. 大预言模型的能力</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%82%E5%BA%94%E6%80%A7"><span class="nav-text">2.1 语言模型的适应性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#language-modeling"><span class="nav-text">2.2 Language Modeling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#penn-tree-bank"><span class="nav-text">2.2.1 Penn Tree Bank</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lambada"><span class="nav-text">2.2.2 LAMBADA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hellaswag"><span class="nav-text">2.2.3 HellaSwag</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#question-answering"><span class="nav-text">2.3 Question answering</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#triviaqa"><span class="nav-text">2.3.1 TriviaQA</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#webquestions"><span class="nav-text">2.3.2 WebQuestions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#naturalquestions"><span class="nav-text">2.3.3 NaturalQuestions</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#translation"><span class="nav-text">2.4 Translation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#arithmetic"><span class="nav-text">2.5 Arithmetic</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#news-article-generation"><span class="nav-text">2.6 News article generation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#novel-tasks"><span class="nav-text">2.7 Novel tasks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%96%B0%E8%AF%8D"><span class="nav-text">2.7.1 使用新词</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%A0%E6%AD%A3%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95"><span class="nav-text">2.7.2 纠正英语语法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#other-tasks"><span class="nav-text">2.8 Other tasks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-text">2.9 总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reference"><span class="nav-text">2.10 Reference</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="YangSu"
      src="/images/YangSu.jpg">
  <p class="site-author-name" itemprop="name">YangSu</p>
  <div class="site-description" itemprop="description">A blog for recording learning notes...</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">56</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/Categories/">
          
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/Tags/">
          
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/YangSuoly" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;YangSuoly" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://gitee.com/yangsuoly" title="Gitee → https:&#x2F;&#x2F;gitee.com&#x2F;yangsuoly" rel="noopener" target="_blank"><i class="fab fa-github-square fa-fw"></i>Gitee</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/64518717" title="B 站 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;64518717" rel="noopener" target="_blank"><i class="fa fa-play-circle fa-fw"></i>B 站</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Related links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.58pic.com/u/19637930/" title="https:&#x2F;&#x2F;www.58pic.com&#x2F;u&#x2F;19637930&#x2F;" rel="noopener" target="_blank">千图网</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YangSu</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'http://yangsuoly.com/2023/09/12/Large-lm-2-Capacity/',]
      });
      });
  </script>

  
  <script id="ribbon" src="js/canvas-ribbon.js"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/22.2017.cba-normal.model.json"},"display":{"position":"right","width":300,"height":450},"mobile":{"show":false},"react":{"opacity":0.7},"log":false});</script></body>
</html>
