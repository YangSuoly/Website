<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>DataAnalysis-Cleaning</title>
    <url>/2021/06/17/DataAnalysis-Cleaning/</url>
    <content><![CDATA[<p>前文已经对数据分析的基本操作进行了学习，接下来要进行数据清洗、数据特征提取、数据重构以及数据可视化的学习。</p>
<h1 id="data-cleaning">1 Data cleaning</h1>
<h2 id="load-data">1.1 Load data</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;./train.csv&#x27;</span>)</span><br><span class="line">df.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h2 id="statistic-description">1.2 Statistic description</h2>
<h3 id="查看信息">1.2.1 查看信息</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.info()</span><br><span class="line"></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">891</span> entries, <span class="number">0</span> to <span class="number">890</span></span><br><span class="line">Data columns (total <span class="number">12</span> columns):</span><br><span class="line"> <span class="comment">#   Column       Non-Null Count  Dtype  </span></span><br><span class="line">---  ------       --------------  -----  </span><br><span class="line"> <span class="number">0</span>   PassengerId  <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">1</span>   Survived     <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">2</span>   Pclass       <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">3</span>   Name         <span class="number">891</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">4</span>   Sex          <span class="number">891</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">5</span>   Age          <span class="number">714</span> non-null    float64</span><br><span class="line"> <span class="number">6</span>   SibSp        <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">7</span>   Parch        <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">8</span>   Ticket       <span class="number">891</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">9</span>   Fare         <span class="number">891</span> non-null    float64</span><br><span class="line"> <span class="number">10</span>  Cabin        <span class="number">204</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">11</span>  Embarked     <span class="number">889</span> non-null    <span class="built_in">object</span></span><br><span class="line">dtypes: float64(<span class="number">2</span>), int64(<span class="number">5</span>), <span class="built_in">object</span>(<span class="number">5</span>)</span><br><span class="line">memory usage: <span class="number">83.7</span>+ KB</span><br></pre></td></tr></table></figure>
<h3 id="缺失值">1.2.2 缺失值</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.isnull().<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">PassengerId      <span class="number">0</span></span><br><span class="line">Survived         <span class="number">0</span></span><br><span class="line">Pclass           <span class="number">0</span></span><br><span class="line">Name             <span class="number">0</span></span><br><span class="line">Sex              <span class="number">0</span></span><br><span class="line">Age            <span class="number">177</span></span><br><span class="line">SibSp            <span class="number">0</span></span><br><span class="line">Parch            <span class="number">0</span></span><br><span class="line">Ticket           <span class="number">0</span></span><br><span class="line">Fare             <span class="number">0</span></span><br><span class="line">Cabin          <span class="number">687</span></span><br><span class="line">Embarked         <span class="number">2</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[[<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Cabin&#x27;</span>,<span class="string">&#x27;Embarked&#x27;</span>]].head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Age
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
22.0
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
38.0
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
26.0
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p><strong>Note</strong>：数值列读取数据后，空缺值的数据类型为 <code>float64</code> 所以用 <code>None</code> 一般索引不到，比较的时候最好用 <code>np.nan</code></p>
<h3 id="填充缺失值">1.2.3 填充缺失值</h3>
<p>处理缺失值一般有：</p>
<ul>
<li>用数字 <code>0</code> 进行填充</li>
<li>用均值进行填充（针对数值型）</li>
<li>用众数进行填充（多用于非数值型）</li>
<li>用特定标识符进行填充（实际处理时特殊对待）</li>
<li>对于缺失值占比太大的列直接进行剔除</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.fillna(<span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">    data.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
0
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
0
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<ul>
<li><p><code>fillna</code> 用法</p>
<p>从帮助文档可以知道，<code>fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)</code>，<code>fillna</code> 包含六个参数：</p>
<ul>
<li><code>Value</code>: 用做填充的值</li>
<li><code>Method</code>: 包含 <code>backfill</code>, <code>bfill</code>, <code>pad</code>, <code>ffill</code>, <code>None</code> 五个值，默认为 <code>None</code>。
<ul>
<li><code>backfill</code>/<code>bfill</code>: 用位于缺失值索引值上的有效值进行填充，直到下一个有效值。</li>
<li><code>pad</code>/<code>ffill</code>: 用位于缺失值索引下的有效值进行填充，直到上一个有效值。</li>
</ul></li>
<li><code>axis</code>: {0 or 'index', 1 or 'columns'}</li>
<li><code>inplace</code> : bool, default False</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df = pd.DataFrame([[np.nan, <span class="number">2</span>, np.nan, <span class="number">0</span>],</span><br><span class="line">                   [<span class="number">3</span>, <span class="number">4</span>, np.nan, <span class="number">1</span>],</span><br><span class="line">                   [np.nan, np.nan, np.nan, <span class="number">5</span>],</span><br><span class="line">                   [np.nan, <span class="number">3</span>, np.nan, <span class="number">4</span>]],</span><br><span class="line">                  columns=<span class="built_in">list</span>(<span class="string">&#x27;ABCD&#x27;</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
A
</th>
<th>
B
</th>
<th>
C
</th>
<th>
D
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
NaN
</td>
<td>
2.0
</td>
<td>
NaN
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
3.0
</td>
<td>
4.0
</td>
<td>
NaN
</td>
<td>
1
</td>
</tr>
<tr>
<th>
2
</th>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
5
</td>
</tr>
<tr>
<th>
3
</th>
<td>
NaN
</td>
<td>
3.0
</td>
<td>
NaN
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df.fillna(method=<span class="string">&#x27;ffill&#x27;</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
A
</th>
<th>
B
</th>
<th>
C
</th>
<th>
D
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
NaN
</td>
<td>
2.0
</td>
<td>
NaN
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
3.0
</td>
<td>
4.0
</td>
<td>
NaN
</td>
<td>
1
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3.0
</td>
<td>
4.0
</td>
<td>
NaN
</td>
<td>
5
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3.0
</td>
<td>
3.0
</td>
<td>
NaN
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
<h3 id="去除空值">1.2.4 去除空值</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.dropna().head(<span class="number">3</span>) <span class="comment"># 未设置 inplace参数</span></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
6
</th>
<td>
7
</td>
<td>
0
</td>
<td>
1
</td>
<td>
McCarthy, Mr. Timothy J
</td>
<td>
male
</td>
<td>
54.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
17463
</td>
<td>
51.8625
</td>
<td>
E46
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h3 id="重复值">1.2.5 重复值</h3>
<ul>
<li><p>查看重复值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[data.duplicated()]</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>PassengerId</p>
</th>
<th>
<p>Survived</p>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
<th>
<p>Age</p>
</th>
<th>
<p>SibSp</p>
</th>
<th>
<p>Parch</p>
</th>
<th>
<p>Ticket</p>
</th>
<th>
<p>Fare</p>
</th>
<th>
<p>Cabin</p>
</th>
<th>
<p>Embarked</p>
</th>
</tr>
</thead>
<tbody>
</tbody>
</table></li>
<li><p>剔除重复值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = data.drop_duplicates()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>PassengerId</p>
</th>
<th>
<p>Survived</p>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
<th>
<p>Age</p>
</th>
<th>
<p>SibSp</p>
</th>
<th>
<p>Parch</p>
</th>
<th>
<p>Ticket</p>
</th>
<th>
<p>Fare</p>
</th>
<th>
<p>Cabin</p>
</th>
<th>
<p>Embarked</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Braund, Mr. Owen Harris</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>22.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>A/5 21171</p>
</td>
<td>
<p>7.2500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Cumings, Mrs. John Bradley (Florence Briggs Th...</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>38.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>PC 17599</p>
</td>
<td>
<p>71.2833</p>
</td>
<td>
<p>C85</p>
</td>
<td>
<p>C</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Heikkinen, Miss. Laina</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>26.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>STON/O2. 3101282</p>
</td>
<td>
<p>7.9250</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>3</p>
</th>
<td>
<p>4</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Futrelle, Mrs. Jacques Heath (Lily May Peel)</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>35.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>113803</p>
</td>
<td>
<p>53.1000</p>
</td>
<td>
<p>C123</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>4</p>
</th>
<td>
<p>5</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Allen, Mr. William Henry</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>35.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>373450</p>
</td>
<td>
<p>8.0500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<h2 id="feature-analysis">1.3 Feature analysis</h2>
<p>对数据进行初步观察后可以发现，特征主要可以分为两大类：</p>
<p>数值型特征：Survived ，Pclass， Age ，SibSp， Parch， Fare，其中Survived， Pclass为离散型数值特征，Age，SibSp， Parch， Fare为连续型数值特征</p>
<p>文本型特征：Name， Sex， Cabin，Embarked， Ticket，其中Sex， Cabin， Embarked， Ticket为类别型文本特征。</p>
<p>数值型特征一般可以直接用于模型的训练，但有时候为了模型的稳定性及鲁棒性会对连续变量进行离散化。文本型特征往往需要转换成数值型特征才能用于建模分析。</p>
<h3 id="分箱操作">1.3.1 分箱操作</h3>
<ul>
<li><p>按平均进行分箱</p>
<p>将连续变量Age平均分成5个年龄段，并分别用类别变量12345表示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.cut(data[<span class="string">&#x27;Age&#x27;</span>], <span class="number">5</span>, labels = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>PassengerId</p>
</th>
<th>
<p>Survived</p>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
<th>
<p>Age</p>
</th>
<th>
<p>SibSp</p>
</th>
<th>
<p>Parch</p>
</th>
<th>
<p>Ticket</p>
</th>
<th>
<p>Fare</p>
</th>
<th>
<p>Cabin</p>
</th>
<th>
<p>Embarked</p>
</th>
<th>
<p>AgeBand</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Braund, Mr. Owen Harris</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>22.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>A/5 21171</p>
</td>
<td>
<p>7.2500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
<td>
<p>2</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Cumings, Mrs. John Bradley (Florence Briggs Th...</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>38.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>PC 17599</p>
</td>
<td>
<p>71.2833</p>
</td>
<td>
<p>C85</p>
</td>
<td>
<p>C</p>
</td>
<td>
<p>3</p>
</td>
</tr>
</tbody>
</table></li>
<li><p>按数值分箱</p>
<p>将连续变量Age划分为[0,5) [5,15) [15,30) [30,50) [50,80)五个年龄段，并分别用类别变量12345表示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.cut(data[<span class="string">&#x27;Age&#x27;</span>], [<span class="number">0</span>, <span class="number">5</span>, <span class="number">15</span>, <span class="number">30</span>, <span class="number">50</span>, <span class="number">80</span>], labels = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>PassengerId</p>
</th>
<th>
<p>Survived</p>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
<th>
<p>Age</p>
</th>
<th>
<p>SibSp</p>
</th>
<th>
<p>Parch</p>
</th>
<th>
<p>Ticket</p>
</th>
<th>
<p>Fare</p>
</th>
<th>
<p>Cabin</p>
</th>
<th>
<p>Embarked</p>
</th>
<th>
<p>AgeBand</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Braund, Mr. Owen Harris</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>22.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>A/5 21171</p>
</td>
<td>
<p>7.2500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
<td>
<p>3</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Cumings, Mrs. John Bradley (Florence Briggs Th...</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>38.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>PC 17599</p>
</td>
<td>
<p>71.2833</p>
</td>
<td>
<p>C85</p>
</td>
<td>
<p>C</p>
</td>
<td>
<p>4</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Heikkinen, Miss. Laina</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>26.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>STON/O2. 3101282</p>
</td>
<td>
<p>7.9250</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
<td>
<p>3</p>
</td>
</tr>
</tbody>
</table></li>
<li><p>按比例分箱</p>
<p>将连续变量Age按10% 30% 50% 70% 90%五个年龄段，并用分类变量12345表示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.cut(data[<span class="string">&#x27;Age&#x27;</span>], [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.7</span>, <span class="number">0.9</span>], labels = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>PassengerId</p>
</th>
<th>
<p>Survived</p>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
<th>
<p>Age</p>
</th>
<th>
<p>SibSp</p>
</th>
<th>
<p>Parch</p>
</th>
<th>
<p>Ticket</p>
</th>
<th>
<p>Fare</p>
</th>
<th>
<p>Cabin</p>
</th>
<th>
<p>Embarked</p>
</th>
<th>
<p>AgeBand</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Braund, Mr. Owen Harris</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>22.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>A/5 21171</p>
</td>
<td>
<p>7.2500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
<td>
<p>NaN</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Cumings, Mrs. John Bradley (Florence Briggs Th...</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>38.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>PC 17599</p>
</td>
<td>
<p>71.2833</p>
</td>
<td>
<p>C85</p>
</td>
<td>
<p>C</p>
</td>
<td>
<p>NaN</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Heikkinen, Miss. Laina</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>26.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>STON/O2. 3101282</p>
</td>
<td>
<p>7.9250</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
<td>
<p>NaN</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<h3 id="提取字符特征">1.3.2 提取字符特征</h3>
<p>从纯文本 <code>Name</code> 特征里提取出 <code>Titles</code> 的特征( <code>Mr, Miss, Mrs</code> 等)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[<span class="string">&#x27;Title&#x27;</span>] = data.Name.<span class="built_in">str</span>.extract(<span class="string">&#x27;([A-Za-z]+)\.&#x27;</span>, expand=<span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
Sex_female
</th>
<th>
Sex_male
</th>
<th>
Embarked_C
</th>
<th>
Embarked_Q
</th>
<th>
Embarked_S
</th>
<th>
Title
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
2
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Mr
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
1
</td>
<td>
1
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
Mrs
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
2
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Miss
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
2
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Mrs
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
2
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Mr
</td>
</tr>
</tbody>
</table>
<h2 id="type-transformation">1.4 Type transformation</h2>
<p>查看文本变量的信息。</p>
<ul>
<li><p><code>value_counts</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[<span class="string">&#x27;Sex&#x27;</span>].value_counts()</span><br><span class="line"></span><br><span class="line">male      <span class="number">577</span></span><br><span class="line">female    <span class="number">314</span></span><br><span class="line">Name: Sex, dtype: int64</span><br></pre></td></tr></table></figure></li>
<li><p><code>unique</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[<span class="string">&#x27;Sex&#x27;</span>].unique()</span><br><span class="line"></span><br><span class="line">array([<span class="string">&#x27;male&#x27;</span>, <span class="string">&#x27;female&#x27;</span>], dtype=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="判别式方式">1.4.1 判别式方式</h3>
<p>将性别转换未数值型数据，用 0 表示男性，1 表示女性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = data_copy.copy()</span><br><span class="line">    data.loc[data[<span class="string">&#x27;Sex&#x27;</span>] == <span class="string">&#x27;male&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>] = <span class="number">0</span> <span class="comment"># &#x27;male&#x27; -&gt; 0</span></span><br><span class="line">    data.loc[data[<span class="string">&#x27;Sex&#x27;</span>] == <span class="string">&#x27;female&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>] = <span class="number">1</span> <span class="comment"># &#x27;female&#x27; -&gt; 1</span></span><br><span class="line">    data.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
0
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
1
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
1
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h3 id="replace-方法">1.4.2 <code>replace</code> 方法：</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = data_copy.copy()</span><br><span class="line">    data[<span class="string">&#x27;Sex_num&#x27;</span>] = data[<span class="string">&#x27;Sex&#x27;</span>].replace([<span class="string">&#x27;male&#x27;</span>,<span class="string">&#x27;female&#x27;</span>],[<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">    data.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
Sex_num
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
2
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
2
</td>
</tr>
</tbody>
</table>
<h3 id="map-方法">1.4.3 <code>map</code> 方法</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = data_copy.copy()</span><br><span class="line">    data[<span class="string">&#x27;Sex_num&#x27;</span>] = data[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;female&#x27;</span>: <span class="number">2</span>&#125;)</span><br><span class="line">    data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
Sex_num
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
2
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
2
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
<td>
2
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
<h3 id="labelencoder">1.4.4 <code>labelEncoder</code></h3>
<p>使用<code>sklearn.preprocessing.labelEncoder</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">    data = data_copy.copy()</span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> [<span class="string">&#x27;Cabin&#x27;</span>, <span class="string">&#x27;Ticket&#x27;</span>]:</span><br><span class="line">        lbl = LabelEncoder()  </span><br><span class="line">        label_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(data[feat].unique(), <span class="built_in">range</span>(data[feat].nunique())))</span><br><span class="line">        data[feat + <span class="string">&quot;_labelEncode&quot;</span>] = data[feat].<span class="built_in">map</span>(label_dict)</span><br><span class="line">        <span class="comment"># data[feat + &quot;_labelEncode&quot;] = lbl.fit_transform(data[feat].astype(str))</span></span><br><span class="line"></span><br><span class="line">    data.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
Cabin_labelEncode
</th>
<th>
Ticket_labelEncode
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
0.0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
1.0
</td>
<td>
1
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
0.0
</td>
<td>
2
</td>
</tr>
</tbody>
</table>
<p>其中，<code>label_dict</code> 是个字典类型，其 <code>key</code> 值表示真实值，即 <code>data[feat].unique()</code>，而对应的数值为 <code>range(data[feat].nunique()</code> 产生的序列。</p>
<p><strong>一点小差异：</strong></p>
<p>从上述代码可以发现，有两种实现方式：</p>
<ul>
<li><p><code>map</code> 方式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[feat].<span class="built_in">map</span>(label_dict).values[:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], dtype=int64)</span><br></pre></td></tr></table></figure></li>
<li><p><code>labelEncoder</code> 方式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>lbl.fit_transform(data[feat].astype(<span class="built_in">str</span>))[:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">array([<span class="number">523</span>, <span class="number">596</span>, <span class="number">669</span>,  <span class="number">49</span>, <span class="number">472</span>])</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>Note:</strong></p>
<p>可以发现，虽然两种方式都能产生同样的效果，当时生成数值编码的方式存在些许差异，第一种方式为按顺序生成，第二种会打乱顺序。</p>
<h3 id="ont-hot-编码">1.4.5 <code>ont-hot</code> 编码</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = data_copy.copy()</span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> [<span class="string">&quot;Sex&quot;</span>, <span class="string">&quot;Embarked&quot;</span>]:</span><br><span class="line">        x = pd.get_dummies(data[feat], prefix=feat)</span><br><span class="line">        data = pd.concat([data, x], axis=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># data[feat] = pd.get_dummies(data[feat], prefix=feat)</span></span><br><span class="line"></span><br><span class="line">    data.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
Sex_female
</th>
<th>
Sex_male
</th>
<th>
Embarked_C
</th>
<th>
Embarked_Q
</th>
<th>
Embarked_S
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
1
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
<p>对于 <code>age</code>，可考虑如下的方式进行处理。</p>
<ul>
<li><p>整除</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.get_dummies(data[<span class="string">&quot;Age&quot;</span>] // <span class="number">6</span>)[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>0.0</p>
</th>
<th>
<p>1.0</p>
</th>
<th>
<p>2.0</p>
</th>
<th>
<p>3.0</p>
</th>
<th>
<p>4.0</p>
</th>
<th>
<p>5.0</p>
</th>
<th>
<p>6.0</p>
</th>
<th>
<p>7.0</p>
</th>
<th>
<p>8.0</p>
</th>
<th>
<p>9.0</p>
</th>
<th>
<p>10.0</p>
</th>
<th>
<p>11.0</p>
</th>
<th>
<p>12.0</p>
</th>
<th>
<p>13.0</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<th>
<p>3</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<th>
<p>4</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
</tbody>
</table></li>
<li><p>分箱</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.get_dummies(pd.cut(data[<span class="string">&#x27;Age&#x27;</span>],<span class="number">5</span>))[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>(0.34, 16.336]</p>
</th>
<th>
<p>(16.336, 32.252]</p>
</th>
<th>
<p>(32.252, 48.168]</p>
</th>
<th>
<p>(48.168, 64.084]</p>
</th>
<th>
<p>(64.084, 80.0]</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<th>
<p>3</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<th>
<p>4</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<h1 id="data-reconstruction">2 Data reconstruction</h1>
<p>前面已经学习了 <code>Pandas</code> 基础和数据清洗，只有数据变得相对干净，之后对数据的分析才可以更有力。本节要做的是数据重构，数据重构依旧属于数据理解（准备）的范围。</p>
<h2 id="data-merge">2.1 Data merge</h2>
<p>数据合并内容之前已经进行了详细的记录，此处便不进行赘述，具体可以查看本人的博客内容，链接： <a href="https://www.yangsuoly.com/2020/11/27/Pandas/">Pandas的Chaper 4 Merge dataframes</a></p>
<h2 id="aggregae-operation">2.2 Aggregae operation</h2>
<ul>
<li><p>计算男女平均票价</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fare_sex  = data[<span class="string">&#x27;Fare&#x27;</span>].groupby(data[<span class="string">&#x27;Sex&#x27;</span>])</span><br><span class="line">    fare_sex.mean()</span><br><span class="line"></span><br><span class="line">Sex</span><br><span class="line">female    <span class="number">44.479818</span></span><br><span class="line">male      <span class="number">25.523893</span></span><br><span class="line">Name: Fare, dtype: float64</span><br></pre></td></tr></table></figure></li>
<li><p>计算男女存活人数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[<span class="string">&#x27;Survived&#x27;</span>].groupby(data[<span class="string">&#x27;Sex&#x27;</span>]).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">Sex</span><br><span class="line">female    <span class="number">233</span></span><br><span class="line">male      <span class="number">109</span></span><br><span class="line">Name: Survived, dtype: int64</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>结论</strong>：可以发现，女性票价远大于男性，其次，女性存活率大于男性。</p>
<h3 id="aggregate-函数">2.2.1 Aggregate 函数</h3>
<p>此外，上述操作还可以通过 <code>agg</code> 函数进行计算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.groupby(<span class="string">&#x27;Sex&#x27;</span>).agg(&#123;<span class="string">&#x27;Fare&#x27;</span>: <span class="string">&#x27;mean&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>: <span class="string">&#x27;count&#x27;</span>&#125;).rename(columns=</span><br><span class="line">                            &#123;<span class="string">&#x27;Fare&#x27;</span>: <span class="string">&#x27;mean_fare&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>: <span class="string">&#x27;count_pclass&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
mean_fare
</th>
<th>
count_pclass
</th>
</tr>
<tr>
<th>
Sex
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
female
</th>
<td>
44.479818
</td>
<td>
314
</td>
</tr>
<tr>
<th>
male
</th>
<td>
25.523893
</td>
<td>
577
</td>
</tr>
</tbody>
</table>
<p><strong>Note</strong>:</p>
<p><code>agg()</code> 函数主要有两个参数：</p>
<ol type="1">
<li><code>func</code>: function, str, list or dict. Function to use for aggregating the data. If a function, must eitherwork when passed a DataFrame or when passed to DataFrame.apply. e.g. mean, median, prod, sum, std, var.</li>
<li><code>axis</code>: default is 0 or 'index', operating based on all columns.</li>
</ol>
<h3 id="其他函数">2.2.2 其他函数</h3>
<ul>
<li><p>统计不同等级的票中，不同年龄的船票花费的平均价格</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.groupby([<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Age&#x27;</span>])[<span class="string">&#x27;Fare&#x27;</span>].mean()</span><br><span class="line"></span><br><span class="line">Pclass  Age  </span><br><span class="line"><span class="number">1</span>       <span class="number">0.92</span>     <span class="number">151.5500</span></span><br><span class="line">        <span class="number">2.00</span>     <span class="number">151.5500</span></span><br><span class="line">        <span class="number">4.00</span>      <span class="number">81.8583</span></span><br><span class="line">        <span class="number">11.00</span>    <span class="number">120.0000</span></span><br><span class="line">        <span class="number">14.00</span>    <span class="number">120.0000</span></span><br><span class="line">                   ...   </span><br><span class="line"><span class="number">3</span>       <span class="number">61.00</span>      <span class="number">6.2375</span></span><br><span class="line">        <span class="number">63.00</span>      <span class="number">9.5875</span></span><br><span class="line">        <span class="number">65.00</span>      <span class="number">7.7500</span></span><br><span class="line">        <span class="number">70.50</span>      <span class="number">7.7500</span></span><br><span class="line">        <span class="number">74.00</span>      <span class="number">7.7750</span></span><br><span class="line">Name: Fare, Length: <span class="number">182</span>, dtype: float64</span><br></pre></td></tr></table></figure></li>
<li><p>不同年龄的存活人数</p>
<p>得出不同年龄的总的存活人数，然后找出存活人数的最高的年龄，最后计算存活人数最高的存活率（存活人数/总人数）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>survived_age = data[<span class="string">&#x27;Survived&#x27;</span>].groupby(data[<span class="string">&#x27;Age&#x27;</span>]).<span class="built_in">sum</span>()</span><br><span class="line">    survived_age.head()</span><br><span class="line"></span><br><span class="line">Age</span><br><span class="line"><span class="number">0.42</span>    <span class="number">1</span></span><br><span class="line"><span class="number">0.67</span>    <span class="number">1</span></span><br><span class="line"><span class="number">0.75</span>    <span class="number">2</span></span><br><span class="line"><span class="number">0.83</span>    <span class="number">2</span></span><br><span class="line"><span class="number">0.92</span>    <span class="number">1</span></span><br><span class="line">Name: Survived, dtype: int64</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>survived_age[survived_age.values == survived_age.<span class="built_in">max</span>()]</span><br><span class="line"></span><br><span class="line">Age</span><br><span class="line"><span class="number">24.0</span>    <span class="number">15</span></span><br><span class="line">Name: Survived, dtype: int64</span><br></pre></td></tr></table></figure>
<p>总人数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[<span class="string">&#x27;Survived&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="number">342</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sum_temp = data[<span class="string">&#x27;Survived&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">    print(<span class="string">&#x27;最大存活率为：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(survived_age.<span class="built_in">max</span>()/sum_temp))</span><br><span class="line"></span><br><span class="line">最大存活率为：<span class="number">0.043859649122807015</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="stack-to-series">2.3 Stack to series</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.stack()</span><br><span class="line"></span><br><span class="line"><span class="number">0</span>    PassengerId                          <span class="number">1</span></span><br><span class="line">     Survived                             <span class="number">0</span></span><br><span class="line">     Pclass                               <span class="number">3</span></span><br><span class="line">     Name           Braund, Mr. Owen Harris</span><br><span class="line">     Sex                               male</span><br><span class="line">                             ...           </span><br><span class="line"><span class="number">890</span>  Sex_male                             <span class="number">1</span></span><br><span class="line">     Embarked_C                           <span class="number">0</span></span><br><span class="line">     Embarked_Q                           <span class="number">1</span></span><br><span class="line">     Embarked_S                           <span class="number">0</span></span><br><span class="line">     Title                               Mr</span><br><span class="line">Length: <span class="number">15172</span>, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure>
<p>探究 <code>stack</code> 函数的功能：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.stack().shape</span><br><span class="line"></span><br><span class="line">(<span class="number">15172</span>,)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; unit_result.head()</span><br><span class="line"></span><br><span class="line">0  Unnamed: 0                           0</span><br><span class="line">   PassengerId                          1</span><br><span class="line">   Survived                             0</span><br><span class="line">   Pclass                               3</span><br><span class="line">   Name           Braund, Mr. Owen Harris</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="number">891</span>*<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">16038</span></span><br></pre></td></tr></table></figure>
<p>可以发现，<code>stack</code> 函数的作用是将数据表中的每一行都转化为一个 <code>Series</code>，共计 <code>891</code> 个 <code>Series</code>，其形状为 <code>15172</code> 行，我们注意到 <span class="math inline">\(891 \times 18 = 16038\)</span>，之间相差一些，是因为 <code>data</code> 中存在部分缺失值。</p>
<h1 id="data-visualization">3 Data visualization</h1>
<p>前文中，已经对基本数据结构有了了解，也学了一些基本的统计方法、数据清洗和重构。本章节中主要学习 <strong>数据可视化</strong>，主要给大家介绍一下 <code>Python</code> 数据可视化库 <code>Matplotlib</code>。</p>
<p>本章节的内容可以通过查阅 《Python for Data Analysis》第九章 进行更深入的学习。</p>
<ul>
<li><p>Import modules</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>%matplotlib inline</span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="柱状图">3.1 柱状图</h2>
<h3 id="简单柱状图">3.1.1 简单柱状图</h3>
<p>可视化展示泰坦尼克号数据集中男女中生存人数分布情况。</p>
<ul>
<li><p>生存情况</p>
<p>由于 <code>Survived = 0</code> 表示死亡，<code>Survived = 1</code> 表示生存，所以使用 <code>sum</code> 函数可以统计生存人数情况。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sex = data.groupby(<span class="string">&#x27;Sex&#x27;</span>)[<span class="string">&#x27;Survived&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">    sex.plot.bar()</span><br><span class="line">    plt.title(<span class="string">&#x27;survived_count&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/06/19/RPLMyd.png" /></p></li>
<li><p>死亡情况</p>
<p>对于死亡人数，可以使用判别式 <code>data['Survived'] != 1</code> 来得到死亡人数的索引，之后用 <code>count</code> 函数进行人数统计。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sex = data[data[<span class="string">&#x27;Survived&#x27;</span>] != <span class="number">1</span>].groupby(<span class="string">&#x27;Sex&#x27;</span>).Survived.count()</span><br><span class="line">    sex.plot.bar()</span><br><span class="line">    plt.title(<span class="string">&#x27;survived_count&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/06/19/RPLKQH.png" /></p></li>
<li><p>合并分析</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.groupby([<span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].count().unstack().plot(kind=<span class="string">&#x27;bar&#x27;</span>,stacked=<span class="string">&#x27;True&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;survived_count&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Text(<span class="number">0</span>, <span class="number">0.5</span>, <span class="string">&#x27;count&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/06/19/RPLuSe.png" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.groupby([<span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].count().unstack()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
<p>Survived</p>
</th>
<th>
<p>0</p>
</th>
<th>
<p>1</p>
</th>
</tr>
<tr>
<th>
<p>Sex</p>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>female</p>
</th>
<td>
<p>81</p>
</td>
<td>
<p>233</p>
</td>
</tr>
<tr>
<th>
<p>male</p>
</th>
<td>
<p>468</p>
</td>
<td>
<p>109</p>
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.groupby([<span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].count()</span><br><span class="line"></span><br><span class="line">Sex     Survived</span><br><span class="line">female  <span class="number">0</span>            <span class="number">81</span></span><br><span class="line">        <span class="number">1</span>           <span class="number">233</span></span><br><span class="line">male    <span class="number">0</span>           <span class="number">468</span></span><br><span class="line">        <span class="number">1</span>           <span class="number">109</span></span><br><span class="line">Name: Survived, dtype: int64</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>Note:</strong></p>
<p>上文简单介绍了 <code>stack</code> 函数，是将整个数据表的每一行转化为一个 <code>pd.Series</code>，而在此处，通过对比上述两行代码，可以发现，<code>unstack()</code> 的作用是反向操作，将 <code>count</code> 函数得到的 <code>Series</code> 转化为 <code>pd.DataFrame</code> 类型。</p>
<h3 id="分层柱状图">3.2.1 分层柱状图</h3>
<p>可视化展示泰坦尼克号数据集中不同仓位等级的人生存和死亡人员的分布情况。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; pclass_sur &#x3D; text.groupby([&#39;Pclass&#39;])[&#39;Survived&#39;].value_counts()</span><br><span class="line">&gt;&gt;&gt; pclass_sur</span><br><span class="line"></span><br><span class="line">Pclass  Survived</span><br><span class="line">1       1           136</span><br><span class="line">        0            80</span><br><span class="line">2       0            97</span><br><span class="line">        1            87</span><br><span class="line">3       0           372</span><br><span class="line">        1           119</span><br><span class="line">Name: Survived, dtype: int64</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">    sns.countplot(x=<span class="string">&quot;Pclass&quot;</span>, hue=<span class="string">&quot;Survived&quot;</span>, data=text)</span><br><span class="line"></span><br><span class="line">&lt;AxesSubplot:xlabel=<span class="string">&#x27;Pclass&#x27;</span>, ylabel=<span class="string">&#x27;count&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/06/19/RPLeJO.png" /></p>
<h2 id="折线图">3.2 折线图</h2>
<h3 id="普通折线图">3.2.1 普通折线图</h3>
<p>可视化展示泰坦尼克号数据集中不同票价的人生存和死亡人数分布情况（横轴是不同票价，纵轴是存活人数）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fare_sur = data.groupby(<span class="string">&#x27;Fare&#x27;</span>)[<span class="string">&#x27;Survived&#x27;</span>].value_counts().sort_values(ascending = <span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fare_sur</span><br><span class="line"></span><br><span class="line">Fare     Survived</span><br><span class="line"><span class="number">8.0500</span>   <span class="number">0</span>           <span class="number">38</span></span><br><span class="line"><span class="number">7.8958</span>   <span class="number">0</span>           <span class="number">37</span></span><br><span class="line"><span class="number">13.0000</span>  <span class="number">0</span>           <span class="number">26</span></span><br><span class="line"><span class="number">7.7500</span>   <span class="number">0</span>           <span class="number">22</span></span><br><span class="line"><span class="number">13.0000</span>  <span class="number">1</span>           <span class="number">16</span></span><br><span class="line">                     ..</span><br><span class="line"><span class="number">7.7417</span>   <span class="number">0</span>            <span class="number">1</span></span><br><span class="line"><span class="number">26.2833</span>  <span class="number">1</span>            <span class="number">1</span></span><br><span class="line"><span class="number">7.7375</span>   <span class="number">1</span>            <span class="number">1</span></span><br><span class="line"><span class="number">26.3875</span>  <span class="number">1</span>            <span class="number">1</span></span><br><span class="line"><span class="number">22.5250</span>  <span class="number">0</span>            <span class="number">1</span></span><br><span class="line">Name: Survived, Length: <span class="number">330</span>, dtype: int64</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 排序后绘折线图</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">18</span>))</span><br><span class="line">    fare_sur.plot(grid=<span class="literal">True</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/06/19/RPLZFK.png" /></p>
<h3 id="核密度图">3.2.2 核密度图</h3>
<p>可视化展示泰坦尼克号数据集中不同年龄的人生存与死亡人数分布情况</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>facet = sns.FacetGrid(text, hue=<span class="string">&quot;Survived&quot;</span>,aspect=<span class="number">3</span>)</span><br><span class="line">    facet.<span class="built_in">map</span>(sns.kdeplot,<span class="string">&#x27;Age&#x27;</span>,shade= <span class="literal">True</span>)</span><br><span class="line">    facet.<span class="built_in">set</span>(xlim=(<span class="number">0</span>, text[<span class="string">&#x27;Age&#x27;</span>].<span class="built_in">max</span>()))</span><br><span class="line">    facet.add_legend()</span><br><span class="line"></span><br><span class="line">&lt;seaborn.axisgrid.FacetGrid at <span class="number">0x1fe9191cc70</span>&gt;</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/06/19/RPLQOA.png" /></p>
<h3 id="多个图形">3.2.3 多个图形</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.Age[data.Pclass == <span class="number">1</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">    data.Age[data.Pclass == <span class="number">2</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">    data.Age[data.Pclass == <span class="number">3</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;age&quot;</span>)</span><br><span class="line">    plt.legend((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line"></span><br><span class="line">&lt;matplotlib.legend.Legend at <span class="number">0x1fe919a5d00</span>&gt;</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/06/19/RPL1eI.png" /></p>
<p><strong>Note:</strong></p>
<p>到这里，可视化就告一段落啦，后期可进一步了解其他可视化模块，如：<code>pyecharts</code>，<code>bokeh</code> 等。</p>
]]></content>
      <categories>
        <category>DataWhale</category>
        <category>Data Analysis</category>
      </categories>
      <tags>
        <tag>Data Analysis</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>DataAnalysis-Describe</title>
    <url>/2021/06/15/DataAnalysis-Describe/</url>
    <content><![CDATA[<h1 id="概述">1 概述</h1>
<p>这门课程得主要目的是通过真实的数据，以实战的方式了解数据分析的流程和熟悉数据分析python的基本操作。知道了课程的目的之后，我们接下来我们要正式的开始数据分析的实战教学，完成kaggle上<a href="https://www.kaggle.com/c/titanic/overview">泰坦尼克的任务</a>，实战数据分析全流程。 这里有两份资料： 教材《Python for Data Analysis》和 baidu.com &amp; google.com（善用搜索引擎）</p>
<a id="more"></a>
<h1 id="数据载入及初步观察">2 数据载入及初步观察</h1>
<h2 id="载入数据">2.1 载入数据</h2>
<p>数据集下载 https://www.kaggle.com/c/titanic/overview</p>
<ul>
<li><p>导入模块</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> nnp</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="加载数据">2.2 加载数据</h2>
<ul>
<li><p>相对路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = pd.read_csv(<span class="string">&#x27;./train.csv&#x27;</span>, encoding = <span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>绝对路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = pd.read_csv(<span class="string">r&quot;D:\Demo\University\XMU\Python\Artificial-intelligence\Data analysis\第一单元项目集合\train.csv&quot;</span>, encoding = <span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p><code>read_table</code> 读取</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置 sep</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = pd.read_table(<span class="string">&#x27;./train.csv&#x27;</span>, sep = <span class="string">&#x27;,&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>获取当前路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> os</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(os.getcwd())</span><br><span class="line"></span><br><span class="line">D:\Demo\University\XMU\Python\Artificial-intelligence\Data analysis\第一单元项目集合</span><br></pre></td></tr></table></figure></li>
<li><p>逐块读取</p>
<p>每500行为一个数据模块，逐块读取</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置 chunksize 参数</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>chunker = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>, chunksize=<span class="number">500</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> df <span class="keyword">in</span> chunker:</span><br><span class="line">        print(<span class="built_in">type</span>(df), df.shape)</span><br><span class="line"></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt; (<span class="params"><span class="number">500</span>, <span class="number">12</span></span>)</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt; (<span class="params"><span class="number">391</span>, <span class="number">12</span></span>)</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="数据预处理">2.3 数据预处理</h2>
<h3 id="更改表头">2.3.1 更改表头</h3>
<p>索引改为乘客ID（对于某些英文资料，我们可以通过翻译来更直观的熟悉我们的数据）： PassengerId =&gt; 乘客ID<br />
Survived =&gt; 是否幸存<br />
Pclass =&gt; 乘客等级(1/2/3等舱位)<br />
Name =&gt; 乘客姓名<br />
Sex =&gt; 性别<br />
Age =&gt; 年龄<br />
SibSp =&gt; 堂兄弟/妹个数<br />
Parch =&gt; 父母与小孩个数<br />
Ticket =&gt; 船票信息<br />
Fare =&gt; 票价<br />
Cabin =&gt; 客舱<br />
Embarked =&gt; 登船港口</p>
<ul>
<li><p>方式一</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>maps = &#123;<span class="string">&#x27;PassengerId&#x27;</span>: <span class="string">&#x27;乘客ID&#x27;</span>, <span class="string">&#x27;Survived&#x27;</span>: <span class="string">&#x27;是否幸存&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>: <span class="string">&#x27;乘客等级(1/2/3等舱位)&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Name&#x27;</span>: <span class="string">&#x27;乘客姓名&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>: <span class="string">&#x27;性别&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>: <span class="string">&#x27;年龄&#x27;</span>, <span class="string">&#x27;SibSp&#x27;</span>: <span class="string">&#x27;堂兄弟/妹个数&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Parch&#x27;</span>: <span class="string">&#x27;父母与小孩个数&#x27;</span>, <span class="string">&#x27;Ticket&#x27;</span>: <span class="string">&#x27;船票信息&#x27;</span>, <span class="string">&#x27;Fare&#x27;</span>: <span class="string">&#x27;票价&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Cabin&#x27;</span>: <span class="string">&#x27;客舱&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>: <span class="string">&#x27;登船港口&#x27;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.rename(columns=maps, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>方式二</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = data = pd.read_csv(<span class="string">&#x27;./train.csv&#x27;</span>, encoding = <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>columns = [<span class="string">&#x27;乘客ID&#x27;</span>,<span class="string">&#x27;是否幸存&#x27;</span>,<span class="string">&#x27;仓位等级&#x27;</span>,<span class="string">&#x27;姓名&#x27;</span>,<span class="string">&#x27;性别&#x27;</span>,<span class="string">&#x27;年龄&#x27;</span>,<span class="string">&#x27;兄弟姐妹个数&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;父母子女个数&#x27;</span>,<span class="string">&#x27;船票信息&#x27;</span>,<span class="string">&#x27;票价&#x27;</span>,<span class="string">&#x27;客舱&#x27;</span>,<span class="string">&#x27;登船港口&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.columns = columns</span><br></pre></td></tr></table></figure></li>
<li><p>方式三</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>,</span><br><span class="line">         names=[<span class="string">&#x27;乘客ID&#x27;</span>,<span class="string">&#x27;是否幸存&#x27;</span>,<span class="string">&#x27;仓位等级&#x27;</span>,<span class="string">&#x27;姓名&#x27;</span>,<span class="string">&#x27;性别&#x27;</span>,<span class="string">&#x27;年龄&#x27;</span>, <span class="string">&#x27;兄弟姐妹个数&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;父母子女个数&#x27;</span>,<span class="string">&#x27;船票信息&#x27;</span>,<span class="string">&#x27;票价&#x27;</span>,<span class="string">&#x27;客舱&#x27;</span>,<span class="string">&#x27;登船港口&#x27;</span>],</span><br><span class="line">                 index_col=<span class="string">&#x27;乘客ID&#x27;</span>,header=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="初步观察">2.3.2 初步观察</h3>
<p>导入数据后，你可能要对数据的整体结构和样例进行概览，比如说，数据大小、有多少列，各列都是什么格式的，是否包含null等。</p>
<ul>
<li><p>查看信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.info()</span><br><span class="line"></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">891</span> entries, <span class="number">0</span> to <span class="number">890</span></span><br><span class="line">Data columns (total <span class="number">12</span> columns):</span><br><span class="line"> <span class="comment">#   Column  Non-Null Count  Dtype  </span></span><br><span class="line">---  ------  --------------  -----  </span><br><span class="line"> <span class="number">0</span>   乘客ID    <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">1</span>   是否幸存    <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">2</span>   仓位等级    <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">3</span>   姓名      <span class="number">891</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">4</span>   性别      <span class="number">891</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">5</span>   年龄      <span class="number">714</span> non-null    float64</span><br><span class="line"> <span class="number">6</span>   兄弟姐妹个数  <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">7</span>   父母子女个数  <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">8</span>   船票信息    <span class="number">891</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">9</span>   票价      <span class="number">891</span> non-null    float64</span><br><span class="line"> <span class="number">10</span>  客舱      <span class="number">204</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">11</span>  登船港口    <span class="number">889</span> non-null    <span class="built_in">object</span></span><br><span class="line">dtypes: float64(<span class="number">2</span>), int64(<span class="number">5</span>), <span class="built_in">object</span>(<span class="number">5</span>)</span><br><span class="line">memory usage: <span class="number">83.7</span>+ KB</span><br></pre></td></tr></table></figure></li>
<li><p>开头和结尾</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>乘客ID</p>
</th>
<th>
<p>是否幸存</p>
</th>
<th>
<p>仓位等级</p>
</th>
<th>
<p>姓名</p>
</th>
<th>
<p>性别</p>
</th>
<th>
<p>年龄</p>
</th>
<th>
<p>兄弟姐妹个数</p>
</th>
<th>
<p>父母子女个数</p>
</th>
<th>
<p>船票信息</p>
</th>
<th>
<p>票价</p>
</th>
<th>
<p>客舱</p>
</th>
<th>
<p>登船港口</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Braund, Mr. Owen Harris</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>22.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>A/5 21171</p>
</td>
<td>
<p>7.2500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Cumings, Mrs. John Bradley (Florence Briggs Th...</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>38.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>PC 17599</p>
</td>
<td>
<p>71.2833</p>
</td>
<td>
<p>C85</p>
</td>
<td>
<p>C</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Heikkinen, Miss. Laina</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>26.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>STON/O2. 3101282</p>
</td>
<td>
<p>7.9250</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>3</p>
</th>
<td>
<p>4</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Futrelle, Mrs. Jacques Heath (Lily May Peel)</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>35.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>113803</p>
</td>
<td>
<p>53.1000</p>
</td>
<td>
<p>C123</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>4</p>
</th>
<td>
<p>5</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Allen, Mr. William Henry</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>35.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>373450</p>
</td>
<td>
<p>8.0500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>5</p>
</th>
<td>
<p>6</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Moran, Mr. James</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>330877</p>
</td>
<td>
<p>8.4583</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>Q</p>
</td>
</tr>
<tr>
<th>
<p>6</p>
</th>
<td>
<p>7</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>McCarthy, Mr. Timothy J</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>54.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>17463</p>
</td>
<td>
<p>51.8625</p>
</td>
<td>
<p>E46</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>7</p>
</th>
<td>
<p>8</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Palsson, Master. Gosta Leonard</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>2.0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>349909</p>
</td>
<td>
<p>21.0750</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>8</p>
</th>
<td>
<p>9</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>27.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>347742</p>
</td>
<td>
<p>11.1333</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>9</p>
</th>
<td>
<p>10</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>Nasser, Mrs. Nicholas (Adele Achem)</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>14.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>237736</p>
</td>
<td>
<p>30.0708</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>C</p>
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.tail(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>乘客ID</p>
</th>
<th>
<p>是否幸存</p>
</th>
<th>
<p>仓位等级</p>
</th>
<th>
<p>姓名</p>
</th>
<th>
<p>性别</p>
</th>
<th>
<p>年龄</p>
</th>
<th>
<p>兄弟姐妹个数</p>
</th>
<th>
<p>父母子女个数</p>
</th>
<th>
<p>船票信息</p>
</th>
<th>
<p>票价</p>
</th>
<th>
<p>客舱</p>
</th>
<th>
<p>登船港口</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>876</p>
</th>
<td>
<p>877</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Gustafsson, Mr. Alfred Ossian</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>20.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>7534</p>
</td>
<td>
<p>9.8458</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>877</p>
</th>
<td>
<p>878</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Petroff, Mr. Nedelio</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>19.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>349212</p>
</td>
<td>
<p>7.8958</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>878</p>
</th>
<td>
<p>879</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Laleff, Mr. Kristo</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>349217</p>
</td>
<td>
<p>7.8958</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>879</p>
</th>
<td>
<p>880</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>56.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>11767</p>
</td>
<td>
<p>83.1583</p>
</td>
<td>
<p>C50</p>
</td>
<td>
<p>C</p>
</td>
</tr>
<tr>
<th>
<p>880</p>
</th>
<td>
<p>881</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>Shelley, Mrs. William (Imanita Parrish Hall)</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>25.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>230433</p>
</td>
<td>
<p>26.0000</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>881</p>
</th>
<td>
<p>882</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Markun, Mr. Johann</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>33.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>349257</p>
</td>
<td>
<p>7.8958</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>882</p>
</th>
<td>
<p>883</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Dahlberg, Miss. Gerda Ulrika</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>22.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>7552</p>
</td>
<td>
<p>10.5167</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>883</p>
</th>
<td>
<p>884</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>Banfield, Mr. Frederick James</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>28.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>C.A./SOTON 34068</p>
</td>
<td>
<p>10.5000</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>884</p>
</th>
<td>
<p>885</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Sutehall, Mr. Henry Jr</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>25.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>SOTON/OQ 392076</p>
</td>
<td>
<p>7.0500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>885</p>
</th>
<td>
<p>886</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Rice, Mrs. William (Margaret Norton)</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>39.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>5</p>
</td>
<td>
<p>382652</p>
</td>
<td>
<p>29.1250</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>Q</p>
</td>
</tr>
<tr>
<th>
<p>886</p>
</th>
<td>
<p>887</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>Montvila, Rev. Juozas</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>27.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>211536</p>
</td>
<td>
<p>13.0000</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>887</p>
</th>
<td>
<p>888</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Graham, Miss. Margaret Edith</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>19.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>112053</p>
</td>
<td>
<p>30.0000</p>
</td>
<td>
<p>B42</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>888</p>
</th>
<td>
<p>889</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Johnston, Miss. Catherine Helen "Carrie"</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>W./C. 6607</p>
</td>
<td>
<p>23.4500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>889</p>
</th>
<td>
<p>890</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Behr, Mr. Karl Howell</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>26.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>111369</p>
</td>
<td>
<p>30.0000</p>
</td>
<td>
<p>C148</p>
</td>
<td>
<p>C</p>
</td>
</tr>
<tr>
<th>
<p>890</p>
</th>
<td>
<p>891</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Dooley, Mr. Patrick</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>32.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>370376</p>
</td>
<td>
<p>7.7500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>Q</p>
</td>
</tr>
</tbody>
</table></li>
<li><p>判断是否为空</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.isnull().head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>乘客ID</p>
</th>
<th>
<p>是否幸存</p>
</th>
<th>
<p>仓位等级</p>
</th>
<th>
<p>姓名</p>
</th>
<th>
<p>性别</p>
</th>
<th>
<p>年龄</p>
</th>
<th>
<p>兄弟姐妹个数</p>
</th>
<th>
<p>父母子女个数</p>
</th>
<th>
<p>船票信息</p>
</th>
<th>
<p>票价</p>
</th>
<th>
<p>客舱</p>
</th>
<th>
<p>登船港口</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>True</p>
</td>
<td>
<p>False</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>True</p>
</td>
<td>
<p>False</p>
</td>
</tr>
<tr>
<th>
<p>3</p>
</th>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
</tr>
<tr>
<th>
<p>4</p>
</th>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>False</p>
</td>
<td>
<p>True</p>
</td>
<td>
<p>False</p>
</td>
</tr>
</tbody>
</table></li>
<li><p>描述性统计</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.describe()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>乘客ID</p>
</th>
<th>
<p>是否幸存</p>
</th>
<th>
<p>仓位等级</p>
</th>
<th>
<p>年龄</p>
</th>
<th>
<p>兄弟姐妹个数</p>
</th>
<th>
<p>父母子女个数</p>
</th>
<th>
<p>票价</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>count</p>
</th>
<td>
<p>891.000000</p>
</td>
<td>
<p>891.000000</p>
</td>
<td>
<p>891.000000</p>
</td>
<td>
<p>714.000000</p>
</td>
<td>
<p>891.000000</p>
</td>
<td>
<p>891.000000</p>
</td>
<td>
<p>891.000000</p>
</td>
</tr>
<tr>
<th>
<p>mean</p>
</th>
<td>
<p>446.000000</p>
</td>
<td>
<p>0.383838</p>
</td>
<td>
<p>2.308642</p>
</td>
<td>
<p>29.699118</p>
</td>
<td>
<p>0.523008</p>
</td>
<td>
<p>0.381594</p>
</td>
<td>
<p>32.204208</p>
</td>
</tr>
<tr>
<th>
<p>std</p>
</th>
<td>
<p>257.353842</p>
</td>
<td>
<p>0.486592</p>
</td>
<td>
<p>0.836071</p>
</td>
<td>
<p>14.526497</p>
</td>
<td>
<p>1.102743</p>
</td>
<td>
<p>0.806057</p>
</td>
<td>
<p>49.693429</p>
</td>
</tr>
<tr>
<th>
<p>min</p>
</th>
<td>
<p>1.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>0.420000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
</tr>
<tr>
<th>
<p>25%</p>
</th>
<td>
<p>223.500000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>2.000000</p>
</td>
<td>
<p>20.125000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>7.910400</p>
</td>
</tr>
<tr>
<th>
<p>50%</p>
</th>
<td>
<p>446.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>3.000000</p>
</td>
<td>
<p>28.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>14.454200</p>
</td>
</tr>
<tr>
<th>
<p>75%</p>
</th>
<td>
<p>668.500000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>3.000000</p>
</td>
<td>
<p>38.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>31.000000</p>
</td>
</tr>
<tr>
<th>
<p>max</p>
</th>
<td>
<p>891.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>3.000000</p>
</td>
<td>
<p>80.000000</p>
</td>
<td>
<p>8.000000</p>
</td>
<td>
<p>6.000000</p>
</td>
<td>
<p>512.329200</p>
</td>
</tr>
</tbody>
</table></li>
<li><p>重复</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.duplicated()</span><br><span class="line"></span><br><span class="line"><span class="number">0</span>      <span class="literal">False</span></span><br><span class="line"><span class="number">1</span>      <span class="literal">False</span></span><br><span class="line"><span class="number">2</span>      <span class="literal">False</span></span><br><span class="line"><span class="number">3</span>      <span class="literal">False</span></span><br><span class="line"><span class="number">4</span>      <span class="literal">False</span></span><br><span class="line">       ...  </span><br><span class="line"><span class="number">886</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">887</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">888</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">889</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">890</span>    <span class="literal">False</span></span><br><span class="line">Length: <span class="number">891</span>, dtype: <span class="built_in">bool</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="保存数据">2.4 保存数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df.to_csv(<span class="string">&#x27;train_chinese.csv&#x27;</span>, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>【总结】数据的加载以及入门，接下来就要接触数据本身的运算，我们将主要掌握numpy和pandas在工作和项目场景的运用。</p>
<h1 id="探索性数据分析">3 探索性数据分析</h1>
<p><strong>复习：</strong> 前面已经学习了Pandas基础，知道利用Pandas读取csv数据的增删查改。这一章节学习的是 <strong>探索性数据分析</strong>，主要介绍如何利用Pandas进行排序、算术计算以及计算描述函数describe()的使用。</p>
<h2 id="加载数据-1">3.1 加载数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#载入之前保存的train_chinese.csv数据，关于泰坦尼克号的任务，我们就使用这个数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = pd.read_csv(<span class="string">&#x27;train_chinese.csv&#x27;</span>)</span><br><span class="line">    data_en = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">    data.head(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
�˿�ID
</th>
<th>
�Ƿ��Ҵ�
</th>
<th>
��λ�ȼ�
</th>
<th>
����
</th>
<th>
�Ա�
</th>
<th>
����.1
</th>
<th>
�ֵܽ��ø���
</th>
<th>
��ĸ��Ů����
</th>
<th>
��Ʊ��Ϣ
</th>
<th>
Ʊ��
</th>
<th>
�Ͳ�
</th>
<th>
�Ǵ��ۿ�
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.25
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p>可以发现直接读取会产生乱码，因此需要设置编码格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = pd.read_csv(<span class="string">&#x27;train_chinese.csv&#x27;</span>, encoding = <span class="string">&#x27;ansi&#x27;</span>)</span><br><span class="line">  data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
乘客ID
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
姓名
</th>
<th>
性别
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
船票信息
</th>
<th>
票价
</th>
<th>
客舱
</th>
<th>
登船港口
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h2 id="了解数据">3.2 了解数据</h2>
<p>详细请参考教材《Python for Data Analysis》第五章</p>
<h3 id="排序">3.2.1 排序</h3>
<ul>
<li><p>理论</p>
<p>具体请看《利用Python进行数据分析》第五章 排序和排名 部分</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 构建数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>frame = pd.DataFrame(np.arange(<span class="number">8</span>).reshape((<span class="number">2</span>, <span class="number">4</span>)),</span><br><span class="line">                     index=[<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;1&#x27;</span>],</span><br><span class="line">                     columns=[<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>frame</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>d</p>
</th>
<th>
<p>a</p>
</th>
<th>
<p>b</p>
</th>
<th>
<p>c</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>3</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>4</p>
</td>
<td>
<p>5</p>
</td>
<td>
<p>6</p>
</td>
<td>
<p>7</p>
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 索引升序frame.sort_index(axis = 0, ascending = True)</span></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>d</p>
</th>
<th>
<p>a</p>
</th>
<th>
<p>b</p>
</th>
<th>
<p>c</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>4</p>
</td>
<td>
<p>5</p>
</td>
<td>
<p>6</p>
</td>
<td>
<p>7</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>3</p>
</td>
</tr>
</tbody>
</table>
<p><strong>Note</strong>:</p>
<ol type="1">
<li><code>axis</code>: 控制索引的维度，默认为 <code>axis = 0</code> 即行索引。将 <code>axis</code> 设置为 <code>1</code> 可以更改为按列排序.</li>
<li><code>ascending</code>: 控制升序 / 降序。默认为 <code>ascending = True</code>，即升序排列。</li>
<li>此外，可以通过设置 <code>by</code> 参数，选择多列进行排序。如 <code>by = ['a', 'c']</code>。</li>
</ol></li>
<li><p>实操</p>
<p>对 <code>data</code> 数据按票价和年龄两列进行综合排序（降序排列）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data.sort_values(by=[<span class="string">&#x27;票价&#x27;</span>, <span class="string">&#x27;年龄&#x27;</span>], ascending=<span class="literal">False</span>).head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>乘客ID</p>
</th>
<th>
<p>是否幸存</p>
</th>
<th>
<p>仓位等级</p>
</th>
<th>
<p>姓名</p>
</th>
<th>
<p>性别</p>
</th>
<th>
<p>年龄</p>
</th>
<th>
<p>兄弟姐妹个数</p>
</th>
<th>
<p>父母子女个数</p>
</th>
<th>
<p>船票信息</p>
</th>
<th>
<p>票价</p>
</th>
<th>
<p>客舱</p>
</th>
<th>
<p>登船港口</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>679</p>
</th>
<td>
<p>680</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Cardeza, Mr. Thomas Drake Martinez</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>36.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>PC 17755</p>
</td>
<td>
<p>512.3292</p>
</td>
<td>
<p>B51 B53 B55</p>
</td>
<td>
<p>C</p>
</td>
</tr>
<tr>
<th>
<p>258</p>
</th>
<td>
<p>259</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Ward, Miss. Anna</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>35.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>PC 17755</p>
</td>
<td>
<p>512.3292</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>C</p>
</td>
</tr>
<tr>
<th>
<p>737</p>
</th>
<td>
<p>738</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Lesurer, Mr. Gustave J</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>35.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>PC 17755</p>
</td>
<td>
<p>512.3292</p>
</td>
<td>
<p>B101</p>
</td>
<td>
<p>C</p>
</td>
</tr>
</tbody>
</table>
<p>排序后，如果我们仅仅关注年龄和票价两列。根据常识我知道发现票价越高的应该客舱越好，所以我们会明显看出，票价前20的乘客中存活的高达14人。</p></li>
</ul>
<h3 id="算数计算">3.2.2 算数计算</h3>
<p>具体参照《利用Python进行数据分析》第五章 算术运算与数据对齐部分</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>frame1_a = pd.DataFrame(np.arange(<span class="number">9.</span>).reshape(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                     columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">                     index=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>frame1_b = pd.DataFrame(np.arange(<span class="number">12.</span>).reshape(<span class="number">4</span>, <span class="number">3</span>),</span><br><span class="line">                     columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">                     index=[<span class="string">&#x27;first&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;second&#x27;</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>frame1_a</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
one
</th>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
2.0
</td>
</tr>
<tr>
<th>
two
</th>
<td>
3.0
</td>
<td>
4.0
</td>
<td>
5.0
</td>
</tr>
<tr>
<th>
three
</th>
<td>
6.0
</td>
<td>
7.0
</td>
<td>
8.0
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>frame1_b</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
a
</th>
<th>
e
</th>
<th>
c
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
first
</th>
<td>
0.0
</td>
<td>
1.0
</td>
<td>
2.0
</td>
</tr>
<tr>
<th>
one
</th>
<td>
3.0
</td>
<td>
4.0
</td>
<td>
5.0
</td>
</tr>
<tr>
<th>
two
</th>
<td>
6.0
</td>
<td>
7.0
</td>
<td>
8.0
</td>
</tr>
<tr>
<th>
second
</th>
<td>
9.0
</td>
<td>
10.0
</td>
<td>
11.0
</td>
</tr>
</tbody>
</table>
<ul>
<li><p>加法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将frame_a和frame_b进行相加</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>frame1_a + frame1_b</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>a</p>
</th>
<th>
<p>b</p>
</th>
<th>
<p>c</p>
</th>
<th>
<p>e</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>first</p>
</th>
<td>
<p>NaN</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>NaN</p>
</td>
</tr>
<tr>
<th>
<p>one</p>
</th>
<td>
<p>3.0</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>7.0</p>
</td>
<td>
<p>NaN</p>
</td>
</tr>
<tr>
<th>
<p>second</p>
</th>
<td>
<p>NaN</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>NaN</p>
</td>
</tr>
<tr>
<th>
<p>three</p>
</th>
<td>
<p>NaN</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>NaN</p>
</td>
</tr>
<tr>
<th>
<p>two</p>
</th>
<td>
<p>9.0</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>13.0</p>
</td>
<td>
<p>NaN</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<h3 id="极值">3.2.3 极值</h3>
<p>查看最大的家族有多少人（‘兄弟姐妹个数’+‘父母子女个数’）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">max</span>(data[<span class="string">&#x27;兄弟姐妹个数&#x27;</span>] + data[<span class="string">&#x27;父母子女个数&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="number">10</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data[<span class="string">&#x27;父母子女个数&#x27;</span>].describe()</span><br><span class="line"></span><br><span class="line">count    <span class="number">891.000000</span></span><br><span class="line">mean       <span class="number">0.381594</span></span><br><span class="line">std        <span class="number">0.806057</span></span><br><span class="line"><span class="built_in">min</span>        <span class="number">0.000000</span></span><br><span class="line"><span class="number">25</span>%        <span class="number">0.000000</span></span><br><span class="line"><span class="number">50</span>%        <span class="number">0.000000</span></span><br><span class="line"><span class="number">75</span>%        <span class="number">0.000000</span></span><br><span class="line"><span class="built_in">max</span>        <span class="number">6.000000</span></span><br><span class="line">Name: 父母子女个数, dtype: float64</span><br></pre></td></tr></table></figure>
<h1 id="pandas-基础">4 Pandas 基础</h1>
<ul>
<li><p>DataFrame and Series</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sdata = &#123;<span class="string">&#x27;Ohio&#x27;</span>: <span class="number">35000</span>, <span class="string">&#x27;Texas&#x27;</span>: <span class="number">71000</span>, <span class="string">&#x27;Oregon&#x27;</span>: <span class="number">16000</span>, <span class="string">&#x27;Utah&#x27;</span>: <span class="number">5000</span>&#125;</span><br><span class="line">    example_1 = pd.Series(sdata)</span><br><span class="line">    example_1</span><br><span class="line"></span><br><span class="line">Ohio      <span class="number">35000</span></span><br><span class="line">Texas     <span class="number">71000</span></span><br><span class="line">Oregon    <span class="number">16000</span></span><br><span class="line">Utah       <span class="number">5000</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>temp = &#123;<span class="string">&#x27;state&#x27;</span>: [<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>],</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2003</span>],<span class="string">&#x27;pop&#x27;</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>, <span class="number">3.2</span>]&#125;</span><br><span class="line">    example_2 = pd.DataFrame(temp)</span><br><span class="line">    example_2</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>state</p>
</th>
<th>
<p>year</p>
</th>
<th>
<p>pop</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>Ohio</p>
</td>
<td>
<p>2000</p>
</td>
<td>
<p>1.5</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>Ohio</p>
</td>
<td>
<p>2001</p>
</td>
<td>
<p>1.7</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>Ohio</p>
</td>
<td>
<p>2002</p>
</td>
<td>
<p>3.6</p>
</td>
</tr>
<tr>
<th>
<p>3</p>
</th>
<td>
<p>Nevada</p>
</td>
<td>
<p>2001</p>
</td>
<td>
<p>2.4</p>
</td>
</tr>
<tr>
<th>
<p>4</p>
</th>
<td>
<p>Nevada</p>
</td>
<td>
<p>2002</p>
</td>
<td>
<p>2.9</p>
</td>
</tr>
<tr>
<th>
<p>5</p>
</th>
<td>
<p>Nevada</p>
</td>
<td>
<p>2003</p>
</td>
<td>
<p>3.2</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<h2 id="数据特征">4.1 数据特征</h2>
<ul>
<li><p>列名称</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data_en.columns</span><br><span class="line"></span><br><span class="line">Index([<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Survived&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;SibSp&#x27;</span>,       <span class="string">&#x27;Parch&#x27;</span>, <span class="string">&#x27;Ticket&#x27;</span>, <span class="string">&#x27;Fare&#x27;</span>, <span class="string">&#x27;Cabin&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>],      dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>查看某些的信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data_en[<span class="string">&#x27;Cabin&#x27;</span>].head(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">0</span>    NaN1    C852    NaNName: Cabin, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data_en.Cabin.head(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">0</span>    NaN1    C852    NaNName: Cabin, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="删除多余的列">4.2 删除多余的列</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>test_1 = pd.read_csv(<span class="string">&#x27;test_1.csv&#x27;</span>)</span><br><span class="line">test_1.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Unnamed: 0
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
a
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
100
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
100
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
100
</td>
</tr>
</tbody>
</table>
<p>经过我们的观察发现一个测试集 <code>test_1.csv</code> 有两列是多余的，需要将多余的列删去。</p>
<ul>
<li><p><code>del</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除多余的列</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">del</span> test_1[<span class="string">&#x27;a&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test_1.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>Unnamed: 0</p>
</th>
<th>
<p>PassengerId</p>
</th>
<th>
<p>Survived</p>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
<th>
<p>Age</p>
</th>
<th>
<p>SibSp</p>
</th>
<th>
<p>Parch</p>
</th>
<th>
<p>Ticket</p>
</th>
<th>
<p>Fare</p>
</th>
<th>
<p>Cabin</p>
</th>
<th>
<p>Embarked</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Braund, Mr. Owen Harris</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>22.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>A/5 21171</p>
</td>
<td>
<p>7.2500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>1</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Cumings, Mrs. John Bradley (Florence Briggs Th...</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>38.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>PC 17599</p>
</td>
<td>
<p>71.2833</p>
</td>
<td>
<p>C85</p>
</td>
<td>
<p>C</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Heikkinen, Miss. Laina</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>26.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>STON/O2. 3101282</p>
</td>
<td>
<p>7.9250</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
</tbody>
</table></li>
<li><p><code>drop</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>test_1.drop(<span class="string">&#x27;a&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)<span class="comment"># test_1 = test_1.drop(&#x27;a&#x27;, axis = 1)test_1.head(3)</span></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>Unnamed: 0</p>
</th>
<th>
<p>PassengerId</p>
</th>
<th>
<p>Survived</p>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
<th>
<p>Age</p>
</th>
<th>
<p>SibSp</p>
</th>
<th>
<p>Parch</p>
</th>
<th>
<p>Ticket</p>
</th>
<th>
<p>Fare</p>
</th>
<th>
<p>Cabin</p>
</th>
<th>
<p>Embarked</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Braund, Mr. Owen Harris</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>22.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>A/5 21171</p>
</td>
<td>
<p>7.2500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>1</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Cumings, Mrs. John Bradley (Florence Briggs Th...</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>38.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>PC 17599</p>
</td>
<td>
<p>71.2833</p>
</td>
<td>
<p>C85</p>
</td>
<td>
<p>C</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Heikkinen, Miss. Laina</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>26.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>STON/O2. 3101282</p>
</td>
<td>
<p>7.9250</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
</tbody>
</table>
<p>Note:</p>
<ul>
<li><code>inplace</code> ：是否替换原始的数据，也可以使用第二行的代码进行替代或存储为新的变量。默认为 <code>False</code>，即不替换</li>
<li><code>axis</code>：在行/列的维度进行操作。
<ul>
<li>0: Row</li>
<li>1: Column</li>
</ul></li>
</ul></li>
<li><p>Replace</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>test_1 = test_1.iloc[:, <span class="number">1</span>:-<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p>可以通过 <code>loc</code> 和 <code>iloc</code> 方法进行取位置来替换原始的数据。</p></li>
</ul>
<h2 id="隐藏信息">4.3 隐藏信息</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data_en.drop([<span class="string">&#x27;PassengerId&#x27;</span>,<span class="string">&#x27;Name&#x27;</span>,<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Ticket&#x27;</span>],axis=<span class="number">1</span>).head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Sex
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
3
</td>
<td>
male
</td>
<td>
1
</td>
<td>
0
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
1
</td>
<td>
female
</td>
<td>
1
</td>
<td>
0
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
3
</td>
<td>
female
</td>
<td>
0
</td>
<td>
0
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p>上述也可用下述代码实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>columns = data_en.columns.drop([<span class="string">&#x27;PassengerId&#x27;</span>,<span class="string">&#x27;Name&#x27;</span>,<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Ticket&#x27;</span>])data_en.drop(columns, axis=<span class="number">1</span>).head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Name
</th>
<th>
Age
</th>
<th>
Ticket
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
22.0
</td>
<td>
A/5 21171
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
38.0
</td>
<td>
PC 17599
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
26.0
</td>
<td>
STON/O2. 3101282
</td>
</tr>
</tbody>
</table>
<p>Note:</p>
<p><code>drop</code> 方法将数据从原数据中去掉，如果不设置 <code>inplace = True</code> 参数的话，默认是用一个临时变量存储新得到的数据。</p>
<h3 id="数据筛选">4.3.1 数据筛选</h3>
<p>表格数据中，最重要的一个功能就是要具有可筛选的能力，选出我所需要的信息，丢弃无用的信息。</p>
<ul>
<li><p>判别式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data_en[data_en[<span class="string">&quot;Age&quot;</span>]&lt;<span class="number">10</span>].head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>PassengerId</p>
</th>
<th>
<p>Survived</p>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
<th>
<p>Age</p>
</th>
<th>
<p>SibSp</p>
</th>
<th>
<p>Parch</p>
</th>
<th>
<p>Ticket</p>
</th>
<th>
<p>Fare</p>
</th>
<th>
<p>Cabin</p>
</th>
<th>
<p>Embarked</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>7</p>
</th>
<td>
<p>8</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Palsson, Master. Gosta Leonard</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>2.0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>349909</p>
</td>
<td>
<p>21.075</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>10</p>
</th>
<td>
<p>11</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Sandstrom, Miss. Marguerite Rut</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>4.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>PP 9549</p>
</td>
<td>
<p>16.700</p>
</td>
<td>
<p>G6</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>16</p>
</th>
<td>
<p>17</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Rice, Master. Eugene</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>2.0</p>
</td>
<td>
<p>4</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>382652</p>
</td>
<td>
<p>29.125</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>Q</p>
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>midage = data_en[(data_en[<span class="string">&quot;Age&quot;</span>]&gt;<span class="number">10</span>) &amp; (data_en[<span class="string">&quot;Age&quot;</span>]&lt;<span class="number">50</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>midage.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>PassengerId</p>
</th>
<th>
<p>Survived</p>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
<th>
<p>Age</p>
</th>
<th>
<p>SibSp</p>
</th>
<th>
<p>Parch</p>
</th>
<th>
<p>Ticket</p>
</th>
<th>
<p>Fare</p>
</th>
<th>
<p>Cabin</p>
</th>
<th>
<p>Embarked</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Braund, Mr. Owen Harris</p>
</td>
<td>
<p>male</p>
</td>
<td>
<p>22.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>A/5 21171</p>
</td>
<td>
<p>7.2500</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>Cumings, Mrs. John Bradley (Florence Briggs Th...</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>38.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>PC 17599</p>
</td>
<td>
<p>71.2833</p>
</td>
<td>
<p>C85</p>
</td>
<td>
<p>C</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>Heikkinen, Miss. Laina</p>
</td>
<td>
<p>female</p>
</td>
<td>
<p>26.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>STON/O2. 3101282</p>
</td>
<td>
<p>7.9250</p>
</td>
<td>
<p>NaN</p>
</td>
<td>
<p>S</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<h3 id="数据提取">4.3.2 数据提取</h3>
<p>将midage的数据中第100行的"Pclass"和"Sex"的数据显示出来</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>midage = midage.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># midage.reset_index(inplace = True, drop=True)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>midage.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th...
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p><strong>Note</strong>:</p>
<p><code>reset_index()</code> 的作用是重置索引值，<code>drop</code> 参数表示是否去掉原始的索引值。</p>
<ul>
<li><p><code>loc</code> 方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>midage.loc[[<span class="number">100</span>],[<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Sex&#x27;</span>]]</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Sex</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>100</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>male</p>
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>midage.loc[[<span class="number">100</span>,<span class="number">105</span>,<span class="number">108</span>],[<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Name&#x27;</span>,<span class="string">&#x27;Sex&#x27;</span>]]</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>100</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>Byles, Rev. Thomas Roussel Davids</p>
</td>
<td>
<p>male</p>
</td>
</tr>
<tr>
<th>
<p>105</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>Cribb, Mr. John Hatfield</p>
</td>
<td>
<p>male</p>
</td>
</tr>
<tr>
<th>
<p>108</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>Calic, Mr. Jovo</p>
</td>
<td>
<p>male</p>
</td>
</tr>
</tbody>
</table></li>
<li><p><code>iloc</code> 方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>midage.iloc[[<span class="number">100</span>,<span class="number">105</span>,<span class="number">108</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Name</p>
</th>
<th>
<p>Sex</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>100</p>
</th>
<td>
<p>2</p>
</td>
<td>
<p>Byles, Rev. Thomas Roussel Davids</p>
</td>
<td>
<p>male</p>
</td>
</tr>
<tr>
<th>
<p>105</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>Cribb, Mr. John Hatfield</p>
</td>
<td>
<p>male</p>
</td>
</tr>
<tr>
<th>
<p>108</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>Calic, Mr. Jovo</p>
</td>
<td>
<p>male</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<p><strong>【总结】</strong>: <code>loc</code> 方法的操作对象是 <code>label</code> 标签，而 <code>iloc</code> 方法的操作对象是标签的索引值。</p>
<p>此外如果要对 <code>DataFrame</code> 对象中的数据进行重赋值操作的话，如果使用的是 <code>loc</code> 方法，当赋值的 <code>label</code> 在数据表中不存在时，会默认新建一列，而 <code>iloc</code> 方法只能在数据表中现有的索引内容中进行覆写，索引值不能超过现有的 <code>shape</code> 值。</p>
]]></content>
      <categories>
        <category>DataWhale</category>
        <category>Data Analysis</category>
      </categories>
      <tags>
        <tag>Data Analysis</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>DataAnalysis-Modeling</title>
    <url>/2021/06/19/DataAnalysis-Modeling/</url>
    <content><![CDATA[<h1 id="modeling-creation">1 Modeling creation</h1>
<p>经过前面的学习，已可以对数数据进行增删查补和清洗工作。接下来需要使用处理好的数据进行分析和建模。这一章要做的是运用数据来得到某些结果。</p>
<p>分析的第一步是搭建一个预测模型或者其他；根据模型的结果，可以分析该模型是否可靠。</p>
<a id="more"></a>
<h2 id="preparation">1.1 Preparation</h2>
<ul>
<li><p>Import modules</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">6</span>)  <span class="comment"># 设置输出图片大小</span></span><br></pre></td></tr></table></figure></li>
<li><p>Load data</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取原数据数集</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">train.shape</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取清洗过的数据集</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;clear_data.csv&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="feature-engineer">1.2 Feature engineer</h2>
<h3 id="fillna">1.2.1 Fillna</h3>
<ul>
<li><p>对分类变量缺失值：填充某个缺失值字符(NA)、用最多类别的进行填充</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>train[<span class="string">&#x27;Cabin&#x27;</span>] = train[<span class="string">&#x27;Cabin&#x27;</span>].fillna(<span class="string">&#x27;NA&#x27;</span>)</span><br><span class="line">    train[<span class="string">&#x27;Embarked&#x27;</span>] = train[<span class="string">&#x27;Embarked&#x27;</span>].fillna(<span class="string">&#x27;S&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>对连续变量缺失值：填充均值、中位数、众数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>train[<span class="string">&#x27;Age&#x27;</span>] = train[<span class="string">&#x27;Age&#x27;</span>].fillna(train[<span class="string">&#x27;Age&#x27;</span>].mean())</span><br></pre></td></tr></table></figure></li>
<li><p>检查缺失值比例</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>train.isnull().<span class="built_in">sum</span>().sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">PassengerId    <span class="number">0</span></span><br><span class="line">Survived       <span class="number">0</span></span><br><span class="line">Pclass         <span class="number">0</span></span><br><span class="line">Name           <span class="number">0</span></span><br><span class="line">Sex            <span class="number">0</span></span><br><span class="line">Age            <span class="number">0</span></span><br><span class="line">SibSp          <span class="number">0</span></span><br><span class="line">Parch          <span class="number">0</span></span><br><span class="line">Ticket         <span class="number">0</span></span><br><span class="line">Fare           <span class="number">0</span></span><br><span class="line">Cabin          <span class="number">0</span></span><br><span class="line">Embarked       <span class="number">0</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h3 id="encoding-classification-variable">1.2.2 Encoding classification variable</h3>
<ul>
<li><p>取出所有输入特征</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = train[[<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;SibSp&#x27;</span>,<span class="string">&#x27;Parch&#x27;</span>, <span class="string">&#x27;Fare&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>]]</span><br></pre></td></tr></table></figure></li>
<li><p>虚拟变量转换</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = pd.get_dummies(data)</span><br><span class="line">    data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>Pclass</p>
</th>
<th>
<p>Age</p>
</th>
<th>
<p>SibSp</p>
</th>
<th>
<p>Parch</p>
</th>
<th>
<p>Fare</p>
</th>
<th>
<p>Sex_female</p>
</th>
<th>
<p>Sex_male</p>
</th>
<th>
<p>Embarked_C</p>
</th>
<th>
<p>Embarked_Q</p>
</th>
<th>
<p>Embarked_S</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>0</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>22.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>7.2500</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<th>
<p>1</p>
</th>
<td>
<p>1</p>
</td>
<td>
<p>38.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>71.2833</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<th>
<p>2</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>26.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>7.9250</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<th>
<p>3</p>
</th>
<td>
<p>1</p>
</td>
<td>
<p>35.0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>53.1000</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<th>
<p>4</p>
</th>
<td>
<p>3</p>
</td>
<td>
<p>35.0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>8.0500</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
</tr>
</tbody>
</table></li>
</ul>
<h2 id="construction">1.3 Construction</h2>
<ul>
<li>处理完数据的下一步是选择合适模型</li>
<li>在进行模型选择前，需要对数据集进行学习的方式是 <strong>监督学习</strong> 还是 <strong>无监督学习</strong></li>
<li>模型的选择通过任务决定</li>
<li>除了根据们任务来选择模型，还可以根据数据样本量以及特征的稀疏性来决定</li>
<li>一般通常会尝试使用一个基本的模型来作为其 <code>baseline</code>，进而再训练其他模型做对比，最终选择泛化能力或性能比较好的模型</li>
</ul>
<p>可以使用机器学习最常用的一个库 <code>sklearn</code> 来完成模型的搭建，<code>sklearn</code> 算法的选择路径如下：</p>
<p><img src="https://z3.ax1x.com/2021/06/20/RF1cYn.png" /></p>
<p><strong>Note:</strong> 图源：<a href="https://mofanpy.com/tutorials/machine-learning/sklearn/select-method/">莫凡Python-选择学习方法</a>，如果想深入学习机器学习的话，也可关注该博客网站，上面有各大常用机器学习库的讲解视频的笔记，视频发布在 <a href="https://space.bilibili.com/243821484?spm_id_from=333.788.b_765f7570696e666f.1">B 站莫烦Python</a> 上，附几个热门的模块：</p>
<ul>
<li><a href="https://www.bilibili.com/video/BV1Jx411L7LU">Matplotlib</a></li>
<li><a href="https://www.bilibili.com/video/BV1xW411Y7Qd">Scikit-learn (sklearn)</a></li>
<li><a href="https://www.bilibili.com/video/BV1Vx411j7kT">Pytorch 神经网络</a></li>
<li><a href="https://www.bilibili.com/video/BV1TW411Y7HU">Keras</a></li>
</ul>
<h3 id="split-data">1.3.1 Split data</h3>
<ul>
<li>按比例切割数据集(常有30%、25%、20%、15%和10%)</li>
<li>按目标变量分层进行等比切割</li>
<li>设置随机种子以便结果能复现</li>
</ul>
<p><strong>Note:</strong></p>
<ul>
<li>切割数据集是为了后续评估模型泛化能力</li>
<li>查看函数文档可以在 <code>notebook</code> 里面使用 <code>train_test_split?</code> 和 <code>help(train_test_split)</code> 后回车即可看到</li>
<li>分层和随机种子在参数里寻找</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">    X = data.astype(<span class="string">&#x27;float64&#x27;</span>)</span><br><span class="line">    y = train[<span class="string">&#x27;Survived&#x27;</span>].astype(<span class="string">&#x27;float64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>查看数据形状</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train.shape, X_test.shape</span><br><span class="line"></span><br><span class="line">((<span class="number">668</span>, <span class="number">10</span>), (<span class="number">223</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<h3 id="modeling">1.3.2 Modeling</h3>
<ul>
<li>创建基于线性模型的分类模型（逻辑回归）</li>
<li>创建基于树的分类模型（决策树、随机森林）</li>
<li>查看模型的参数，并更改参数值，观察模型变化</li>
</ul>
<p><strong>Note:</strong></p>
<ul>
<li>逻辑回归不是回归模型而是 <strong>分类模型</strong>，不要与<code>LinearRegression</code> 混淆</li>
<li>随机森林其实是决策树集成为了降低决策树过拟合的情况</li>
<li>线性模型所在的模块为 <code>sklearn.linear_model</code></li>
<li>树模型所在的模块为 <code>sklearn.ensemble</code></li>
</ul>
<p><strong>线性模型的处理逻辑:</strong> 线性函数可以将平面进行分割，就形成了二分类问题。多分类的处理逻辑类似于线性规划，将平面分割为一个个小块。</p>
<h3 id="cases">1.3.3 Cases</h3>
<p>本小节使用支持向量机和随即森林两个模型进行模型构建。</p>
<ul>
<li><p>支持向量机</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVCfrom sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">    clf = SVC(probability=<span class="literal">True</span>)</span><br><span class="line">    clf.fit(X_train, y_train</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看训练集和测试集score值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(clf.score(X_train, y_train)))</span><br><span class="line">    print(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(clf.score(X_test, y_test)))</span><br><span class="line"></span><br><span class="line">Training <span class="built_in">set</span> score: <span class="number">0.70</span>Testing <span class="built_in">set</span> score: <span class="number">0.64</span></span><br></pre></td></tr></table></figure></li>
<li><p>随机森林</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认参数的随机森林分类模型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rfc = RandomForestClassifier()</span><br><span class="line">    rfc.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">RandomForestClassifier()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(rfc.score(X_train, y_train)))</span><br><span class="line">    print(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(rfc.score(X_test, y_test)))</span><br><span class="line"></span><br><span class="line">Training <span class="built_in">set</span> score: <span class="number">0.99</span>Testing <span class="built_in">set</span> score: <span class="number">0.81</span></span><br></pre></td></tr></table></figure>
<p>对随机森林模型进行调参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 调整参数后的随机森林分类模型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rfc2 = RandomForestClassifier(n_estimators=<span class="number">100</span>, max_depth=<span class="number">5</span>)</span><br><span class="line">    rfc2.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(rfc2.score(X_train, y_train)))</span><br><span class="line">    print(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(rfc2.score(X_test, y_test)))</span><br><span class="line"></span><br><span class="line">Training <span class="built_in">set</span> score: <span class="number">0.86</span>Testing <span class="built_in">set</span> score: <span class="number">0.83</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="prediction">1.4 Prediction</h2>
<p>一般监督模型在 <code>sklearn</code> 里面有个 <code>predict</code> 能输出预测标签，<code>predict_proba</code> 则可以输出标签概率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>pred = clf.predict(X_train)</span><br><span class="line">    pred[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line">array([<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li><p>预测概率</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>pred_proba = clf.predict_proba(X_train)</span><br><span class="line">    pred_proba[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line">array([[<span class="number">0.43518882</span>, <span class="number">0.56481118</span>],</span><br><span class="line">       [<span class="number">0.68639392</span>, <span class="number">0.31360608</span>],</span><br><span class="line">       [<span class="number">0.62646492</span>, <span class="number">0.37353508</span>],</span><br><span class="line">       [<span class="number">0.62676837</span>, <span class="number">0.37323163</span>],</span><br><span class="line">       [<span class="number">0.70955025</span>, <span class="number">0.29044975</span>],</span><br><span class="line">       [<span class="number">0.72361218</span>, <span class="number">0.27638782</span>],</span><br><span class="line">       [<span class="number">0.64503542</span>, <span class="number">0.35496458</span>],</span><br><span class="line">       [<span class="number">0.38964073</span>, <span class="number">0.61035927</span>],</span><br><span class="line">       [<span class="number">0.23539098</span>, <span class="number">0.76460902</span>],</span><br><span class="line">       [<span class="number">0.26563197</span>, <span class="number">0.73436803</span>]])</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="model-evaluation">2 Model evaluation</h1>
<p>根据之前的模型的建模，已经学会了运用 <code>sklearn</code> 库来完成建模，以及数据集的划分等操作。那么如何评估模型的优劣呢？以及如何判断模型给出的结果是否有效呢？这也是本次任务需要学习的内容。</p>
<h2 id="preparation-1">2.1 Preparation</h2>
<h3 id="load-modules">2.1.1 Load modules</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">6</span>)  <span class="comment"># 设置输出图片大小</span></span><br></pre></td></tr></table></figure>
<h3 id="load-data">2.1.2 Load data</h3>
<p>一般先取出 <code>X</code> 和 <code>y</code> 后再切割，有些情况会使用到未切割的，这时候 <code>X</code> 和 <code>y</code> 就可以用，<code>x</code> 是清洗好的数据，<code>y</code> 是我们要预测的存活数据 <code>Survived</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = pd.read_csv(<span class="string">&#x27;clear_data.csv&#x27;</span>)</span><br><span class="line">    train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">    X = data.astype(<span class="string">&#x27;float64&#x27;</span>)</span><br><span class="line">    y = train[<span class="string">&#x27;Survived&#x27;</span>].astype(<span class="string">&#x27;float64&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="split-data-1">2.1.3 Split data</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对数据集进行切割</span></span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>注意到，在本例子中使用了 <code>stratify</code> 参数，其目的是保持测试集与整个数据集里 <code>y</code> 的数据分类比例一致。</p>
<p>举个栗子： 如何整个数据集有 1000 行，<code>y</code> 列的数据也是 1000 个，而且分两类：0 和 1，其中 0 有 300 个，1 有 700 个，即数据分类的比例为 3：7。那么现在把整个数据 <code>split</code>，因为 <code>test_size = 0.2</code>，所以训练集分到 800 个数据，测试集分到 200 个数据。</p>
<p><strong>重点</strong>：由于 <code>stratify = y</code>，则训练集和测试集中的数据分类比例将与 <code>y</code> 一致，也是 3：7，结果就是在训练集中，有 240 个 0 和 560 个 1；测试集中有 60 个 0 和 140 个 1 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_train.values.shape</span><br><span class="line"></span><br><span class="line">(<span class="number">668</span>,)</span><br></pre></td></tr></table></figure>
<h2 id="construction-1">2.2 Construction</h2>
<ul>
<li><p>拟合</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认参数逻辑回归模型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf = RandomForestClassifier()</span><br><span class="line">    clf.fit(X_train.values, y_train)</span><br></pre></td></tr></table></figure></li>
<li><p>预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.predict(X_test)[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line">array([<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="evaluation">2.3 Evaluation</h2>
<ul>
<li>模型评估是为了知道模型的泛化能力。</li>
<li>交叉验证（<code>cross-validation</code>）是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。</li>
<li>在交叉验证中，数据被多次划分，并且需要训练多个模型。</li>
<li>最常用的交叉验证是 <code>k</code> 折交叉验证（<code>k-fold cross-validation</code>），其中 <code>k</code> 是由用户指定的数字，通常取 5 或 10。</li>
<li>准确率（<code>Precision</code>）度量的是被预测为正例的样本中有多少是真正的正例</li>
<li>召回率（<code>Recall</code>）度量的是正类样本中有多少被预测为正类</li>
<li>f-分数是准确率与召回率的调和平均</li>
</ul>
<h3 id="cross-validation">2.3.1 Cross-validation</h3>
<ol type="1">
<li><p>概念</p>
<p>交叉验证是建立模型和验证模型参数时常用的办法。顾名思义，就是重复的对样本数据进行切分，组合为不同的训练集和测试集，并用训练集来训练模型，用测试集来评估模型。</p>
<p>在此基础上可以得到多组不同的训练集和测试集，某次训练集中的某样本在下次可能成为测试集中的样本，即所谓“交叉”。</p></li>
<li><p><strong>思考：那么什么时候才需要交叉验证呢？</strong></p>
<p>交叉验证常用在数据不是很充足时。如果数据样本量较小，可以采用交叉验证来训练优化选择模型。若样本充足，一般可把数据随机地分成三份：<code>Training Set</code>，<code>Validation Set</code>，<code>Test Set</code>。用 <code>Training Set</code> 来训练模型，用 <code>Validation Set</code> 来评估模型预测的好坏和选择模型及其对应的参数。把最终得到的模型再用于 <code>Test Set</code> ，最终决定使用哪个模型以及对应参数。</p></li>
<li><p><strong>常见形式：</strong></p>
<ul>
<li><code>Holdout</code></li>
</ul>
<p>常识来说，Holdout 验证并非一种交叉验证，因为数据并没有交叉使用。 随机从最初的样本中选出部分，形成交叉验证数据，而剩余的就当做训练数据。 一般来说，少于原本样本三分之一的数据被选做验证数据。</p>
<ul>
<li><code>K-fold cross-validation</code>:</li>
</ul>
<p><code>K</code> 折交叉验证，初始采样分割成 <code>K</code> 个子样本，一个单独的子样本被保留作为验证模型的数据，其他 <code>K-1</code> 个样本用来训练。交叉验证重复K次，每个子样本验证一次，平均 <code>K</code> 次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10 折交叉验证是最常用的。5 折交叉验证的示例图如下： <img src="https://z3.ax1x.com/2021/06/20/RF1soj.png" /></p>
<ul>
<li><code>Leave-one-out Cross Validation</code>:</li>
</ul>
<p>留一验证（<code>LOOCV</code>）是 <code>K</code> 折交叉验证的特例，此时折数 <code>K</code> 等于原本样本个数。意指只使用原本样本中的一项来当做验证资料， 而剩余的则留下来当做训练资料。 这个步骤一直持续到每个样本都被当做一次验证资料。在某些情况下是存在有效率的演算法，如使用<code>kernel regression</code> 和 <code>Tikhonov regularization</code>。</p>
<p><strong>Note:</strong> 上述交叉验证的解释内容部分来自搜狗百科词条 <a href="https://baike.sogou.com/v7413760.htm?fromTitle=%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81">交叉验证</a>。</p></li>
<li><p><strong>K 折交叉验证的使用</strong></p>
<p>在本节中主要介绍 <code>K</code> 折交叉验证的使用，借助 <code>sklearn.model_selection</code> 来实现利用 10 折交叉验证来评估前文的随机森林分类模型。</p></li>
</ol>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line">    clf = RandomForestClassifier()</span><br><span class="line">    scores = cross_val_score(clf, X_train, y_train, cv=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># k折交叉验证分数</span></span><br><span class="line">    scores</span><br><span class="line"></span><br><span class="line">array([<span class="number">0.88059701</span>, <span class="number">0.80597015</span>, <span class="number">0.8358209</span> , <span class="number">0.82089552</span>, <span class="number">0.7761194</span> ,</span><br><span class="line">       <span class="number">0.8358209</span> , <span class="number">0.8358209</span> , <span class="number">0.80597015</span>, <span class="number">0.83333333</span>, <span class="number">0.8030303</span> ])</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 平均交叉验证分数</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">&quot;Average cross-validation score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(scores.mean()))</span><br><span class="line"></span><br><span class="line">Average cross-validation score: <span class="number">0.82</span></span><br></pre></td></tr></table></figure></p>
<p>折数越多代表着运行时间越长。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> timefrom sklearn.model_selection</span><br><span class="line"><span class="keyword">import</span> LeaveOneOut</span><br><span class="line"></span><br><span class="line"><span class="comment"># 10 折</span></span><br><span class="line">start = time.time()</span><br><span class="line">scores_fold = cross_val_score(clf, X_train, y_train, cv=<span class="number">10</span>)</span><br><span class="line">transition = time.time()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 留一验证</span></span><br><span class="line">loocv = LeaveOneOut()</span><br><span class="line">scores_leave = cross_val_score(clf, X_train, y_train, cv=loocv)</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;The 10-fold spend &#123;:.2f&#125;s, the leave one spend &#123;:.2f&#125;s&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        transition-start, end-transition))</span><br><span class="line">print(<span class="string">&quot;Average 10-fold cross-validation score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(scores.mean()))</span><br><span class="line">print(<span class="string">&quot;Average leave-one-out cross-validation score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(scores.mean()))</span><br></pre></td></tr></table></figure></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">The <span class="number">10</span>-fold spend <span class="number">2.72</span>s, the leave one spend <span class="number">189.75</span>s</span><br><span class="line">Average <span class="number">10</span>-fold cross-validation score: <span class="number">0.82</span></span><br><span class="line">Average leave-one-out cross-validation score: <span class="number">0.82</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="built_in">len</span>(y_train)/<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">66.8</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="number">189.75</span>/<span class="number">2.72</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">69.7610294117647</span></span><br></pre></td></tr></table></figure>
<p>可以发现采用 <code>10</code> 折仅费了 <code>2.72s</code>，而将折数上调至极限（留一验证）时，花费的时间几乎增加了了 70 倍，同时可以发现倍数与折数比几乎相同。</p>
<h3 id="confusion-matrix">2.3.2 Confusion matrix</h3>
<p><strong>任务：</strong></p>
<ul>
<li>计算二分类问题的混淆矩阵</li>
<li>计算精确率、召回率以及f-分数</li>
</ul>
<ol type="1">
<li><p>混肴矩阵</p>
<p>示意图如下：</p>
<p><img src="https://z3.ax1x.com/2021/06/20/RF16Fs.png" /></p></li>
<li><p>指标值</p>
<p>准确率 <code>Accuracy</code>，精确度 <code>Precision</code>，<code>Recall</code>，<code>f-score</code> 的计算方式：</p>
<p><img src="https://z3.ax1x.com/2021/06/20/RF1Deg.png" /></p>
<ul>
<li>混淆矩阵的方法在 <code>sklearn.metrics</code> 模块</li>
<li>混淆矩阵需要输入真实标签和预测标签</li>
<li><code>Precision</code>，<code>Recall</code>，<code>f-score</code>可以使用 <code>classification_report</code> 模块</li>
</ul></li>
</ol>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">clf = RandomForestClassifier()</span><br><span class="line">clf.fit(X_train.values, y_train) <span class="comment"># 训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测结果</span></span><br><span class="line">pred = clf.predict(X_train)</span><br></pre></td></tr></table></figure></p>
<p><strong>混淆矩阵：</strong></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>confusion_matrix(y_train, pred)</span><br><span class="line"></span><br><span class="line">array([[<span class="number">412</span>,   <span class="number">0</span>],</span><br><span class="line">       [  <span class="number">0</span>, <span class="number">256</span>]], dtype=int64)</span><br></pre></td></tr></table></figure></p>
<p><strong>指标值：</strong></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">print(classification_report(y_train, pred))</span><br></pre></td></tr></table></figure></p>
<pre><code>              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00       412
         1.0       1.00      1.00      1.00       256

    accuracy                           1.00       668
   macro avg       1.00      1.00      1.00       668
weighted avg       1.00      1.00      1.00       668</code></pre>
<h3 id="roc-curve">2.3.3 ROC curve</h3>
<ul>
<li>ROC曲线在sklearn中的模块为<code>sklearn.metrics</code></li>
<li>ROC曲线下面所包围的面积越大越好</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC <span class="comment"># 支持向量机</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line"></span><br><span class="line"><span class="comment"># clf = SVC(decision_function_shape=&quot;ovr&quot;,probability=True)</span></span><br><span class="line">clf = SVC(probability=<span class="literal">True</span>)</span><br><span class="line">clf.fit(X_train.values, y_train) <span class="comment"># 训练</span></span><br><span class="line"></span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, clf.decision_function(X_test))</span><br><span class="line">plt.plot(fpr, tpr, label=<span class="string">&quot;ROC Curve&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;FPR&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;TPR (recall)&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到最接近于0的阈值</span></span><br><span class="line">close_zero = np.argmin(np.<span class="built_in">abs</span>(thresholds))</span><br><span class="line">plt.plot(fpr[close_zero], tpr[close_zero], <span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">10</span>,</span><br><span class="line">         label=<span class="string">&quot;threshold zero&quot;</span>, fillstyle=<span class="string">&quot;none&quot;</span>, c=<span class="string">&#x27;k&#x27;</span>, mew=<span class="number">2</span>)</span><br><span class="line">plt.legend(loc=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://z3.ax1x.com/2021/06/20/RF1wy8.png" /></p>
<p>在上述使用的支持向量机中，对于 <code>n</code> 分类，会有 <code>n</code> 个分类器，然后，任意两个分类器都可以算出一个分类界面，这样，用 <code>decision_function()</code> 时，对于任意一个样例，就会有 <span class="math inline">\(n*(n-1)/2\)</span> 个值。</p>
<p>任意两个分类器可以算出一个分类界面，然后这个值就是距离分类界面的距离。这个函数可能是为了统计画图，对于二分类时最明显，用来统计每个点离超平面有多远，为了在空间中直观的表示数据以及画超平面还有间隔平面等。 <code>decision_function_shape</code> 为 <code>ovr</code> 时是 4 个值，为 <code>ovo</code> 时是 6 个值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.decision_function(X_test)[:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">array([-<span class="number">0.98942638</span>, -<span class="number">0.96365727</span>, -<span class="number">0.81459531</span>, -<span class="number">0.64715413</span>, -<span class="number">0.38873267</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li><p><code>np.argmin()</code></p>
<p>获取最小值索引位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmin(np.<span class="built_in">abs</span>(thresholds))</span><br><span class="line"></span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure></li>
<li><p>计算得分</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.predict_proba(X) <span class="comment">#这个是得分,每个分类器的得分，取最大得分对应的类。</span></span><br><span class="line"></span><br><span class="line">array([[<span class="number">0.68136476</span>, <span class="number">0.31863524</span>],</span><br><span class="line">       [<span class="number">0.61321679</span>, <span class="number">0.38678321</span>],</span><br><span class="line">       [<span class="number">0.68211357</span>, <span class="number">0.31788643</span>],</span><br><span class="line">       			...,       </span><br><span class="line">       [<span class="number">0.63577539</span>, <span class="number">0.36422461</span>],</span><br><span class="line">       [<span class="number">0.61380992</span>, <span class="number">0.38619008</span>],</span><br><span class="line">       [<span class="number">0.68829583</span>, <span class="number">0.31170417</span>]])</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="classification-boundary">2.3.4 Classification boundary</h3>
<p>借助 <code>decision_function</code> 还在输入特征较少时直观地画出分类边界图。下面以一个输入特征为二维的小例子展示二维平面分类边界的绘制，案例参考自 <a href="https://blog.csdn.net/o1101574955/article/details/70212126">胖大海瘦西湖的博文</a>。</p>
<ul>
<li><p>模型构建</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建输入特征和输出特征</span></span><br><span class="line">X = np.array([[-<span class="number">1</span>,-<span class="number">1</span>],[-<span class="number">2</span>,-<span class="number">1</span>],[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">1</span>],[-<span class="number">1</span>,<span class="number">1</span>],[-<span class="number">1</span>,<span class="number">2</span>],[<span class="number">1</span>,-<span class="number">1</span>],[<span class="number">1</span>,-<span class="number">2</span>]])</span><br><span class="line">y = np.array([<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># clf = SVC(decision_function_shape=&quot;ovr&quot;,probability=True)</span></span><br><span class="line">clf = SVC(probability=<span class="literal">True</span>)</span><br><span class="line">clf.fit(X, y)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plot_step=<span class="number">0.02</span></span><br><span class="line">x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span> <span class="comment"># X 的第一维作为横坐标</span></span><br><span class="line">y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span> <span class="comment"># 第二维作为纵坐标</span></span><br><span class="line"></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),</span><br><span class="line">                     np.arange(y_min, y_max, plot_step))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对坐标风格上的点进行预测，来画分界面。其实最终看到的类的分界线就是分界面的边界线。</span></span><br><span class="line">Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">Z = Z.reshape(xx.shape)</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>Note:</strong> 上述代码中使用到了 <code>np.meshgrid</code> 函数，官方文档看起来文绉绉的，理解起来不是很直观。通俗来讲，这个函数的作用是利用两个坐标轴上的点在平面上画网格。</p>
<p>返回两个参数，<code>xx</code> 中记录了网格中所有点的横坐标，<code>yy</code> 记录了网格中所有点的纵坐标。其运行过程可通过下图加深理解：</p>
<p><img src="https://z3.ax1x.com/2021/06/20/RF10OS.jpg" /></p>
<center>
（图源公众号： Python数据之道）
</center>
<p><strong>用法：</strong></p>
<ul>
<li><code>[X, Y] = meshgrid(x, y)</code></li>
<li><code>[X, Y] = meshgrid(x)</code>与 <code>[X, Y] = meshgrid(x, x)</code> 等同</li>
<li><code>[X, Y, Z] = meshgrid(x, y, z)</code> 生成三维数组，可用来计算三变量的函数和绘制三维立体图</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired) <span class="comment"># 绘制轮廓线</span></span><br><span class="line">plt.axis(<span class="string">&quot;tight&quot;</span>)</span><br><span class="line"></span><br><span class="line">class_names=<span class="string">&quot;ABCD&quot;</span></span><br><span class="line">plot_colors=<span class="string">&quot;rybg&quot;</span></span><br><span class="line"><span class="keyword">for</span> i, n, c <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">4</span>), class_names, plot_colors):</span><br><span class="line">    idx = np.where(y == i) <span class="comment">#i为0或者1，两个类</span></span><br><span class="line">    plt.scatter(X[idx, <span class="number">0</span>], X[idx, <span class="number">1</span>],</span><br><span class="line">                c=c, cmap=plt.cm.Paired,</span><br><span class="line">                label=<span class="string">&quot;Class %s&quot;</span> % n)</span><br><span class="line"></span><br><span class="line">plt.xlim(x_min, x_max)</span><br><span class="line">plt.ylim(y_min, y_max)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Decision Boundary&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<p><img src="https://z3.ax1x.com/2021/06/20/RF1rwQ.png" /></p>
]]></content>
      <categories>
        <category>DataWhale</category>
        <category>Data Analysis</category>
      </categories>
      <tags>
        <tag>Data Analysis</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Econometrics</title>
    <url>/2020/12/15/Econometrics/</url>
    <content><![CDATA[<h1 id="introduction">1 Introduction</h1>
<p>本文为参考洪永淼老师《高级计量学》复习高级计量经济学的学习笔记。</p>
<a id="more"></a>
<h1 id="一般回归分析和模型设定">2 一般回归分析和模型设定</h1>
<h2 id="条件概率分别">2.1 条件概率分别</h2>
<ul>
<li><p>边际概率密度函数 （<span class="math inline">\(\rm{P}_{18}\)</span>） <span class="math display">\[
\begin{align*}
f_x(x) = \int_{-\infty}^\infty f_{XY}(x,y)\rm{d}y
\end{align*}
\]</span></p></li>
<li><p>给定 <span class="math inline">\(X = x\)</span>，<span class="math inline">\(Y\)</span> 的条件概率密度函数 （<span class="math inline">\(\rm{P}_{18}\)</span>） <span class="math display">\[
\begin{align*}
f_{Y|X}(y|x) = \frac{f_{XY}(x,y)}{f_X{(x)}}
\end{align*}
\]</span></p></li>
<li><p>条件均值（<span class="math inline">\(\rm{P}_{19}\)</span>） <span class="math display">\[
\begin{align*}
E(Y|x) \equiv E(Y|X=x) = \int_{-\infty}^{\infty} y f_{Y|X}(y|x)\rm{d}y
\end{align*}
\]</span></p></li>
<li><p>条件方差（<span class="math inline">\(\rm{P}_{19}\)</span>） <span class="math display">\[
\begin{align*}
var(Y|x) \equiv var(Y|X=x) &amp;= \int_{-\infty}^{\infty} [y-E(Y|x)]^2f_{Y|X}(y|x)\rm{d}y  \\
&amp;= E(Y^2|x)-[E(Y|x)]^2
\end{align*}
\]</span></p></li>
<li><p>条件偏度（Conditional skewness）（<span class="math inline">\(\rm{P}_{19}\)</span>） <span class="math display">\[
\begin{align*}
S(Y|x) \equiv \frac{E[(Y-E(Y|x)]^3|x)}{[var(Y|x)]^{3/2}}
\end{align*}
\]</span></p></li>
<li><p>条件峰度（Conditional kurtosis）（<span class="math inline">\(\rm{P}_{19}\)</span>） <span class="math display">\[
\begin{align*}
K(Y|x) \equiv \frac{E[(Y-E(Y|x)]^4|x)}{[var(Y|x)]^{2}}
\end{align*}
\]</span></p></li>
<li><p>条件 <span class="math inline">\(\alpha\)</span> - 分位数（Conditional <span class="math inline">\(\alpha\)</span>-quantile）（<span class="math inline">\(\rm{P}_{19}\)</span>） <span class="math display">\[
\begin{align*}
P[Y \leq Q(X, \alpha)|X = x] = \alpha \in (0,1)
\end{align*}
\]</span></p></li>
</ul>
<h2 id="条件均值与回归分析">2.2 条件均值与回归分析</h2>
<h3 id="定义">2.2.1 定义</h3>
<ul>
<li><strong>定义 2.1</strong>（<span class="math inline">\(\rm{P}_{20}\)</span>）&lt; 回归函数 (Regression Function) &gt;：条件均值 <span class="math inline">\(E(Y|X)\)</span> 称为 <span class="math inline">\(Y\)</span> 对 <span class="math inline">\(X\)</span> 的回归函数;</li>
</ul>
<h3 id="定理">2.2.2 定理</h3>
<ul>
<li><p><strong>定理 2.1</strong>（<span class="math inline">\(\rm{P}_{21}\)</span>）：<span class="math inline">\(E(E(Y|X)) = E(Y)\)</span>；</p></li>
<li><p><strong>定理 2.2</strong>（<span class="math inline">\(\rm{P}_{21}\)</span>） &lt; 重复期望法则 (Law of Interated Expectations, LIE) &gt;：对给定的可测函数 <span class="math inline">\(G(X,Y)\)</span>，假设期望 <span class="math inline">\(E[G(X,Y)]\)</span> 存在，则： <span class="math display">\[
\begin{align*}
E[G(X, Y)] = E\{E[G(X,Y)|X])\}
\end{align*}
\]</span></p></li>
<li><p><strong>定理 2.3</strong>（<span class="math inline">\(\rm{P}_{23}\)</span>）&lt; <span class="math inline">\(MSE\)</span> 最优解 &gt;：条件均值 <span class="math inline">\(E(Y|X)\)</span> 是下列问题的最优解： <span class="math display">\[
\begin{align*}
E(Y|X = \arg \min_{g\ \in\ \mathbb{F}} E[Y - g(X)]^2
\end{align*}
\]</span> 其中，<span class="math inline">\(\mathbb{F}\)</span> 是所有可测和平方可积函数的集合 (Space of all measurable and quare-integrable functions)，即： <span class="math display">\[
\begin{align*}
\mathbb{F} = \left\{g:\mathbb{R}^{k+1} \to \mathbb{R}\ \left| \int g^2(x) f_X(x) \rm{d}x &lt; \infty \right.\right\}
\end{align*}
\]</span> &lt; 注：可通过中间变量 <span class="math inline">\(g_0(X) \equiv E(Y|X)\)</span> 证明 &gt;</p></li>
<li><p><strong>定理 2.4</strong>（<span class="math inline">\(\rm{P}_{25}\)</span>）&lt; 回归等式 (Regression Identity) &gt;：给定条件均值 <span class="math inline">\(E(Y|X)\)</span>，总有： <span class="math display">\[
\begin{align*}
Y = E(Y|X) + \varepsilon
\end{align*}
\]</span> 其中，<span class="math inline">\(\varepsilon\)</span> 称为回归扰动项（Regression disturbance），满足： <span class="math display">\[
\begin{align*}
E(\varepsilon|X) = 0
\end{align*}
\]</span></p></li>
</ul>
<h2 id="线性回归建模">2.3 线性回归建模</h2>
<h3 id="定义-1">2.3.1 定义</h3>
<ul>
<li><p><strong>定义 2.3</strong>（<span class="math inline">\(\rm{P}_{29}\)</span>）&lt; 仿射函数 (Affine Function) &gt;：记 <span class="math inline">\(X = (1, X_1, \dots , X_k)^\prime\)</span>，<span class="math inline">\(\beta = (\beta_0, \beta_1, \dots, \beta_k)^\prime\)</span>。则仿射函数族定义为： <span class="math display">\[
\begin{align*}
\mathbb{A} &amp;= \left\{ g:\mathbb{R}^{k+1} \to \mathbb{R}\ |\ g(X) = \beta_0 + \sum_{j=1}^{k} \beta_jX_j, \beta_j \in \mathbb{R} \right\} \\
&amp;= \left\{ g:\mathbb{R}^{k+1} \to \mathbb{R}\ |\ g(X) = X^\prime\beta \right\}
\end{align*}
\]</span> 这里，对参数向量 <span class="math inline">\(\beta\)</span> 的值没有限制。对于这族函数，函数形式一致，分别是解释变量和参数 <span class="math inline">\(\beta\)</span> 的线性函数；</p></li>
<li><p><strong>定义 2.4</strong>（<span class="math inline">\(\rm{P}_{32}\)</span>）&lt; 线性回归模型 (Linear Regression Model) &gt;：方程： <span class="math display">\[
\begin{align*}
Y = X^\prime \beta + u, \beta \in \mathbb{R}^{k+1}
\end{align*}
\]</span> 称为 <span class="math inline">\(Y\)</span> 对 <span class="math inline">\(X\)</span> 的线性回归模型，其中 <span class="math inline">\(u\)</span> 是回归模型误差 (Regression model error)。如果 <span class="math inline">\(k=1\)</span>，称为二元线性回归模型 (Bivariate linear regression model) 或直线回归模型 (Straight linere gression model)。如果 <span class="math inline">\(k&gt;1\)</span>，则称为多元线性回归模型 (Multiple linear regression model)；</p></li>
</ul>
<h3 id="定理-1">2.3.2 定理</h3>
<ul>
<li><p><strong>定理 2.5</strong>（<span class="math inline">\(\rm{P}_{30}\)</span>）&lt; 最优线性最小二乘预测 (Best Linear Least Squares Predictstion) &gt; ：假设<span class="math inline">\(E(Y^2) &lt; \infty\)</span>，且<span class="math inline">\((k+1) \times (k+1)\)</span> 矩阵 <span class="math inline">\(E(X^\prime X)\)</span> 是非奇异的。则以下优化问题： <span class="math display">\[
\begin{align*}
\min_{g\ \in\ \mathbb{A} }E[Y - g(X)]^2 = \min_{\beta\ \in \mathbb{R}^{k+1}}E(Y - X^\prime \beta)^2
\end{align*}
\]</span> 的解，即最优线性最小二乘法预测值为： <span class="math display">\[
\begin{align*}
g^*(X) = X^\prime\beta^*
\end{align*}
\]</span> 其中最优系数向量为（<span class="math inline">\(\star \star \star\)</span>）： <span class="math display">\[
\begin{align*}
\beta^* = [E(X X^\prime)]^{-1}E(XY)
\end{align*}
\]</span></p></li>
<li><p><strong>定理 2.6</strong>（<span class="math inline">\(\rm{P}_{32}\)</span>）：假设定理 2.5 的条件成立。令： <span class="math display">\[
\begin{align*}
Y =  X^\prime \beta + u
\end{align*}
\]</span> 并令 <span class="math inline">\(\beta^* = [E(XX^\prime)]^{-1}E(XY)\)</span> 为最优线性最小二乘近似系数。则： <span class="math display">\[
\begin{align*}
\beta = \beta^*
\end{align*}
\]</span> 当且仅当以下正交条件成立： <span class="math display">\[
\begin{align*}
E(Xu) = 0
\end{align*}
\]</span></p></li>
</ul>
<h2 id="条件均值的模型设定">2.4 条件均值的模型设定</h2>
<h3 id="定义-2">2.4.1 定义</h3>
<ul>
<li><strong>定义 2.5</strong>（<span class="math inline">\(\rm{P}_{34}\)</span>）&lt; 条件均值模型的正确设定 &gt;：线性回归模型： <span class="math display">\[
\begin{align*}
Y = X^\prime \beta + u, \beta \in \mathbb{R^{k+1}}
\end{align*}
\]</span> 是条件均值 <span class="math inline">\(E(Y|X)\)</span> 的正确设定，如果存在某个参数值 <span class="math inline">\(\beta^o \in \mathbb{R^{k+1}}\)</span>，有： <span class="math display">\[
\begin{align*}
E(Y|X) = X^\prime \beta^o
\end{align*}
\]</span> 另一方面，如果对于任意的参数值 <span class="math inline">\(\beta \in \mathbb{R^{k+1}}\)</span>， <span class="math display">\[
\begin{align*}
E(Y|X) \neq X^\prime \beta
\end{align*}
\]</span> 则称线性回归模型是对 <span class="math inline">\(E(Y|X)\)</span> 的错误设定 (Misspecified)；</li>
</ul>
<h3 id="定理-2">2.4.2 定理</h3>
<ul>
<li><p><strong>定理 2.7</strong>（<span class="math inline">\(\rm{P}_{35}\)</span>）：如果线性回归模型： <span class="math display">\[
\begin{align*}
Y =  X^\prime \beta + u
\end{align*}
\]</span> 是对条件均值<span class="math inline">\(E(Y|X)\)</span> 的正确设定则：</p>
<p>1）存在一个参数 <span class="math inline">\(\beta^o\)</span> 和一个随机变量 <span class="math inline">\(\varepsilon\)</span>，有 <span class="math inline">\(Y = X^\prime \beta^o+\varepsilon\)</span>，其中 <span class="math inline">\(E(\varepsilon|X) = 0\)</span>；</p>
<p>2）<span class="math inline">\(\beta^* = \beta^o\)</span></p></li>
</ul>
<h1 id="经典线性回归模型">3. 经典线性回归模型</h1>
<h2 id="假设">3.1 假设</h2>
<ul>
<li><p><strong>假设 3.1</strong>（<span class="math inline">\(\rm{P}_{45}\)</span>）&lt; 线性 (Linearity) &gt;：<span class="math inline">\(\{Y_t, X_t^\prime\}_{t=1}^n\)</span> 是一个可观测的随机样本，且： <span class="math display">\[
Y_t = X_t^\prime \beta^o + \varepsilon_t, t = 1, \dots, n
\]</span> 其中，<span class="math inline">\(\beta^o\)</span> 是一个 <span class="math inline">\(K \times 1 (K = k + 1)\)</span> 未知参数向量，<span class="math inline">\(\varepsilon_t\)</span> 是一个不可观测的随机扰动项；</p>
<p>令： <span class="math display">\[
\begin{align*}
Y &amp; = (Y_1, \dots , Y_n)^\prime, &amp;n \times 1 \\
\varepsilon &amp; = (\varepsilon_1, \dots , \varepsilon_n)^\prime, &amp;n \times 1 \\
X &amp; = (X_1, \dots , X_n)^\prime, &amp;n \times K \\
\end{align*}
\]</span> 这里 <span class="math inline">\(X\)</span> 的第 <span class="math inline">\(t\)</span> 行是 <span class="math inline">\(K\)</span> 维行向量 <span class="math inline">\(X_t^\prime = (1, X_{1t},\dots,X_{kt})\)</span>。从而，(1) 式可以表示为： <span class="math display">\[
\begin{align*}
Y = X \beta^o + \varepsilon
\end{align*}
\]</span></p></li>
<li><p><strong>假设 3.2</strong>（<span class="math inline">\(\rm{P}_{46}\)</span>）&lt; 严格外生性 (Strict Exogeneity) &gt;： <span class="math display">\[
\begin{align*}
E(\varepsilon_t|X) = E(\varepsilon_t|X_1, \dots, X_t,\dots,X_n) = 0 \qquad t = 1,\dots,n
\end{align*}
\]</span> 这一假设隐含着 <span class="math inline">\(E(Y_t|X_t)\)</span> 的模型设定正确；</p></li>
<li><p><strong>假设 3.3</strong>（<span class="math inline">\(\rm{P}_{48}\)</span>）&lt; 非奇异性 (Nonsingularity) &gt;：</p>
<p>1）<span class="math inline">\(K \times K\)</span> 方阵 <span class="math inline">\(X^\prime X = \sum_\limits{t=1}^n X_t X_t^\prime\)</span> 是非奇异的（排除了 <span class="math inline">\(X_t\)</span> 中存在多重共线性）；</p>
<p>2）当 <span class="math inline">\(n \to \infty\)</span> 时，<span class="math inline">\(X^\prime X\)</span> 的最小特征值: <span class="math display">\[
\begin{align*}
\lambda_{min}(X^\prime X) \to \infty
\end{align*}
\]</span> 的概率为 1;</p></li>
<li><p><strong>假设 3.4</strong>（<span class="math inline">\(\rm{P}_{49}\)</span>）&lt; 球形误差方差 (Spherical Error Variance) &gt;：</p>
<p>1）条件同方差: <span class="math display">\[
\begin{align*}
E(\varepsilon_t^2|X) = \sigma^2 &gt; 0, \quad t =1,\dots,n
\end{align*}
\]</span> 2）条件不相关： <span class="math display">\[
\begin{align*}
E(\varepsilon_t\varepsilon_s|X) = 0, t \neq s, \quad t,s \in \{1,\dots,n\}
\end{align*}
\]</span> 上述可写为： <span class="math display">\[
\begin{align*}
E(\varepsilon_t\varepsilon_s|X) = \sigma^2 \delta_{ts} = \sigma^2I,  \quad t,s \in \{1,\dots,n\}
\end{align*}
\]</span> 其中，<span class="math inline">\(\delta_{ts} = 1\)</span> 当且仅当 <span class="math inline">\(t=s\)</span>；</p></li>
</ul>
<h3 id="总结">3.1.1 总结</h3>
<p>给定假设 3.2 和 3.4 意味着 <span class="math inline">\(\varepsilon_t\)</span> 存在条件同方差，即： <span class="math display">\[
\begin{align*}
var(\varepsilon_t|X) = E(\varepsilon_t^2|X) - [E(\varepsilon_t|X)]^2 = E(\varepsilon_t^2|X) = \sigma^2
\end{align*}
\]</span> 同样的，对于所有的 <span class="math inline">\(t \neq s\)</span>，有： <span class="math display">\[
\begin{align*}
cov(\varepsilon_t,\varepsilon_s|X) = E(\varepsilon_t\varepsilon_s|X) = 0
\end{align*}
\]</span> 如果 <span class="math inline">\(t\)</span> 表示个体单元，这意味着 <strong>横截面不相关</strong>，如果 <span class="math inline">\(t\)</span> 表示时间，这意味着 <strong>序列不相关</strong>，为方便起见，这两种情况均称为 <span class="math inline">\(\{\varepsilon_t\}\)</span> <strong>不存在自相关</strong>；</p>
<h2 id="普通最小二乘法-ols">3.2 普通最小二乘法 (OLS)</h2>
<h3 id="定义-3">3.2.1 定义</h3>
<ul>
<li><p><strong>定义 3.1</strong>（<span class="math inline">\(\rm{P}_{50}\)</span>）&lt; <span class="math inline">\(OLS\)</span> 估计量 &gt;：定义线性回归模型 <span class="math inline">\(Y_t = X_t^\prime \beta + u_t\)</span> 的残差平方和 (Sum of squared residuals, SSR) 为： <span class="math display">\[
\begin{align*}
SSR(\beta) \equiv (Y - X\beta)^\prime(Y - X\beta) = \sum_{t=1}^{n}(Y_t - X_t^\prime\beta)^2
\end{align*}
\]</span> 则普通最小二乘法 ( <span class="math inline">\(OLS\)</span> ) 估计量 <span class="math inline">\(\hat\beta\)</span> 是以下优化问题的解： <span class="math display">\[
\begin{align*}
\hat \beta = \arg \min_{\beta\ \in \mathbb{R}^K} SSR(\beta)
\end{align*}
\]</span> <strong>注：</strong> <span class="math inline">\(OLS\)</span> 具有以下良好性质（陈强，<span class="math inline">\(\rm{P}_{87}\)</span>）：</p>
<p>1）<strong>线性性。</strong><span class="math inline">\(OLS\)</span> 估计量 <span class="math inline">\(\hat \beta\)</span> 为线性估计量（Linear estimator）。从 <span class="math inline">\(OLS\)</span> 估计量的表达式 <span class="math inline">\(\hat \beta = (X^\prime X)^{-1} X^\prime Y\)</span> 可知，<span class="math inline">\(\hat \beta\)</span> 可以视为 <span class="math inline">\(Y\)</span> 的线性组合，同时也是 <span class="math inline">\(\varepsilon\)</span> 的线性组合（<strong>将 <span class="math inline">\((X^\prime X)^{-1} X^\prime\)</span> 视为系数矩阵</strong>，<span class="math inline">\(\star\star\star\)</span>）。故为线性估计量。</p>
<p>2）<strong>无偏性。</strong><span class="math inline">\(E(\hat\beta|X) = \beta\)</span>，即 <span class="math inline">\(\hat\beta\)</span> 不会系统地高估或低估 <span class="math inline">\(\beta\)</span>，即定理 3.5 (1)。</p>
<p>3）<strong>估计量 <span class="math inline">\(\hat\beta\)</span> 的协方差矩阵。</strong><span class="math inline">\(var(\hat \beta |X) = \sigma^2(X^\prime X)^{-1}\)</span>，见定理 3.5 (2)。</p>
<p>4）<strong>最小方差性。</strong>所有无偏估计量中最小二乘估计的方差最小。</p></li>
</ul>
<h3 id="定理-3">3.2.2 定理</h3>
<ul>
<li><p><strong>定理 3.1</strong>（<span class="math inline">\(\rm{P}_{50}\)</span>）&lt; <span class="math inline">\(OLS\)</span> 的存在性 &gt;：在假设 3.1 和 3.3 (1) 下， <span class="math inline">\(OLS\)</span> 估计量 <span class="math inline">\(\hat \beta\)</span> 存在，并且： <span class="math display">\[
\begin{align*}
\hat \beta &amp;= (X^\prime  X)^{-1} X^\prime Y \\
 &amp; = \left(\frac{1}{n} \sum_{t = 1}^{n} X_t X_t^\prime\right)^{-1} \frac{1}{n} \sum_{t=1}^{n} X_t Y_t
\end{align*}
\]</span> 其中第二个表达式在后面章节的渐近分析中将经常用到。</p>
<p><strong>注：</strong> <span class="math inline">\(\hat Y_t \equiv X_t^\prime \hat\beta\)</span> 称为观测值 <span class="math inline">\(Y_t\)</span> 的 <strong>拟合值或者预测值</strong>，而 <span class="math inline">\(e_t \equiv Y_t - \hat Y_t\)</span> 是观测值 <span class="math inline">\(Y_t\)</span> 的 <strong>估计残差或预测误差</strong>。被解释变量 <span class="math inline">\(Y_t\)</span> 可以分解为相互正交的拟合值 <span class="math inline">\(\hat Y\)</span> 与残差 <span class="math inline">\(e\)</span> 之和，参见 Fig. 3-1。</p>
<p><img src="https://s3.ax1x.com/2020/12/21/r03CND.jpg" style="zoom:80%;" /></p></li>
</ul>
<center>
Fig. 3-1 OLS 的正交性
</center>
<ul>
<li><p><strong>定理 3.2</strong>（<span class="math inline">\(\rm{P}_{52}\)</span>）：给定假设 3.1 和 3.3 (1)，有：</p>
<ol type="1">
<li><span class="math display">\[
\begin{align*}
X ^\prime e = 0
\end{align*}
\]</span></li>
<li><span class="math display">\[
\begin{align*}
\hat \beta - \beta^o = (X^\prime X)^{-1}X^{\prime}\varepsilon
\end{align*}
\]</span></li>
</ol>
<p><strong>注：</strong> 上式可变为 <span class="math inline">\(C\varepsilon\)</span>，其中 <span class="math inline">\(C\)</span> 是权重向量，因此，给定 <span class="math inline">\(X, \hat\beta-\beta^o\)</span> 是 <span class="math inline">\(\varepsilon\)</span> 的线性组合，当 <span class="math inline">\(\varepsilon\)</span> 服从联合正态分布时，<span class="math inline">\(\hat\beta-\beta^o\)</span> 也服从正态分布。</p>
<ol start="3" type="1">
<li>定义 <span class="math inline">\(n \times n\)</span> 投影矩阵 <span class="math display">\[
\begin{align*}
P = X(X^\prime X)^{-1}X^{\prime}
\end{align*}
\]</span> 和 <span class="math display">\[
\begin{align*}
M = I_n - P
\end{align*}
\]</span> 则 <span class="math inline">\(P\)</span> 和 <span class="math inline">\(M\)</span> 是对称的（即 <span class="math inline">\(P = P^{\prime},\ M = M^{\prime}\)</span>）幂等矩阵（即 <span class="math inline">\(P = P^{2},\ M = M^{2}\)</span>），并且 <span class="math display">\[
\begin{align*}
PX = X \\
MX = 0
\end{align*}
\]</span></li>
<li><span class="math display">\[
\begin{align*}
SSR(\hat \beta) = e^\prime e = Y^{-1} MY = \varepsilon^{\prime} M \varepsilon
\end{align*}
\]</span> <strong>注：</strong><span class="math inline">\(e = Y - X \hat\beta = M \varepsilon\)</span>（<span class="math inline">\(\star\star\star\)</span>）</li>
</ol></li>
</ul>
<h2 id="拟合优度和模型选择准则">3.3 拟合优度和模型选择准则</h2>
<h3 id="定义-4">3.3.1 定义</h3>
<ul>
<li><p><strong>定义 3.2</strong>（<span class="math inline">\(\rm{P}_{54}\)</span>）&lt; 非中心化 <span class="math inline">\(\mathcal{R}^2\)</span> &gt;：非中心化多元相关系数平方 <span class="math inline">\(\mathcal{R}^2\)</span> 定义为：</p>
<p><span class="math display">\[
\begin{align*}
\mathcal{R}^2_{uc} = \frac{\hat Y{}^\prime \hat Y}{Y^\prime Y} = 1 - \frac{e^\prime e}{Y^\prime Y}
\end{align*}
\]</span></p>
<p><span class="math inline">\(\mathcal{R}^2\)</span> 的含义是因变量 <span class="math inline">\({Y_t}\)</span> 的非中心化的样本二次型变动可以被预测值 <span class="math inline">\(\{\hat Y{}^\prime\}\)</span> 的非中心化样本二次型变动所预测的比例。由定义可知，总有 <span class="math inline">\(0 \leq \mathcal{R}^2_{uc} \leq 1\)</span>。</p></li>
<li><p><strong>定义 3.3</strong>（<span class="math inline">\(\rm{P}_{54}\)</span>）&lt; 中心化 <span class="math inline">\(\mathcal{R}^2\)</span> 或决定系数 (Coefficient of Determination) &gt;：决定系数定义为：</p>
<p><span class="math display">\[
\begin{align*}
\mathcal{R}^2 &amp;\equiv 1 - \frac{\sum_\limits{t=1}^{n} e_t^2}{\sum_\limits{t=1}^{n} (Y_t - \overline Y)^2} \\
&amp;= 1 - \frac{SSE}{SST} = \frac{SSR}{SST} = \frac{\sum\limits_{i=1}^{n}(\hat{Y_i} - \bar Y)^2}{\sum\limits_{i=1}^{n}(Y_i - \bar Y)^2}
\end{align*}
\]</span></p>
<p>其中 <span class="math inline">\(\overline Y = n^{-1}\sum_\limits{t=1}^{n}Y_t\)</span> 是样本均值。</p>
<p><strong>注：</strong></p>
<ul>
<li><p>当 <span class="math inline">\(X_t\)</span> 包括截距项，即 <span class="math inline">\(X_{0t} = 1\)</span> 时，可进行如下正交分解：</p>
<p><span class="math display">\[
\begin{align*}
\sum_{t=1}^{n}(Y_t - \overline Y)^2 &amp;= \sum_{t=1}^{n}(\hat Y_t - \overline Y + Y_t - \hat Y_t)^2 \\
&amp; = \sum_{t=1}^{n}(\hat Y_t - \overline Y)^2 + \sum_{t=1}^{n}e_t^2
\end{align*}
\]</span></p>
<p>此时（<span class="math inline">\(\star \star\star\)</span>）：</p>
<p><span class="math display">\[
\begin{align*}
\mathcal{R}^2 &amp;\equiv 1 - \frac{e^\prime e}{\sum_\limits{t=1}^{n}(Y_t - \overline Y)^2}\\
&amp;= \frac{\sum_\limits{t=1}^{n}(\hat Y_t - \overline Y)^2}{\sum_\limits{t=1}^{n}(Y_t - \overline Y)^2}
\end{align*}
\]</span></p></li>
<li><p>如果 <span class="math inline">\(X_t\)</span> 不包括截距项，此时 <span class="math inline">\((X^\prime X)\)</span> 是奇异矩阵，且可能有 <span class="math inline">\(E(e_t) \neq 0\)</span>，所以有：</p>
<p><span class="math display">\[
\begin{align*}
\sum_{t=1}^{n}(Y_t - \overline Y)^2 &amp;= \sum_{t=1}^{n}(\hat Y_t - \overline Y)^2 + \sum_{t=1}^{n}e_t^2 + 2 \sum_{t=1}^{n}(\hat Y_t - \overline Y)e_t \\
&amp;\neq \sum_{t=1}^{n}(\hat Y_t - \overline Y)^2 + \sum_{t=1}^{n}e_t^2
\end{align*}
\]</span></p>
<p>在这种情况下，<strong><span class="math inline">\(\mathcal{R}^2\)</span> 可能为负值</strong>，因为交叉项 <span class="math inline">\(\sum_\limits{t=1}^{n}(\hat Y_t - \overline Y)e_t\)</span> 可能为负值。</p></li>
</ul></li>
</ul>
<h3 id="定理-4">3.3.2 定理</h3>
<ul>
<li><p><strong>定理 3.3</strong>（<span class="math inline">\(\rm{P}_{56}\)</span>）：<span class="math inline">\(\mathcal{R}^2 = \hat \rho_{Y\hat Y}^2 = \frac{cov(Y, \hat Y)}{var(Y)var(\hat Y)}\)</span>，这里 <span class="math inline">\(\hat \rho_{Y\hat Y}^2\)</span> 是 <span class="math inline">\(\{Y_t\}\)</span> 和 <span class="math inline">\(\{\hat Y_t\}\)</span> 的样本相关系数。</p></li>
<li><p><strong>定理 3.4</strong>（<span class="math inline">\(\rm{P}_{56}\)</span>）：假设 <span class="math inline">\(\{Y_t, X_{1t}, \dots, X_{ (k+q)t}\}_{t=1}^n\)</span> 是一容量为 <span class="math inline">\(n\)</span> 的随机样本，<span class="math inline">\(\mathcal{R}_1^2\)</span> 是下列线性回归模型的中心化拟合度：</p>
<p><span class="math display">\[
\begin{align*}
Y_t= X_t^{\prime}\beta + \varepsilon_t
\end{align*}
\]</span></p>
<p>其中， <span class="math inline">\(X_t = (1, X_{1t}, \dots, X_{kt})^\prime\)</span>，<span class="math inline">\(\beta\)</span> 是 <span class="math inline">\(K \times 1\)</span> 未知参数向量；<span class="math inline">\(\mathcal{R}_2^2\)</span> 是下面扩展的线性回归模型的中心化扰合优度：</p>
<p><span class="math display">\[
\begin{align*}
Y_t = \tilde X_t^\prime \gamma + u_t
\end{align*}
\]</span></p>
<p>其中，<span class="math inline">\(\tilde X_t = (1, X_{1t}, \dots, X_{kt}, X_{(k+1)t)})^\prime\)</span>，<span class="math inline">\(\gamma\)</span> 是 <span class="math inline">\((K+q) \times 1\)</span> 未知参数向量，<span class="math inline">\(q\)</span> 是正整数。则：</p>
<p><span class="math display">\[
\begin{align*}
\mathcal{R}_2^2 \geq \mathcal{R}_1^2
\end{align*}
\]</span></p>
<p><strong>注：</strong>定理 3.4 有重要含义：</p>
<ul>
<li><p><span class="math inline">\(\mathcal{R}^2\)</span> 可用于 <strong>解释变量数目相等</strong> 的线性回归模型的比较，但它不适用于 <strong>比较不同解释变量数目</strong> 的线性模型，因为 <strong>模型的解释变量越多，<span class="math inline">\(\mathcal{R}^2\)</span> 就会越大</strong>。</p></li>
<li><p><span class="math inline">\(\mathcal{R}^2\)</span> 也不是正确模型设定的判断标准。<span class="math inline">\(\mathcal{R}^2\)</span> 高并不意味着模型设定正确，事实上，给定解释变量 <span class="math inline">\(X_t\)</span>，<span class="math inline">\(\mathcal{R}_2\)</span> 值的大小 <strong>与线性回归模型的信噪比</strong> 有关。</p></li>
</ul></li>
</ul>
<h3 id="模型选择准则">3.3.3 模型选择准则</h3>
<ol type="1">
<li><p><strong>Akaike 信息准则</strong>（Akaike information criterion, AIC）</p>
<p>线性回归模型可通过选择合适的解释变量数模 <span class="math inline">\(K\)</span>，以最小化下面的 Akaike 信息准则来选择模型。 <span class="math display">\[
\begin{align*}
AIC = {\rm{ln}}(s^2) + \frac{2K}{n}
\end{align*}
\]</span> 其中， <span class="math display">\[
\begin{align*}
s^2 = e^\prime e / (n - K)
\end{align*}
\]</span> <span class="math inline">\(K = k+1\)</span> 是自变量 <span class="math inline">\(X_t\)</span> 的数目，第一项 <span class="math inline">\({\rm{ln}} s^2\)</span> 测度模型的拟合优度，而第二项 <span class="math inline">\(2K/n\)</span> 测度模型的复杂程度。另外，<span class="math inline">\(s^2\)</span> 是 <span class="math inline">\(E(\varepsilon_t^2) = \sigma^2\)</span> 的残差方差估计量（Residual variance estimator）。</p></li>
<li><p><strong>Bayesian 信息准则</strong>（Bayesian information criterion, BIC）</p>
<p>线性模型也可以通过选择合适的 <span class="math inline">\(K\)</span>，以最小化以下 <span class="math inline">\(Bayesian\)</span> 信息准则来选择模型： <span class="math display">\[
\begin{align*}
BIC = {\rm{ln}} (s^2) +\frac{K {\rm{ln}}(n)}{n}
\end{align*}
\]</span></p></li>
<li><p><span class="math inline">\(\overline{\mathcal{R}}{}^2\)</span></p>
<p>我们知道 <span class="math inline">\(\mathcal{R}^2\)</span> 的定义为：</p>
<p><span class="math display">\[
\begin{align*}
\mathcal{R}^2 = 1 - \frac{e^\prime e / n}{\sum_\limits{t=1}^{n}(Y_t - \overline Y)^2 / n} = 1 - \frac{SSE}{SST}
\end{align*}
\]</span></p>
<p>其中，<span class="math inline">\(e^\prime e / n\)</span> 和 <span class="math inline">\(\sum_\limits{t=1}^{n}(Y_t - \overline Y)^2 / n\)</span> 分别是方差 <span class="math inline">\(\sigma^2 = var(\varepsilon_t)\)</span> 和 <span class="math inline">\(\sigma_Y^2 = var(Y_t)\)</span> 的有偏估计。残差平方和：<span class="math inline">\(SSE\)</span>（书中为 <span class="math inline">\(SSR\)</span>（residual），调整的 <span class="math inline">\(\mathcal{R}^2\)</span> 为：</p>
<p><span class="math display">\[
\begin{align*}
\overline{\mathcal{R}}{}^2 = 1 - \frac{e^\prime e / (n-K)}{(n-1)^{-1}\sum_\limits{t=1}^{n}(Y_t - \overline Y)^2} = 1 - \frac{n-1}{n-K}(1 - \mathcal{R})
\end{align*}
\]</span></p></li>
</ol>
<p>此时有：<span class="math inline">\(E[e^\prime e / (n-K)] = \sigma^2\)</span> 和 <span class="math inline">\(E[(n-1)^{-1}\sum_\limits{t=1}^{n}(Y_t - \overline Y)^2] = \sigma_Y^2\)</span> ，在 <span class="math inline">\(\overline{\mathcal{R}}{}^2\)</span> 中，调整的是自由度，此时即使 <span class="math inline">\(X_t\)</span> 中包含截距项，<span class="math inline">\(\bar{\mathcal{R}}\)</span> 也可能取负值。</p>
<p><span class="math inline">\(\bar{\mathcal{R}}\)</span> 作用：① 消除解释变量的多少对决定系数计算的影响。② 可用于比较解释变量个数不同的模型，而 <span class="math inline">\(\mathcal{R}\)</span> 则不能比较。</p>
<h2 id="ols-估计量的无偏性和有效性">3.4 <span class="math inline">\(OLS\)</span> 估计量的无偏性和有效性</h2>
<h3 id="定理-5">3.4.1 定理</h3>
<ul>
<li><p><strong>定理 3.5</strong>（<span class="math inline">\(\rm{P}_{60}\)</span>）：如果假设 3.1、3.3 (1) 和 3.4 成立，则：</p>
<p>1）<strong>无偏性</strong> &lt; Unbiasedness &gt; ：<span class="math inline">\(E(\hat \beta|X) = \beta^o\)</span>，并且 <span class="math inline">\(E(\hat\beta) = \beta^o\)</span>； <strong>注：将 <span class="math inline">\((X^\prime X)^{-1} X^\prime\)</span> 视为系数矩阵</strong>（<span class="math inline">\(\star\star\star\)</span>）。</p>
<p>2）<strong>方差偏小性</strong> &lt; Vanishing variance &gt; 所有无偏估计中，最小二乘的方差最小： <span class="math display">\[
\begin{align*}
var(\hat \beta |X) = E\{[\hat\beta - E(\hat \beta|X)][\hat\beta - E(\hat\beta|X)]^\prime |X\} = \sigma^2(X^\prime X)^{-1}
\end{align*}
\]</span> 如果假设 3.3 (2) 也成立，那么对于任意的 <span class="math inline">\(K \times 1\)</span> 向量 <span class="math inline">\(\tau\)</span>，满足 <span class="math inline">\(\tau^\prime \tau = 1\)</span>，有： <span class="math display">\[
\begin{align*}
  \mathsf{当} n \to \infty \mathsf{时，}\tau^\prime var(\hat\beta|X)\tau \to 0
  \end{align*}
\]</span> 3）<strong>正交性</strong> &lt; Orthogonality between <span class="math inline">\(e\)</span> and <span class="math inline">\(\beta\)</span> &gt; ： <span class="math display">\[
\begin{align*}
  cov(\hat \beta, e|X) = 0
\end{align*}
\]</span> 4）<strong>Gauss - Markov 定理</strong>：对于任意的线性无偏估计量 <span class="math inline">\(\hat b, var(\hat b|X) - var(\hat\beta|X)\)</span> 是半正定 (Positive semi-definite, PSD) 的（说明 <span class="math inline">\(\hat{\beta}\)</span> 是方差最小的。</p>
<p>5）<strong>残差方差估计量</strong> &lt; Residual variance estimator &gt;： <span class="math display">\[
\begin{align*}
  s^2 = e^\prime e/(n - K) = \frac{1}{n - K }\sum_\limits{t = 1}^{n} e_t^2
\end{align*}
\]</span> 是 <span class="math inline">\(\sigma^2 = E(\varepsilon_t^2)\)</span> 的无偏估计量，即 <span class="math inline">\(E(s^2 | X) = \sigma^2\)</span>。</p>
<p><strong>注：</strong> <strong>由于随机变量 <span class="math inline">\(\{e_t\}\)</span> 必须满足 <span class="math inline">\(K\)</span> 个正规方程 <span class="math inline">\(X^\prime e = 0\)</span>，故其中只有 <span class="math inline">\((n - K)\)</span> 个残差是（自由）独立的，</strong>经过自由度校正后，才是无偏估计。如果样本容量 <span class="math inline">\(n\)</span> 很大，当 <span class="math inline">\(n \to \infty\)</span> 时，<span class="math inline">\(\frac{n - K}{n} \to 1\)</span>，是否进行“小样本校正”并无多大区别。</p></li>
</ul>
<h2 id="ols-估计量的抽样分布">3.5 <span class="math inline">\(OLS\)</span> 估计量的抽样分布</h2>
<h3 id="假设-1">3.5.1 假设</h3>
<ul>
<li><p><strong>假设 3.5</strong>（<span class="math inline">\(\rm{P}_{65}\)</span>）&lt; 条件正态分布 (Conditional Normality) &gt;：<span class="math inline">\(\varepsilon|X \sim N(0, \sigma^2 I)\)</span> 。</p>
<p>假设 3.5 可以推出假设 3.2（<span class="math inline">\(E(\varepsilon|X) = 0\)</span>） 和假设 3.4 （<span class="math inline">\(E(\varepsilon_t\varepsilon_s|X) = \sigma^2I\)</span>）。事实上，在假设 3.5 下，<span class="math inline">\(\varepsilon\)</span> 的条件概率密度函数： <span class="math display">\[
\begin{align*}
  f(\varepsilon|X) = \frac{1}{(\sqrt{2 \pi \sigma^2})^n}exp(-\frac{\varepsilon^\prime \varepsilon} {2\sigma^2}) = f(\varepsilon)
\end{align*}
\]</span> 不依赖于 <span class="math inline">\(X\)</span>，从而随机扰动项 <span class="math inline">\(\varepsilon\)</span> 独立于 <span class="math inline">\(X\)</span>。因此， <span class="math inline">\(\varepsilon\)</span> 的任何条件矩均不依赖于 <span class="math inline">\(X\)</span>。</p></li>
</ul>
<h3 id="定理-6">3.5.2 定理</h3>
<ul>
<li><p><strong>定理 3.6</strong>（<span class="math inline">\(\rm{P}_{65}\)</span>）&lt; <span class="math inline">\(\hat\beta\)</span> 的条件正态分布 &gt;：给定假设 3.1、3.3 (1) 和 3.5，对所有的 <span class="math inline">\(n&gt;K\)</span>： <span class="math display">\[
\begin{align*}
  (\hat \beta - \beta^o)|X \sim N[0, \sigma^2(X^\prime X)^{-1}]
\end{align*}
\]</span></p></li>
<li><p><strong>推论 3.7</strong>（<span class="math inline">\(\rm{P}_{66}\)</span>）&lt; <span class="math inline">\(R(\hat\beta - \beta^o)\)</span> 的条件正态分布 &gt;：给定假设 3.1、3.3 (1) 和 3.5，则对于任何非随机的 <span class="math inline">\(J \times K\)</span> 矩阵 <span class="math inline">\(R\)</span>（<span class="math inline">\(J\)</span> 为参数限制数目），有： <span class="math display">\[
  \begin{align*}
  R(\hat \beta - \beta^o)|X \sim N[0, R \sigma^2(X^\prime X)^{-1} R^\prime]
  \end{align*}
\]</span> 其中，<span class="math inline">\(R\)</span> 可以视为一个选择矩阵，如 <span class="math inline">\(R = (1, 0, 0, \cdots, 0)\)</span>，则 <span class="math inline">\(R(\hat{\beta} - \beta^o) = \hat{\beta}_0 - \beta_0^o\)</span>，在假设检验中需要用到 <span class="math inline">\(R(\hat{\beta} - \beta^o_0)\)</span> 的抽样分布。但由于 <span class="math inline">\(var(\varepsilon_t) = \sigma^2\)</span> 是未知的，因此要估计 <span class="math inline">\(\sigma^2\)</span>。</p></li>
</ul>
<h2 id="ols-估计量的方差---协方差矩阵的估计">3.6 <span class="math inline">\(OLS\)</span> 估计量的方差 - 协方差矩阵的估计</h2>
<h3 id="定理-7">3.6.1 定理</h3>
<ul>
<li><p><strong>引理 3.8</strong>（<span class="math inline">\(\rm{P}_{66}\)</span>）&lt; 正态随机变量的二次型 (Quadratic Form of Normal Random Variables) &gt;：如果一个 <span class="math inline">\(m\times 1\)</span> 随机变量 <span class="math inline">\(v \sim N(0, 1)\)</span>，并且 <span class="math inline">\(Q\)</span> 是一个 <span class="math inline">\(m \times m\)</span> 非随机对称幂等矩阵， 秩 <span class="math inline">\(1\leq m\)</span>，则二次型： <span class="math display">\[
 \begin{align*}
  v^\prime Q v \sim \chi^2_q
  \end{align*}
\]</span> 在以下引用中，<span class="math inline">\(v = \varepsilon/\sigma\sim N(0,1), Q = M\)</span>。因为 <span class="math inline">\(rank(M) = n - K\)</span>，所以： <span class="math display">\[
  \begin{align*}
  \left.\frac{e^\prime e}{\sigma^2} \right|X \sim \chi^2_{n-K}
  \end{align*}
\]</span></p></li>
<li><p><strong>引理 3.9</strong>（<span class="math inline">\(\rm{P}_{67}\)</span>）&lt; 残差方差的估计量 (Residual Variance Estimator) &gt;：给定假设 3.1、3.3 (1) 和 3.5，则对于任意的 <span class="math inline">\(n\leq K\)</span>，有：</p>
<p>1） <span class="math display">\[
\begin{align*}
  \left.\frac{(n-K)s^2}{\sigma^2} \right|X = \left.\frac{e^\prime e}{\sigma^2} \right|X \sim \chi^2_{n-K}
\end{align*}
\]</span> 其中，<span class="math inline">\(e = M\varepsilon\)</span>。 2）给定 <span class="math inline">\(X\)</span> 的条件下，<span class="math inline">\(s^2\)</span> 和 <span class="math inline">\(\hat\beta\)</span> 是独立的。从定理 3.4(3) 可知：<span class="math inline">\(cov(\hat{\beta, e|X}) = 0\)</span>，对于联合正态分布而言，零相关意味着相互独立。</p></li>
</ul>
<h2 id="参数假设检验">3.7 参数假设检验</h2>
<h3 id="定义-5">3.7.1 定义</h3>
<ul>
<li><strong>定义 3.4</strong>（<span class="math inline">\(\rm{P}_{73}\)</span>）&lt; 依分布收敛 (Convergence in Distribution) &gt; ：假设 <span class="math inline">\(\{Z_n, n= 1, 2, \dots\}\)</span> 是一个分布函数为<span class="math inline">\(\{F_n(z) = P(Z_n \leq z)\}\)</span> 的随机变量或随机向量的序列，<span class="math inline">\(Z\)</span> 是一个不依赖于 <span class="math inline">\(n\)</span> 的分布函数为 <span class="math inline">\(F(z) = P(Z \leq z)\)</span> 的随机变量或随机向量。称 <span class="math inline">\(Z_n\)</span> 依分布收敛于 <span class="math inline">\(Z\)</span>，如果在分布函数 <span class="math inline">\(F(z)\)</span> 的任何连续点，<span class="math inline">\(Z_n\)</span> 的分布函数值均收敛于 <span class="math inline">\(Z\)</span> 的分布函数值，即： <span class="math display">\[
\begin{align*}
  \lim_{n\to\infty} F_n(z) = F(z)
\end{align*}
\]</span> 或等价地： <span class="math display">\[
\begin{align*}
  \mathsf{当}\ n\to\infty\ \mathsf{时}, F_n(z) \to F(z)
\end{align*}
\]</span> 用符号 <span class="math inline">\(Z_n \overset{d}{\to} Z\)</span> 表示。<span class="math inline">\(Z\)</span> 的分布称为 <span class="math inline">\(Z_n\)</span> 的渐近分布或极限分布。</li>
</ul>
<h3 id="定理-8">3.7.2 定理</h3>
<ul>
<li><strong>推论 3.10</strong>（<span class="math inline">\(\rm{P}_{71}\)</span>）：给定假设 3.1、3.3 (1) 和 3.5，当原假设 <span class="math inline">\(\mathbb{H}_0: R\beta^o = r\)</span> 成立时，对于每一个 <span class="math inline">\(n\geq K\)</span>，有：</li>
</ul>
<p><span class="math display">\[
\begin{align*}
  (R\hat\beta - r)|X \sim N[0, \sigma^2 R(X^\prime X)^{-1}R^\prime]
\end{align*}
\]</span> - <strong>推论 3.11</strong>（<span class="math inline">\(\rm{P}_{76}\)</span>）：如果 <span class="math inline">\(q \times 1\)</span> 随机向量 <span class="math inline">\(Z \sim N(0, V)\)</span>，其中 <span class="math inline">\(V = var(Z)\)</span> 是一个 <span class="math inline">\(q\times q\)</span> 对称、非奇异的方差 - 协方差矩阵，则： <span class="math display">\[
  \begin{align*}
    Z^\prime V^{-1}Z \sim \chi_q^2
  \end{align*}
  \]</span></p>
<ul>
<li><p><strong>定理 3.12</strong>（<span class="math inline">\(\rm{P}_{78}\)</span>）：给定假设 3.1、3.3 (1) 和 3.5，当原假设 <span class="math inline">\(\mathbb{H}_0: R\beta^o = r\)</span> 成立时，对于每一个 <span class="math inline">\(n\geq K\)</span>，有： <span class="math display">\[
\begin{align*}
F = \frac{(R \hat\beta - r)^\prime[R(X^\prime X)^{-1}R^\prime]^{-1}(R \hat\beta - r)/J}{s^2} \sim F_{J,n-K}
\end{align*} \\
\frac{s^2(n-K)}{\sigma^2} \sim \chi^2(n-K)
\]</span></p></li>
<li><p><strong>定理 3.13</strong>（<span class="math inline">\(\rm{P}_{79}\)</span>）：给定假设 3.1、3.3 (1) ，令 <span class="math inline">\(SSR_u = e^\prime e\)</span> 是以下无约束回归模型的残差平方和： <span class="math display">\[
\begin{align*}
Y = X\beta^o + \varepsilon
\end{align*}
\]</span> 令 <span class="math inline">\(SSR_r = \tilde e^\prime \tilde e\)</span> 是以下有约束模型的残差平方和 ： <span class="math display">\[
\begin{align*}
Y = X\beta^o + \varepsilon
\end{align*}
\]</span> 其约束条件为： <span class="math display">\[
\begin{align*}
R \beta^o = r
\end{align*}
\]</span> 这里 <span class="math inline">\(\tilde e = Y - X \tilde \beta\)</span>，<span class="math inline">\(\tilde \beta\)</span> 是有约束回归模型的 <span class="math inline">\(OLS\)</span> 估计量。则 <span class="math inline">\(F\)</span> 检验统计量可写为： <span class="math display">\[
\begin{align*}
F = \frac{(\tilde e^\prime \tilde e - e^\prime e)/J}{e^\prime e/(n - K)}
\end{align*}
\]</span></p></li>
<li><p><strong>定理 3.14</strong>（<span class="math inline">\(\rm{P}_{81}\)</span>）：给定假设 3.1、3.3 (1) 和 3.5，则当原假设是 <span class="math inline">\(\mathbb{H}_0: R\beta^o = r\)</span> 成立且 <span class="math inline">\(n \to \infty\)</span> 时，<span class="math inline">\(Wald\)</span> 检验统计量： <span class="math display">\[
\begin{align*}
\mathcal{W} = \frac{(R\hat\beta - r)^\prime[R(X^\prime X)^{-1} R^\prime]^{-1}(R\hat\beta  - r)}{s^2} = J \cdot F \overset{d}{\to}\chi^2_J
\end{align*}
\]</span> 可以发现，这里定义的 <span class="math inline">\(Wald\)</span> 检验统计量与 <span class="math inline">\(F\)</span> 检验统计量 <strong>只相差一个比例常数</strong> <span class="math inline">\(J\)</span>，这是因为目前考虑条件同方差的情形。如果存在条件异方差，仍然可以定义 <span class="math inline">\(Wald\)</span> 检验统计量，但是 <span class="math inline">\(W = J \cdot F\)</span> 这一关系将不再成立。</p></li>
</ul>
<h2 id="广义最小二乘估计">3.9 广义最小二乘估计</h2>
<p>经典线性回归模型依赖于关键假设—假设 3.5（<span class="math inline">\(\varepsilon|X \sim N(0, \sigma^2 I)\)</span> ）。除了条件正态分布外，还隐含不存在条件异方差和自相关性。</p>
<h3 id="假设-2">3.9.1 假设</h3>
<ul>
<li><p><strong>假设 3.6</strong>（<span class="math inline">\(\rm{P}_{87}\)</span>）：<span class="math inline">\(\varepsilon|X \sim N(0, \sigma^2 V)\)</span>，其中 <span class="math inline">\(0 &lt; \sigma^2 &lt; \infty\)</span> 是未知的，但 <span class="math inline">\(V = V(X)\)</span> 是一个已知的对称与有限的 <span class="math inline">\(n \times n\)</span> 正定矩阵。</p>
<p>从假设可知条件方差（<span class="math inline">\(\star\star\star\)</span>）： <span class="math display">\[
\begin{align*}
var(\varepsilon|X) = E(\varepsilon^\prime\varepsilon|X) = \sigma^2V = \sigma^2 V(X)
\end{align*}
\]</span> 虽然 <span class="math inline">\(var(\varepsilon|X)\)</span> 仅包含一个未知常数 <span class="math inline">\(\sigma^2\)</span>，但它允许存在已知形式的条件异方差 <span class="math inline">\(V(X)\)</span>。</p></li>
</ul>
<h3 id="定义-6">3.9.2 定义</h3>
<h3 id="定理-9">3.9.3 定理</h3>
<ul>
<li><p><strong>定理 3.15</strong>（<span class="math inline">\(\rm{P}_{87}\)</span>）：给定假设 3.1、3.3 (1) 和 3.6，则：</p>
<p>1）<strong>无偏性</strong>：<span class="math inline">\(E(\hat\beta|X) = \beta^o\)</span>；</p>
<p>2）<strong>方差</strong>：<span class="math inline">\(var(\hat\beta|X) = \sigma^2(X^\prime X)^{-1} X^\prime VX(X^\prime X)^{-1} \neq \sigma^2(X^\prime X)^{-1}\)</span>；</p>
<p>3）<strong>正态分布</strong>：<span class="math inline">\((\hat\beta - \beta^o)|X \sim N[0,\sigma^2 (X^\prime X)^{-1}X^\prime VX(X^\prime X)^{-1}]\)</span>；</p>
<p>4）<strong>相关性</strong>：<span class="math inline">\(cov(\hat\beta,e|X) = E[(X^\prime X)^{-1} X^\prime \varepsilon \varepsilon^\prime M] = \sigma^2 (X^\prime X)^{-1} X^\prime V M \neq 0\)</span>（其中，<span class="math inline">\(V \neq I,\ e = M \varepsilon,\ M = I - P,\ P = X(X^\prime X)^{-1} X\)</span>）。</p>
<p>相关性表明，由于给定 <span class="math inline">\(X, \hat \beta\)</span> 和 <span class="math inline">\(e\)</span> 存在相关性，<span class="math inline">\(t\)</span> 检验和 <span class="math inline">\(F\)</span> 检验统计量定义中的分子和分母不再独立，所以不能得到有限样本条件下的 <span class="math inline">\(t\)</span> 分布和 <span class="math inline">\(F\)</span> 分布。为了解决该问题，需要考虑新的估计方法——GLS。</p></li>
<li><p><strong>引理 3.16</strong>（<span class="math inline">\(\rm{P}_{88}\)</span>）：对于任意的 <span class="math inline">\(n \times n\)</span> 对称正定矩阵 <span class="math inline">\(V\)</span>，总可以写成： <span class="math display">\[
\begin{align*}
V^{-1} &amp;= C^\prime C \\
V &amp;= C^{-1}(C^\prime)^{-1}
\end{align*}
\]</span> 这里，<span class="math inline">\(C\)</span> 是一个 <span class="math inline">\(n \times n\)</span> 非奇异矩阵。这称为 Cholesky 分解（Cholesky factorization），其中 C 可能是非对称矩阵。</p>
<p>考虑线性回归模型： <span class="math display">\[
\begin{align*}
CY = (CX)\beta^o + C \varepsilon
\end{align*}
\]</span> 令 <span class="math inline">\(Y^* = CY, X^* = CX, \varepsilon^* = C\varepsilon\)</span>。所以有：</p>
<p><span class="math inline">\(E(\varepsilon^*|X) = E(C \varepsilon|X) = 0\)</span>;</p>
<p><span class="math inline">\(var(\varepsilon^*|X) = CE(\varepsilon \varepsilon^\prime | X) C^\prime = \sigma^2 CVC^\prime = \sigma^2 I\)</span> ;</p>
<p>变换后的回归模型的 <span class="math inline">\(OLS\)</span> 估计量为： <span class="math display">\[
\begin{align*}
\hat\beta{}^* = (X^{*\prime}X^*)^{-1}(X^{*\prime}Y^*) = (X^\prime V^{-1}X)^{-1} X^\prime V^{-1} Y
\end{align*}
\]</span> 称为广义最小二乘 (<span class="math inline">\(GLS\)</span>) 估计量。变换后的 <span class="math inline">\(\hat{\beta^*}\)</span> 和 <span class="math inline">\(e^*\)</span> 不相关，故 <span class="math inline">\(t\)</span> 和 <span class="math inline">\(F\)</span> 检验可用：</p>
<p><span class="math display">\[
\begin{align*}
T^* &amp;= \frac{R \hat\beta {}^* - r}{\sqrt{s^*{}^2 {R(X{}^*}^\prime {X{}^*})^{-1}R^\prime}} \sim t(n-K) \\
F{}^* &amp;= \frac{(R \hat\beta {}^* - r)^\prime[{R(X{}^*}^\prime {X{}^*})^{-1}R^\prime]^{-1}(R \hat\beta{}^* - r)}{s^2} \sim F_{J,n-K}
\end{align*}
\]</span></p></li>
<li><p><strong>定理 3.17</strong>（<span class="math inline">\(\rm{P}_{91}\)</span>）：给定假设 3.1、3.3 (1) 和 3.6，则：</p>
<p>1）<strong>无偏性</strong>：<span class="math inline">\(E(\hat\beta{}^*|X) = \beta^o\)</span>；</p>
<p>2）<strong>方差</strong>：<span class="math inline">\(var(\hat\beta{}^*|X) = \sigma^2(X^{*\prime} X^*)^{-1} = \sigma^2(X^\prime V^{-1} X)^{-1}\)</span>；</p>
<p>3）<strong>相关性</strong>：<span class="math inline">\(cov(\hat\beta{}^*,e^*|X) = 0\)</span>，其中 <span class="math inline">\(e^* = Y^* - X^* \hat\beta{}^*\)</span>；</p>
<p>4）<span class="math inline">\(\hat\beta{}^*\)</span> 是最优线性无偏估计量(BLUE);</p>
<p>5）<span class="math inline">\((s^{*2}|X) = \sigma^2\)</span>，其中 <span class="math inline">\(s^{*2} = e^{*\prime}e^*/(n-K)\)</span>。</p></li>
</ul>
<h1 id="独立同分布随机样本的线性回归模型">4 独立同分布随机样本的线性回归模型</h1>
<p>在 <span class="math inline">\(var(\varepsilon | X) = \sigma^2 V\)</span> 形式未定时，仍可用 <span class="math inline">\(OLS\)</span> 估计量 <span class="math inline">\(\hat \beta\)</span>，根据正确的方差公式 <span class="math inline">\(var(\hat\beta|X) = \sigma^2(X^\prime X)^{-1} X^\prime VX(X^\prime X)^{-1}\)</span>，可构造 <span class="math inline">\(var(\hat\beta|X)\)</span> 的估计量，此时经典的 <span class="math inline">\(t\)</span> 和 <span class="math inline">\(F\)</span> 检验已不再适用，因为他们建立在不正确的 <span class="math inline">\(var(\hat\beta|X)\)</span> 上的，此时，仅能适用渐近分布理论。</p>
<h2 id="渐近理论导论">4.1 渐近理论导论</h2>
<h3 id="定义-7">4.1.1 定义</h3>
<ul>
<li><p><strong>定义 4.1</strong>（<span class="math inline">\(\rm{P}_{103}\)</span>）&lt; 依均方收敛或依二次方均值收敛 (Convergence in Mean Squares or in Quadratic Mean) &gt; ：一个随机变量（或固定维数的随机向量，即 <span class="math inline">\(Z_n\)</span> 的维数不随 <span class="math inline">\(n\)</span> 的增加而变化）序列 <span class="math inline">\(\{Z_n, n = 1, 2, \dots\}\)</span> 依均方收敛于随机变量（或随机向量） <span class="math inline">\(Z\)</span>，如果当 <span class="math inline">\(n \to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
E\ \Vert Z_n - Z \Vert^2 \to 0
\end{align*}
\]</span> 其中，<span class="math inline">\(\Vert \cdot \Vert\)</span> 是随机变量或随机向量的模。记 <span class="math inline">\(Z_n \overset{q.m.}{\to} Z\)</span>。</p>
<p><strong>注：</strong>当 <span class="math inline">\(Z_n\)</span> 是一个固定维数的随机向量时，可理解为 <span class="math inline">\(Z_n\)</span> 的每一个元素的序列收敛于 <span class="math inline">\(Z\)</span> 的相对应元素。如果 <span class="math inline">\(Z_n - Z\)</span> 是一个 <span class="math inline">\(l \times m\)</span> 的矩阵时，可将平方模定义为： <span class="math display">\[
\begin{align*}
\Vert Z_n - Z \Vert^2 = \sum_{t=1}^{l}\sum_{s = 1}^{m} [Z_n - Z]^2_{(t, s)}
\end{align*}
\]</span></p></li>
<li><p><strong>定义 4.2</strong>（<span class="math inline">\(\rm{P}_{103}\)</span>）&lt; 依概率收敛 (Convergence in Probability) &gt; ：一个随机变量序列 <span class="math inline">\(\{Z_n, n = 1, 2, \dots\}\)</span> 依概率收敛于 <span class="math inline">\(Z\)</span>，如果对任意给定的常数 <span class="math inline">\(\epsilon &gt; 0\)</span>，有： <span class="math display">\[
\begin{align*}
\mathsf{当}\ n\to \infty \mathsf{时},\ Pr[\ \Vert Z_n - Z \Vert &gt;\epsilon] \to 0
\end{align*}
\]</span> 或等价地： <span class="math display">\[
\begin{align*}
\mathsf{当}\ n\to \infty \mathsf{时},\ Pr[\ \Vert Z_n - Z \Vert \leq \epsilon] \to 1
\end{align*}
\]</span> 对于依概率收敛，可记为 <span class="math inline">\(Z_n - Z \overset{p}{\to} 0\)</span> 或 <span class="math inline">\(Z_n - Z = O_P(1)\)</span>。</p></li>
<li><p><strong>定义 4.3</strong>（<span class="math inline">\(\rm{P}_{106}\)</span>）&lt; 依概率有界 (Boundedness in Probability) &gt; ：一个随机变量序列 <span class="math inline">\(\{Z_n, n = 1, 2, \dots\}\)</span> 依概率有界的，如果对任意小的常数 <span class="math inline">\(\delta &gt; 0\)</span>，存在常数 <span class="math inline">\(C= C(\delta)&lt; \infty\)</span>，使得，当 <span class="math inline">\(n \to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
P(\ \Vert Z_n \Vert &gt; C\ ) \leq \delta
\end{align*}
\]</span> 记为 <span class="math inline">\(Z_n = O_P(1)\)</span>。</p></li>
<li><p><strong>定义 4.4</strong>（<span class="math inline">\(\rm{P}_{108}\)</span>）&lt; 几乎必然收敛 (Almost sure convergence)) &gt; ：<span class="math inline">\(\{Z_n, n = 1, 2, \dots\}\)</span> 几乎必然收敛于 <span class="math inline">\(Z\)</span>，如果： <span class="math display">\[
\begin{align*}
\Pr[\lim_{n\to\infty}\Vert Z_n - Z \Vert = 0] = 1
\end{align*}
\]</span> 记为 <span class="math inline">\(Z_n - Z \overset{a.s.}{\to}\)</span> 或 <span class="math inline">\(Z_n - Z = o_{a.s.}(1)\)</span>。</p>
<p><strong>注：</strong>几乎必然收敛可以推出依概率收敛，但依概率收敛不一定能推出几乎必然收敛。</p></li>
</ul>
<h3 id="定理-10">4.1.2 定理</h3>
<ul>
<li><p><strong>引理 4.1</strong>（<span class="math inline">\(\rm{P}_{105}\)</span>）&lt; 独立同分布样本的弱大数定律 (Weak Law of Large Numbers (WLLN) for I.I.D Samples) &gt; ：假设随机样本 <span class="math inline">\(\{Z_t\}^n_{t=1}\)</span> 服从 <span class="math inline">\(i.i.d.(\mu,\sigma^2)\)</span>，并定义 <span class="math inline">\(\bar Z_n = n^{-1} \sum_\limits{t=1}^{n} Z_t\)</span>，这里 <span class="math inline">\(n = 1,2,\cdots\)</span>。则当 <span class="math inline">\(n \to \infty\)</span> 时： <span class="math display">\[
\begin{align*}
\bar Z_n \overset{p}{\to} \mu
\end{align*}
\]</span></p></li>
<li><p><strong>引理 4.2</strong>（<span class="math inline">\(\rm{P}_{105}\)</span>）&lt; 独立同分布随机样本的弱大数定律 (WLLN for I.I.D Samples) &gt; ：假设 <span class="math inline">\(\{Z_t\}^n_{t=1}\)</span> 是一个独立同分布随机样本，<span class="math inline">\(E(Z_t) = \mu\)</span> 且 <span class="math inline">\(E |Z_t| &lt; \infty\)</span>。定义 <span class="math inline">\(\bar Z_n = n^{-1} \sum_\limits{t=1}^{n} Z_t\)</span>，则当 <span class="math inline">\(n \to \infty\)</span> 时： <span class="math display">\[
\begin{align*}
\bar Z_n \overset{p}{\to} \mu
\end{align*}
\]</span></p></li>
<li><p><strong>引理 4.3</strong>（<span class="math inline">\(\rm{P}_{106}\)</span>）：如果 <span class="math inline">\(Z_t - Z \overset{q.m.}{\to} 0\)</span>，则 <span class="math inline">\(Z_t - Z \overset{p}{\to} 0\)</span>。</p></li>
<li><p><strong>引理 4.4</strong>（<span class="math inline">\(\rm{P}_{109}\)</span>）&lt; 独立同分布随机样本的强大数定律 (Strong Law of Large Numbers (SLLN) for I.I.D Samples) &gt; ：假设 <span class="math inline">\(\{Z_t\}^n_{t=1}\)</span> 是一个独立同分布随机样本，<span class="math inline">\(E(Z_t) = \mu\)</span> 且 <span class="math inline">\(E |Z_t| &lt; \infty\)</span>。则当 <span class="math inline">\(n \to \infty\)</span> 时： <span class="math display">\[
\begin{align*}
\bar Z_n \overset{a.s.}{\to} \mu
\end{align*}
\]</span></p></li>
<li><p><strong>引理 4.5</strong>（<span class="math inline">\(\rm{P}_{109}\)</span>）&lt; 连续性 (Continuity) &gt; ：</p>
<p>1）假设当 <span class="math inline">\(n \to \infty\)</span> 时，<span class="math inline">\(A_n - A \overset{p}{\to} 0, B_n - B \overset{p}{\to} 0\)</span>，且 <span class="math inline">\(g(\cdot)\)</span> 和 <span class="math inline">\(h(\cdot)\)</span> 是连续函数。则： <span class="math display">\[
\begin{align*}
[g(A_n) + h(B_n)] - [g(A) + h(B)] \overset{p}{\to} 0 \\
g(A_n)h(B_n) - g(A)h(B) \overset{p}{\to} 0
\end{align*}
\]</span> 2）对于几乎必然收敛，也有类似结论。</p></li>
<li><p><strong>引理 4.6</strong>（<span class="math inline">\(\rm{P}_{110}\)</span>）&lt; 独立同分布随机样本的中心极限定理 (CLT for I.I.D Random Samples) &gt;：假设 <span class="math inline">\(\{Z_t\}_{t=1}^{n}\)</span> 是一个 <span class="math inline">\(i.i.d.(\mu, \sigma^2)\)</span> 随机样本呢，这里 <span class="math inline">\(Z_t\)</span> 是随机变量。定义 <span class="math inline">\(\bar Z_n = n^{-1} \sum_\limits{t=1}^n Z_t\)</span> 时，有： <span class="math display">\[
\begin{align*}
\frac{\bar Z_n - E(\bar Z_n)}{\sqrt{var(\bar Z_n)}} = \frac{\sqrt{n}(\bar Z_n - \mu)}{\sigma} \overset{d}{\to} N(0,1)
\end{align*}
\]</span></p></li>
<li><p><strong>引理 4.7</strong>（<span class="math inline">\(\rm{P}_{112}\)</span>）&lt; Cramer-Wold 方法 &gt; ：假设 <span class="math inline">\(Z_n\)</span> 和 <span class="math inline">\(Z\)</span> 均是 <span class="math inline">\(p \times 1\)</span> 随机向量，这里 <span class="math inline">\(p\)</span> 是一个固定正整数。令 <span class="math inline">\(n \to \infty\)</span>。则 <span class="math inline">\(Z_n \overset{d}{\to} Z\)</span>，当且仅当对于任意非零的 <span class="math inline">\(\tau \in R^p\)</span>，且满足 <span class="math inline">\(\tau^\prime\tau = 1\)</span>，使得： <span class="math display">\[
\begin{align*}
\tau^\prime Z_n \overset{d}{\to} \tau^\prime Z
\end{align*}
\]</span></p></li>
<li><p><strong>定理 4.8</strong>（<span class="math inline">\(\rm{P}_{112}\)</span>）&lt; Slutsky 定理 &gt; ：令 <span class="math inline">\(Z_n \overset{d}{\to}Z, a_n \overset{d}{\to} a\)</span> 且 <span class="math inline">\(b_n \overset{d}{\to}b\)</span>, 其中 <span class="math inline">\(a\)</span> 和 <span class="math inline">\(b\)</span> 是常数。则当 <span class="math inline">\(n \to \infty\)</span> 时，有 ： <span class="math display">\[
\begin{align*}
a_n + b_n Z_n \overset{d}{\to} a + bZ
\end{align*}
\]</span></p></li>
<li><p><strong>定理 4.9</strong>（<span class="math inline">\(\rm{P}_{112}\)</span>）&lt; Delta 方法 &gt; ：假设 <span class="math inline">\(\sqrt n(Z_n - \mu)/\sigma \overset{d}{\to} N(0,1)\)</span>，<span class="math inline">\(g(\cdot)\)</span> 是连续可导的函数。且 <span class="math inline">\(g^\prime(\mu) \neq 0\)</span>。则当 <span class="math inline">\(n \to \infty\)</span> 时，有 <span class="math inline">\(\sqrt n [g(\bar Z_n) - g(\mu)] = g^\prime(\mu)\sqrt n(\bar Z_n - \mu) + O_P(1)\)</span>，且： <span class="math display">\[
\begin{align*}
\sqrt n [g(\bar Z_n) - g(\mu)] &amp;\overset{d}{\to} N\{0,\sigma^2[g^\prime(\mu)]^2\} \\
g(\bar{Z}_n) &amp;= g(\mu) + g^\prime(\bar{\mu}_n)(\bar{Z}_n - \mu) \\
\bar{\mu}_n &amp;= \lambda \mu + (1 - \lambda) \bar{Z}_n, \lambda \in [0, 1]
\end{align*}
\]</span></p></li>
</ul>
<h2 id="线性回归模型假设">4.2 线性回归模型假设</h2>
<h3 id="假设-3">4.2.1 假设</h3>
<ul>
<li><p><strong>假设 4.1</strong>（<span class="math inline">\(\rm{P}_{114}\)</span>）&lt; 独立同分布 (I.I.D) &gt; ：<span class="math inline">\(\{Y_t,X_t^\prime\}\)</span> 是一个可观测的独立同分布随机样本（独立同分布意味着，对于 <span class="math inline">\(t \neq s, cov(\varepsilon_t, \varepsilon_s) = 0\)</span>，回归扰动项不存在自相关）；</p></li>
<li><p><strong>假设 4.2</strong>（<span class="math inline">\(\rm{P}_{114}\)</span>）&lt; 线性 (Linearity) &gt; ： <span class="math display">\[
\begin{align*}
Y_t = X_t^\prime \beta^o + \varepsilon_t \qquad t = 1,\cdots,n
\end{align*}
\]</span></p></li>
<li><p><strong>假设 4.3</strong>（<span class="math inline">\(\rm{P}_{114}\)</span>）&lt; 正确模型设定 (Correct Model Specification) &gt; ：<span class="math inline">\(E(\varepsilon_t|X_t) = 0\)</span> 且 <span class="math inline">\(E(\varepsilon_t^2) = \sigma^2 &lt; \infty\)</span>；</p></li>
<li><p><strong>假设 4.4</strong>（<span class="math inline">\(\rm{P}_{114}\)</span>）&lt; 非奇异性同分布 (Nonsingularity) &gt; ： <span class="math inline">\(K\times K\)</span> 阶矩阵 <span class="math inline">\(Q = E(X_t X_t^\prime)\)</span> 是对称、有限与非奇异的；</p>
<p>由强大数定理可知：<span class="math inline">\(n \to \infty\)</span> 时，<span class="math inline">\(\frac{X^\prime X}{n} = \frac 1 n \sum\limits_{t=1}^{n}X_t X_t^\prime \overset{a.s}{\to} E(X_t X_t^\prime) = Q\)</span></p></li>
<li><p><strong>假设 4.5</strong>（<span class="math inline">\(\rm{P}_{114}\)</span>）： <span class="math inline">\(K\times K\)</span> 阶矩阵 <span class="math inline">\(V \equiv var(X_t \varepsilon_t) = E(X_t X_t^\prime\varepsilon_t^2)\)</span> 是对称、有限与正定 (PD) 的；</p></li>
</ul>
<p>这些假设的一个重要特征时：不要求 <span class="math inline">\(\varepsilon\)</span> 服从条件正态分布，同时允许条件异方差，即 <span class="math inline">\(var(\varepsilon|X_t) \neq \sigma^2\)</span>。</p>
<h2 id="ols-估计量的一致性">4.3 <span class="math inline">\(OLS\)</span> 估计量的一致性</h2>
<p>由假设 4.4 可知，对于所有的 <span class="math inline">\(j\in\{0, 1, \cdots, k\}, E(X_{jt}^2)&lt;\infty\)</span>。根据对立同分布随机样本的强大数据定律（引理 4.4），当 <span class="math inline">\(n \to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
\frac{X^\prime X}{n} = \frac{1}{n}\sum_{t=1}^{n} X_t X_t^\prime \overset{a.s.}{\to}E(X_t X_t^\prime) = Q \qquad (\star\star\star)
\end{align*}
\]</span> 假设有一个随机样本 <span class="math inline">\(\{Y_t, X_t^\prime\}_{t=1}^n\)</span>。回忆 <span class="math inline">\(OLS\)</span> 估计量： <span class="math display">\[
\begin{align*}
\hat \beta = (X^\prime X)^{-1}X^\prime Y = \hat Q{}^{-1} n^{-1} \sum_{t=1}^{n} X_t Y_t
\end{align*}
\]</span> 其中， <span class="math display">\[
\begin{align*}
\hat Q{}^{-1} = n^{-1} \sum_{t=1}^{n} X_t X_t^\prime
\end{align*}
\]</span> 将 <span class="math inline">\(Y_t = X_t^\prime \beta^o + \varepsilon_t\)</span>（参见假设 4.2）代入，得： <span class="math display">\[
\begin{align*}
\hat \beta  = \beta^o + \hat Q{}^{-1} n^{-1}\sum_{t=1}^{n} X_t \varepsilon_t
\end{align*}
\]</span> <span class="math inline">\(\hat{\beta} - \beta^o = \hat{Q}{}^{-1}\sum\limits_{t=1}^{n} X_t \varepsilon_t \overset{P}{\to} 0\)</span> 下面考察 <span class="math inline">\(\hat\beta\)</span> 的一致性。 ### 4.3.1 定理</p>
<ul>
<li><strong>定理 4.10</strong>（<span class="math inline">\(\rm{P}_{116}\)</span>）&lt; <span class="math inline">\(OLS\)</span> 估计量的一致性 (Consistency of OLS) &gt; ：给定假设 4.1-4.4，且当 <span class="math inline">\(n\to\infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
\hat\beta \overset{d}{\to} \beta^o \mathsf{或} \hat\beta - \beta^o = O_P(1)
\end{align*}
\]</span></li>
</ul>
<h3 id="ols-估计量的渐近正态性">4.4 <span class="math inline">\(OLS\)</span> 估计量的渐近正态性</h3>
<h3 id="假设-4">4.4.1 假设</h3>
<ul>
<li><strong>假设 4.6</strong>（<span class="math inline">\(\rm{P}_{119}\)</span>）&lt; 条件同方差 (Conditional Homoskedasticity) &gt;：<span class="math inline">\(E(\varepsilon_t^2|X_t) = \sigma^2\)</span>。</li>
</ul>
<h3 id="定理-11">4.4.2 定理</h3>
<ul>
<li><p><strong>引理 4.11</strong>（<span class="math inline">\(\rm{P}_{117}\)</span>）&lt; 独立同分布随机样本的多元中心极限定理 (Multivariate CLT for I.I.D. Random Samples) &gt;：假设 <span class="math inline">\(\{Z_t\}^n_{t=1}\)</span> 是一个独立同分布随机样本，且 <span class="math inline">\(E(Z_t) = 0, var(Z_t) = E(Z_t Z_t^\prime) = V\)</span> 是一个有限、对称与正定的矩阵，定义： <span class="math display">\[
\begin{align*}
\bar Z_n = n^{-1} \sum_{t=1}^n Z_t
\end{align*}
\]</span> 则当 <span class="math inline">\(n \to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
\sqrt n \bar Z_n \overset{d}{\to} N(0, V)
\end{align*}
\]</span> 或等价地： <span class="math display">\[
\begin{align*}
V^{-\frac{1}{2}} \sqrt n \bar Z_n \overset{d}{\to} N(0, I)
\end{align*}
\]</span> 其中，<span class="math inline">\(I\)</span> 是一个维数与 <span class="math inline">\(V\)</span> 相同的单位矩阵。引理 4.11 表明，<span class="math inline">\(V \equiv var(Z_t)\)</span> 是 <span class="math inline">\(\sqrt n \bar Z_n\)</span> 的渐近分布的方差，简称 <span class="math inline">\(\sqrt n \bar Z_n\)</span> 的渐近方差，记为 <span class="math inline">\(avar(\sqrt n \bar Z_n) = V\)</span>。</p></li>
<li><p><strong>定理 4.12</strong>（<span class="math inline">\(\rm{P}_{118}\)</span>）&lt; <span class="math inline">\(OLS\)</span> 估计量的渐近正态分布 (Asymptotic Normality of OLS) &gt;：给定假设 4.1-4.5，则当 <span class="math inline">\(n\to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
\sqrt n (\hat \beta - \beta^o) \overset{d}{\to} N(0, Q^{-1}VQ^{-1})
\end{align*}
\]</span> 其中 <span class="math inline">\(V \equiv var(X_t\varepsilon_t) = E(X_t X_t^\prime \varepsilon_t^2)\)</span>。</p></li>
<li><p><strong>定理 4.13</strong>（<span class="math inline">\(\rm{P}_{119}\)</span>）：给定假设 4.1-4.6，则当 <span class="math inline">\(n\to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
\sqrt n (\hat \beta - \beta^o) \overset{d}{\to} N(0, \sigma^2Q^{-1})
\end{align*}
\]</span> 定理 4.13 表明，当存在条件同方差时，<span class="math inline">\(\sqrt n(\bar \beta - \beta^o)\)</span> 的渐近方差 (<span class="math inline">\(\star\star\star\)</span>) 为： <span class="math display">\[
\begin{align*}
avar(\sqrt n \hat \beta) = \sigma^2Q^{-1}
\end{align*}
\]</span></p></li>
</ul>
<h2 id="渐近方差估计量">4.5 渐近方差估计量</h2>
<h3 id="定理-12">4.5.1 定理</h3>
<p><strong>1. 条件同法差</strong></p>
<p>在这种情况下，由定理 4.13，<span class="math inline">\(\sqrt{n}(\hat\beta - \beta^o)\)</span> 渐近方差为： <span class="math display">\[
\begin{align*}
avar(\sqrt n \hat \beta) = \sigma^2 Q^{-1}
\end{align*}
\]</span></p>
<ul>
<li><p><strong>引理 4.14</strong>（<span class="math inline">\(\rm{P}_{120}\)</span>）：给定假设 4.1、4.2 和 4.4，则： <span class="math display">\[
\begin{align*}
\hat Q = n^{-1} \sum_{t=1}^n X_t X_t^\prime \overset{p}{\to} Q
\end{align*}
\]</span> 其次，考虑估计 <span class="math inline">\(\sigma^2\)</span>。因为 <span class="math inline">\(\sigma^2 = E(\varepsilon_t^2)\)</span>，可使用样本残差方差估计量： <span class="math display">\[
\begin{align*}
s^2 = e^\prime e/(n-K) = \frac{1}{n-K} \sum_{t=1}{n} e_t^2
\end{align*}
\]</span></p></li>
<li><p><strong>定理 4.15</strong>（<span class="math inline">\(\rm{P}_{120}\)</span>）：&lt; <span class="math inline">\(\sigma^2\)</span> 的一致估计量 (Consistent Estimator of <span class="math inline">\(\sigma^2\)</span>)&gt;：给定假设 4.1-4.4，当 <span class="math inline">\(n \to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
s^2 \overset{p}{\to} \sigma^2
\end{align*}
\]</span></p></li>
<li><p><strong>定理 4.16</strong>（<span class="math inline">\(\rm{P}_{121}\)</span>）：&lt; 条件同方差下 <span class="math inline">\(\sqrt n (\hat\beta - \beta^o)\)</span> 的渐近方差估计量 (Asymototic Variance Estimator of OLS Under Conditional Homoskedasticity) &gt;：给定假设 4.1-4.4，当 <span class="math inline">\(n \to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
s^2 \hat Q {}^{-1} \overset{p}{\to} avar(\sqrt n \hat \beta) = \sigma^2 Q^{-1}
\end{align*}
\]</span> <span class="math inline">\(\sqrt n (\hat\beta - \beta^o)\)</span> 的渐近方差估计量是： <span class="math display">\[
\begin{align*}
s^2 \hat Q {}^{-1} = s^2(X^\prime X /n)^{-1}
\end{align*}
\]</span> 这等价于，当 <span class="math inline">\(n\)</span> 很大时，<span class="math inline">\((\hat\beta - \beta^o)\)</span> 的方差估计量近似为： <span class="math display">\[
\begin{align*}
s^2 \hat Q {}^{-1}/n = s^2(X^\prime X)^{-1}
\end{align*}
\]</span></p></li>
</ul>
<p><strong>2. 条件异方差</strong></p>
<p>在存在条件异方差（即 <span class="math inline">\(E(\varepsilon_t^2|X_t) \neq \sigma^2\)</span>) 时，<span class="math inline">\(\sqrt n (\hat\beta - \beta^o)\)</span> 的渐近方差为： <span class="math display">\[
\begin{align*}
avar(\sqrt n \hat \beta) = Q^{-1} V Q^{-1}
\end{align*}
\]</span> 其中，<span class="math inline">\(V = E(X_t X_t^\prime \varepsilon_t^2)\)</span>。</p>
<ul>
<li><p><strong>引理 4.17</strong>（<span class="math inline">\(\rm{P}_{122}\)</span>）：给定假设 4.1-4.5 和 4.7，则当 <span class="math inline">\(n \to \infty\)</span> 时，有 <span class="math display">\[
\begin{align*}
\hat V = \frac{1}{n} \sum_{t = 1}^{n} X_t X_t^\prime e_t^2 \overset{p}{\to} V
\end{align*}
\]</span></p></li>
<li><p><strong>引理 4.18</strong>（<span class="math inline">\(\rm{P}_{123}\)</span>）&lt; 条件异方差下 <span class="math inline">\(\sqrt n \hat \beta\)</span> 的渐近方差估计量 (Asymptotic Variance Estimator of OLS Under Conditional Heteroskedasticity) &gt;：给定假设 4.1-4.5 和 4.7，则当 <span class="math inline">\(n \to \infty\)</span> 时，有 <span class="math display">\[
\begin{align*}
\hat Q{}^{-1} \hat V \hat Q{}^{-1} \overset{p}{\to} avar{\sqrt n \hat \beta} = Q^{-1} V Q^{-1}
\end{align*}
\]</span> 这就是 <span class="math inline">\(\sqrt n \hat \beta\)</span> 的 <span class="math inline">\(White (1980)\)</span> 异方差一致性方差 - 协方差矩阵估计量 (Heteroskedasticity-consistent variance-covariance matrix estimator)。因此，当存在条件异方差及 <span class="math inline">\(n\)</span> 很大时，<span class="math inline">\(\hat \beta - \beta^o\)</span> 的方差估计量为: <span class="math display">\[
\begin{align*}
\frac{\hat Q{}^{-1} \hat V \hat Q{}^{-1}}{n} &amp;= \frac{(X^\prime X /n)^{-1} \hat V (X^\prime X /n)^{-1}}{n}\\
&amp;=  (X^\prime X)^{-1} X^\prime D(e) D(e)^\prime X (X^\prime X)^{-1}\\
&amp;\neq s^2(X^\prime X)^{-1}
\end{align*}
\]</span></p>
<p>其中 <span class="math inline">\(D(e) = diag(e_1, \cdots, e_n) \neq s^2 I\)</span>。</p></li>
</ul>
<h3 id="假设-5">4.5.2 假设</h3>
<ul>
<li><p><strong>假设 4.7</strong>（<span class="math inline">\(\rm{P}_{122}\)</span>）：(1) 对于所有的 <span class="math inline">\(j \in \{0,1,\cdots,k\}, E(X_{jt}^4)&lt;\infty\)</span>。(2) <span class="math inline">\(E(X\varepsilon_{t}^4)&lt;\infty\)</span>。 <span class="math display">\[
\begin{align*}
s^2 \hat Q {}^{-1} \overset{p}{\to} avar(\sqrt n \hat \beta) = \sigma^2 Q^{-1}
\end{align*}
\]</span></p>
<p>注：渐近方差估计 <span class="math inline">\(\hat Q {}^{-1} V \hat Q {}^{-1}\)</span> 在条件同方差下也是渐近有效的，即 <span class="math inline">\(\hat Q {}^{-1} V \hat{Q}{}^{-1} \overset{P}{\to} Avar(\sqrt{n}\hat{\beta}) = \sigma^2 Q{}^{-1}\)</span>，但在有限样本条件下，可能不如 <span class="math inline">\(\sigma^2 Q^{-1}\)</span> 表现好，因为后者利用了条件同方差这一信息。</p></li>
</ul>
<h2 id="参数假设检验-1">4.6 参数假设检验</h2>
<p>下面考虑如何构建统计量以检验原假设： <span class="math display">\[
\begin{align*}
\mathbb{H}: R\beta^o = r
\end{align*}
\]</span> 其中 <span class="math inline">\(R\)</span> 时 <span class="math inline">\(J \times K\)</span> 满秩矩阵，<span class="math inline">\(r\)</span> 是 <span class="math inline">\(J \times 1\)</span> 常向量，且 <span class="math inline">\(J \leq K\)</span>。</p>
<p>首先考虑统计量 <span class="math inline">\(R \hat\beta - r = R(\hat\beta - \beta^o) + R\beta^o - r\)</span>，所以再原假设 <span class="math inline">\(\mathbb{H}: R\beta^o = r\)</span> 下有： <span class="math display">\[
\begin{align*}
\sqrt n (R \hat\beta - r) &amp;= R\sqrt n(\hat\beta - \beta^o) \\
&amp;\overset{d}{\to} N(0, RQ^{-1}VQ^{-1}R^\prime)
\end{align*}
\]</span></p>
<p>其中，<span class="math inline">\(\hat Q = \frac{X^{\prime} X}{n} \overset{P}{\to} Q,\ s^2 \overset{P}{\to} \sigma^2\)</span>。</p>
<p><strong>1. 条件同方差情形</strong>(<span class="math inline">\(V = \sigma^2 Q\)</span>)</p>
<ul>
<li><p><strong>定理 4.19</strong>（<span class="math inline">\(\rm{P}_{125}\)</span>）&lt; <span class="math inline">\(t\)</span> 检验 &gt;：给定假设 4.1-4.4 和 4.6，则当假设 <span class="math inline">\(\mathbb{H}_0: R\beta^o = r\)</span> 成立， <span class="math inline">\(J = 1\)</span>，且 <span class="math inline">\(n\to \infty\)</span> 时，经典 <span class="math inline">\(t\)</span> 检验统计量： <span class="math display">\[
\begin{align*}
T &amp;= \frac{\sqrt n(R\beta_o - r)}{\sqrt{\sigma^2 R Q^{-1} R^{\prime}}} \\
&amp;= \frac{R\beta_o - r}{\sqrt{s^2 R (nQ)^{-1} R^{\prime}}} \\
&amp;=  \frac{R\beta^o - r}{\sqrt{s^2 R(X^\prime X)^{-1}R^\prime}}   \overset{p}{\to} N(0, 1)
\end{align*}
\]</span></p></li>
<li><p><strong>定理 4.20</strong>（<span class="math inline">\(\rm{P}_{125}\)</span>）&lt; 渐近 <span class="math inline">\(\chi^2\)</span> 检验 &gt;：给定假设 4.1-4.4 和 4.6，则当假设 <span class="math inline">\(\mathbb{H}_0: R\beta^o = r\)</span> 成立， <span class="math inline">\(J \leq 1\)</span>，且 <span class="math inline">\(n\to \infty\)</span>, <span class="math inline">\(Wald\)</span> 检验统计量（同方差，方差可知： <span class="math display">\[
\begin{align*}
\mathcal{W} &amp;\equiv (R\beta^o - r)^\prime[s^2 R(X^\prime X)^{-1}R]^{-1}(R\beta^o - r) \\
&amp;= J \cdot F \overset{d}{\to} \chi^2_J
\end{align*}
\]</span></p></li>
<li><p><strong>定理 4.21</strong>（<span class="math inline">\(\rm{P}_{126}\)</span>）&lt; <span class="math inline">\((n-K)\mathcal{R}^2\)</span> 检验 &gt;：给定假设 4.1-4.6，检验以下原假设： <span class="math display">\[
\begin{align*}
\mathbb{H}_0:\beta^o_0 = \beta^o_1 = \cdots = \beta^o_k = 0
\end{align*}
\]</span> 其中，<span class="math inline">\(\beta^o_0, \beta^o_1, \cdots, \beta^o_k\)</span> 是线性回归方程: <span class="math display">\[
\begin{align*}
Y = \beta^o_0 + \beta^o_1 X_{1t} + \cdots + \beta^o_k X_{kt} + \varepsilon_t
\end{align*}
\]</span> 除截距项 <span class="math inline">\(\beta_0^o\)</span> 意外的所有回归系数。令 <span class="math inline">\(\mathcal{R}^2\)</span> 是无约束线性回归模型的决定系数，则当原假设 <span class="math inline">\(\mathbb{H}_0\)</span> 成立及 <span class="math inline">\(n \to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
(n - K) \mathcal{R}^2 \overset{d}{\to} \chi^2_k
\end{align*}
\]</span> 其中，<span class="math inline">\(\mathcal{R}^2\)</span> 的定义（<span class="math inline">\(\rm{P}_{82}\)</span>）为： <span class="math display">\[
\begin{align*}
\mathcal{R}^2 &amp;= 1 - \frac{e^\prime e}{(Y - \bar Y l)^\prime (Y - \bar Y l)} = 1 - \frac{e^\prime e}{\tilde e{}^\prime \tilde e} \\
&amp; \frac{R^2/(k-1)}{(1-R^2)/(n-K)} \overset{d}{\to} F(K-1, n-K)
\end{align*}
\]</span> 在原假设 <span class="math inline">\(\mathcal{H}_0: \beta_1^o = \cdots = \beta_k^o = 0\)</span> 时，<span class="math inline">\(R^2 \overset{P}{\to} 0\)</span>。</p></li>
</ul>
<p><strong>2. 条件异方差情形</strong>(<span class="math inline">\(V \neq \sigma^2 Q\)</span>) 在原假设 <span class="math inline">\(\mathbb{H}_0: R \beta^o = r\)</span> 成立的条件下，有： <span class="math display">\[
\begin{align*}
\sqrt n (R \hat\beta - r) \overset{d}{\to} N(0, RQ^{-1}VQ^{-1}R^\prime)
\end{align*}
\]</span> 其中，<span class="math inline">\(V = E(X_t X_T^\prime \varepsilon_t^2)\)</span>，因此有 <span class="math display">\[
\begin{align*}
\frac{R\beta^o - r}{\sqrt{R Q^{-1} V Q^{-1} R^\prime}} \overset{p}{\to} N(0, 1)
\end{align*}
\]</span> 给定 <span class="math inline">\(\hat Q \overset{p}{\to} Q, \hat V \overset{p}{\to} V\)</span>，这里 <span class="math inline">\(\hat V = X^\prime D(e) D(e)^\prime X/n\)</span>，并由 Slutsky 定理，可定义稳健性 <span class="math inline">\(t\)</span> 检验统计量： <span class="math display">\[
\begin{align*}
T_r \equiv \frac{\sqrt n(R \hat\beta - r)}{\sqrt{R \hat Q{}^{-1} \hat V \hat Q{}^{-1} R^\prime}}
\end{align*}
\]</span> 当 <span class="math inline">\(\mathbb{H}_0:R\beta^o = r\)</span> 成立，且 <span class="math inline">\(n \to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
T_r \overset{p}{\to} N(0, 1)
\end{align*}
\]</span> 这里，稳健性 (Robustness) 是指，当存在条件异方差时，<span class="math inline">\(T_r\)</span> 也是渐近有效的。</p>
<ul>
<li><p><strong>定理 4.22</strong>（<span class="math inline">\(\rm{P}_{128}\)</span>）&lt; 条件异方差下的稳健 <span class="math inline">\(t\)</span> 检验 (Robust t-Test Under Conditional Heteroskedasticity) &gt;：给定假设 4.1-4.5 和 4.7，则当原假设 <span class="math inline">\(\mathbb{H}_0: R \beta^o = r\)</span> 成立。</p>
<p>当 <span class="math inline">\(J = 1\)</span>，且 <span class="math inline">\(n \to \infty\)</span> 时，稳健 <span class="math inline">\(t\)</span> 检验统计量为： <span class="math display">\[
\begin{align*}
T_r \equiv \frac{\sqrt n(R \hat\beta - r)}{\sqrt{R \hat Q{}^{-1} \hat V \hat Q{}^{-1} R^\prime}} \overset{p}{\to} N(0, 1)
\end{align*}
\]</span> 当 <span class="math inline">\(J \geq 1\)</span>，在原假设 <span class="math inline">\(\mathbb{H}_0: R \beta^o = r\)</span> 下，有二次型： <span class="math display">\[
\begin{align*}
\mathcal{W} &amp;\equiv \sqrt n (R\hat \beta - r)^\prime[R \hat Q{}^{-1} \hat V \hat Q{}^{-1} R^\prime]^{-1}\sqrt n(R\hat \beta - r) \\
&amp;\overset{d}{\to} \chi^2_J
\end{align*}
\]</span> 其中， <span class="math display">\[
\begin{align*}
\hat Q &amp;= \frac{X^\prime X}{n}\\
\hat V &amp;= var(X_t e_t) = \frac{X^\prime D(e)D(e)^\prime X}{n}
\end{align*}
\]</span> 这里，<span class="math inline">\(D(e) = diag\{e_1, 2_2, \cdots,e_n\}\)</span>。</p></li>
<li><p><strong>定理 4.23</strong>（<span class="math inline">\(\rm{P}_{128}\)</span>）&lt; 条件异方差下的稳健 <span class="math inline">\(Wald\)</span> 检验 (Robust Wald Test Under Conditional Heteroskedasticity) &gt;：给定假设 4.1-4.5 和 4.7，则当原假设 <span class="math inline">\(\mathbb{H}_0: R \beta^o = r\)</span> 成立，且 <span class="math inline">\(n \to \infty\)</span> 时，有： <span class="math display">\[
\begin{align*}
\mathcal{W} &amp;\equiv \sqrt n (R\hat \beta - r)^\prime[R \hat Q{}^{-1} \hat V \hat Q{}^{-1} R^\prime]^{-1}\sqrt n(R\hat \beta - r) \\
&amp;\overset{d}{\to} \chi^2_J
\end{align*}
\]</span></p>
<p>异方差下，方差不可知，用渐近分布估计方差。</p></li>
</ul>
<h2 id="条件异方差检验">4.7 条件异方差检验</h2>
<p><strong><span class="math inline">\(White\)</span> 条件异方差检验</strong></p>
<p>考虑原假设：<span class="math inline">\(\mathbb{H}_0: E(\varepsilon_t^2|X_t) = \sigma^2\)</span>，其中，<span class="math inline">\(\varepsilon_t\)</span> 是 <span class="math inline">\(Y_t = X_t^\prime \beta^o + \varepsilon_t\)</span> 的随机扰动项。</p>
<p>非零假设为： <span class="math display">\[
\begin{align*}
\varepsilon_t^2 &amp;= \gamma^\prime \rm{vech}(X_t X_t^\prime) + v_t \\
&amp;= \beta_0 + \beta_1 
X_1 + \beta_2 X_2 + \cdots + \beta_t X_1 X_2 + \beta_s X_1 X_3 + \cdots + v_t
\end{align*}
\]</span> 其中，<span class="math inline">\(\rm{vech}(X_t X_t^\prime)\)</span> 是一个向量化算子，它将 <span class="math inline">\(K \times K\)</span> 对称矩阵 <span class="math inline">\(X_t X_t^\prime\)</span> 下三角元素转变为一个 <span class="math inline">\(\frac{K(K+1)}{2} \times 1\)</span> 向量。在 <span class="math inline">\(\mathbb{H}_0: E(\varepsilon_t^2|X_t) = \sigma^2\)</span> 下，<span class="math inline">\(\varepsilon_t^2\)</span> 与任何 <span class="math inline">\(X_t\)</span> 都不相关，故除截距项外，所有斜率系数均为零。</p>
<p>假设 <span class="math inline">\(E(\varepsilon_t^4|X_t) = \mu_4\)</span>，可以得到： <span class="math display">\[
\begin{align*}
(n-J-1)\tilde{\mathcal{R}} \overset{d}{\to} \chi_J^2
\end{align*}
\]</span></p>
<h1 id="平稳时间序列的线性回归模型">5 平稳时间序列的线性回归模型</h1>
<h2 id="时间序列分析导论">5.1 时间序列分析导论</h2>
<h3 id="定义-8">5.1 定义</h3>
<ul>
<li><strong>定义 5.1</strong>（<span class="math inline">\(\rm{P}_{137}\)</span>）&lt; 随机时间序列过程 (Stochastic Time Series Process) &gt;：一个随机时间序列过程 <span class="math inline">\(\{Z_t\}\)</span> 是由概率法则 <span class="math inline">\((\Omega, \mathbb{F}, P)\)</span> 支配而产生的随机变量或向量序列。其中， <span class="math inline">\(t \in \{\cdots, 0, 1, 2, \cdots\}\)</span> 代表时间，<span class="math inline">\(\Omega\)</span> 是样本空间，<span class="math inline">\(\mathbb{F}\)</span> 是 <span class="math inline">\(\sigma\ -\)</span> 域，<span class="math inline">\(P: \mathbb{F} \to [0, 1]\)</span> 是概率测度。</li>
</ul>
]]></content>
      <categories>
        <category>Class Notes</category>
        <category>Econometrics</category>
      </categories>
      <tags>
        <tag>Econometrics</tag>
      </tags>
  </entry>
  <entry>
    <title>Energy Economic Codes</title>
    <url>/2020/12/08/Energy-Economic/</url>
    <content><![CDATA[<h1 id="markov-model">1 Markov model</h1>
<h2 id="preparation-and-definition">1.1 Preparation and definition</h2>
<ul>
<li><p>Import modules</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg <span class="keyword">as</span> la</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error, r2_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot module</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"><span class="comment"># Microsoft YaHei, Times New Roman</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure></li>
</ul>
<a id="more"></a>
<ul>
<li><p>Plot results</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_result</span>(<span class="params">test_Y, pred_Y, Title</span>):</span></span><br><span class="line">    ylim_min = np.<span class="built_in">round</span>(test_Y.<span class="built_in">min</span>()) - <span class="number">1</span></span><br><span class="line">    ylim_max = np.<span class="built_in">round</span>(test_Y.<span class="built_in">max</span>()) + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># plot comparison results</span></span><br><span class="line">    fig = plt.figure(figsize = (<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">    ax0 = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax0.scatter(test_Y, pred_Y)</span><br><span class="line">    ax0.plot([ylim_min, ylim_max], [ylim_min, ylim_max], <span class="string">&#x27;--k&#x27;</span>)</span><br><span class="line">    ax0.set_xlabel(<span class="string">&#x27;True Target&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">    ax0.set_ylabel(<span class="string">&#x27;Target predicted&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">    ax0.set_title(Title , fontsize = <span class="number">16</span>)</span><br><span class="line">    ax0.text(ylim_min + <span class="number">2</span>, ylim_max - <span class="number">4</span>, <span class="string">r&#x27;$R^2$ = %.2f, $MAE$ = %.2f&#x27;</span> %(r2_score(test_Y, pred_Y), </span><br><span class="line">                mean_absolute_error(test_Y, pred_Y)), fontsize = <span class="number">14</span>)</span><br><span class="line">    ax0.text(ylim_min + <span class="number">2</span>, ylim_max - <span class="number">5</span>, <span class="string">r&#x27;$MSE$ = %.2f, $RMSE$ = %.2f&#x27;</span> %(mean_squared_error(test_Y, pred_Y), </span><br><span class="line">                mean_squared_error(test_Y, pred_Y, squared=<span class="literal">False</span>)), fontsize = <span class="number">14</span>)</span><br><span class="line">    </span><br><span class="line">    ax0.set_xlim([ylim_min, ylim_max])</span><br><span class="line">    ax0.set_ylim([ylim_min, ylim_max])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot prediction and real values</span></span><br><span class="line">    plt.figure(figsize = (<span class="number">8</span>, <span class="number">6</span>)) <span class="comment"># length x width</span></span><br><span class="line">    plt.plot(pred_Y, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;prediction&#x27;</span>, lw = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(test_Y, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;real&#x27;</span>, lw = <span class="number">0.8</span>)</span><br><span class="line">    plt.xticks(<span class="built_in">range</span>(<span class="number">19</span>), fontsize = <span class="number">15</span>)</span><br><span class="line">    plt.yticks(fontsize = <span class="number">15</span>)</span><br><span class="line">    plt.title(Title, fontsize = <span class="number">16</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;best&#x27;</span>, fontsize  = <span class="number">15</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>绘制结果图（可选，可通过调整 <code>plot_b</code> 的值来选择是否绘图），包含两个:</p>
<p><img src="https://s3.ax1x.com/2020/12/08/rpDV56.md.png" /></p>
<center>
<p>Fig. 1-1 Trend figure of Coal</p>
</center>
<p><img src="https://s3.ax1x.com/2020/12/08/rpDePK.png" /></p>
<center>
<p>Fig. 1-2 Comparison figure of Coal</p>
</center></li>
<li><p>Calculate loss</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_error</span>(<span class="params">test_data, np_Pred_results, title</span>):</span></span><br><span class="line">    <span class="comment"># Storing error results </span></span><br><span class="line">    R2 = r2_score(test_data, np_Pred_results)</span><br><span class="line">    MAE = mean_absolute_error(test_data, np_Pred_results)</span><br><span class="line">    MSE = mean_squared_error(test_data, np_Pred_results)</span><br><span class="line">    RMSE = mean_squared_error(test_data, np_Pred_results, squared=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    error = [title, R2, MAE, MSE, RMSE]</span><br><span class="line">    <span class="keyword">return</span> error</span><br></pre></td></tr></table></figure>
<p>Calculate the loss: R2, MAE, MSE, RMSE</p></li>
<li><p>Definition of Markov model</p>
<p>The first step: calculate and return transfer matrix (type: np.array)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Markov_trans</span>(<span class="params">data_stru, year_start, year_end</span>):</span></span><br><span class="line">    P = np.identity(<span class="number">4</span>)</span><br><span class="line">    K = np.array([<span class="number">1.0</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line">    </span><br><span class="line">    year_start_data = data_stru.loc[year_start, :]</span><br><span class="line">    year_end_data = data_stru.loc[year_end,:]</span><br><span class="line">    </span><br><span class="line">    bool_value = np.array(year_end_data &lt; year_start_data)</span><br><span class="line">    i = <span class="number">0</span> <span class="comment"># index</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> bool_value:</span><br><span class="line">        <span class="keyword">if</span> b == <span class="literal">False</span>: <span class="comment"># Decrease</span></span><br><span class="line">            K[i] =  year_end_data[i] - year_start_data[i]</span><br><span class="line">        <span class="keyword">elif</span> b == <span class="literal">True</span>: <span class="comment"># Increase</span></span><br><span class="line">            P[i, i] = year_end_data[i]/year_start_data[i]</span><br><span class="line">            K[i] = <span class="number">0</span></span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">          </span><br><span class="line">    KK = <span class="built_in">sum</span>(K)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            <span class="keyword">if</span> (j != n) &amp; (K[j] == <span class="number">0</span>):</span><br><span class="line">                P[j,n] = (<span class="number">1</span>-P[j,j])*K[n]/KK</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># v 为特征值    Q 为特征向量</span></span><br><span class="line">    P = np.<span class="built_in">round</span>(P, <span class="number">3</span>)</span><br><span class="line">    v, Q = la.eig(P)</span><br><span class="line">    <span class="comment"># diag_P = np.round(np.dot(np.dot(la.inv(Q), P), Q), 3)</span></span><br><span class="line">    V = np.diag(v)**((<span class="number">1</span>)/(year_end-year_start))</span><br><span class="line">    Predict_P =  np.<span class="built_in">round</span>(np.dot(np.dot(Q, V), la.inv(Q)), <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> Predict_P</span><br></pre></td></tr></table></figure>
<p>The second step: calculate and return forecasting result (type: np.array)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Markov_predict</span>(<span class="params">data_stru, P, year_end, year_pred</span>):</span></span><br><span class="line">    year_end_data = data_stru.loc[year_end,:]</span><br><span class="line">    P = np.<span class="built_in">round</span>(P, <span class="number">3</span>)</span><br><span class="line">    v, Q = la.eig(P)</span><br><span class="line">    <span class="comment"># diag_P = np.round(np.dot(np.dot(la.inv(Q), P), Q), 3)</span></span><br><span class="line">    V = np.diag(v)**(year_pred - year_end)</span><br><span class="line">    Predict_P =  np.<span class="built_in">round</span>(np.dot(np.dot(Q, V), la.inv(Q)), <span class="number">3</span>)</span><br><span class="line">    np_year_end_data =np.array(year_end_data)</span><br><span class="line">    Predict_energy_stru = np.around(np.dot(np_year_end_data, Predict_P), <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> Predict_energy_stru</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="preparation">1.2 Preparation</h2>
<ul>
<li><p>Read data file</p>
<p><code>Data.xlsx</code> 文件需要根程序文件在同一目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Read datafile</span></span><br><span class="line">data_stru = pd.read_excel(<span class="string">&#x27;./Data.xlsx&#x27;</span>, header = <span class="number">0</span>, </span><br><span class="line">                          sheet_name = <span class="number">0</span>, index_col= <span class="number">0</span>)</span><br><span class="line">num_year = <span class="built_in">len</span>(data_stru) <span class="comment"># the length of the dataset</span></span><br><span class="line">train_percent = <span class="number">0.7</span> <span class="comment"># Set the first 70% data as train set</span></span><br><span class="line">Error_results = [] <span class="comment"># Store all error results</span></span><br><span class="line">plot_b = <span class="literal">False</span> <span class="comment"># Choose whether plot result</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataset start with 1953, end with 2017</span></span><br><span class="line">year_train_start, year_end = <span class="number">1953</span>, <span class="number">2018</span></span><br><span class="line">year_train_end = year_train_start + <span class="built_in">round</span>(<span class="built_in">len</span>(data_stru) * <span class="number">0.7</span>) <span class="comment"># = 1999</span></span><br><span class="line"></span><br><span class="line">test_data = np.array(data_stru.loc[year_train_end:, :]) <span class="comment"># from 1999 to 2017</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="model-application">1.3 Model application</h2>
<ul>
<li><p>Avarage trans_P</p>
<p>Model test based on avarage trans_P</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trans_P = [] <span class="comment"># store all transfer matric</span></span><br><span class="line"><span class="keyword">for</span> startY <span class="keyword">in</span> <span class="built_in">range</span>(year_train_start, year_train_end - <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> endY <span class="keyword">in</span> <span class="built_in">range</span>(startY, year_train_end):</span><br><span class="line">        trans_temp = Markov_trans(year_start = year_train_start, </span><br><span class="line">                        year_end = year_train_end, data_stru = data_stru)</span><br><span class="line">        temp = trans_temp.tolist()</span><br><span class="line">        trans_P.append(temp)</span><br><span class="line"></span><br><span class="line">np_trans_P = np.array(trans_P) <span class="comment"># Transfer list into numpy</span></span><br><span class="line">av_trans_P = np.<span class="built_in">sum</span>(np_trans_P, <span class="number">0</span>)/np_trans_P.shape[<span class="number">0</span>] <span class="comment"># Calculate avarage</span></span><br><span class="line"></span><br><span class="line">Pred_results = [] <span class="comment"># Using average transfer matrix to predict energy structure</span></span><br><span class="line"><span class="keyword">for</span> predY <span class="keyword">in</span> <span class="built_in">range</span>(year_train_end, year_end):</span><br><span class="line">    <span class="comment"># Forecasting</span></span><br><span class="line">    Pred_temp = Markov_predict(data_stru = data_stru, P = av_trans_P, </span><br><span class="line">                            year_end = year_train_end - <span class="number">1</span>, year_pred = predY)</span><br><span class="line">    temp = Pred_temp.tolist() <span class="comment"># Turn numpy.array into list</span></span><br><span class="line">    Pred_results.append(temp) <span class="comment"># It&#x27;s convenient to append value using list</span></span><br><span class="line">    </span><br><span class="line">np_Pred_results = np.array(Pred_results) <span class="comment"># Turn list into np.array</span></span><br><span class="line">Columns = data_stru.columns</span><br><span class="line"><span class="comment"># Plot forecasting result if needed</span></span><br><span class="line"><span class="keyword">if</span> plot_b == <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        test_Y, pred_Y = test_data[:, i], np_Pred_results[:, i]</span><br><span class="line">        Title = <span class="string">&#x27;&#123;&#125; based on average transfer matrix to predict:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(regression, </span><br><span class="line">                                    Columns[i])</span><br><span class="line">        plot_result(test_Y, pred_Y, Title)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># Storing error results</span></span><br><span class="line">title = <span class="string">&#x27;average transfer matrix&#x27;</span>  </span><br><span class="line"><span class="comment"># Calculate 4 error</span></span><br><span class="line">error = calculate_error(test_data, np_Pred_results, title)</span><br><span class="line">Error_results.append(error)</span><br></pre></td></tr></table></figure></li>
<li><p>One step and 46 step</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> year_train_start <span class="keyword">in</span> [<span class="number">1953</span>, <span class="number">1998</span>]: <span class="comment"># from &#x27;1953 to 1999&#x27; or &#x27;1998 to 1999&#x27;</span></span><br><span class="line">    year_train_end, year_end = <span class="number">1999</span>, <span class="number">2018</span></span><br><span class="line">    trans_temp = Markov_trans(year_start = year_train_start, </span><br><span class="line">                            year_end = year_train_end, data_stru = data_stru)</span><br><span class="line">    Pred_results = []</span><br><span class="line">    <span class="keyword">for</span> predY <span class="keyword">in</span> <span class="built_in">range</span>(year_train_end, year_end):</span><br><span class="line">        Pred_temp = Markov_predict(data_stru = data_stru, P = trans_temp, </span><br><span class="line">                                year_end = year_train_end - <span class="number">1</span>, year_pred = predY)</span><br><span class="line">        temp = Pred_temp.tolist()</span><br><span class="line">        Pred_results.append(temp)</span><br><span class="line">        </span><br><span class="line">    np_Pred_results = np.array(Pred_results)</span><br><span class="line">    Columns = data_stru.columns</span><br><span class="line">    <span class="keyword">if</span> plot_b == <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            test_Y, pred_Y = test_data[:, i], np_Pred_results[:, i]</span><br><span class="line">            Title = <span class="string">&#x27;&#123;&#125; based on &#123;&#125; and &#123;&#125; to predict:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(regression, </span><br><span class="line">                                    year_train_start, year_train_end, Columns[i])             </span><br><span class="line">            plot_result(test_Y, pred_Y, Title)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Storing error results  </span></span><br><span class="line">    title = <span class="string">&#x27;&#123;&#125; step&#x27;</span>.<span class="built_in">format</span>(year_train_end - year_train_start)   </span><br><span class="line">    error = calculate_error(test_data, np_Pred_results, title)</span><br><span class="line">    Error_results.append(error)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="export-result-to-excel">1.4 Export result to excel</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np_error = np.array(Error_results)</span><br><span class="line">columns = [<span class="string">&#x27;Transfer Matrix&#x27;</span>, <span class="string">&#x27;R2&#x27;</span>, <span class="string">&#x27;MAE&#x27;</span>, <span class="string">&#x27;MSE&#x27;</span>, <span class="string">&#x27;RMSE&#x27;</span>]</span><br><span class="line">pd_error = pd.DataFrame(np_error, columns = columns, dtype = <span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">pd_error.to_excel(<span class="string">&#x27;Error result.xlsx&#x27;</span>, encoding = <span class="string">&#x27;utf_8_sig&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="all-codes">1.5 All codes</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Markov model for energy structure prediction#</span></span><br><span class="line"><span class="comment"># ========================= Import modules ====================================</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg <span class="keyword">as</span> la</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error, r2_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot module</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"><span class="comment"># Microsoft YaHei, Times New Roman</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== Preparation =======================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read datafile</span></span><br><span class="line">data_stru = pd.read_excel(<span class="string">&#x27;./Data.xlsx&#x27;</span>, header = <span class="number">0</span>, </span><br><span class="line">                          sheet_name = <span class="number">0</span>, index_col= <span class="number">0</span>)</span><br><span class="line">num_year = <span class="built_in">len</span>(data_stru) <span class="comment"># the length of the dataset</span></span><br><span class="line">train_percent = <span class="number">0.7</span> <span class="comment"># Set the first 70% data as train set</span></span><br><span class="line">Error_results = [] <span class="comment"># Store all error results</span></span><br><span class="line">plot_b = <span class="literal">False</span> <span class="comment"># Choose whether plot result</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataset start with 1953, end with 2017</span></span><br><span class="line">year_train_start, year_end = <span class="number">1953</span>, <span class="number">2018</span></span><br><span class="line">year_train_end = year_train_start + <span class="built_in">round</span>(<span class="built_in">len</span>(data_stru) * <span class="number">0.7</span>) <span class="comment"># = 1999</span></span><br><span class="line"></span><br><span class="line">test_data = np.array(data_stru.loc[year_train_end:, :]) <span class="comment"># from 1999 to 2017</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== Plot Results =====================================</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_result</span>(<span class="params">test_Y, pred_Y, Title</span>):</span></span><br><span class="line">    ylim_min = np.<span class="built_in">round</span>(test_Y.<span class="built_in">min</span>()) - <span class="number">1</span></span><br><span class="line">    ylim_max = np.<span class="built_in">round</span>(test_Y.<span class="built_in">max</span>()) + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># plot comparison results</span></span><br><span class="line">    fig = plt.figure(figsize = (<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">    ax0 = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax0.scatter(test_Y, pred_Y)</span><br><span class="line">    ax0.plot([ylim_min, ylim_max], [ylim_min, ylim_max], <span class="string">&#x27;--k&#x27;</span>)</span><br><span class="line">    ax0.set_xlabel(<span class="string">&#x27;True Target&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">    ax0.set_ylabel(<span class="string">&#x27;Target predicted&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">    ax0.set_title(Title , fontsize = <span class="number">16</span>)</span><br><span class="line">    ax0.text(ylim_min + <span class="number">2</span>, ylim_max - <span class="number">4</span>, <span class="string">r&#x27;$R^2$ = %.2f, $MAE$ = %.2f&#x27;</span> %(r2_score(test_Y, pred_Y), </span><br><span class="line">                mean_absolute_error(test_Y, pred_Y)), fontsize = <span class="number">14</span>)</span><br><span class="line">    ax0.text(ylim_min + <span class="number">2</span>, ylim_max - <span class="number">5</span>, <span class="string">r&#x27;$MSE$ = %.2f, $RMSE$ = %.2f&#x27;</span> %(mean_squared_error(test_Y, pred_Y), </span><br><span class="line">                mean_squared_error(test_Y, pred_Y, squared=<span class="literal">False</span>)), fontsize = <span class="number">14</span>)</span><br><span class="line">    </span><br><span class="line">    ax0.set_xlim([ylim_min, ylim_max])</span><br><span class="line">    ax0.set_ylim([ylim_min, ylim_max])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot prediction and real values</span></span><br><span class="line">    plt.figure(figsize = (<span class="number">8</span>, <span class="number">6</span>)) <span class="comment"># length x width</span></span><br><span class="line">    plt.plot(pred_Y, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;prediction&#x27;</span>, lw = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(test_Y, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;real&#x27;</span>, lw = <span class="number">0.8</span>)</span><br><span class="line">    plt.xticks(<span class="built_in">range</span>(<span class="number">19</span>), fontsize = <span class="number">15</span>)</span><br><span class="line">    plt.yticks(fontsize = <span class="number">15</span>)</span><br><span class="line">    plt.title(Title, fontsize = <span class="number">16</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;best&#x27;</span>, fontsize  = <span class="number">15</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate the loss: R2, MAE, MSE, RMSE</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_error</span>(<span class="params">test_data, np_Pred_results, title</span>):</span></span><br><span class="line">    <span class="comment"># Storing error results </span></span><br><span class="line">    R2 = r2_score(test_data, np_Pred_results)</span><br><span class="line">    MAE = mean_absolute_error(test_data, np_Pred_results)</span><br><span class="line">    MSE = mean_squared_error(test_data, np_Pred_results)</span><br><span class="line">    RMSE = mean_squared_error(test_data, np_Pred_results, squared=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    error = [title, R2, MAE, MSE, RMSE]</span><br><span class="line">    <span class="keyword">return</span> error</span><br><span class="line"></span><br><span class="line"><span class="comment"># =================== Markov model definition =============================</span></span><br><span class="line"><span class="comment"># The first step: calculate and return transfer matrix (type: np.array)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Markov_trans</span>(<span class="params">data_stru, year_start, year_end</span>):</span></span><br><span class="line">    P = np.identity(<span class="number">4</span>)</span><br><span class="line">    K = np.array([<span class="number">1.0</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line">    </span><br><span class="line">    year_start_data = data_stru.loc[year_start, :]</span><br><span class="line">    year_end_data = data_stru.loc[year_end,:]</span><br><span class="line">    </span><br><span class="line">    bool_value = np.array(year_end_data &lt; year_start_data)</span><br><span class="line">    i = <span class="number">0</span> <span class="comment"># index</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> bool_value:</span><br><span class="line">        <span class="keyword">if</span> b == <span class="literal">False</span>: <span class="comment"># Decrease</span></span><br><span class="line">            K[i] =  year_end_data[i] - year_start_data[i]</span><br><span class="line">        <span class="keyword">elif</span> b == <span class="literal">True</span>: <span class="comment"># Increase</span></span><br><span class="line">            P[i, i] = year_end_data[i]/year_start_data[i]</span><br><span class="line">            K[i] = <span class="number">0</span></span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">          </span><br><span class="line">    KK = <span class="built_in">sum</span>(K)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            <span class="keyword">if</span> (j != n) &amp; (K[j] == <span class="number">0</span>):</span><br><span class="line">                P[j,n] = (<span class="number">1</span>-P[j,j])*K[n]/KK</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># v 为特征值    Q 为特征向量</span></span><br><span class="line">    P = np.<span class="built_in">round</span>(P, <span class="number">3</span>)</span><br><span class="line">    v, Q = la.eig(P)</span><br><span class="line">    <span class="comment"># diag_P = np.round(np.dot(np.dot(la.inv(Q), P), Q), 3)</span></span><br><span class="line">    V = np.diag(v)**((<span class="number">1</span>)/(year_end-year_start))</span><br><span class="line">    Predict_P =  np.<span class="built_in">round</span>(np.dot(np.dot(Q, V), la.inv(Q)), <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> Predict_P</span><br><span class="line"></span><br><span class="line"><span class="comment"># The second step: calculate and return forecasting result (type: np.array)    </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Markov_predict</span>(<span class="params">data_stru, P, year_end, year_pred</span>):</span></span><br><span class="line">    year_end_data = data_stru.loc[year_end,:]</span><br><span class="line">    P = np.<span class="built_in">round</span>(P, <span class="number">3</span>)</span><br><span class="line">    v, Q = la.eig(P)</span><br><span class="line">    <span class="comment"># diag_P = np.round(np.dot(np.dot(la.inv(Q), P), Q), 3)</span></span><br><span class="line">    V = np.diag(v)**(year_pred - year_end)</span><br><span class="line">    Predict_P =  np.<span class="built_in">round</span>(np.dot(np.dot(Q, V), la.inv(Q)), <span class="number">3</span>)</span><br><span class="line">    np_year_end_data =np.array(year_end_data)</span><br><span class="line">    Predict_energy_stru = np.around(np.dot(np_year_end_data, Predict_P), <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> Predict_energy_stru</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Lable</span></span><br><span class="line">regression = <span class="string">&#x27;Markov model&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># =========== Model test based on avarage trans_P ==========================</span></span><br><span class="line">trans_P = [] <span class="comment"># store all transfer matric</span></span><br><span class="line"><span class="keyword">for</span> startY <span class="keyword">in</span> <span class="built_in">range</span>(year_train_start, year_train_end - <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> endY <span class="keyword">in</span> <span class="built_in">range</span>(startY, year_train_end):</span><br><span class="line">        trans_temp = Markov_trans(year_start = year_train_start, </span><br><span class="line">                        year_end = year_train_end, data_stru = data_stru)</span><br><span class="line">        temp = trans_temp.tolist()</span><br><span class="line">        trans_P.append(temp)</span><br><span class="line"></span><br><span class="line">np_trans_P = np.array(trans_P) <span class="comment"># Transfer list into numpy</span></span><br><span class="line">av_trans_P = np.<span class="built_in">sum</span>(np_trans_P, <span class="number">0</span>)/np_trans_P.shape[<span class="number">0</span>] <span class="comment"># Calculate avarage</span></span><br><span class="line"></span><br><span class="line">Pred_results = [] <span class="comment"># Using average transfer matrix to predict energy structure</span></span><br><span class="line"><span class="keyword">for</span> predY <span class="keyword">in</span> <span class="built_in">range</span>(year_train_end, year_end):</span><br><span class="line">    <span class="comment"># Forecasting</span></span><br><span class="line">    Pred_temp = Markov_predict(data_stru = data_stru, P = av_trans_P, </span><br><span class="line">                            year_end = year_train_end - <span class="number">1</span>, year_pred = predY)</span><br><span class="line">    temp = Pred_temp.tolist() <span class="comment"># Turn numpy.array into list</span></span><br><span class="line">    Pred_results.append(temp) <span class="comment"># It&#x27;s convenient to append value using list</span></span><br><span class="line">    </span><br><span class="line">np_Pred_results = np.array(Pred_results) <span class="comment"># Turn list into np.array</span></span><br><span class="line">Columns = data_stru.columns</span><br><span class="line"><span class="comment"># Plot forecasting result if needed</span></span><br><span class="line"><span class="keyword">if</span> plot_b == <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        test_Y, pred_Y = test_data[:, i], np_Pred_results[:, i]</span><br><span class="line">        Title = <span class="string">&#x27;&#123;&#125; based on average transfer matrix to predict:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(regression, </span><br><span class="line">                                    Columns[i])</span><br><span class="line">        plot_result(test_Y, pred_Y, Title)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># Storing error results</span></span><br><span class="line">title = <span class="string">&#x27;average transfer matrix&#x27;</span>  </span><br><span class="line"><span class="comment"># Calculate 4 error</span></span><br><span class="line">error = calculate_error(test_data, np_Pred_results, title)</span><br><span class="line">Error_results.append(error)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ======== Model test based on datas from 1953 to 1999 ==================</span></span><br><span class="line"><span class="keyword">for</span> year_train_start <span class="keyword">in</span> [<span class="number">1953</span>, <span class="number">1998</span>]: <span class="comment"># from &#x27;1953 to 1999&#x27; or &#x27;1998 to 1999&#x27;</span></span><br><span class="line">    year_train_end, year_end = <span class="number">1999</span>, <span class="number">2018</span></span><br><span class="line">    trans_temp = Markov_trans(year_start = year_train_start, </span><br><span class="line">                            year_end = year_train_end, data_stru = data_stru)</span><br><span class="line">    Pred_results = []</span><br><span class="line">    <span class="keyword">for</span> predY <span class="keyword">in</span> <span class="built_in">range</span>(year_train_end, year_end):</span><br><span class="line">        Pred_temp = Markov_predict(data_stru = data_stru, P = trans_temp, </span><br><span class="line">                                year_end = year_train_end - <span class="number">1</span>, year_pred = predY)</span><br><span class="line">        temp = Pred_temp.tolist()</span><br><span class="line">        Pred_results.append(temp)</span><br><span class="line">        </span><br><span class="line">    np_Pred_results = np.array(Pred_results)</span><br><span class="line">    Columns = data_stru.columns</span><br><span class="line">    <span class="keyword">if</span> plot_b == <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            test_Y, pred_Y = test_data[:, i], np_Pred_results[:, i]</span><br><span class="line">            Title = <span class="string">&#x27;&#123;&#125; based on &#123;&#125; and &#123;&#125; to predict:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(regression, </span><br><span class="line">                                    year_train_start, year_train_end, Columns[i])             </span><br><span class="line">            plot_result(test_Y, pred_Y, Title)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Storing error results  </span></span><br><span class="line">    title = <span class="string">&#x27;&#123;&#125; step&#x27;</span>.<span class="built_in">format</span>(year_train_end - year_train_start)   </span><br><span class="line">    error = calculate_error(test_data, np_Pred_results, title)</span><br><span class="line">    Error_results.append(error)</span><br><span class="line"></span><br><span class="line">np_error = np.array(Error_results)</span><br><span class="line">columns = [<span class="string">&#x27;Transfer Matrix&#x27;</span>, <span class="string">&#x27;R2&#x27;</span>, <span class="string">&#x27;MAE&#x27;</span>, <span class="string">&#x27;MSE&#x27;</span>, <span class="string">&#x27;RMSE&#x27;</span>]</span><br><span class="line">pd_error = pd.DataFrame(np_error, columns = columns, dtype = <span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">pd_error.to_excel(<span class="string">&#x27;Error result.xlsx&#x27;</span>, encoding = <span class="string">&#x27;utf_8_sig&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="traditional-models">2 Traditional models</h1>
<ul>
<li>Ridge</li>
<li>Lasso</li>
<li>PLS</li>
<li>MLP</li>
<li>Linear SVM</li>
<li>DecisionTree</li>
</ul>
<p>不同之处在于104 行开始的模型定义不同</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ========================= Import modules ====================================</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge, Lasso</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.cross_decomposition <span class="keyword">import</span> PLSRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVR</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error, r2_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot module</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"><span class="comment"># Microsoft YaHei, Times New Roman</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== Preparation =======================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read datafile</span></span><br><span class="line">data_stru = pd.read_excel(<span class="string">&#x27;./Data.xlsx&#x27;</span>, header = <span class="number">0</span>, </span><br><span class="line">                          sheet_name = <span class="number">0</span>, index_col= <span class="number">0</span>)</span><br><span class="line">data_stru = data_stru.dropna()</span><br><span class="line">dataset = data_stru.values</span><br><span class="line">dataset = dataset.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Columns = data_stru.columns <span class="comment"># columns name</span></span><br><span class="line">num_year = <span class="built_in">len</span>(data_stru) <span class="comment"># the length of the dataset</span></span><br><span class="line">train_percent = <span class="number">0.70</span> <span class="comment"># Set the first 70% data as train set</span></span><br><span class="line">test_percent = <span class="number">1</span> - train_percent</span><br><span class="line">Error_results = [] <span class="comment"># Store all error results</span></span><br><span class="line">input_size = <span class="number">10</span> <span class="comment"># Feed the previous 10 years as the input</span></span><br><span class="line">num_features = <span class="number">4</span> <span class="comment"># 4 energy categories</span></span><br><span class="line">plot_b = <span class="literal">False</span> <span class="comment"># Choose whether plot result</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # Put NN calculating module into GPU if available</span></span><br><span class="line"><span class="comment"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Feed the previous 10 years as the input and the 11th year as prediction output</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span>(<span class="params">dataset, look_back = input_size</span>):</span></span><br><span class="line">    dataX, dataY = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataset) - look_back):</span><br><span class="line">        a = dataset[i:(i + look_back)]</span><br><span class="line">        dataX.append(a)</span><br><span class="line">        dataY.append(dataset[i + look_back])</span><br><span class="line">    <span class="keyword">return</span> np.array(dataX), np.array(dataY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Input datasets and output datasets</span></span><br><span class="line">data_X, data_Y = create_dataset(dataset)</span><br><span class="line">ylim_min = np.<span class="built_in">round</span>(data_Y.<span class="built_in">min</span>()) - <span class="number">1</span></span><br><span class="line">ylim_max = np.<span class="built_in">round</span>(data_Y.<span class="built_in">max</span>()) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Divide training set and test set</span></span><br><span class="line">train_X, test_X, train_Y, test_Y = train_test_split(data_X, data_Y, </span><br><span class="line">        shuffle = <span class="literal">False</span>, test_size = test_percent) </span><br><span class="line"><span class="comment"># shuffle: don&#x27;t shuffle data</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== Plot Results =====================================</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_result</span>(<span class="params">test_Y, pred_Y, Title</span>):</span></span><br><span class="line">    ylim_min = np.<span class="built_in">round</span>(test_Y.<span class="built_in">min</span>()) - <span class="number">1</span></span><br><span class="line">    ylim_max = np.<span class="built_in">round</span>(test_Y.<span class="built_in">max</span>()) + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># plot comparison results</span></span><br><span class="line">    fig = plt.figure(figsize = (<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">    ax0 = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax0.scatter(test_Y, pred_Y)</span><br><span class="line">    ax0.plot([ylim_min, ylim_max], [ylim_min, ylim_max], <span class="string">&#x27;--k&#x27;</span>)</span><br><span class="line">    ax0.set_xlabel(<span class="string">&#x27;True Target&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">    ax0.set_ylabel(<span class="string">&#x27;Target predicted&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">    ax0.set_title(Title , fontsize = <span class="number">16</span>)</span><br><span class="line">    ax0.text(ylim_min + <span class="number">2</span>, ylim_max - <span class="number">4</span>, <span class="string">r&#x27;$R^2$ = %.2f, $MAE$ = %.2f&#x27;</span> %(r2_score(test_Y, pred_Y), </span><br><span class="line">                mean_absolute_error(test_Y, pred_Y)), fontsize = <span class="number">14</span>)</span><br><span class="line">    ax0.text(ylim_min + <span class="number">2</span>, ylim_max - <span class="number">5</span>, <span class="string">r&#x27;$MSE$ = %.2f, $RMSE$ = %.2f&#x27;</span> %(mean_squared_error(test_Y, pred_Y), </span><br><span class="line">                mean_squared_error(test_Y, pred_Y, squared=<span class="literal">False</span>)), fontsize = <span class="number">14</span>)</span><br><span class="line">    </span><br><span class="line">    ax0.set_xlim([ylim_min, ylim_max])</span><br><span class="line">    ax0.set_ylim([ylim_min, ylim_max])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot prediction and real values</span></span><br><span class="line">    plt.figure(figsize = (<span class="number">8</span>, <span class="number">6</span>)) <span class="comment"># length x width</span></span><br><span class="line">    plt.plot(pred_Y, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;prediction&#x27;</span>, lw = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(test_Y, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;real&#x27;</span>, lw = <span class="number">0.8</span>)</span><br><span class="line">    plt.xticks(<span class="built_in">range</span>(<span class="number">19</span>), fontsize = <span class="number">15</span>)</span><br><span class="line">    plt.yticks(fontsize = <span class="number">15</span>)</span><br><span class="line">    plt.title(Title, fontsize = <span class="number">16</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;best&#x27;</span>, fontsize  = <span class="number">15</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate the loss: R2, MAE, MSE, RMSE</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_error</span>(<span class="params">test_data, np_Pred_results, title</span>):</span></span><br><span class="line">    <span class="comment"># Storing error results</span></span><br><span class="line">    R2 = <span class="built_in">float</span>(<span class="string">&#x27;&#123;:.5f&#125;&#x27;</span>.<span class="built_in">format</span>(r2_score(test_data, np_Pred_results)))</span><br><span class="line">    MAE = <span class="built_in">float</span>(<span class="string">&#x27;&#123;:.5f&#125;&#x27;</span>.<span class="built_in">format</span>(mean_absolute_error(test_data, np_Pred_results)))</span><br><span class="line">    MSE = <span class="built_in">float</span>(<span class="string">&#x27;&#123;:.5f&#125;&#x27;</span>.<span class="built_in">format</span>(mean_squared_error(test_data, np_Pred_results)))</span><br><span class="line">    RMSE =<span class="built_in">float</span>(<span class="string">&#x27;&#123;:.5f&#125;&#x27;</span>.<span class="built_in">format</span>( mean_squared_error(test_data, np_Pred_results, squared=<span class="literal">False</span>)))</span><br><span class="line">    error = [title, R2, MAE, MSE, RMSE]</span><br><span class="line">    <span class="keyword">return</span> error</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================= Ridge Regression =============================</span></span><br><span class="line"><span class="comment"># Ridge model</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_model</span>(<span class="params">model_train_X, model_train_Y</span>):</span></span><br><span class="line">    regr = Ridge()</span><br><span class="line">    regr.fit(model_train_X, model_train_Y)</span><br><span class="line">    model_pred_Y = regr.predict(model_test_X)</span><br><span class="line">    regression_name = <span class="string">&#x27;Ridge Regression&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> model_pred_Y, regression_name</span><br><span class="line"></span><br><span class="line"><span class="comment"># # Lasso model</span></span><br><span class="line"><span class="comment"># def predict_model(model_train_X, model_train_Y):</span></span><br><span class="line"><span class="comment">#     regr = Lasso()</span></span><br><span class="line"><span class="comment">#     regr.fit(model_train_X, model_train_Y)</span></span><br><span class="line"><span class="comment">#     model_pred_Y = regr.predict(model_test_X)</span></span><br><span class="line"><span class="comment">#     regression_name = &#x27;Lasso Model&#x27;</span></span><br><span class="line"><span class="comment">#     return model_pred_Y, regression_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # PLS model</span></span><br><span class="line"><span class="comment"># def predict_model(model_train_X, model_train_Y):</span></span><br><span class="line"><span class="comment">#     regr = PLSRegression(n_components=1)</span></span><br><span class="line"><span class="comment">#     regr.fit(model_train_X, model_train_Y)</span></span><br><span class="line"><span class="comment">#     model_pred_Y = regr.predict(model_test_X)</span></span><br><span class="line"><span class="comment">#     regression_name = &#x27;PLS Regression&#x27;</span></span><br><span class="line"><span class="comment">#     return model_pred_Y, regression_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ================= MLP Regression =============================</span></span><br><span class="line"><span class="comment"># # MLP model</span></span><br><span class="line"><span class="comment"># def predict_model(model_train_X, model_train_Y):</span></span><br><span class="line"><span class="comment">#     regr = MLPRegressor(random_state = 1, max_iter = 500)</span></span><br><span class="line"><span class="comment">#     regr.fit(model_train_X, model_train_Y)</span></span><br><span class="line"><span class="comment">#     model_pred_Y = regr.predict(model_test_X)</span></span><br><span class="line"><span class="comment">#     regression_name = &#x27;MLP Regression&#x27;</span></span><br><span class="line"><span class="comment">#     return model_pred_Y, regression_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ================= Linear SVM regression =============================</span></span><br><span class="line"><span class="comment"># # SVC model</span></span><br><span class="line"><span class="comment"># def predict_model(model_train_X, model_train_Y):</span></span><br><span class="line"><span class="comment">#     regr = LinearSVR(random_state= 0, tol= 1e-5)</span></span><br><span class="line"><span class="comment">#     regr.fit(model_train_X, model_train_Y)</span></span><br><span class="line"><span class="comment">#     model_pred_Y = regr.predict(model_test_X)</span></span><br><span class="line"><span class="comment">#     regression_name = &#x27;Linear SVR Regression&#x27;</span></span><br><span class="line"><span class="comment">#     return model_pred_Y, regression_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ================= DecisionTree Regressor =============================</span></span><br><span class="line"><span class="comment"># # DecisionTree model</span></span><br><span class="line"><span class="comment"># def predict_model(model_train_X, model_train_Y):</span></span><br><span class="line"><span class="comment">#     regr = DecisionTreeRegressor(random_state=0)</span></span><br><span class="line"><span class="comment">#     regr.fit(model_train_X, model_train_Y)</span></span><br><span class="line"><span class="comment">#     model_pred_Y = regr.predict(model_test_X)</span></span><br><span class="line"><span class="comment">#     regression_name = &#x27;Decision-Tree Regression&#x27;</span></span><br><span class="line"><span class="comment">#     return model_pred_Y, regression_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Forecasting</span></span><br><span class="line">pred_result = [] <span class="comment"># to store prediction results</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">if</span> i &lt; <span class="number">3</span>:</span><br><span class="line">        model_train_X = train_X[:, :, i].reshape(-<span class="number">1</span>, input_size)</span><br><span class="line">        model_test_X = test_X[:, :, i].reshape(-<span class="number">1</span>, input_size)</span><br><span class="line">        model_train_Y = train_Y[:, i].reshape(-<span class="number">1</span>)</span><br><span class="line">        model_test_Y = test_Y[:, i].reshape(-<span class="number">1</span>)</span><br><span class="line">        model_pred_Y, regression = predict_model(model_train_X = model_train_X,</span><br><span class="line">                    model_train_Y = model_train_Y)</span><br><span class="line">        pred_result.append(model_pred_Y.tolist())</span><br><span class="line">    <span class="keyword">elif</span> i == <span class="number">3</span>:</span><br><span class="line">        <span class="comment"># Calculate the last energy consumption percent</span></span><br><span class="line">        np_pred_result = np.array(pred_result).T</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(np_pred_result.shape) == <span class="number">3</span>: <span class="comment"># Model output is 3-dimension</span></span><br><span class="line">            model_pred_Y = <span class="number">100</span> - np_pred_result.<span class="built_in">sum</span>(<span class="number">2</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>) <span class="comment"># PLS model</span></span><br><span class="line">            np_pred_result = np.concatenate((np_pred_result[<span class="number">0</span>], model_pred_Y), axis = <span class="number">1</span>) <span class="comment"># for PLS model</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">len</span>(np_pred_result.shape) == <span class="number">2</span>: <span class="comment"># Model output is 2-dimension</span></span><br><span class="line">            model_pred_Y = <span class="number">100</span> - np_pred_result.<span class="built_in">sum</span>(<span class="number">1</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>) <span class="comment"># Lasso model </span></span><br><span class="line">            np_pred_result = np.concatenate((np_pred_result, model_pred_Y), axis = <span class="number">1</span>) <span class="comment"># for Lasso model</span></span><br><span class="line">    Title = <span class="string">&#x27;Using &#123;&#125; to predict:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(regression, Columns[i])</span><br><span class="line">    <span class="keyword">if</span> plot_b == <span class="literal">True</span>:</span><br><span class="line">        plot_result(model_test_Y, model_pred_Y, Title) </span><br><span class="line">        </span><br><span class="line"><span class="comment"># Updata Error table</span></span><br><span class="line">error = calculate_error(test_Y, np_pred_result, regression)</span><br><span class="line">np_error = np.array(error).reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">columns = [<span class="string">&#x27;Transfer Matrix&#x27;</span>, <span class="string">&#x27;R2&#x27;</span>, <span class="string">&#x27;MAE&#x27;</span>, <span class="string">&#x27;MSE&#x27;</span>, <span class="string">&#x27;RMSE&#x27;</span>]</span><br><span class="line">pd_error = pd.DataFrame(np_error, columns = columns)</span><br><span class="line"></span><br><span class="line">error_excel =  pd.read_excel(<span class="string">&#x27;./Error result.xlsx&#x27;</span>, header = <span class="number">0</span>, sheet_name = <span class="number">0</span>, index_col= <span class="literal">None</span>)</span><br><span class="line">res = pd.concat([error_excel, pd_error], axis = <span class="number">0</span>, ignore_index = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Updata predict table</span></span><br><span class="line">model_col = []</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> Columns:</span><br><span class="line">    temp = <span class="string">&#x27;&#123;&#125;_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(c, regression.split(<span class="string">&#x27; &#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">    model_col.append(temp)</span><br><span class="line">pd_pred_result = pd.DataFrame(np_pred_result, columns = model_col, index = <span class="built_in">range</span>(<span class="number">2001</span>, <span class="number">2018</span>))</span><br><span class="line">pred_excel =  pd.read_excel(<span class="string">&#x27;./Predict results.xlsx&#x27;</span>, header = <span class="number">0</span>, sheet_name = <span class="number">0</span>, index_col= <span class="number">0</span>)</span><br><span class="line">pred_res = pd.concat([pred_excel, pd_pred_result], axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Store updated data</span></span><br><span class="line">res.to_excel(<span class="string">&#x27;./Error result.xlsx&#x27;</span>, encoding = <span class="string">&#x27;utf_8_sig&#x27;</span>, header = <span class="literal">True</span>, index = <span class="literal">False</span>)</span><br><span class="line">pred_res.to_excel(<span class="string">&#x27;./Predict results.xlsx&#x27;</span>, encoding = <span class="string">&#x27;utf_8_sig&#x27;</span>,  header = <span class="literal">True</span>, index = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h1 id="linear-nn-model">3 Linear NN model</h1>
]]></content>
      <categories>
        <category>Class Notes</category>
        <category>Energy economics</category>
      </categories>
      <tags>
        <tag>Prediction</tag>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Ensemble-Blending</title>
    <url>/2021/05/11/Ensemble-Blending/</url>
    <content><![CDATA[<h1 id="introduction">1. Introduction</h1>
<p>Blending 方法可以看是一个简化版的 Stacking 方法，blend 的中文意思是 “混合”，这就很好地诠释了 Blending 方法的思想 —— 不同模型的混合，也就是集成的本意。该方法仅在验证集中进行预测，如下为 Blending 的步骤：</p>
<a id="more"></a>
<ol type="1">
<li>将数据划分为 train set 和 test set，其中，train set 需要进一步被细分为 Training set 和 validation set (见 Fig. 1 (i)，图片来源：<a href="https://courses.analyticsvidhya.com/courses/take/ensemble-learning-and-ensemble-learning-techniques/texts/11126029-blending">Analytics vidhya</a>)；</li>
<li>构建多个模型 （第一层），并使用细分后的 Training set 作为输入数据来训练这些模型，并用训练好的模型来预测 validation set 和 test set，得到 val_pred 和 test_pred；</li>
<li>再次构建模型（第二层），并将 val_pred 视为训练集来训练该层的模型(见 Fig. 1 (ii)；</li>
<li>用训练好的模型来对测试集 (test_pred) 进行预测，得到预测结果 test prediction 记为整个 Blending 集成学习的预测结果。</li>
</ol>
<img src="https://z3.ax1x.com/2021/05/11/gUN4RU.png" />
<center>
Fig.1 Bleding procedutre
</center>
<h1 id="sample">2. Sample</h1>
<h2 id="steps">2.1 Steps</h2>
<p>为了对 Blending 有进一步的了解，参考 Analytics vidhya, 构建了一个两层的 Blending 模型，其中第一层由决策树和 KNN 组成，对这两个模型用 Training set 进行预测，并用训练好的模型预测 Valitation set 和 test set。之后构建一个逻辑回归利用上述两个预测结果进行预测训练。具体步骤如下：</p>
<ul>
<li><p>Import Module</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br></pre></td></tr></table></figure></li>
<li><p>Creating Datasets</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data, target = make_blobs(n_samples = <span class="number">10000</span>, centers = <span class="number">2</span>,</span><br><span class="line">                    random_state = <span class="number">1</span>, cluster_std = <span class="number">1.0</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Creatint test set and temporary train set, test_percent = 20%</span></span><br><span class="line">x_train1,x_test,y_train1,y_test = train_test_split(data,</span><br><span class="line">                  target, test_size = <span class="number">0.2</span>, random_state = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># Spliting temporary train set into train set and validation set, validation_percent = 80%*30%</span></span><br><span class="line">x_train,x_val,y_train,y_val = train_test_split(X_train1,</span><br><span class="line">                  y_train1, test_size = <span class="number">0.3</span>, random_state = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;The shape of training X:&quot;</span>, x_train.shape)</span><br><span class="line">print(<span class="string">&quot;The shape of training y:&quot;</span>, y_train.shape)</span><br><span class="line">print(<span class="string">&quot;The shape of test set:&quot;</span>, x_test.shape)</span><br><span class="line">print(<span class="string">&quot;The shape of test y:&quot;</span>, y_test.shape)</span><br><span class="line">print(<span class="string">&quot;The shape of validation X:&quot;</span>, x_val.shape)</span><br><span class="line">print(<span class="string">&quot;The shape of validation y:&quot;</span>, y_val.shape)</span><br></pre></td></tr></table></figure>
<p>Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">The shape of training X: (<span class="number">5600</span>, <span class="number">2</span>)</span><br><span class="line">The shape of training y: (<span class="number">5600</span>,)</span><br><span class="line">The shape of test <span class="built_in">set</span>: (<span class="number">2000</span>, <span class="number">2</span>)</span><br><span class="line">The shape of test y: (<span class="number">2000</span>,)</span><br><span class="line">The shape of validation X: (<span class="number">2400</span>, <span class="number">2</span>)</span><br><span class="line">The shape of validation y: (<span class="number">2400</span>,)</span><br></pre></td></tr></table></figure></p></li>
<li><p>First Layer</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model1 = tree.DecisionTreeClassifier()</span><br><span class="line">model1.fit(x_train, y_train)</span><br><span class="line">val_pred1=model1.predict(x_val)</span><br><span class="line">test_pred1=model1.predict(x_test)</span><br><span class="line"></span><br><span class="line">val_pred1=pd.DataFrame(val_pred1)</span><br><span class="line">test_pred1=pd.DataFrame(test_pred1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model2 = KNeighborsClassifier()</span><br><span class="line">model2.fit(x_train,y_train)</span><br><span class="line">val_pred2=model2.predict(x_val)</span><br><span class="line">test_pred2=model2.predict(x_test)</span><br><span class="line"></span><br><span class="line">val_pred2=pd.DataFrame(val_pred2)</span><br><span class="line">test_pred2=pd.DataFrame(test_pred2)</span><br></pre></td></tr></table></figure></li>
<li><p>Second Layer</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_val=pd.concat([pd.DataFrame(x_val), val_pred1, val_pred2],axis=<span class="number">1</span>)</span><br><span class="line">df_test=pd.concat([pd.DataFrame(x_test),test_pred1,test_pred2],axis=<span class="number">1</span>)</span><br><span class="line">model = LogisticRegression()</span><br><span class="line">model.fit(df_val,y_val)</span><br></pre></td></tr></table></figure></li>
<li><p>Forecasting Results</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.score(df_test,y_test)</span><br><span class="line">cross_val_score(model,df_test,y_test,cv=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1.0</span></span><br><span class="line">array([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="complete-codes">2.2 Complete codes</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Inporting modules</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># Creating datasets</span></span><br><span class="line">data, target = make_blobs(n_samples = <span class="number">10000</span>, centers = <span class="number">2</span>,</span><br><span class="line">                    random_state = <span class="number">1</span>, cluster_std = <span class="number">1.0</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Creatint test set and temporary train set, test_percent = 20%</span></span><br><span class="line">x_train1,x_test,y_train1,y_test = train_test_split(data,</span><br><span class="line">                  target, test_size = <span class="number">0.2</span>, random_state = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># Spliting temporary train set into train set and validation set, validation_percent = 80%*30%</span></span><br><span class="line">x_train,x_val,y_train,y_val = train_test_split(X_train1,</span><br><span class="line">                  y_train1, test_size = <span class="number">0.3</span>, random_state = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Constructing model</span></span><br><span class="line"><span class="comment">## First layer</span></span><br><span class="line">model1 = tree.DecisionTreeClassifier()</span><br><span class="line">model1.fit(x_train, y_train)</span><br><span class="line">val_pred1=model1.predict(x_val)</span><br><span class="line">test_pred1=model1.predict(x_test)</span><br><span class="line"></span><br><span class="line">val_pred1=pd.DataFrame(val_pred1)</span><br><span class="line">test_pred1=pd.DataFrame(test_pred1)</span><br><span class="line"></span><br><span class="line">model2 = KNeighborsClassifier()</span><br><span class="line">model2.fit(x_train,y_train)</span><br><span class="line">val_pred2=model2.predict(x_val)</span><br><span class="line">test_pred2=model2.predict(x_test)</span><br><span class="line"></span><br><span class="line">val_pred2=pd.DataFrame(val_pred2)</span><br><span class="line">test_pred2=pd.DataFrame(test_pred2)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Second layer</span></span><br><span class="line">df_val=pd.concat([pd.DataFrame(x_val), val_pred1, val_pred2],axis=<span class="number">1</span>)</span><br><span class="line">df_test=pd.concat([pd.DataFrame(x_test),test_pred1,test_pred2],axis=<span class="number">1</span>)</span><br><span class="line">model = LogisticRegression()</span><br><span class="line">model.fit(df_val,y_val)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print forecasting results</span></span><br><span class="line">model.score(df_test,y_test)</span><br><span class="line">cross_val_score(model,df_test,y_test,cv=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>DataWhale</category>
        <category>Ensemble</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Ensemble</tag>
        <tag>Sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title>Ensemble-happiness</title>
    <url>/2021/05/18/Ensemble-Happiness/</url>
    <content><![CDATA[<h1 id="problem">1. Problem</h1>
<h2 id="introduction-of-background">1.1 Introduction of background</h2>
<p>幸福感是一个古老而深刻的话题，是人类世代追求的方向。与幸福感相关的因素成千上万，这些错综复杂的因素中，我们能找到其中的共性，一窥幸福感的要义吗？</p>
<a id="more"></a>
<p>该案例为幸福感预测这一经典课题，希望在现有社会科学研究外有其他维度的算法尝试，结合多学科各自优势，挖掘潜在的影响因素，发现更多可解释、可理解的相关关系。</p>
<p>具体来说，该案例就是一个数据挖掘类型的比赛——幸福感预测的baseline。具体来说，我们需要使用包括个体变量（性别、年龄、地域、职业、健康、婚姻与政治面貌等等）、家庭变量（父母、配偶、子女、家庭资本等等）、社会态度（公平、信用、公共服务等等）等139维度的信息来预测其对幸福感的影响。</p>
<p>数据来源于国家官方的《中国综合社会调查（CGSS）》文件中的调查结果中的数据，数据来源可靠可依赖。</p>
<p>数据包下载地址: <a href="https://yangsuoly.com/file/Data-of-forcasting-happiness.rar">Data of case</a>。</p>
<h2 id="data-information">1.2 Data information</h2>
<p>要求使用以上 139 维的特征，使用 8000 余组数据进行对于个人幸福感的预测（预测值为1，2，3，4，5，其中1代表幸福感最低，5代 表幸福感最高）。 因为考虑到变量个数较多，部分变量间关系复杂，数据分为完整版和精简版两类。同时给出了 <code>index</code> 文件中包含每个变量对应的问卷题目，以及变量取值的含义；<code>survey</code> 文件中为原版问卷，作为补充以方便理解问题背景。</p>
<h1 id="data-process">2. Data process</h1>
<h2 id="load-data">2.1 Load data</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">train = pd.read_csv(<span class="string">&quot;train.csv&quot;</span>, parse_dates=[<span class="string">&#x27;survey_time&#x27;</span>],encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">&quot;test.csv&quot;</span>, parse_dates=[<span class="string">&#x27;survey_time&#x27;</span>],encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line"><span class="comment">#latin-1向下兼容ASCII</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>Deleting the rows that happiness values equal to -8</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Deleting the rows that happiness values equal to -8</span></span><br><span class="line">target_name = <span class="string">&#x27;happiness&#x27;</span></span><br><span class="line">train_copy = train.copy()</span><br></pre></td></tr></table></figure></li>
<li><p>Train and target set</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train = train[train[target_name] != -<span class="number">8</span>].reset_index(drop = <span class="literal">True</span>)</span><br><span class="line">target = train_copy[target_name] <span class="comment"># Target</span></span><br></pre></td></tr></table></figure></li>
<li><p>Concatenation</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">del</span> train_copy[target_name] <span class="comment"># Drop the target column</span></span><br><span class="line"><span class="comment"># Store the train set(without happiness values)</span></span><br><span class="line"></span><br><span class="line">data = pd.concat([train_copy, test], axis = <span class="number">0</span>, ignore_index = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="information">2.2 Information</h2>
<ul>
<li><p><code>describe</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train.happiness.describe()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>count    7988.000000
mean        3.867927
std         0.818717
min         1.000000
25%         4.000000
50%         4.000000
75%         4.000000
max         5.000000
Name: happiness, dtype: float64</code></pre></li>
<li><p><code>info</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train.info()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 8000 entries, 0 to 7999
Columns: 140 entries, id to public_service_9
dtypes: datetime64[ns](1), float64(25), int64(111), object(3)
memory usage: 8.5+ MB</code></pre></li>
</ul>
<h2 id="data-preparation">2.3 Data preparation</h2>
<h3 id="missing-values">2.3.1 Missing values</h3>
<ul>
<li><p>Number of columns having missing values</p>
<p>通过如下代码了解数据中的缺省值信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_nomiss = data.dropna(axis=<span class="number">1</span>, inplace = <span class="literal">False</span>) <span class="comment"># 没有缺失值的数据信息</span></span><br><span class="line"></span><br><span class="line">name_data = data.columns</span><br><span class="line">name_miss = name_data.drop(data_nomiss.columns) <span class="comment"># 含有缺失值的列名称</span></span><br><span class="line"></span><br><span class="line">data_miss = data.loc[:, name_miss] <span class="comment"># 存储含有缺失值的数据，方便查看数据</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>data_miss.shape</span><br><span class="line"></span><br><span class="line">(<span class="number">10968</span>, <span class="number">25</span>)</span><br></pre></td></tr></table></figure>
<p>可以发现，数据集中 25 列中含有缺失值，具体的列名称如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>miss_name</span><br><span class="line"></span><br><span class="line">Index([<span class="string">&#x27;edu_other&#x27;</span>, <span class="string">&#x27;edu_status&#x27;</span>, <span class="string">&#x27;edu_yr&#x27;</span>, <span class="string">&#x27;join_party&#x27;</span>, <span class="string">&#x27;property_other&#x27;</span>, <span class="string">&#x27;hukou_loc&#x27;</span>, <span class="string">&#x27;social_neighbor&#x27;</span>, <span class="string">&#x27;social_friend&#x27;</span>, <span class="string">&#x27;work_status&#x27;</span>, <span class="string">&#x27;work_yr&#x27;</span>, <span class="string">&#x27;work_type&#x27;</span>, <span class="string">&#x27;work_manage&#x27;</span>, <span class="string">&#x27;family_income&#x27;</span>, <span class="string">&#x27;invest_other&#x27;</span>, <span class="string">&#x27;minor_child&#x27;</span>, <span class="string">&#x27;marital_1st&#x27;</span>, <span class="string">&#x27;s_birth&#x27;</span>, <span class="string">&#x27;marital_now&#x27;</span>, <span class="string">&#x27;s_edu&#x27;</span>, <span class="string">&#x27;s_political&#x27;</span>, <span class="string">&#x27;s_hukou&#x27;</span>, <span class="string">&#x27;s_income&#x27;</span>, <span class="string">&#x27;s_work_exper&#x27;</span>, <span class="string">&#x27;s_work_status&#x27;</span>, <span class="string">&#x27;s_work_type&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>Processing</p>
<p>进一步查看缺失数据的信息：</p>
<pre><code>&gt;&gt;&gt; data_miss.info()

&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 10968 entries, 0 to 10967
Data columns (total 25 columns):
 #   Column           Non-Null Count  Dtype  
---  ------           --------------  -----  
 0   edu_other        6 non-null      object
 1   edu_status       9399 non-null   float64
 2   edu_yr           8212 non-null   float64
 3   join_party       1126 non-null   float64
 4   property_other   89 non-null     object
 5   hukou_loc        10964 non-null  float64
 6   social_neighbor  9871 non-null   float64
 7   social_friend    9871 non-null   float64
 8   work_status      4029 non-null   float64
 9   work_yr          4029 non-null   float64
 10  work_type        4030 non-null   float64
 11  work_manage      4030 non-null   float64
 12  family_income    10967 non-null  float64
 13  invest_other     45 non-null     object
 14  minor_child      9520 non-null   float64
 15  marital_1st      9839 non-null   float64
 16  s_birth          8601 non-null   float64
 17  marital_now      8521 non-null   float64
 18  s_edu            8601 non-null   float64
 19  s_political      8601 non-null   float64
 20  s_hukou          8601 non-null   float64
 21  s_income         8601 non-null   float64
 22  s_work_exper     8601 non-null   float64
 23  s_work_status    3524 non-null   float64
 24  s_work_type      3524 non-null   float64
dtypes: float64(22), object(3)
memory usage: 2.1+ MB</code></pre>
<p>可以发现，<code>edu_other</code>, <code>join_party</code>, <code>property_other</code>, <code>invest_other</code>, 四列含有缺失值较多，占到了样本总体的90%以上，综合考虑后，选择将这四个变量从分析中剔除。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">name_del = [<span class="string">&#x27;edu_other&#x27;</span>, <span class="string">&#x27;join_party&#x27;</span>, <span class="string">&#x27;property_other&#x27;</span>, <span class="string">&#x27;invest_other&#x27;</span>]</span><br><span class="line">name_data = name_data.drop(name_del)</span><br><span class="line">name_miss = name_miss.drop(name_del) <span class="comment"># 剔除上述四个变量</span></span><br><span class="line"></span><br><span class="line">data_miss = data_miss.loc[:, name_miss]</span><br><span class="line">data = data.copy().loc[:, name_miss]</span><br></pre></td></tr></table></figure></li>
<li><p>Information</p>
<p>查看每列缺失值的数量：</p>
<pre><code>&gt;&gt;&gt; data_miss.isnull().sum()

edu_status         0
edu_yr             0
hukou_loc          0
social_neighbor    0
social_friend      0
work_status        0
work_yr            0
work_type          0
work_manage        0
family_income      0
minor_child        0
marital_1st        0
s_birth            0
marital_now        0
s_edu              0
s_political        0
s_hukou            0
s_income           0
s_work_exper       0
s_work_status      0
s_work_type        0
dtype: int64</code></pre></li>
<li><p>Fillna</p>
<p>可以发现，部分列缺失值比较多，部分缺失值较少，为此，我们对缺失值做如下处理：</p>
<ul>
<li>缺失值数量少于总数的 20% (即 2193.6)的列，用该列的众数进行填充；</li>
<li>缺失值数量大于2193的列，用0进行填充，防止过分干预数据而导致失真。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(name_miss)):</span><br><span class="line">    num_nulls = data_miss.isnull().<span class="built_in">sum</span>() <span class="comment"># 对缺失值进行计数</span></span><br><span class="line">    num_null = num_nulls[i] <span class="comment"># 当前列的缺失值数</span></span><br><span class="line">    name = name_miss[i] <span class="comment"># 当前列的名称</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> num_null &lt; <span class="number">0.2</span>*data.shape[<span class="number">0</span>]:</span><br><span class="line">        data.loc[:, name].fillna(data_miss.mode().loc[<span class="number">0</span>, name], inplace = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        data.loc[:, name].fillna(<span class="number">0</span>, inplace = <span class="literal">True</span>)                    </span><br><span class="line">data_miss = data.loc[:, name_miss]</span><br></pre></td></tr></table></figure></li>
</ul>
<p>至此，缺失值处理完成。</p>
<h3 id="negative-values">2.3.2 Negative values</h3>
<p>对数据中的连续出现的负的数值进行处理。由于数据中的负值只有 -1, -2, -3, -8，故进行如下处理：</p>
<ul>
<li><p>Self definition function</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># make feature +5</span></span><br><span class="line"><span class="comment">#csv中有复数值：-1、-2、-3、-8，将他们视为有问题的特征，但是不删去</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getres1</span>(<span class="params">row</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>([x <span class="keyword">for</span> x <span class="keyword">in</span> row.values <span class="keyword">if</span> <span class="built_in">type</span>(x)==<span class="built_in">int</span> <span class="keyword">and</span> x&lt;<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getres2</span>(<span class="params">row</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>([x <span class="keyword">for</span> x <span class="keyword">in</span> row.values <span class="keyword">if</span> <span class="built_in">type</span>(x)==<span class="built_in">int</span> <span class="keyword">and</span> x==-<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getres3</span>(<span class="params">row</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>([x <span class="keyword">for</span> x <span class="keyword">in</span> row.values <span class="keyword">if</span> <span class="built_in">type</span>(x)==<span class="built_in">int</span> <span class="keyword">and</span> x==-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getres4</span>(<span class="params">row</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>([x <span class="keyword">for</span> x <span class="keyword">in</span> row.values <span class="keyword">if</span> <span class="built_in">type</span>(x)==<span class="built_in">int</span> <span class="keyword">and</span> x==-<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getres5</span>(<span class="params">row</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>([x <span class="keyword">for</span> x <span class="keyword">in</span> row.values <span class="keyword">if</span> <span class="built_in">type</span>(x)==<span class="built_in">int</span> <span class="keyword">and</span> x==-<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#检查数据</span></span><br><span class="line">data[<span class="string">&#x27;neg1&#x27;</span>] = data[data.columns].apply(<span class="keyword">lambda</span> row:getres1(row),axis=<span class="number">1</span>)</span><br><span class="line">data.loc[data[<span class="string">&#x27;neg1&#x27;</span>]&gt;<span class="number">20</span>,<span class="string">&#x27;neg1&#x27;</span>] = <span class="number">20</span> <span class="comment">#平滑处理,最多出现20次</span></span><br><span class="line">data[<span class="string">&#x27;neg2&#x27;</span>] = data[data.columns].apply(<span class="keyword">lambda</span> row:getres2(row),axis=<span class="number">1</span>)</span><br><span class="line">data[<span class="string">&#x27;neg3&#x27;</span>] = data[data.columns].apply(<span class="keyword">lambda</span> row:getres3(row),axis=<span class="number">1</span>)</span><br><span class="line">data[<span class="string">&#x27;neg4&#x27;</span>] = data[data.columns].apply(<span class="keyword">lambda</span> row:getres4(row),axis=<span class="number">1</span>)</span><br><span class="line">data[<span class="string">&#x27;neg5&#x27;</span>] = data[data.columns].apply(<span class="keyword">lambda</span> row:getres5(row),axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>Process</p>
<p>记录下含有负值的列名称，然后对比 index.csv 中的信息对这些负值进行填充性处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先将问卷时间变为年份</span></span><br><span class="line">data[<span class="string">&#x27;survey_time&#x27;</span>] = pd.to_datetime(data[<span class="string">&#x27;survey_time&#x27;</span>], <span class="built_in">format</span> = <span class="string">&#x27;%Y-%m-%d&#x27;</span>,</span><br><span class="line">                                errors = <span class="string">&#x27;coerce&#x27;</span>) <span class="comment"># 强制转换</span></span><br><span class="line">data[<span class="string">&#x27;survey_time&#x27;</span>] = data[<span class="string">&#x27;survey_time&#x27;</span>].dt.year <span class="comment"># 截取年份，用于计算年龄</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看所有含有负值的列</span></span><br><span class="line">neg_name = data.<span class="built_in">min</span>()[data.<span class="built_in">min</span>()&lt;<span class="number">0</span>].index <span class="comment"># 存储 data 中最小的值小于 0 的列名称</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 借助 index.csv 查看缺失值的信息</span></span><br><span class="line">data_index = pd.read_csv(<span class="string">&quot;index.csv&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">data_index.set_index(<span class="string">&#x27;变量名&#x27;</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">data_index_column = data_index.columns</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;There are &#123;&#125; columns have negative values&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(neg_name)))</span><br></pre></td></tr></table></figure>
<pre><code>There are 100 columns have negative values</code></pre>
<p>可以到整个数据表中有 <code>100</code> 列中含有负值。</p></li>
<li><p>查看字段详细信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_index.loc[neg_name, data_index_column[<span class="number">1</span>:<span class="number">3</span>]].head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>问题</p>
</th>
<th>
<p>取值含义</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>nationality</p>
</th>
<td>
<p>您的民族</p>
</td>
<td>
<p>1 = 汉; 2 = 蒙; 3 = 满; 4 = 回; 5 = 藏; 6 = 壮; 7 = ...</p>
</td>
</tr>
<tr>
<th>
<p>religion</p>
</th>
<td>
<p>您的宗教信仰-不信仰宗教</p>
</td>
<td>
<p>0 = 否; 1 = 是;</p>
</td>
</tr>
<tr>
<th>
<p>religion_freq</p>
</th>
<td>
<p>您参加宗教活动的频繁程度</p>
</td>
<td>
<p>1 = 从来没有参加过; 2 = 一年不到1次; 3 = 一年大概1到2次; 4 = 一年几...</p>
</td>
</tr>
<tr>
<th>
<p>edu</p>
</th>
<td>
<p>您目前的最高教育程度（包括目前在读的）</p>
</td>
<td>
<p>1 = 没有受过任何教育; 2 = 私塾、扫盲班; 3 = 小学; 4 = 初中; 5 = ...</p>
</td>
</tr>
<tr>
<th>
<p>edu_status</p>
</th>
<td>
<p>您目前的最高教育程度的状态</p>
</td>
<td>
<p>1 = 正在读; 2 = 辍学和中途退学; 3 = 肄业; 4 = 毕业;</p>
</td>
</tr>
</tbody>
</table></li>
<li><p>填充</p>
<p>根据实际情况，对数据进行填充处理，填充分为如下几种方式：</p>
<ul>
<li>根据生活常识进行填充</li>
<li>根据非负数中的众数进行填充</li>
<li>根据非负数中的均值进行填充</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> neg_name:</span><br><span class="line">    <span class="keyword">if</span>(data[col].loc[data[col]&lt;<span class="number">0</span>].count()&gt;<span class="number">1000</span>):</span><br><span class="line">        print(col, data[col].loc[data[col]&lt;<span class="number">0</span>].count(), sep = <span class="string">&#x27; | &#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>edu_yr | 1679
marital_1st | 1901
f_birth | 4664
m_birth | 4448
inc_ability | 1325
inc_exp | 1501
trust_3 | 1399
trust_4 | 1413
trust_6 | 1562
trust_8 | 1381
trust_10 | 2451
trust_11 | 5456
trust_12 | 3382</code></pre>
<p>通过上述预处理，可以发现，仅有 5列数据中的负值多余2000</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ===================== 生活常识 ========================</span></span><br><span class="line"><span class="comment"># 民族</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;nationality&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;nationality&#x27;</span>] = <span class="number">1</span> <span class="comment"># 1为汉族</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 宗教</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;religion&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;religion&#x27;</span>] = <span class="number">1</span> <span class="comment"># 1为不信仰宗教</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;religion_freq&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;religion_freq&#x27;</span>] = <span class="number">1</span> <span class="comment"># 1为从来没参加过宗教活动</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================= 众数 ============================</span></span><br><span class="line"><span class="comment"># 教育</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;edu&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;edu&#x27;</span>] = data[<span class="string">&#x27;edu&#x27;</span>].mode()[<span class="number">0</span>]  <span class="comment"># 众数为 4，初中</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;edu_status&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;edu_status&#x27;</span>] = data[<span class="string">&#x27;edu_status&#x27;</span>].mode()[<span class="number">0</span>] <span class="comment"># 众数为 4，毕业</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;edu_yr&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;edu_yr&#x27;</span>] = <span class="number">0</span> <span class="comment"># 毕业年份</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 政治面貌</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;political&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;political&#x27;</span>] = data[<span class="string">&#x27;political&#x27;</span>].mode()[<span class="number">0</span>] <span class="comment"># 众数为 1，群众</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 健康</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;health&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;health&#x27;</span>] = data[<span class="string">&#x27;health&#x27;</span>].mode()[<span class="number">0</span>] <span class="comment"># 众数为 4，比较健康</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;health_problem&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;health_problem&#x27;</span>] = data[<span class="string">&#x27;health_problem&#x27;</span>].mode()[<span class="number">0</span>] <span class="comment"># 众数为 4，比较健康</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 沮丧</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;depression&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;depression&#x27;</span>] = data[<span class="string">&#x27;depression&#x27;</span>].mode()[<span class="number">0</span>] <span class="comment"># 众数为 4，很少</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 媒体：报纸、杂志、广播、电视、互联网、手机定值消息</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    col = <span class="string">&#x27;media_&#x27;</span> + <span class="built_in">str</span>(i+<span class="number">1</span>)</span><br><span class="line">    data.loc[data[col]&lt;<span class="number">0</span>,col] = data[col].mode()[<span class="number">0</span>] <span class="comment"># 以众数填充</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">data.loc[data[&#x27;media_1&#x27;]&lt;0,&#x27;media_1&#x27;] = data[&#x27;media_1&#x27;].mode().values # 众数为1，从不</span></span><br><span class="line"><span class="string">data.loc[data[&#x27;media_2&#x27;]&lt;0,&#x27;media_2&#x27;] = data[&#x27;media_2&#x27;].mode().values # 众数为1，从不</span></span><br><span class="line"><span class="string">data.loc[data[&#x27;media_3&#x27;]&lt;0,&#x27;media_3&#x27;] = data[&#x27;media_3&#x27;].mode().values # 众数为1，从不</span></span><br><span class="line"><span class="string">data.loc[data[&#x27;media_4&#x27;]&lt;0,&#x27;media_4&#x27;] = data[&#x27;media_4&#x27;].mode().values # 众数为4，经常</span></span><br><span class="line"><span class="string">data.loc[data[&#x27;media_5&#x27;]&lt;0,&#x27;media_5&#x27;] = data[&#x27;media_5&#x27;].mode().values # 众数为1，从不</span></span><br><span class="line"><span class="string">data.loc[data[&#x27;media_6&#x27;]&lt;0,&#x27;media_6&#x27;] = data[&#x27;media_6&#x27;].mode().values # 众数为1，经常</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 空闲：看碟、看电影、逛街购物、读书、文化活动等共12项</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>):</span><br><span class="line">    col = <span class="string">&#x27;leisure_&#x27;</span> + <span class="built_in">str</span>(i+<span class="number">1</span>)</span><br><span class="line">    data.loc[data[col]&lt;<span class="number">0</span>,col] = data[col].mode()[<span class="number">0</span>] <span class="comment"># 以众数填充</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">socialize、relax、learn、social_neighbor、learn、social_neighbor、</span></span><br><span class="line"><span class="string">social_friend、socia_outing、equity、class、class_10_before、</span></span><br><span class="line"><span class="string">class_10_after、class_14、work_status、work_yr、work_type、work_manage、</span></span><br><span class="line"><span class="string">insur_1、insur_2、insur_3、insur_4</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">29</span>, <span class="number">48</span>):</span><br><span class="line">    col = neg_name[i]</span><br><span class="line">    data.loc[data[col]&lt;<span class="number">0</span>,col] = data[col].mode()[<span class="number">0</span>] <span class="comment"># 以众数填充</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;socialize&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;socialize&#x27;</span>] = data[<span class="string">&#x27;socialize&#x27;</span>].mode()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 收入状态</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">49</span>, <span class="number">56</span>):</span><br><span class="line">    col = neg_name[i]</span><br><span class="line">    data.loc[data[col]&lt;<span class="number">0</span>,col] = data[col].mode()[<span class="number">0</span>] <span class="comment"># 以众数填充</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;socialize&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;socialize&#x27;</span>] = data[<span class="string">&#x27;socialize&#x27;</span>].mode()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">58</span>, <span class="number">64</span>):</span><br><span class="line">    col = neg_name[i]</span><br><span class="line">    data.loc[data[col]&lt;<span class="number">0</span>,col] = data[col].mode()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 信任</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">77</span>, <span class="number">100</span>):</span><br><span class="line">    col = neg_name[i]</span><br><span class="line">    <span class="comment"># 考虑到 trust 中包含较多负数，故考虑在大于零的数中取众数</span></span><br><span class="line">    data.loc[data[col]&lt;<span class="number">0</span>,col] = data[name].loc[data[name]&gt;<span class="number">0</span>].mode()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ========================= 均值 ==========================</span></span><br><span class="line"><span class="comment"># 收入</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;income&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;income&#x27;</span>] = data[<span class="string">&#x27;income&#x27;</span>].mean() <span class="comment"># 取均值填充收入</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 家庭收入：49列</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;family_income&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;family_income&#x27;</span>] = data[<span class="string">&#x27;family_income&#x27;</span>].mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预期收入：76</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;inc_exp&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;inc_exp&#x27;</span>] = data[<span class="string">&#x27;inc_exp&#x27;</span>].mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 0 填充 ===========================</span></span><br><span class="line"><span class="comment"># 婚姻：56-57</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;marital_1st&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;marital_1st&#x27;</span>] = <span class="number">0</span> <span class="comment"># 首次结婚</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;marital_now&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;marital_now&#x27;</span>] = <span class="number">0</span> <span class="comment"># 现在</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 父亲：64</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;f_birth&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;f_birth&#x27;</span>] = <span class="number">0</span> <span class="comment"># 出生年份</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">65</span>, <span class="number">68</span>):</span><br><span class="line">    col = neg_name[i]</span><br><span class="line">    data.loc[data[col]&lt;<span class="number">0</span>,col] = data[col].mode()[<span class="number">0</span>]<span class="comment"># 众数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 母亲：68</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;m_birth&#x27;</span>]&lt;<span class="number">0</span>,<span class="string">&#x27;m_birth&#x27;</span>] = <span class="number">0</span> <span class="comment"># 出生年份</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">69</span>, <span class="number">76</span>):</span><br><span class="line">    col = neg_name[i]</span><br><span class="line">    data.loc[data[col]&lt;<span class="number">0</span>,col] = data[col].mode()[<span class="number">0</span>] <span class="comment"># 众数</span></span><br></pre></td></tr></table></figure></li>
<li><p>确认负值处理完成</p>
<p>对所有的列进行查看，确认是否所有的列中的负值都已处理完成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">neg_count = <span class="built_in">len</span>(data.<span class="built_in">min</span>()[data.<span class="built_in">min</span>()&lt;<span class="number">0</span>].index) <span class="comment"># 记录负值列的个数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> neg_count != <span class="number">0</span>:</span><br><span class="line">    print(<span class="string">&#x27;&#123;&#125; columns still have Negative values!&#x27;</span>.<span class="built_in">format</span>(neg_count))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">&#x27;Congratulations! No columns have negative values!&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Congratulations! No columns have negative values!</code></pre></li>
</ul>
<p>可以发现所有的负值都已处理完成。</p>
<h3 id="special-infromation-process">Special infromation process</h3>
<ul>
<li><p>Age strafitication</p>
<p>考虑到年龄对于收入水平、教育水平等都有重要的影响，因此，根据表格信息<code>survey_time</code> 和 <code>birth</code> 两列的信息计算年龄，并对年龄进行分段。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Calculate age</span></span><br><span class="line">data[<span class="string">&#x27;age&#x27;</span>] = data[<span class="string">&#x27;survey_time&#x27;</span>] - data[<span class="string">&#x27;birth&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Age strafitication</span></span><br><span class="line">bins = [<span class="number">0</span>, <span class="number">17</span>, <span class="number">26</span>, <span class="number">34</span>, <span class="number">50</span>, <span class="number">63</span>, <span class="number">100</span>]</span><br><span class="line">data[<span class="string">&#x27;age_bin&#x27;</span>] = pd.cut(data[<span class="string">&#x27;age&#x27;</span>], bins, labels = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]) <span class="comment"># 分层</span></span><br></pre></td></tr></table></figure></li>
<li><p>Data augmentation</p>
<p>为了挖掘更多信息，我们需要进一步分析每个特征之间的关系，进行数据增广。经过仔细分析，加入了如下特征：</p>
<ul>
<li>第一次结婚年龄</li>
<li>最近结婚年龄</li>
<li>是否再婚</li>
<li>配偶年龄</li>
<li>配偶年龄差</li>
<li>各种收入比（与配偶之间的收入比、十年后预期收入与现在的收入比等）</li>
<li>收入与住房买诺记比（包括10年后期望收入等）</li>
<li>社会阶级（10年后的社会阶级、14年后的社会阶级等）</li>
<li>悠闲指数</li>
<li>满意指数</li>
<li>信任指数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第一次结婚年龄 143</span></span><br><span class="line">new_col = <span class="string">&#x27;marital_1stbir&#x27;</span></span><br><span class="line">data[new_col] = data[<span class="string">&#x27;marital_1st&#x27;</span>] - data[<span class="string">&#x27;birth&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最近结婚年龄 144</span></span><br><span class="line">new_col = <span class="string">&#x27;marital_nowtbir&#x27;</span></span><br><span class="line">data[new_col] = data[<span class="string">&#x27;marital_now&#x27;</span>] - data[<span class="string">&#x27;birth&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否再婚 145</span></span><br><span class="line">new_col = <span class="string">&#x27;mar&#x27;</span></span><br><span class="line">data[new_col] = data[<span class="string">&#x27;marital_nowtbir&#x27;</span>] - data[<span class="string">&#x27;marital_1stbir&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配偶年龄 146</span></span><br><span class="line">new_col = <span class="string">&#x27;marital_sbir&#x27;</span></span><br><span class="line">data[new_col] = data[<span class="string">&#x27;marital_now&#x27;</span>]-data[<span class="string">&#x27;s_birth&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配偶年龄差 147</span></span><br><span class="line">new_col = <span class="string">&#x27;age__&#x27;</span></span><br><span class="line">data[new_col] = data[<span class="string">&#x27;marital_nowtbir&#x27;</span>] - data[<span class="string">&#x27;marital_sbir&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 收入比 147+7 = 154</span></span><br><span class="line">data[<span class="string">&#x27;income/s_income&#x27;</span>] = data[<span class="string">&#x27;income&#x27;</span>]/(data[<span class="string">&#x27;s_income&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">data[<span class="string">&#x27;income+s_income&#x27;</span>] = data[<span class="string">&#x27;income&#x27;</span>]+(data[<span class="string">&#x27;s_income&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">data[<span class="string">&#x27;income/family_income&#x27;</span>] = data[<span class="string">&#x27;income&#x27;</span>]/(data[<span class="string">&#x27;family_income&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">data[<span class="string">&#x27;all_income/family_income&#x27;</span>] = (data[<span class="string">&#x27;income&#x27;</span>]+data[<span class="string">&#x27;s_income&#x27;</span>])/(data[<span class="string">&#x27;family_income&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">data[<span class="string">&#x27;income/inc_exp&#x27;</span>] = data[<span class="string">&#x27;income&#x27;</span>]/(data[<span class="string">&#x27;inc_exp&#x27;</span>]+<span class="number">1</span>)</span><br><span class="line">data[<span class="string">&#x27;family_income/m&#x27;</span>] = data[<span class="string">&#x27;family_income&#x27;</span>]/(data[<span class="string">&#x27;family_m&#x27;</span>]+<span class="number">0.01</span>)</span><br><span class="line">data[<span class="string">&#x27;income/m&#x27;</span>] = data[<span class="string">&#x27;income&#x27;</span>]/(data[<span class="string">&#x27;family_m&#x27;</span>]+<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 收入/面积比 154+4=158</span></span><br><span class="line">data[<span class="string">&#x27;income/floor_area&#x27;</span>] = data[<span class="string">&#x27;income&#x27;</span>]/(data[<span class="string">&#x27;floor_area&#x27;</span>]+<span class="number">0.01</span>)</span><br><span class="line">data[<span class="string">&#x27;all_income/floor_area&#x27;</span>] = (data[<span class="string">&#x27;income&#x27;</span>]+data[<span class="string">&#x27;s_income&#x27;</span>])/(data[<span class="string">&#x27;floor_area&#x27;</span>]+<span class="number">0.01</span>)</span><br><span class="line">data[<span class="string">&#x27;family_income/floor_area&#x27;</span>] = data[<span class="string">&#x27;family_income&#x27;</span>]/(data[<span class="string">&#x27;floor_area&#x27;</span>]+<span class="number">0.01</span>)</span><br><span class="line">data[<span class="string">&#x27;floor_area/m&#x27;</span>] = data[<span class="string">&#x27;floor_area&#x27;</span>]/(data[<span class="string">&#x27;family_m&#x27;</span>]+<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># class 158+3=161</span></span><br><span class="line">data[<span class="string">&#x27;class_10_diff&#x27;</span>] = (data[<span class="string">&#x27;class_10_after&#x27;</span>] - data[<span class="string">&#x27;class&#x27;</span>])</span><br><span class="line">data[<span class="string">&#x27;class_diff&#x27;</span>] = data[<span class="string">&#x27;class&#x27;</span>] - data[<span class="string">&#x27;class_10_before&#x27;</span>]</span><br><span class="line">data[<span class="string">&#x27;class_14_diff&#x27;</span>] = data[<span class="string">&#x27;class&#x27;</span>] - data[<span class="string">&#x27;class_14&#x27;</span>]</span><br><span class="line"><span class="comment"># 悠闲指数 162</span></span><br><span class="line">leisure_fea_lis = [<span class="string">&#x27;leisure_&#x27;</span>+<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">13</span>)]</span><br><span class="line">data[<span class="string">&#x27;leisure_sum&#x27;</span>] = data[leisure_fea_lis].<span class="built_in">sum</span>(axis=<span class="number">1</span>) <span class="comment">#skew</span></span><br><span class="line"><span class="comment"># 满意指数 163</span></span><br><span class="line">public_service_fea_lis = [<span class="string">&#x27;public_service_&#x27;</span>+<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>)]</span><br><span class="line">data[<span class="string">&#x27;public_service_sum&#x27;</span>] = data[public_service_fea_lis].<span class="built_in">sum</span>(axis=<span class="number">1</span>) <span class="comment">#skew</span></span><br><span class="line"><span class="comment"># 信任指数 164</span></span><br><span class="line">trust_fea_lis = [<span class="string">&#x27;trust_&#x27;</span>+<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">14</span>)]</span><br><span class="line">data[<span class="string">&#x27;trust_sum&#x27;</span>] = data[trust_fea_lis].<span class="built_in">sum</span>(axis=<span class="number">1</span>) <span class="comment">#skew</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># province mean 164+13=177</span></span><br><span class="line">data[<span class="string">&#x27;province_income_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;income&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_family_income_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;family_income&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_equity_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;equity&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_depression_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;depression&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_floor_area_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;floor_area&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_health_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;health&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_class_10_diff_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;class_10_diff&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_class_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;class&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_health_problem_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;health_problem&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_family_status_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;family_status&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_leisure_sum_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;leisure_sum&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_public_service_sum_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])</span><br><span class="line">[<span class="string">&#x27;public_service_sum&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;province_trust_sum_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;province&#x27;</span>])[<span class="string">&#x27;trust_sum&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line"></span><br><span class="line"><span class="comment"># city mean 177+13=190</span></span><br><span class="line">data[<span class="string">&#x27;city_income_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;income&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_family_income_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;family_income&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_equity_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;equity&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_depression_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;depression&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_floor_area_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;floor_area&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_health_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;health&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_class_10_diff_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;class_10_diff&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_class_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;class&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_health_problem_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;health_problem&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_family_status_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;family_status&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_leisure_sum_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;leisure_sum&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_public_service_sum_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;public_service_sum&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;city_trust_sum_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;city&#x27;</span>])[<span class="string">&#x27;trust_sum&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line"></span><br><span class="line"><span class="comment"># county mean 190 + 13 = 203</span></span><br><span class="line">data[<span class="string">&#x27;county_income_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;income&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_family_income_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;family_income&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_equity_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;equity&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_depression_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;depression&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_floor_area_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;floor_area&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_health_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;health&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_class_10_diff_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;class_10_diff&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_class_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;class&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_health_problem_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;health_problem&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_family_status_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;family_status&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_leisure_sum_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;leisure_sum&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_public_service_sum_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])</span><br><span class="line">[<span class="string">&#x27;public_service_sum&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line">data[<span class="string">&#x27;county_trust_sum_mean&#x27;</span>] = data.groupby([<span class="string">&#x27;county&#x27;</span>])[<span class="string">&#x27;trust_sum&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>).values</span><br><span class="line"></span><br><span class="line"><span class="comment"># ratio 相比同省 203 + 13 =216</span></span><br><span class="line">data[<span class="string">&#x27;income/province&#x27;</span>] = data[<span class="string">&#x27;income&#x27;</span>]/(data[<span class="string">&#x27;province_income_mean&#x27;</span>])</span><br><span class="line">data[<span class="string">&#x27;family_income/province&#x27;</span>] = data[<span class="string">&#x27;family_income&#x27;</span>]/(data[<span class="string">&#x27;province_family_income_mean&#x27;</span>])</span><br><span class="line">data[<span class="string">&#x27;equity/province&#x27;</span>] = data[<span class="string">&#x27;equity&#x27;</span>]/(data[<span class="string">&#x27;province_equity_mean&#x27;</span>])</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>DataWhale</category>
        <category>Ensemble</category>
        <category>Cases</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Ensemble</tag>
        <tag>Sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title>Ensemble-Stacking</title>
    <url>/2021/05/13/Ensemble-Stacking/</url>
    <content><![CDATA[<h1 id="introduction">1. Introduction</h1>
<p>Blending 集成方法的学习过程中，可以发现 Blending 在集成过程中只使用到了验证集的数据，这就造成了很大的浪费。因此可以靠用使用 Stacking 集成方法进行改进。</p>
<a id="more"></a>
<p>Blending 产生验证集的方式是使用分割的方式，产生一组训练集和验证集，那么是否可以将这种方式改进为交叉验证的方式呢？于是就有了如下的 Stacking 集成方法，其步骤如下：</p>
<ol type="1">
<li>记初始训练集为 <code>Train set</code>，测试集为 <code>Test set</code>，shape 分别为 <code>(train_size, 1)</code> 和 <code>(test_size, 1)</code>。 将 <code>Train set</code> 划分为多个部分（如 10 个），如下图 (Source: <a href="https://courses.analyticsvidhya.com/courses/take/ensemble-learning-and-ensemble-learning-techniques/texts/11125921-stacking">Analytics Vidhya</a>)；</li>
</ol>
<p><img src="https://z3.ax1x.com/2021/05/13/g0zJv4.png" /></p>
<ol start="2" type="1">
<li>用划分后的的 9/10 作为训练集 (<code>train_set</code>) 训练基准模型 (如决策树)，并用训练好的模型对剩下的 1/10 数据 (验证集, <code>val_set</code>) 和测试集 (<code>Test_set</code>) 来预测数据；</li>
<li>重复迭代训练 10 次直到所有数据都作为 <code>val_set</code>，并将 <code>val_set</code> 的 10 份预测的数据拼接为一个 shape 为 (<code>train_size</code>, 1) 的矩阵 (记为 <code>Trainset</code>)。</li>
<li>对迭代过程中得到的 10 份测试集 (<code>Test set</code>) 的预测数据取加权平均，得到一个shape 为 (<code>test_size</code>, 1)的矩阵。</li>
<li>重复步骤 2-4 训练其他基准模型 (如 knn) : <img src="https://z3.ax1x.com/2021/05/13/g0ztKJ.png" /></li>
<li>将上述训练得到的一系列 Trainset 串联，得到一个形状为 <code>(train_size, num_features)</code> 的矩阵，并用该矩阵训练第二层的模型，然后用训练好的新模型来做测试集的预测，并作为最终预测结果。</li>
</ol>
<p>下面借助实例来体验 Stacking 的魅力（参考案例：<a href="https://www.cnblogs.com/Christina-Notebook/p/10063146.html">cnblogs</a>）： 注：<code>sklearn</code> 模块并没有 <code>Stacking</code> 的方法，因此需要使用 <code>mlxtend</code> 工具包。</p>
<h1 id="a-example-of-stacking-model">2. A example of stacking model</h1>
<h2 id="data-process">2.1 Data process</h2>
<ul>
<li><p>Import modules <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> mlxtend.classifier <span class="keyword">import</span> StackingCVClassifier</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score <span class="keyword">as</span> ac</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure></p></li>
<li><p>Load data 本案例使用了 <code>Kaggle</code> 比赛中的一份泰坦尼克号乘客的数据来进行处理，下载链接：<a href="https://yangsuoly.com/file/titanic-data.csv">Titanic-data.csv</a> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;./titanic-data.csv&#x27;</span>)</span><br></pre></td></tr></table></figure> <strong>Information</strong>:</p>
<ul>
<li>PassengerId：乘客ID</li>
<li>Survived：是否获救，用1和Rescued表示获救,用0或者not saved表示没有获救</li>
<li>Pclass：乘客等级，“1”表示Upper，“2”表示Middle，“3”表示Lower</li>
<li>Name：乘客姓名</li>
<li>Sex：性别</li>
<li>Age：年龄</li>
<li>SibSp：乘客在船上的配偶数量或兄弟姐妹数量）</li>
<li>Parch：乘客在船上的父母或子女数量</li>
<li>Ticket：船票信息</li>
<li>Fare：票价</li>
<li>Cabin：是否住在独立的房间，“1”表示是，“0”为否</li>
<li>embarked：表示乘客上船的码头距离泰坦尼克出发码头的距离，数值越大表示距离越远</li>
</ul></li>
<li><p>Statistical description <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data.info() <span class="comment"># See datatype</span></span><br></pre></td></tr></table></figure> Results: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">891</span> entries, <span class="number">0</span> to <span class="number">890</span></span><br><span class="line">Data columns (total <span class="number">12</span> columns):</span><br><span class="line"> <span class="comment">#   Column       Non-Null Count  Dtype  </span></span><br><span class="line">---  ------       --------------  -----  </span><br><span class="line"> <span class="number">0</span>   PassengerId  <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">1</span>   Survived     <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">2</span>   Pclass       <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">3</span>   Name         <span class="number">891</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">4</span>   Sex          <span class="number">891</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">5</span>   Age          <span class="number">714</span> non-null    float64</span><br><span class="line"> <span class="number">6</span>   SibSp        <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">7</span>   Parch        <span class="number">891</span> non-null    int64  </span><br><span class="line"> <span class="number">8</span>   Ticket       <span class="number">891</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">9</span>   Fare         <span class="number">891</span> non-null    float64</span><br><span class="line"> <span class="number">10</span>  Cabin        <span class="number">204</span> non-null    <span class="built_in">object</span></span><br><span class="line"> <span class="number">11</span>  Embarked     <span class="number">889</span> non-null    <span class="built_in">object</span></span><br><span class="line">dtypes: float64(<span class="number">2</span>), int64(<span class="number">5</span>), <span class="built_in">object</span>(<span class="number">5</span>)</span><br><span class="line">memory usage: <span class="number">83.7</span>+ KB</span><br></pre></td></tr></table></figure></p></li>
<li><p>Missing values processing</p>
<ul>
<li><p>Embarked</p>
<p>Embarked 列仅有两个缺失值，而 'S' 占比最高，故将缺失值用 'S' 填充； <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data[<span class="string">&#x27;Embarked&#x27;</span>] = data[<span class="string">&#x27;Embarked&#x27;</span>].fillna(<span class="string">&#x27;S&#x27;</span>)</span><br></pre></td></tr></table></figure></p></li>
<li><p>Age</p>
<p>Age 包含较多缺失值，用均值填充； <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dmean_age = data[<span class="string">&#x27;Age&#x27;</span>].mean()</span><br><span class="line">data[<span class="string">&#x27;Age&#x27;</span>] = data[<span class="string">&#x27;Age&#x27;</span>].fillna(mean_age)</span><br></pre></td></tr></table></figure></p></li>
<li><p>Cabin</p>
<p>Cabin 值缺失过多，且每位乘客房间号均不一样，且无规律，故舍去。</p></li>
</ul></li>
<li><p>Datatype transformation</p>
<ul>
<li><p>Sex 将性别转换未数值型数据，用 0 表示男性，1 表示女性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data.loc[data[<span class="string">&#x27;Sex&#x27;</span>] == <span class="string">&#x27;male&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>] = <span class="number">0</span> <span class="comment"># &#x27;male&#x27; -&gt; 0</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;Sex&#x27;</span>] == <span class="string">&#x27;female&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>] = <span class="number">1</span> <span class="comment"># &#x27;female&#x27; -&gt; 1</span></span><br></pre></td></tr></table></figure></li>
<li><p>Embarked</p>
<p>将 'C' 所在位置的值改为 1, 'S' 所在位置的值改为 2, 'Q' 所在位置的值改为 3；</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data.loc[data[<span class="string">&#x27;Embarked&#x27;</span>] == <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>] = <span class="number">1</span> <span class="comment"># &#x27;C&#x27; -&gt; 1</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;Embarked&#x27;</span>] == <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>] = <span class="number">2</span> <span class="comment"># &#x27;S&#x27; -&gt; 2</span></span><br><span class="line">data.loc[data[<span class="string">&#x27;Embarked&#x27;</span>] == <span class="string">&#x27;Q&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>] = <span class="number">3</span> <span class="comment"># &#x27;Q&#x27; -&gt; 3</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Drop irrelevant variables <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">columns = data.columns</span><br><span class="line">columns = columns.drop([<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Cabin&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Ticket&#x27;</span>])</span><br><span class="line">data = data.loc[:, columns]</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><p>Parameters setting 可以直到 data的列名称为 <code>['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']</code>。选择最后一列作为分类标准。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_percent = <span class="number">0.10</span> <span class="comment"># 测试集大小</span></span><br><span class="line"></span><br><span class="line">train_X = train.loc[:, data.columns[<span class="number">1</span>:]]</span><br><span class="line">train_Y = train.loc[:, data.columns[<span class="number">0</span>]].values.reshape(-<span class="number">1</span>,)</span><br><span class="line">test_X = test.loc[:, data.columns[<span class="number">1</span>:]]</span><br><span class="line">test_Y = test.loc[:, data.columns[<span class="number">0</span>]].values.reshape(-<span class="number">1</span>,)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="creating-stacking-model">2.2 Creating Stacking model</h2>
<ul>
<li><p>Stacking <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">RANDOM_SEED = <span class="number">42</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The first layer</span></span><br><span class="line">clf1 = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line">clf2 = RandomForestClassifier(random_state=RANDOM_SEED)</span><br><span class="line">clf3 = GaussianNB()</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Starting from v0.16.0, StackingCVRegressor supports</span></span><br><span class="line"><span class="comment"># `random_state` to get deterministic result.</span></span><br><span class="line">sclf = StackingCVClassifier(</span><br><span class="line">      classifiers=[clf1, clf2, clf3],  <span class="comment"># The first layer</span></span><br><span class="line">      meta_classifier=lr,   <span class="comment"># THe second layer</span></span><br><span class="line">      random_state=RANDOM_SEED)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;3-fold cross validation:\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> clf, label <span class="keyword">in</span> <span class="built_in">zip</span>([clf1, clf2, clf3, sclf], [<span class="string">&#x27;KNN&#x27;</span>, <span class="string">&#x27;Random Forest&#x27;</span>, <span class="string">&#x27;Naive Bayes&#x27;</span>,<span class="string">&#x27;StackingClassifier&#x27;</span>]):</span><br><span class="line">    scores = cross_val_score(clf, train_X, train_Y,</span><br><span class="line">              cv=<span class="number">3</span>, scoring=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">    print(<span class="string">&quot;Accuracy: %0.2f (+/- %0.2f) [%s]&quot;</span> % (scores.mean(),</span><br><span class="line">               scores.std(), label))</span><br></pre></td></tr></table></figure> Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">3</span>-fold cross validation:</span><br><span class="line"></span><br><span class="line">Accuracy: <span class="number">0.70</span> (+/- <span class="number">0.02</span>) [KNN]</span><br><span class="line">Accuracy: <span class="number">0.80</span> (+/- <span class="number">0.01</span>) [Random Forest]</span><br><span class="line">Accuracy: <span class="number">0.76</span> (+/- <span class="number">0.02</span>) [Naive Bayes]</span><br><span class="line">Accuracy: <span class="number">0.79</span> (+/- <span class="number">0.01</span>) [StackingClassifier]</span><br></pre></td></tr></table></figure></p></li>
<li><p>Ploting decision region 由于使用了多维数据，决策边界暂无法成功绘制，有时间了再琢磨。</p></li>
</ul>
<h1 id="conclusion">3. Conclusion</h1>
<h2 id="blending-和-stacking-对比">3.1 Blending 和 Stacking 对比</h2>
<ul>
<li>Blending 优点：
<ul>
<li>比 Stacking 简单，不用进行 <code>K</code> 次的交叉验证来获得 stacker feature</li>
</ul></li>
<li>缺点：
<ul>
<li>在训练第二层的模型的时候，仅使用了很少的数据；</li>
<li>由于第二层训练数据较少，容易导致过拟合</li>
<li>stacking 使用多测的 CV 会比较文件。</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>DataWhale</category>
        <category>Ensemble</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Ensemble</tag>
        <tag>Sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title>Ensemble-Steam</title>
    <url>/2021/05/22/Ensemble-Steam/</url>
    <content><![CDATA[<h1 id="problem">1. Problem</h1>
<h2 id="introduction-of-background">1.1 Introduction of Background</h2>
<p>火力发电的基本原理是：颜料燃烧时加热水会生成蒸汽，蒸汽压力推动汽轮机旋转，然后汽轮机带动带动发电机旋转，产生电能。在这一系列的能量转化中，影响发电效率的核心是锅炉的燃烧效率，即燃料燃烧加热水产生高温高压蒸汽。锅炉的燃烧效率的影响因素很多，包括锅炉的可调参数，如燃烧给量，一二次风，引风，返料风，给水水量；以及锅炉的工况，比如锅炉床温、床压，炉膛温度、压力，过热器的温度等。我们如何使用以上的信息，根据锅炉的工况，预测产生的蒸汽量，来为我国的工业届的产量预测贡献自己的一份力量呢？</p>
<a id="more"></a>
<p>此次的案列时使用工业指标的特征，进行蒸汽量的预测。所使用的数据均为脱敏后的数据。</p>
<h2 id="data-source">1.2 Data source</h2>
<p>数据分成训练数据（<code>train.txt</code>）和测试数据（<code>test.txt</code>），其中字段 <code>V0-V37</code>，这 <code>38</code> 个字段是作为特征变量，<code>target</code> 作为目标变量。我们需要利用训练数据训练出模型，预测测试数据的目标变量。</p>
<p>数据包下载地址: <a href="https://yangsuoly.com/file/Data-of-forcasting-Steams.rar">Data of case</a>。</p>
<h2 id="evaluation-metrics">1.3 Evaluation metrics</h2>
<p>最终的评价指标为均方误差 <span class="math inline">\(MSE\)</span> ，即： <span class="math inline">\(Score = \frac{1}{n}\sum^n_1 (y_i - y^*)^2\)</span></p>
<h1 id="data-process">2. Data process</h1>
<h2 id="load-data">2.1 Load data</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data_train = pd.read_csv(<span class="string">&#x27;train.txt&#x27;</span>, sep = <span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">data_test = pd.read_csv(<span class="string">&#x27;test.txt&#x27;</span>, sep = <span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># concantenate</span></span><br><span class="line">data_train[<span class="string">&#x27;oringin&#x27;</span>] = <span class="string">&#x27;train&#x27;</span></span><br><span class="line">data_test[<span class="string">&#x27;oringin&#x27;</span>] = <span class="string">&#x27;test&#x27;</span></span><br><span class="line">data_all = pd.concat([data_train, data_test], axis = <span class="number">0</span>, ignore_index = <span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>查看合并后的数据信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_all.head()</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
V0
</th>
<th>
V1
</th>
<th>
V2
</th>
<th>
V3
</th>
<th>
V4
</th>
<th>
V5
</th>
<th>
V6
</th>
<th>
V7
</th>
<th>
V8
</th>
<th>
V9
</th>
<th>
...
</th>
<th>
V30
</th>
<th>
V31
</th>
<th>
V32
</th>
<th>
V33
</th>
<th>
V34
</th>
<th>
V35
</th>
<th>
V36
</th>
<th>
V37
</th>
<th>
target
</th>
<th>
oringin
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0.566
</td>
<td>
0.016
</td>
<td>
-0.143
</td>
<td>
0.407
</td>
<td>
0.452
</td>
<td>
-0.901
</td>
<td>
-1.812
</td>
<td>
-2.360
</td>
<td>
-0.436
</td>
<td>
-2.114
</td>
<td>
...
</td>
<td>
0.109
</td>
<td>
-0.615
</td>
<td>
0.327
</td>
<td>
-4.627
</td>
<td>
-4.789
</td>
<td>
-5.101
</td>
<td>
-2.608
</td>
<td>
-3.508
</td>
<td>
0.175
</td>
<td>
train
</td>
</tr>
<tr>
<th>
1
</th>
<td>
0.968
</td>
<td>
0.437
</td>
<td>
0.066
</td>
<td>
0.566
</td>
<td>
0.194
</td>
<td>
-0.893
</td>
<td>
-1.566
</td>
<td>
-2.360
</td>
<td>
0.332
</td>
<td>
-2.114
</td>
<td>
...
</td>
<td>
0.124
</td>
<td>
0.032
</td>
<td>
0.600
</td>
<td>
-0.843
</td>
<td>
0.160
</td>
<td>
0.364
</td>
<td>
-0.335
</td>
<td>
-0.730
</td>
<td>
0.676
</td>
<td>
train
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1.013
</td>
<td>
0.568
</td>
<td>
0.235
</td>
<td>
0.370
</td>
<td>
0.112
</td>
<td>
-0.797
</td>
<td>
-1.367
</td>
<td>
-2.360
</td>
<td>
0.396
</td>
<td>
-2.114
</td>
<td>
...
</td>
<td>
0.361
</td>
<td>
0.277
</td>
<td>
-0.116
</td>
<td>
-0.843
</td>
<td>
0.160
</td>
<td>
0.364
</td>
<td>
0.765
</td>
<td>
-0.589
</td>
<td>
0.633
</td>
<td>
train
</td>
</tr>
<tr>
<th>
3
</th>
<td>
0.733
</td>
<td>
0.368
</td>
<td>
0.283
</td>
<td>
0.165
</td>
<td>
0.599
</td>
<td>
-0.679
</td>
<td>
-1.200
</td>
<td>
-2.086
</td>
<td>
0.403
</td>
<td>
-2.114
</td>
<td>
...
</td>
<td>
0.417
</td>
<td>
0.279
</td>
<td>
0.603
</td>
<td>
-0.843
</td>
<td>
-0.065
</td>
<td>
0.364
</td>
<td>
0.333
</td>
<td>
-0.112
</td>
<td>
0.206
</td>
<td>
train
</td>
</tr>
<tr>
<th>
4
</th>
<td>
0.684
</td>
<td>
0.638
</td>
<td>
0.260
</td>
<td>
0.209
</td>
<td>
0.337
</td>
<td>
-0.454
</td>
<td>
-1.073
</td>
<td>
-2.086
</td>
<td>
0.314
</td>
<td>
-2.114
</td>
<td>
...
</td>
<td>
1.078
</td>
<td>
0.328
</td>
<td>
0.418
</td>
<td>
-0.843
</td>
<td>
-0.215
</td>
<td>
0.364
</td>
<td>
-0.280
</td>
<td>
-0.028
</td>
<td>
0.384
</td>
<td>
train
</td>
</tr>
</tbody>
</table>
<p>
5 rows × 40 columns
</p>
<h2 id="data-exploration">2.2 Data exploration</h2>
<h3 id="eda">2.2.1 EDA</h3>
<p>由于是传感器数据，所以这些变量都是连续便来给你，故使用 <code>kdeplot</code>（核密度估计图）进行数据的初步分析，即 <code>EDA</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">columns = data_all.columns[<span class="number">0</span>:-<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">num_subfig = <span class="number">6</span> <span class="comment"># 每个大图中有多少小图</span></span><br><span class="line">num_fig = <span class="built_in">len</span>(columns) // num_subfig <span class="comment"># 需要多少个大图</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_fig):</span><br><span class="line">    f = plt.figure(figsize = (<span class="number">12</span>, <span class="number">9</span>))</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_subfig):</span><br><span class="line">        column = columns[i*num_subfig+j]</span><br><span class="line">        <span class="comment"># ax = f.add_subplot(4, 3, j+1) # 当 num_subfit = 12 时使用</span></span><br><span class="line">        ax = f.add_subplot(<span class="number">3</span>, <span class="number">2</span>, j+<span class="number">1</span>) <span class="comment"># 当 num_subfit = 6 时使用</span></span><br><span class="line">        sns.kdeplot(data_all[column][(data_all[<span class="string">&quot;oringin&quot;</span>] == <span class="string">&quot;train&quot;</span>)],</span><br><span class="line">                    color=<span class="string">&quot;Red&quot;</span>, shade = <span class="literal">True</span>)</span><br><span class="line">        sns.kdeplot(data_all[column][(data_all[<span class="string">&quot;oringin&quot;</span>] == <span class="string">&quot;test&quot;</span>)],</span><br><span class="line">                    ax = ax, color=<span class="string">&quot;Blue&quot;</span>, shade= <span class="literal">True</span>)</span><br><span class="line">        ax.set_title(<span class="string">&#x27;V&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i*num_subfig+j), fontsize = <span class="number">16</span>)</span><br><span class="line">        ax.set_xlabel(column)</span><br><span class="line">        ax.set_ylabel(<span class="string">&#x27;Frenquency&#x27;</span>)</span><br><span class="line">        ax.legend([<span class="string">&#x27;Train&#x27;</span>, <span class="string">&#x27;Test&#x27;</span>])</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    f = plt.figure(figsize = (<span class="number">12</span>, <span class="number">3</span>))</span><br><span class="line">    column = columns[<span class="number">36</span>+i]</span><br><span class="line">    ax = f.add_subplot(<span class="number">1</span>, <span class="number">2</span>, i+<span class="number">1</span>)</span><br><span class="line">    sns.kdeplot(data_all[column][(data_all[<span class="string">&quot;oringin&quot;</span>] == <span class="string">&quot;train&quot;</span>)],</span><br><span class="line">                color=<span class="string">&quot;Red&quot;</span>, shade = <span class="literal">True</span>)</span><br><span class="line">    sns.kdeplot(data_all[column][(data_all[<span class="string">&quot;oringin&quot;</span>] == <span class="string">&quot;test&quot;</span>)],</span><br><span class="line">                ax = ax, color=<span class="string">&quot;Blue&quot;</span>, shade= <span class="literal">True</span>)</span><br><span class="line">    ax.set_title(<span class="string">&#x27;V&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="number">36</span>+i), fontsize = <span class="number">16</span>)</span><br><span class="line">    ax.set_xlabel(column)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Frenquency&#x27;</span>)</span><br><span class="line">    ax.legend([<span class="string">&#x27;Train&#x27;</span>, <span class="string">&#x27;Test&#x27;</span>])</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/05/22/gO9rZt.png" /></p>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjwKx.png" /></p>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjBqK.png" /></p>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjrVO.png" /></p>
<p><img src="https://z3.ax1x.com/2021/05/22/gLj0r6.png" /></p>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjyIe.png" /></p>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjsaD.png" /></p>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjcPH.png" /></p>
<ul>
<li><p>Delete variables</p>
<p>从上述的图中可以看出，特征征 <code>V5</code>, <code>V9</code>, <code>V11</code>, <code>V17</code>, <code>V22</code>, <code>V28</code>中的训练集数据分布和测试集数据分布分布不均，所以我们删除这些特则会给你数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">f = plt.figure(figsize = (<span class="number">12</span>, <span class="number">9</span>))</span><br><span class="line"></span><br><span class="line">drop_columns = [<span class="string">&#x27;V5&#x27;</span>, <span class="string">&#x27;V9&#x27;</span>, <span class="string">&#x27;V11&#x27;</span>, <span class="string">&#x27;V17&#x27;</span>, <span class="string">&#x27;V22&#x27;</span>, <span class="string">&#x27;V28&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    column = drop_columns[i]</span><br><span class="line">    <span class="comment"># ax = f.add_subplot(4, 3, j+1) # 当 num_subfit = 12 时使用</span></span><br><span class="line">    ax = f.add_subplot(<span class="number">3</span>, <span class="number">2</span>, i+<span class="number">1</span>) <span class="comment"># 当 num_subfit = 6 时使用</span></span><br><span class="line">    sns.kdeplot(data_all[column][(data_all[<span class="string">&quot;oringin&quot;</span>] == <span class="string">&quot;train&quot;</span>)],</span><br><span class="line">                color=<span class="string">&quot;Red&quot;</span>, shade = <span class="literal">True</span>)</span><br><span class="line">    sns.kdeplot(data_all[column][(data_all[<span class="string">&quot;oringin&quot;</span>] == <span class="string">&quot;test&quot;</span>)],</span><br><span class="line">                ax = ax, color=<span class="string">&quot;Blue&quot;</span>, shade= <span class="literal">True</span>)</span><br><span class="line">    ax.set_title(column, fontsize = <span class="number">16</span>)</span><br><span class="line">    ax.set_xlabel(column)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Frenquency&#x27;</span>)</span><br><span class="line">    ax.legend([<span class="string">&#x27;Train&#x27;</span>, <span class="string">&#x27;Test&#x27;</span>])</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">data_all.drop([<span class="string">&quot;V5&quot;</span>,<span class="string">&quot;V9&quot;</span>,<span class="string">&quot;V11&quot;</span>,<span class="string">&quot;V17&quot;</span>,<span class="string">&quot;V22&quot;</span>,<span class="string">&quot;V28&quot;</span>],axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjax1.png" /></p></li>
</ul>
<h3 id="dimentsionality">2.2.2 Dimentsionality</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data_train1 = data_all[data_all[<span class="string">&quot;oringin&quot;</span>]==<span class="string">&quot;train&quot;</span>].drop(<span class="string">&quot;oringin&quot;</span>,axis=<span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">16</span>)) <span class="comment"># 指定绘图对象宽度和高度</span></span><br><span class="line">colnm = data_train1.columns.tolist() <span class="comment"># 列表头</span></span><br><span class="line">mcorr = data_train1[colnm].corr(method=<span class="string">&quot;spearman&quot;</span>) <span class="comment"># 相关系数矩阵，即给出了任意两个变量之间的相关系数</span></span><br><span class="line">mask = np.zeros_like(mcorr, dtype=np.<span class="built_in">bool</span>) <span class="comment"># 构造与mcorr同维数矩阵 为bool型</span></span><br><span class="line">mask[np.triu_indices_from(mask)] = <span class="literal">True</span> <span class="comment"># 角分线右侧为True</span></span><br><span class="line">cmap = sns.diverging_palette(<span class="number">220</span>, <span class="number">10</span>, as_cmap=<span class="literal">True</span>) <span class="comment"># 返回matplotlib colormap对象，调色板</span></span><br><span class="line">g = sns.heatmap(mcorr, mask=mask, cmap=cmap, square=<span class="literal">True</span>, annot=<span class="literal">True</span>, fmt=<span class="string">&#x27;0.2f&#x27;</span>) <span class="comment"># 热力图（看两两相似度）</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjfMt.md.png" /></p>
<ul>
<li><p>降维操作</p>
<p>可以发现部分特征 (<code>V14, V21, V22, V25, V26, V32, V33, V34, V35</code>) 与 <code>target</code> 的相关性非常小，其中可能包含几乎很少的对target 的预测信息，因此，对这些变量进行剔除。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">threshold = <span class="number">0.1</span></span><br><span class="line">corr_matrix = data_train1.corr().<span class="built_in">abs</span>()</span><br><span class="line">drop_col=corr_matrix[corr_matrix[<span class="string">&quot;target&quot;</span>]&lt;threshold].index</span><br><span class="line">data_all.drop(drop_col,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>Normalization</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cols_numeric = <span class="built_in">list</span>(data_all.columns)</span><br><span class="line">cols_numeric.remove(<span class="string">&#x27;oringin&#x27;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scale_minmax</span>(<span class="params">col</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (col - col.<span class="built_in">min</span>())/(col.<span class="built_in">max</span>()-col.<span class="built_in">min</span>())</span><br><span class="line">scale_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> cols_numeric <span class="keyword">if</span> col != <span class="string">&#x27;target&#x27;</span>]</span><br><span class="line">data_all[scale_cols] = data_all[scale_cols].apply(scale_minmax,axis=<span class="number">0</span>)</span><br><span class="line">data_all[scale_cols].describe()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }

</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
<p>V0</p>
</th>
<th>
<p>V1</p>
</th>
<th>
<p>V2</p>
</th>
<th>
<p>V3</p>
</th>
<th>
<p>V4</p>
</th>
<th>
<p>V6</p>
</th>
<th>
<p>V7</p>
</th>
<th>
<p>V8</p>
</th>
<th>
<p>V10</p>
</th>
<th>
<p>V12</p>
</th>
<th>
<p>...</p>
</th>
<th>
<p>V20</p>
</th>
<th>
<p>V23</p>
</th>
<th>
<p>V24</p>
</th>
<th>
<p>V27</p>
</th>
<th>
<p>V29</p>
</th>
<th>
<p>V30</p>
</th>
<th>
<p>V31</p>
</th>
<th>
<p>V35</p>
</th>
<th>
<p>V36</p>
</th>
<th>
<p>V37</p>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
<p>count</p>
</th>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>...</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
<td>
<p>4813.000000</p>
</td>
</tr>
<tr>
<th>
<p>mean</p>
</th>
<td>
<p>0.694172</p>
</td>
<td>
<p>0.721357</p>
</td>
<td>
<p>0.602300</p>
</td>
<td>
<p>0.603139</p>
</td>
<td>
<p>0.523743</p>
</td>
<td>
<p>0.748823</p>
</td>
<td>
<p>0.745740</p>
</td>
<td>
<p>0.715607</p>
</td>
<td>
<p>0.348518</p>
</td>
<td>
<p>0.578507</p>
</td>
<td>
<p>...</p>
</td>
<td>
<p>0.456147</p>
</td>
<td>
<p>0.744438</p>
</td>
<td>
<p>0.356712</p>
</td>
<td>
<p>0.881401</p>
</td>
<td>
<p>0.388683</p>
</td>
<td>
<p>0.589459</p>
</td>
<td>
<p>0.792709</p>
</td>
<td>
<p>0.762873</p>
</td>
<td>
<p>0.332385</p>
</td>
<td>
<p>0.545795</p>
</td>
</tr>
<tr>
<th>
<p>std</p>
</th>
<td>
<p>0.144198</p>
</td>
<td>
<p>0.131443</p>
</td>
<td>
<p>0.140628</p>
</td>
<td>
<p>0.152462</p>
</td>
<td>
<p>0.106430</p>
</td>
<td>
<p>0.132560</p>
</td>
<td>
<p>0.132577</p>
</td>
<td>
<p>0.118105</p>
</td>
<td>
<p>0.134882</p>
</td>
<td>
<p>0.105088</p>
</td>
<td>
<p>...</p>
</td>
<td>
<p>0.134083</p>
</td>
<td>
<p>0.134085</p>
</td>
<td>
<p>0.265512</p>
</td>
<td>
<p>0.128221</p>
</td>
<td>
<p>0.133475</p>
</td>
<td>
<p>0.130786</p>
</td>
<td>
<p>0.102976</p>
</td>
<td>
<p>0.102037</p>
</td>
<td>
<p>0.127456</p>
</td>
<td>
<p>0.150356</p>
</td>
</tr>
<tr>
<th>
<p>min</p>
</th>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>...</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
<td>
<p>0.000000</p>
</td>
</tr>
<tr>
<th>
<p>25%</p>
</th>
<td>
<p>0.626676</p>
</td>
<td>
<p>0.679416</p>
</td>
<td>
<p>0.514414</p>
</td>
<td>
<p>0.503888</p>
</td>
<td>
<p>0.478182</p>
</td>
<td>
<p>0.683324</p>
</td>
<td>
<p>0.696938</p>
</td>
<td>
<p>0.664934</p>
</td>
<td>
<p>0.284327</p>
</td>
<td>
<p>0.532892</p>
</td>
<td>
<p>...</p>
</td>
<td>
<p>0.370475</p>
</td>
<td>
<p>0.719362</p>
</td>
<td>
<p>0.040616</p>
</td>
<td>
<p>0.888575</p>
</td>
<td>
<p>0.292445</p>
</td>
<td>
<p>0.550092</p>
</td>
<td>
<p>0.761816</p>
</td>
<td>
<p>0.727273</p>
</td>
<td>
<p>0.270584</p>
</td>
<td>
<p>0.445647</p>
</td>
</tr>
<tr>
<th>
<p>50%</p>
</th>
<td>
<p>0.729488</p>
</td>
<td>
<p>0.752497</p>
</td>
<td>
<p>0.617072</p>
</td>
<td>
<p>0.614270</p>
</td>
<td>
<p>0.535866</p>
</td>
<td>
<p>0.774125</p>
</td>
<td>
<p>0.771974</p>
</td>
<td>
<p>0.742884</p>
</td>
<td>
<p>0.366469</p>
</td>
<td>
<p>0.591635</p>
</td>
<td>
<p>...</p>
</td>
<td>
<p>0.447305</p>
</td>
<td>
<p>0.788817</p>
</td>
<td>
<p>0.381736</p>
</td>
<td>
<p>0.916015</p>
</td>
<td>
<p>0.375734</p>
</td>
<td>
<p>0.594428</p>
</td>
<td>
<p>0.815055</p>
</td>
<td>
<p>0.800020</p>
</td>
<td>
<p>0.347056</p>
</td>
<td>
<p>0.539317</p>
</td>
</tr>
<tr>
<th>
<p>75%</p>
</th>
<td>
<p>0.790195</p>
</td>
<td>
<p>0.799553</p>
</td>
<td>
<p>0.700464</p>
</td>
<td>
<p>0.710474</p>
</td>
<td>
<p>0.585036</p>
</td>
<td>
<p>0.842259</p>
</td>
<td>
<p>0.836405</p>
</td>
<td>
<p>0.790835</p>
</td>
<td>
<p>0.432965</p>
</td>
<td>
<p>0.641971</p>
</td>
<td>
<p>...</p>
</td>
<td>
<p>0.522660</p>
</td>
<td>
<p>0.792706</p>
</td>
<td>
<p>0.574728</p>
</td>
<td>
<p>0.932555</p>
</td>
<td>
<p>0.471837</p>
</td>
<td>
<p>0.650798</p>
</td>
<td>
<p>0.852229</p>
</td>
<td>
<p>0.800020</p>
</td>
<td>
<p>0.414861</p>
</td>
<td>
<p>0.643061</p>
</td>
</tr>
<tr>
<th>
<p>max</p>
</th>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>...</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
<td>
<p>1.000000</p>
</td>
</tr>
</tbody>
</table>
<p>
<p>8 rows × 25 columns</p>
</p></li>
</ul>
<h3 id="features-engineering">2.3.3 Features engineering</h3>
<p>绘图显示 <code>Box-Cox</code> 变换对数据分布影响，<code>Box-Cox</code> 用于连续的响应变量不满足正态分布的情况。在进行 <code>Box-Cox</code> 变换之后，可以一定程度上减少不可观测的误差和预测变量的相关性。</p>
<p><code>quantitle-quantile(q-q)</code> 图，可参考 <a href="https://blog.csdn.net/u012193416/article/details/83210790">QQ图，stats.probplot</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">fcols = <span class="number">6</span></span><br><span class="line">frows = <span class="built_in">len</span>(cols_numeric)-<span class="number">1</span></span><br><span class="line">plt.figure(figsize=(<span class="number">4</span>*fcols,<span class="number">4</span>*frows))</span><br><span class="line">i=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> var <span class="keyword">in</span> cols_numeric:</span><br><span class="line">    <span class="keyword">if</span> var!=<span class="string">&#x27;target&#x27;</span>:</span><br><span class="line">        dat = data_all[[var, <span class="string">&#x27;target&#x27;</span>]].dropna()</span><br><span class="line"></span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">        plt.subplot(frows,fcols,i)</span><br><span class="line">        sns.distplot(dat[var] , fit=stats.norm);</span><br><span class="line">        plt.title(var+<span class="string">&#x27; Original&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">        plt.subplot(frows,fcols,i)</span><br><span class="line">        _=stats.probplot(dat[var], plot=plt)</span><br><span class="line">        plt.title(<span class="string">&#x27;skew=&#x27;</span>+<span class="string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(stats.skew(dat[var])))</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">        plt.subplot(frows,fcols,i)</span><br><span class="line">        plt.plot(dat[var], dat[<span class="string">&#x27;target&#x27;</span>],<span class="string">&#x27;.&#x27;</span>,alpha=<span class="number">0.5</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;corr=&#x27;</span>+<span class="string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(np.corrcoef(dat[var], dat[<span class="string">&#x27;target&#x27;</span>])[<span class="number">0</span>][<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">        plt.subplot(frows,fcols,i)</span><br><span class="line">        trans_var, lambda_var = stats.boxcox(dat[var].dropna()+<span class="number">1</span>)</span><br><span class="line">        trans_var = scale_minmax(trans_var)</span><br><span class="line">        sns.distplot(trans_var , fit=stats.norm);</span><br><span class="line">        plt.title(var+<span class="string">&#x27; Tramsformed&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">        plt.subplot(frows,fcols,i)</span><br><span class="line">        _=stats.probplot(trans_var, plot=plt)</span><br><span class="line">        plt.title(<span class="string">&#x27;skew=&#x27;</span>+<span class="string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(stats.skew(trans_var)))</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">        plt.subplot(frows,fcols,i)</span><br><span class="line">        plt.plot(trans_var, dat[<span class="string">&#x27;target&#x27;</span>],<span class="string">&#x27;.&#x27;</span>,alpha=<span class="number">0.5</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;corr=&#x27;</span>+<span class="string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(np.corrcoef(trans_var,dat[<span class="string">&#x27;target&#x27;</span>])[<span class="number">0</span>][<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjIZ8.md.png" /></p>
<ul>
<li><p>Box-Cox 变换</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进行Box-Cox变换</span></span><br><span class="line">cols_transform=data_all.columns[<span class="number">0</span>:-<span class="number">2</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_transform:</span><br><span class="line">    <span class="comment"># transform column</span></span><br><span class="line">    data_all.loc[:,col], _ = stats.boxcox(data_all.loc[:,col]+<span class="number">1</span>)</span><br><span class="line">print(data_all.target.describe())</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">sns.distplot(data_all.target.dropna() , fit=stats.norm);</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">_=stats.probplot(data_all.target.dropna(), plot=plt)</span><br></pre></td></tr></table></figure>
<p>Results: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">count    <span class="number">2888.000000</span></span><br><span class="line">mean        <span class="number">0.126353</span></span><br><span class="line">std         <span class="number">0.983966</span></span><br><span class="line"><span class="built_in">min</span>        -<span class="number">3.044000</span></span><br><span class="line"><span class="number">25</span>%        -<span class="number">0.350250</span></span><br><span class="line"><span class="number">50</span>%         <span class="number">0.313000</span></span><br><span class="line"><span class="number">75</span>%         <span class="number">0.793250</span></span><br><span class="line"><span class="built_in">max</span>         <span class="number">2.538000</span></span><br><span class="line">Name: target, dtype: float64</span><br></pre></td></tr></table></figure></p></li>
</ul>
<p><img src="https://z3.ax1x.com/2021/05/22/gLj2RA.png" /></p>
<ul>
<li><p>对数变换 <code>target</code></p>
<p>使用对数变换 <code>target</code> 目标提升特征数量的正态性，可以参考知乎文章：<a href="https://www.zhihu.com/question/22012482">在统计学中为什么要对变量取对数？</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sp = data_train.target</span><br><span class="line">data_train.target1 = np.power(<span class="number">1.5</span>,sp)</span><br><span class="line">print(data_train.target1.describe())</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">sns.distplot(data_train.target1.dropna(),fit=stats.norm);</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">_ = stats.probplot(data_train.target1.dropna(), plot=plt)</span><br></pre></td></tr></table></figure>
<p>Results: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">count    <span class="number">2888.000000</span></span><br><span class="line">mean        <span class="number">1.129957</span></span><br><span class="line">std         <span class="number">0.394110</span></span><br><span class="line"><span class="built_in">min</span>         <span class="number">0.291057</span></span><br><span class="line"><span class="number">25</span>%         <span class="number">0.867609</span></span><br><span class="line"><span class="number">50</span>%         <span class="number">1.135315</span></span><br><span class="line"><span class="number">75</span>%         <span class="number">1.379382</span></span><br><span class="line"><span class="built_in">max</span>         <span class="number">2.798463</span></span><br><span class="line">Name: target, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjRxI.png" /></p></li>
</ul>
<h1 id="model-construction">3. Model construction</h1>
<h2 id="self-definition-fuction">3.1 Self definition fuction</h2>
<ul>
<li><p>Train set and Test set</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># function to get training samples</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_training_data</span>():</span></span><br><span class="line">    <span class="comment"># extract training samples</span></span><br><span class="line">    df_train = data_all[data_all[<span class="string">&quot;oringin&quot;</span>]==<span class="string">&quot;train&quot;</span>]</span><br><span class="line">    df_train[<span class="string">&quot;label&quot;</span>] = data_train.target1</span><br><span class="line">    <span class="comment"># split SalePrice and features</span></span><br><span class="line">    y = df_train.target</span><br><span class="line">    X = df_train.drop([<span class="string">&quot;oringin&quot;</span>,<span class="string">&quot;target&quot;</span>,<span class="string">&quot;label&quot;</span>], axis=<span class="number">1</span>)</span><br><span class="line">    X_train,X_valid,y_train,y_valid=train_test_split(X,</span><br><span class="line">                        y,test_size=<span class="number">0.3</span>,random_state=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train,X_valid,y_train,y_valid</span><br><span class="line">    <span class="comment"># extract test data (without SalePrice)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_test_data</span>():</span></span><br><span class="line">    df_test = data_all[data_all[<span class="string">&quot;oringin&quot;</span>]==<span class="string">&quot;test&quot;</span>].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> df_test.drop([<span class="string">&quot;oringin&quot;</span>,<span class="string">&quot;target&quot;</span>],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>Evaluation metrics</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> make_scorer,mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># metric for evaluation</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rmse</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">    diff = y_pred - y_true</span><br><span class="line">    sum_sq = <span class="built_in">sum</span>(diff**<span class="number">2</span>)</span><br><span class="line">    n = <span class="built_in">len</span>(y_pred)</span><br><span class="line">    <span class="keyword">return</span> np.sqrt(sum_sq/n)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mse</span>(<span class="params">y_ture,y_pred</span>):</span></span><br><span class="line">    <span class="keyword">return</span> mean_squared_error(y_ture,y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># scorer to be used in sklearn model fitting</span></span><br><span class="line">rmse_scorer = make_scorer(rmse, greater_is_better=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入的score_func为记分函数时，该值为True（默认值）；输入函数为损失函数时，该值为False</span></span><br><span class="line">mse_scorer = make_scorer(mse, greater_is_better=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>Outliers</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"></span><br><span class="line"><span class="comment"># function to detect outliers based on the predictions of a model</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_outliers</span>(<span class="params">model, X, y, sigma=<span class="number">3</span></span>):</span></span><br><span class="line">    <span class="comment"># predict y values using model</span></span><br><span class="line">    model.fit(X,y)</span><br><span class="line">    y_pred = pd.Series(model.predict(X), index=y.index)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate residuals between the model prediction and true y values</span></span><br><span class="line">    resid = y - y_pred</span><br><span class="line">    mean_resid = resid.mean()</span><br><span class="line">    std_resid = resid.std()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate z statistic, define outliers to be where |z|&gt;sigma</span></span><br><span class="line">    z = (resid - mean_resid)/std_resid</span><br><span class="line">    outliers = z[<span class="built_in">abs</span>(z)&gt;sigma].index</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print and plot the results</span></span><br><span class="line">    print(<span class="string">&#x27;R2=&#x27;</span>,model.score(X,y))</span><br><span class="line">    print(<span class="string">&#x27;rmse=&#x27;</span>,rmse(y, y_pred))</span><br><span class="line">    print(<span class="string">&quot;mse=&quot;</span>,mean_squared_error(y,y_pred))</span><br><span class="line">    print(<span class="string">&#x27;---------------------------------------&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;mean of residuals:&#x27;</span>,mean_resid)</span><br><span class="line">    print(<span class="string">&#x27;std of residuals:&#x27;</span>,std_resid)</span><br><span class="line">    print(<span class="string">&#x27;---------------------------------------&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="built_in">len</span>(outliers),<span class="string">&#x27;outliers:&#x27;</span>)</span><br><span class="line">    print(outliers.tolist())</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">    ax_131 = plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">    plt.plot(y,y_pred,<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    plt.plot(y.loc[outliers],y_pred.loc[outliers],<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">    plt.legend([<span class="string">&#x27;Accepted&#x27;</span>,<span class="string">&#x27;Outlier&#x27;</span>])</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;y_pred&#x27;</span>);</span><br><span class="line"></span><br><span class="line">    ax_132=plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">    plt.plot(y,y-y_pred,<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    plt.plot(y.loc[outliers],y.loc[outliers]-y_pred.loc[outliers],<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">    plt.legend([<span class="string">&#x27;Accepted&#x27;</span>,<span class="string">&#x27;Outlier&#x27;</span>])</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;y - y_pred&#x27;</span>);</span><br><span class="line"></span><br><span class="line">    ax_133=plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">    z.plot.hist(bins=<span class="number">50</span>,ax=ax_133)</span><br><span class="line">    z.loc[outliers].plot.hist(color=<span class="string">&#x27;r&#x27;</span>,bins=<span class="number">50</span>,ax=ax_133)</span><br><span class="line">    plt.legend([<span class="string">&#x27;Accepted&#x27;</span>,<span class="string">&#x27;Outlier&#x27;</span>])</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;z&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> outliers</span><br><span class="line"></span><br><span class="line"><span class="comment"># get training data</span></span><br><span class="line">X_train, X_valid,y_train,y_valid = get_training_data()</span><br><span class="line">test=get_test_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># find and remove outliers using a Ridge model</span></span><br><span class="line">outliers = find_outliers(Ridge(), X_train, y_train)</span><br><span class="line">X_outliers=X_train.loc[outliers]</span><br><span class="line">y_outliers=y_train.loc[outliers]</span><br><span class="line">X_t=X_train.drop(outliers)</span><br><span class="line">y_t=y_train.drop(outliers)</span><br></pre></td></tr></table></figure>
<p>Results: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">R2= <span class="number">0.8760125992975717</span></span><br><span class="line">rmse= <span class="number">0.3499365298917651</span></span><br><span class="line">mse= <span class="number">0.12245557495269015</span></span><br><span class="line">---------------------------------------</span><br><span class="line">mean of residuals: -<span class="number">3.28946831838468e-16</span></span><br><span class="line">std of residuals: <span class="number">0.3500231371273175</span></span><br><span class="line">---------------------------------------</span><br><span class="line"><span class="number">21</span> outliers:</span><br><span class="line">[<span class="number">2655</span>, <span class="number">2159</span>, <span class="number">1164</span>, <span class="number">2863</span>, <span class="number">1145</span>, <span class="number">2697</span>, <span class="number">2528</span>, <span class="number">2645</span>, <span class="number">691</span>, <span class="number">1874</span>,</span><br><span class="line"><span class="number">2647</span>, <span class="number">884</span>, <span class="number">2696</span>, <span class="number">2668</span>, <span class="number">1310</span>, <span class="number">1901</span>, <span class="number">1458</span>, <span class="number">2769</span>, <span class="number">2002</span>, <span class="number">2669</span>, <span class="number">1972</span>]</span><br></pre></td></tr></table></figure></p>
<p><img src="https://z3.ax1x.com/2021/05/22/gLjhsP.png" /></p></li>
</ul>
<h2 id="model-training">3.2 Model training</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_trainning_data_omitoutliers</span>():</span></span><br><span class="line">    <span class="comment">#获取训练数据省略异常值</span></span><br><span class="line">    y=y_t.copy()</span><br><span class="line">    X=X_t.copy()</span><br><span class="line">    <span class="keyword">return</span> X,y</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>(<span class="params">model, param_grid=[], X=[], y=[],</span></span></span><br><span class="line"><span class="function"><span class="params">                splits=<span class="number">5</span>, repeats=<span class="number">5</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取数据</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(y)==<span class="number">0</span>:</span><br><span class="line">        X,y = get_trainning_data_omitoutliers()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 交叉验证</span></span><br><span class="line">    rkfold = RepeatedKFold(n_splits=splits, n_repeats=repeats)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 网格搜索最佳参数</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(param_grid)&gt;<span class="number">0</span>:</span><br><span class="line">        gsearch = GridSearchCV(model, param_grid, cv=rkfold,</span><br><span class="line">        scoring=<span class="string">&quot;neg_mean_squared_error&quot;</span>,</span><br><span class="line">        verbose=<span class="number">1</span>, return_train_score=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        gsearch.fit(X,y)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 最好的模型</span></span><br><span class="line">        model = gsearch.best_estimator_</span><br><span class="line">        best_idx = gsearch.best_index_</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取交叉验证评价指标</span></span><br><span class="line">        grid_results = pd.DataFrame(gsearch.cv_results_)</span><br><span class="line">        cv_mean = <span class="built_in">abs</span>(grid_results.loc[best_idx,<span class="string">&#x27;mean_test_score&#x27;</span>])</span><br><span class="line">        cv_std = grid_results.loc[best_idx,<span class="string">&#x27;std_test_score&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 没有网格搜索</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        grid_results = []</span><br><span class="line">        cv_results = cross_val_score(model, X, y, scoring=<span class="string">&quot;neg_mean_squared_error&quot;</span>, cv=rkfold)</span><br><span class="line">        cv_mean = <span class="built_in">abs</span>(np.mean(cv_results))</span><br><span class="line">        cv_std = np.std(cv_results)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 合并数据</span></span><br><span class="line">    cv_score = pd.Series(&#123;<span class="string">&#x27;mean&#x27;</span>:cv_mean,<span class="string">&#x27;std&#x27;</span>:cv_std&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测</span></span><br><span class="line">    y_pred = model.predict(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型性能的统计数据</span></span><br><span class="line">    print(<span class="string">&#x27;----------------------&#x27;</span>)</span><br><span class="line">    print(model)</span><br><span class="line">    print(<span class="string">&#x27;----------------------&#x27;</span>)</span><br><span class="line">    print(<span class="string">&#x27;score=&#x27;</span>,model.score(X,y))</span><br><span class="line">    print(<span class="string">&#x27;rmse=&#x27;</span>,rmse(y, y_pred))</span><br><span class="line">    print(<span class="string">&#x27;mse=&#x27;</span>,mse(y, y_pred))</span><br><span class="line">    print(<span class="string">&#x27;cross_val: mean=&#x27;</span>,cv_mean,<span class="string">&#x27;, std=&#x27;</span>,cv_std)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 残差分析与可视化</span></span><br><span class="line">    y_pred = pd.Series(y_pred,index=y.index)</span><br><span class="line">    resid = y - y_pred</span><br><span class="line">    mean_resid = resid.mean()</span><br><span class="line">    std_resid = resid.std()</span><br><span class="line">    z = (resid - mean_resid)/std_resid</span><br><span class="line">    n_outliers = <span class="built_in">sum</span>(<span class="built_in">abs</span>(z)&gt;<span class="number">3</span>)</span><br><span class="line">    outliers = z[<span class="built_in">abs</span>(z)&gt;<span class="number">3</span>].index</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model, cv_score, grid_results</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV, RepeatedKFold, cross_val_score,cross_val_predict,KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练变量存储数据</span></span><br><span class="line">opt_models = <span class="built_in">dict</span>()</span><br><span class="line">score_models = pd.DataFrame(columns=[<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;std&#x27;</span>])</span><br><span class="line">splits=<span class="number">5</span></span><br><span class="line">repeats=<span class="number">5</span></span><br><span class="line"></span><br><span class="line">model = <span class="string">&#x27;Ridge&#x27;</span></span><br><span class="line">opt_models[model] = Ridge()</span><br><span class="line">alph_range = np.arange(<span class="number">0.25</span>,<span class="number">6</span>,<span class="number">0.25</span>)</span><br><span class="line">param_grid = &#123;<span class="string">&#x27;alpha&#x27;</span>: alph_range&#125;</span><br><span class="line"></span><br><span class="line">opt_models[model],cv_score,grid_results = train_model(opt_models[model],</span><br><span class="line">                    param_grid=param_grid, splits=splits, repeats=repeats)</span><br><span class="line"></span><br><span class="line">cv_score.name = model</span><br><span class="line">score_models = score_models.append(cv_score)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.errorbar(alph_range, <span class="built_in">abs</span>(grid_results[<span class="string">&#x27;mean_test_score&#x27;</span>]),</span><br><span class="line">        <span class="built_in">abs</span>(grid_results[<span class="string">&#x27;std_test_score&#x27;</span>])/np.sqrt(splits*repeats))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;alpha&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;score&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>Fitting 25 folds for each of 23 candidates, totalling 575 fits
----------------------
Ridge(alpha=0.25)
----------------------
score= 0.8914965873982021
rmse= 0.32638045120253134
mse= 0.1065241989271679
cross_val: mean= 0.11019851747204477 , std= 0.006413351282774973

Text(0, 0.5, &#39;score&#39;)</code></pre>
<p><img src="https://z3.ax1x.com/2021/05/22/gLj4qf.png" /></p>
<ul>
<li><p>Forecasting function</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 预测函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_predict</span>(<span class="params">test_data,test_y=[]</span>):</span></span><br><span class="line">    i=<span class="number">0</span></span><br><span class="line">    y_predict_total=np.zeros((test_data.shape[<span class="number">0</span>],))</span><br><span class="line">    <span class="keyword">for</span> model <span class="keyword">in</span> opt_models.keys():</span><br><span class="line">        <span class="keyword">if</span> model!=<span class="string">&quot;LinearSVR&quot;</span> <span class="keyword">and</span> model!=<span class="string">&quot;KNeighbors&quot;</span>:</span><br><span class="line">            y_predict=opt_models[model].predict(test_data)</span><br><span class="line">            y_predict_total+=y_predict</span><br><span class="line">            i+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(test_y)&gt;<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">&quot;&#123;&#125;_mse:&quot;</span>.<span class="built_in">format</span>(model),mean_squared_error(y_predict,test_y))</span><br><span class="line"></span><br><span class="line">    y_predict_mean=np.<span class="built_in">round</span>(y_predict_total/i,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(test_y)&gt;<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">&quot;mean_mse:&quot;</span>,mean_squared_error(y_predict_mean,test_y))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y_predict_mean=pd.Series(y_predict_mean)</span><br><span class="line">        <span class="keyword">return</span> y_predict_mean</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="预测并保存结果">3.3 预测并保存结果</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_ = model_predict(test)</span><br><span class="line">y_.to_csv(<span class="string">&#x27;predict.txt&#x27;</span>,header = <span class="literal">None</span>,index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>DataWhale</category>
        <category>Ensemble</category>
        <category>Cases</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Ensemble</tag>
        <tag>Sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title>Eviews notes</title>
    <url>/2020/11/22/Eviews/</url>
    <content><![CDATA[<h1 id="create-workfile">1 Create workfile</h1>
<p>Eviews 10 创建时间序列工作文件，界面如下</p>
<p><img src="https://s3.ax1x.com/2020/11/25/DUNDeA.png" /></p>
<center>
figure 1-1 时间序列类型
</center>
<p>参数释义为：</p>
<a id="more"></a>
<ul>
<li>Annual：年度数据</li>
<li>Semi-annual：半年(2010S1 - 2019S1)</li>
<li>Quarteryly：季度 （2010Q3 - 2019Q2）</li>
<li>Monthly：月度（2010M01 - 2019M11）</li>
<li>Bimonthly：半月（2010-3-01 - 2019-8-8）</li>
<li>Fortnightly：两周</li>
<li>Daily-custom week：用户自定义选择周几</li>
<li>Intraday：当日数据，精确到每天每隔多少时间</li>
<li>Integer data：可以是年度（eg：2001 - 2012），也可以是哪一期（eg：3 - 33）</li>
</ul>
<p>创建平衡面板数据：</p>
<p><img src="https://s3.ax1x.com/2020/11/25/DUN0Ld.png" /></p>
<center>
figure 1-2 平衡面板数据
</center>
<h1 id="least-squares最小二乘法">2 Least Squares（最小二乘法）</h1>
<p>Command中输入 <code>ls y c x</code>即可得到如下结果：</p>
<p><img src="https://s3.ax1x.com/2020/11/25/DUNrdI.md.png" /></p>
<center>
figure 1-3 Parameters
</center>
<p>Parameters:</p>
<ul>
<li>Coefficient：系数，参数估计值</li>
<li>Std. Error：参数估计量标准差估计值</li>
<li>t-Statistic：<span class="math inline">\(t\)</span> 统计量的值</li>
<li>Prob: <span class="math inline">\(P\)</span> 值</li>
<li>R-squared: $ R^2$</li>
<li>Adjusted R-squared: $^ - $</li>
<li>S.E. of regression: <span class="math inline">\(\sigma ^2\)</span></li>
<li>Sum squared resid: $ RSS$，残差平方和</li>
<li>Mean dependent var: <span class="math inline">\(\overset{-}{Y}\)</span>，被解释变量的均值</li>
<li>S.D. dependent var: 被解释变量的标准差</li>
</ul>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Software</category>
      </categories>
      <tags>
        <tag>Eviews</tag>
        <tag>Software</tag>
      </tags>
  </entry>
  <entry>
    <title>Git notes</title>
    <url>/2020/11/22/Git-notes/</url>
    <content><![CDATA[<h1 id="版本控制">1. 版本控制</h1>
<h2 id="版本控制迭代">1.1 版本控制（迭代）</h2>
<p>版本控制（Revision control）是一种在开发的过程中用于管理我们对文件、目录或工程等内容的修改历史，方便查看更改历史记录，备份以便恢复以前的版本的软件工程技术。</p>
<ul>
<li>实现跨区域多人协同开发</li>
<li>追踪和记载一个或者多个文件的历史记录</li>
<li>组织和保护你的源代码和文档</li>
<li>统计工作量</li>
<li>并行开发、提高开发效率</li>
<li>跟踪记录整个软件的开发过程</li>
<li>减轻开发人员的负担，节省时间，同时降低人为错误</li>
</ul>
<a id="more"></a>
<h2 id="版本控制工具">1.2 版本控制工具</h2>
<h3 id="主流的版本控制器">1.2.1 主流的版本控制器：</h3>
<ul>
<li><strong>Git</strong></li>
<li><strong>SVN</strong>（Subversion）</li>
<li><strong>CVS</strong>（Concurrent Versions System）</li>
<li><strong>VSS</strong>（Micorosoft Visual SourceSafe）</li>
<li><strong>TFS</strong>（Team Foundation Server）</li>
<li>Visual Studio Online</li>
</ul>
<h3 id="版本控制分类">1.2.2 版本控制分类</h3>
<ul>
<li>本地版本控制：RCS</li>
</ul>
<blockquote>
<p><img src="https://s3.ax1x.com/2020/11/25/DauN11.png" /></p>
</blockquote>
<center>
图 1-1 本地版本控制
</center>
<ul>
<li>集中版本控制：SVN</li>
</ul>
<p><img src="https://s3.ax1x.com/2020/11/25/Dauu60.png" /></p>
<center>
图 1-2 集中版本控制
</center>
<ul>
<li>分布式版本控制：Git</li>
</ul>
<p><img src="https://s3.ax1x.com/2020/11/25/DauZfs.md.jpg" /></p>
<center>
图 1-3 分布式版本控制
</center>
<h3 id="git-与-svn-的区别">1.2.3 Git 与 SVN 的区别</h3>
<blockquote>
<ul>
<li><p>SVN是集中式版本控制系统，版本库集中放在中央服务器的，工作时，需要从中央服务器得到最新的版本，完成工作后，把做完的活推送到中央服务器。集中式版本控制系统是必须联网才能工作，对网络带宽要求较高。</p></li>
<li><p>Git是分布式版本控制系统，没有中央服务器，每个人的电脑就是一个完整的版本库</p></li>
</ul>
</blockquote>
<h1 id="git-环境配置">2. Git 环境配置</h1>
<h2 id="git配置">2.1 Git配置</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">git config -l</span><br><span class="line"><span class="comment"># 查看配置</span></span><br><span class="line"></span><br><span class="line">git config --system --<span class="built_in">list</span></span><br><span class="line"><span class="comment"># 系统配置</span></span><br><span class="line"></span><br><span class="line">git config --<span class="keyword">global</span> --<span class="built_in">list</span></span><br><span class="line"><span class="comment"># 查看当前用户 (global) 配置</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Git 相关的配置文件</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">D:\Program files\Git\Git\etc：</span><br><span class="line"><span class="comment"># Git 安装目录下的 gitconfig --system 系统级</span></span><br><span class="line"></span><br><span class="line">C:\Users\YangSu\.gitconfig</span><br><span class="line"><span class="comment">#  只适用于当前登录用户的配置  --global 全局</span></span><br><span class="line"></span><br><span class="line">git config --<span class="keyword">global</span> user.name <span class="string">&quot;YS&quot;</span> <span class="comment">#名称</span></span><br><span class="line">git config --<span class="keyword">global</span> user.email num@qq.com   <span class="comment"># 邮箱</span></span><br></pre></td></tr></table></figure>
<h1 id="git-基本理论">3. Git 基本理论</h1>
<h2 id="工作区域">3.1 工作区域</h2>
<blockquote>
<p>四个工作区域：</p>
<ul>
<li>工作目录 (Working Directory)</li>
<li>暂存区 (Stage / Index)</li>
<li>资源库 (Repository 或 Git Directory)</li>
<li>远程 Git 仓库 (Remote Directory)</li>
</ul>
</blockquote>
<p><img src="https://s3.ax1x.com/2020/11/25/Daunlq.png" /></p>
<center>
图 1-4 工作区域（核心）
</center>
<ul>
<li>Workspace：工作区，就是你平时存放项目代码的地方</li>
<li>Index / Stage：暂存区，用于临时存放你的改动，事实上它只是一个文件，保存即将提交到文件列表信息</li>
<li>Repository：仓库区（或本地仓库），就是安全存放数据的位置，这里面有你提交到所有版本的数据。其中HEAD指向最新放入仓库的版本</li>
<li>Remote：远程仓库，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换</li>
</ul>
<p>本地的三个区域确切的说应该是git仓库中HEAD指向的版本：</p>
<p><img src="https://s3.ax1x.com/2020/11/25/Daumpn.png" /></p>
<center>
图 1-5 Git示意图
</center>
<ul>
<li>Directory：使用Git管理的一个目录，也就是一个仓库，包含我们的工作空间和Git的管理空间。</li>
<li>WorkSpace：需要通过Git进行版本控制的目录和文件，这些目录和文件组成了工作空间。</li>
<li>.git：存放Git管理信息的目录，初始化仓库的时候自动创建。</li>
<li>Index/Stage：暂存区，或者叫待提交更新区，在提交进入repo之前，我们可以把所有的更新放在暂存区。</li>
<li>Local Repo：本地仓库，一个存放在本地的版本库；HEAD会只是当前的开发分支（branch）。</li>
<li>Stash：隐藏，是一个工作状态保存栈，用于保存/恢复WorkSpace中的临时状态。</li>
</ul>
<h2 id="工作流程">3.2 工作流程</h2>
<ol type="1">
<li>在工作目录中添加、修改文件；</li>
<li>将需要进行版本管理的文件放入暂存区域；</li>
<li>将暂存区域的文件提交到git仓库。</li>
</ol>
<p>因此，git管理的文件有三种状态：已修改（modified）,已暂存（staged）,已提交(committed)</p>
<p><img src="https://s3.ax1x.com/2020/11/25/DauKXV.jpg" /></p>
<center>
1-6 工作流程
</center>
<h1 id="项目搭建">4. 项目搭建</h1>
<h2 id="创建工作目录">4.1 创建工作目录</h2>
<p>工作目录（WorkSpace)一般就是你希望Git帮助你管理的文件夹，可以是你项目的目录，也可以是一个空目录，建议不要有中文。</p>
<p><img src="https://s3.ax1x.com/2020/11/25/DauQmT.png" /></p>
<center>
1-7 常用命令
</center>
<h2 id="创建本地仓库">4.2 创建本地仓库</h2>
<ul>
<li>创建全新的仓库</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在当前目录新建一个Git代码库</span></span><br><span class="line">$ git init</span><br><span class="line"><span class="comment"># 执行后，项目目录多出了一个.git目录</span></span><br></pre></td></tr></table></figure>
<ul>
<li>克隆远程仓库</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 克隆一个项目和它的整个代码历史(版本信息)</span></span><br><span class="line">$ git clone [url]  </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">从 gitee 或 github 中克隆</span></span><br><span class="line"><span class="string">https://gitee.com/kuangstudy/openclass.git</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h1 id="git-文件操作">5. Git 文件操作</h1>
<h2 id="文件的四种状态">5.1 文件的四种状态</h2>
<ul>
<li>Untracked: 未跟踪, 此文件在文件夹中, 但并没有加入到git 库, 不参与版本控制. 通过 git add 状态变为 Staged.</li>
<li>Unmodify: 文件已经入库, 未修改, 即版本库中的文件快照内容与文件夹中完全一致. 这种类型的文件有两种去处, 如果它被修改, 而变为 Modified. 如果使用git rm移出版本库, 则成为 Untracked 文件</li>
<li>Modified: 文件已修改, 仅仅是修改, 并没有进行其他的操作. 这个文件也有两个去处, 通过git add可进入暂存staged状态, 使用git checkout 则丢弃修改过, 返回到unmodify状态, 这个git checkout即从库中取出文件, 覆盖当前修改 !</li>
<li>Staged: 暂存状态. 执行git commit则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为Unmodify状态. 执行git reset HEAD filename取消暂存, 文件状态为Modified</li>
</ul>
<h2 id="查看文件状态">5.2 查看文件状态</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">touch hello.py</span><br><span class="line"></span><br><span class="line">git status hello.py <span class="comment"># 产看指定文件状态</span></span><br><span class="line">git status <span class="comment"># 查看所有文件状态</span></span><br><span class="line"></span><br><span class="line">git add hello.py <span class="comment"># 添加指定文件到暂存区</span></span><br><span class="line">git add . <span class="comment"># 添加所有文件到暂存区 (repository)</span></span><br><span class="line"></span><br><span class="line">git rm --cached hello.py <span class="comment"># 将文件从暂存区移除</span></span><br><span class="line">git restore -staged add.py <span class="comment"># 将文件从暂存区移除</span></span><br><span class="line"></span><br><span class="line">git commit -m <span class="string">&quot;a new file named hello.py&quot;</span> </span><br><span class="line"><span class="comment"># 提交暂存区内容至本地仓库</span></span><br><span class="line"></span><br><span class="line">git push -u origin master -f</span><br><span class="line"><span class="comment"># 第一次使用push的时候加上-u,以后可不加，-f强制上传</span></span><br></pre></td></tr></table></figure>
<h2 id="忽略文件">5.3 忽略文件</h2>
<p>有些时候我们不想把某些文件纳入版本控制中，比如数据库文件，临时文件，设计文件等</p>
<p>在主目录下建立".gitignore"文件，此文件有如下规则：</p>
<ul>
<li>忽略文件中的空行或以井号（#）开始的行将会被忽略。</li>
<li>可以使用Linux通配符。例如：星号（*）代表任意多个字符，问号（？）代表一个字符，方括号（[abc]）代表可选字符范围，大括号（{string1,string2,...}）代表可选的字符串等。</li>
<li>如果名称的最前面有一个感叹号（!），表示例外规则，将不被忽略。</li>
<li>如果名称的最前面是一个路径分隔符（/），表示要忽略的文件在此目录下，而子目录中的文件不忽略。</li>
<li>如果名称的最后面是一个路径分隔符（/），表示要忽略的是此目录下该名称的子目录，而非文件（默认文件或目录都忽略）。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为注释</span></span><br><span class="line">*.txt  <span class="comment"># 忽略.txt结尾的文件,上传时不会被选中！</span></span><br><span class="line">!lib.txt     <span class="comment"># 但lib.txt除外</span></span><br><span class="line">/temp        <span class="comment">#仅忽略项目根目录下的TODO文件,不包括其它目录temp</span></span><br><span class="line">build/       <span class="comment">#忽略build/目录下的所有文件</span></span><br><span class="line">doc/*.txt    <span class="comment">#忽略doc/notes.txt 但不包括 doc/server/arch.txt</span></span><br></pre></td></tr></table></figure>
<h1 id="使用码云">6. 使用码云</h1>
<blockquote>
<p>github 是有墙的，比较慢，国内一般用 gitee</p>
</blockquote>
<h2 id="设置免密码登录">6.1 设置免密码登录</h2>
<ol type="1">
<li><p>设置本机绑定SSH公钥，实现免密码登录！</p>
<p>免密码登录，这一步挺重要的，码云是远程仓库，我们是平时工作在本地仓库！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入 C:\Users\YangSu\.ssh 目录</span></span><br><span class="line"><span class="comment"># 生成公钥</span></span><br><span class="line">ssh-keygen -t rsa <span class="comment"># 加密算法</span></span><br></pre></td></tr></table></figure></li>
<li><p>将公钥信息public key 添加到码云账户中</p>
<p>密钥信息存储在 id_rsa.pub 文件中</p></li>
<li><p>使用 gitee 创建一个自己的仓库</p>
<p><strong>许可证：</strong>开源是否可以随意转载，开源但是不能商业使用，不能转载，... 限制！</p></li>
</ol>
<h2 id="添加远程库">7.2 添加远程库</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">git remote add origin https://gitee.com/yangsuoly/GitStudy.git</span><br><span class="line"><span class="comment"># 添加远程库, HTTPS方式，ssh可以免密</span></span><br><span class="line"></span><br><span class="line">git remote -v <span class="comment"># 查看 clone 的地址</span></span><br><span class="line">git remote rm origin <span class="comment"># 移除远程库地址</span></span><br><span class="line">git remote add origin git@gitee.com:yangsuoly/GitStudy.git <span class="comment"># 添加远程库地址，SSH方式</span></span><br><span class="line"></span><br><span class="line">cat /c/Users/YangSu/.ssh/id_rsa.pub <span class="comment"># 查看公玥</span></span><br><span class="line">    </span><br><span class="line">git push -u origin master -f <span class="comment"># 首次使用</span></span><br><span class="line">git push <span class="comment"># 之后</span></span><br></pre></td></tr></table></figure>
<h1 id="git-分支">8. Git 分支</h1>
<h2 id="git-常用指令">8.1 Git 常用指令</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 列出所有本地分支</span></span><br><span class="line">git branch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有远程分支</span></span><br><span class="line">git branch -r</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个分支，但依然停留在当前分支</span></span><br><span class="line">git branch [branch-name]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个分支，并切换到该分支</span></span><br><span class="line">git checkout -b [branch]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并指定分支到当前分支</span></span><br><span class="line">$ git merge [branch]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除分支</span></span><br><span class="line">$ git branch -d [branch-name]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除远程分支</span></span><br><span class="line">$ git push origin --delete [branch-name]</span><br><span class="line">$ git branch -dr [remote/branch]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Notes</category>
        <category>OS</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Group-Pictures</title>
    <url>/2020/12/02/Group-Pictures/</url>
    <content><![CDATA[<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://s3.ax1x.com/2020/11/30/DgWRZ6.png" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://s3.ax1x.com/2020/11/30/DgWA8H.png" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img src="https://s3.ax1x.com/2020/11/30/DgWA8H.png" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://s3.ax1x.com/2020/11/30/DgWA8H.png" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://s3.ax1x.com/2020/11/30/DgWA8H.png" /></div></div></div></div>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Pics</tag>
      </tags>
  </entry>
  <entry>
    <title>Latex</title>
    <url>/2021/01/19/Latex/</url>
    <content><![CDATA[<h1 id="recognize-latex">1 Recognize <span class="math inline">\(\LaTeX\)</span></h1>
<p>通过更换文档类型，可以正确显示中文。</p>
<a id="more"></a>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% English environment, can&#x27;t display chinese</span></span><br><span class="line"><span class="keyword">\documentclass</span>&#123;article&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">\begin</span>&#123;article&#125;</span><br><span class="line">	This is my first document.</span><br><span class="line"></span><br><span class="line">	Happy <span class="keyword">\TeX</span> ing!</span><br><span class="line"></span><br><span class="line"><span class="keyword">\end</span>&#123;article&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">%---------------------------</span></span><br><span class="line"><span class="comment">% below is chinese environment</span></span><br><span class="line"><span class="keyword">\documentclass</span>[UTF8]&#123;ctexart&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">\begin</span>&#123;document&#125;</span><br><span class="line">	<span class="keyword">\section</span>&#123;文字&#125;</span><br><span class="line">	测试文字。</span><br><span class="line">	<span class="keyword">\section</span>&#123;数学&#125;</span><br><span class="line">	<span class="keyword">\[</span></span><br><span class="line">		a<span class="built_in">^</span>2 + b<span class="built_in">^</span>2 = c<span class="built_in">^</span>2</span><br><span class="line">	<span class="keyword">\]</span></span><br><span class="line"><span class="keyword">\end</span>&#123;document&#125;</span><br></pre></td></tr></table></figure>
<h2 id="从一个例子说起">1.1 从一个例子说起</h2>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% -*- coding:UTF-8 -*-</span></span><br><span class="line"><span class="comment">% gougu.tex</span></span><br><span class="line"><span class="comment">% 勾股定理</span></span><br><span class="line"><span class="keyword">\documentclass</span>[UTF8]&#123;ctexart&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">\title</span>&#123;杂谈勾股定理&#125;</span><br><span class="line"><span class="keyword">\author</span>&#123;张三&#125;</span><br><span class="line"><span class="keyword">\date</span>&#123;<span class="keyword">\today</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">\bibliographystyle</span>&#123;plain&#125; <span class="comment">% 声明参考文献的格式</span></span><br><span class="line"><span class="comment">% 导言区（preamble），对文档的性质做一些设置，或者自定义一些命令</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">\begin</span>&#123;document&#125;</span><br><span class="line">	<span class="keyword">\maketitle</span> <span class="comment">% 输出论文标题</span></span><br><span class="line">	<span class="keyword">\begin</span>&#123;abstract&#125;</span><br><span class="line">		这是一篇关于沟谷定理的小短文。</span><br><span class="line">	<span class="keyword">\end</span>&#123;abstract&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">\tableofcontents</span> <span class="comment">% 输出目录</span></span><br><span class="line">	<span class="keyword">\section</span>&#123;勾股定理在古代&#125;</span><br><span class="line">	西方称勾股定理为<span class="keyword">\emph</span>&#123;毕达哥拉斯定理&#125;，将勾股定理的发现归功于公元前 6 世纪的毕达哥拉斯学派。该学派得到了一个法则，可以求出可排成直角三角形三边的三元数组。毕达哥拉斯学派没有书面著作，该定理的严格表述和证明则见于欧几里德<span class="keyword">\footnote</span>&#123;欧几里得，约公元前 330--275年。&#125;《几何原本》的命题 47：“直角三角形斜边上的正方形等于两直角边上的两个正方形之和。”证明是用面积做的。</span><br><span class="line"></span><br><span class="line">	我国《周髀算经》载商高（约公元前 2 世纪）答周公问⋯⋯</span><br><span class="line"></span><br><span class="line">	<span class="comment">% 引用环境</span></span><br><span class="line">	<span class="keyword">\begin</span>&#123;quote&#125;</span><br><span class="line">		<span class="keyword">\zihao</span>&#123;-5&#125;<span class="keyword">\kaishu</span> 引用的内容 <span class="comment">% 小五号楷书</span></span><br><span class="line">	<span class="keyword">\end</span>&#123;quote&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">\section</span>&#123;勾股定理的近代形式&#125;</span><br><span class="line">	<span class="keyword">\bibliography</span>&#123;math&#125; <span class="comment">% 从文献数据库 math 中获取文献信息，打印文献列表</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">\end</span>&#123;document&#125;</span><br></pre></td></tr></table></figure>
<p>整个文章的框架为：</p>
<ul>
<li>前面以百分号 <code>%</code> 开头的行是注释，TeXStudio 中的多行注释快捷键为<code>ctrl</code>+<code>T</code>，取消多行注释快捷键为<code>ctrl</code>+<code>U</code></li>
<li>第 4 行是文档类，中文短文所以使用 ctexart，并用 [UTF8] 说明编码</li>
<li>第 6-8 行声明了整个文章的标题、作者和写作日期，这些信息通过<code>\maketitle</code>出现在排版中</li>
<li><code>\bibliographstyle</code>声明参考文献的格式</li>
</ul>
<p>以上<code>\begin&#123;document&#125;</code>之前的部分为导言区（preamble），导言区用来对文档的性质做一些设置，或自定义一些命令</p>
<ul>
<li><p><code>\begin&#123;document&#125;</code>和<code>\end&#123;document&#125;</code>声明了一个 document 环境，里面是论文的正文部分，也就是直接输出的部分。</p></li>
<li><p><code>\tableofcontents</code>命令输出目录</p></li>
<li><p><code>\bibliography&#123;math&#125;</code>提示 <span class="math inline">\(\TeX\)</span> 从文献数据库 math 中获取文献信息，打印参考文献列表</p></li>
<li><p>为了格式上的清晰，源文件中适当使用了一些空行作为分隔，在正文外的部分，空行不表示任何意义。</p></li>
<li><p>通常汉字后的空格会被忽略，其他符号后面的空格会被保留</p></li>
</ul>
<h2 id="command-and-enviroment">1.2 Command and Enviroment</h2>
<ul>
<li><p><strong>Command</strong></p>
<ul>
<li><code>\footnote</code>：脚注</li>
<li><code>\emph&#123;Text&#125;</code>：强调</li>
<li><code>\zihao&#123;number&#125;</code>：字号</li>
<li><code>\qquad</code>：产生<code>2 em</code>（大约 2 个 ’M‘ 的宽度）的空白</li>
</ul></li>
<li><p><strong>Environment</strong></p>
<p>格式为</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;envi name&#125;</span><br><span class="line">	&lt; content &gt;</span><br><span class="line"><span class="keyword">\end</span>&#123;envi name&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>quote</code>：引用环境</li>
<li><code>abstract</code>：摘要环境</li>
<li><code>euqation</code>：公式环境</li>
</ul>
<p>特殊环境</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\newtheorem</span>&#123;thm&#125;&#123;定理&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;thm&#125;[勾股定理]</span><br><span class="line">	直角三角形斜边的平方等于两腰的平方和。</span><br><span class="line"></span><br><span class="line">	可以用符号语言表述为……</span><br><span class="line"><span class="keyword">\end</span>&#123;thm&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="graph">1.3 graph</h2>
<p><code>\includegraphics[width]&#123;pic_dir&#125;</code>：插图</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;center&#125;</span><br><span class="line">	<span class="comment">% Requires \usepackage&#123;graphicx&#125;</span></span><br><span class="line">	<span class="keyword">\includegraphics</span>[width=0.9<span class="keyword">\textwidth</span>]&#123;pic<span class="built_in">_</span>dir&#125;</span><br><span class="line">	<span class="comment">% Requires \usepackage&#123;caption&#125;</span></span><br><span class="line">	<span class="keyword">\captionsetup</span>&#123;font=small&#125;</span><br><span class="line">	<span class="keyword">\captionsetup</span>&#123;labelsep=quad&#125;</span><br><span class="line">	<span class="keyword">\captionof</span>&#123;figure&#125;&#123;WTI crude oil price&#125;</span><br><span class="line">	<span class="keyword">\label</span>&#123;fig:WTI&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;center&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 可选参数 ht，表明浮动体可以出现在周围文本所在处（here）或一页顶部（top）</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[ht]</span><br><span class="line">	<span class="keyword">\centering</span></span><br><span class="line">	<span class="keyword">\includegraphics</span>[width=0.9<span class="keyword">\textwidth</span>]&#123;pic<span class="built_in">_</span>dir&#125;</span><br><span class="line">	<span class="keyword">\captionsetup</span>&#123;font=small&#125;</span><br><span class="line">	<span class="keyword">\captionsetup</span>&#123;labelsep=quad&#125;</span><br><span class="line">	<span class="keyword">\captionof</span>&#123;figure&#125;&#123;WTI crude oil price&#125;</span><br><span class="line">	<span class="keyword">\label</span>&#123;fig:WTI&#125; <span class="comment">% 给图形定义标签，使用这个标签可以再文章其他地方引用</span></span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure>
<p>插入的图形就是一个有内容的矩形盒子，在正文中和一个很大的字符没有区别。除了一些很小的标志图形，一般很少把插图直接夹在文字之中，而是使用可以变动相对位置的环境列出，称为浮动体（float）</p>
<h2 id="table">1.4 Table</h2>
<p>表格与<code>\includegraphics</code>命令得到的插图一样，都是比较大的盒子。一般也放在浮动环境<code>table</code>中</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 参数 H 表示 ‘就放在这里，不浮动’，需要 \usepackage&#123;float&#125;</span></span><br><span class="line">下表列出了一些较小的勾股数：</span><br><span class="line"><span class="keyword">\begin</span>&#123;table&#125;[h]</span><br><span class="line">	<span class="keyword">\centering</span></span><br><span class="line">	<span class="keyword">\begin</span>&#123;tabular&#125;&#123;|c|c|c|&#125;</span><br><span class="line">		<span class="keyword">\hline</span></span><br><span class="line">		直角边 <span class="built_in">$</span>a<span class="built_in">$</span> <span class="built_in">&amp;</span> 直角边 <span class="built_in">$</span>b<span class="built_in">$</span> <span class="built_in">&amp;</span> 斜边 <span class="built_in">$</span>c<span class="built_in">$</span> <span class="keyword">\\</span></span><br><span class="line">		<span class="keyword">\hline</span></span><br><span class="line">		3 <span class="built_in">&amp;</span> 		4 <span class="built_in">&amp;</span>		5 <span class="keyword">\\</span></span><br><span class="line">		5 <span class="built_in">&amp;</span>		 	12 <span class="built_in">&amp;</span>	13 <span class="keyword">\\</span></span><br><span class="line">		<span class="keyword">\hline</span>			</span><br><span class="line">    <span class="keyword">\end</span>&#123;tabular&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125;</span><br></pre></td></tr></table></figure>
<p><code>tabular</code>环境有一个参数，里面声明了表格中列的模式：</p>
<ul>
<li><code>|c|c|c|</code>：三列，居中对其，不同列数据用表格线隔开</li>
<li><code>\\</code>：表格换行，内部不同数据单元用<code>&amp;</code>分隔</li>
<li><code>\hline</code>：横向表格线</li>
</ul>
<p>上表和正文是直接连在一起，不允许浮动，这里本来不应该使用浮动<code>table</code>环境的，但仍然使用了<code>table</code>环境，在表示位置的参数处使用了<code>[H]</code>，表示 “就放在这里，不浮动”，该参数是 <code>float</code>宏包提供的功能，需要在导言区使用<code>\usepackage&#123;float&#125;</code>。</p>
<h2 id="bibliography">1.5 Bibliography</h2>
<p>BibTeX 是专用于处理 $ $ 文档文献列表的程序，此时编译<code>test.tex</code>文档时运行程序四次：</p>
<ul>
<li>xelatex test.tex</li>
<li>bibtex test.tex</li>
<li>xelatex test.tex</li>
<li>xelatex test.tex</li>
</ul>
<p>正文中通过用命令<code>\cite&#123;label&#125;</code>引用文献，使用<code>\cite</code>命令会在引用的位置显示文献在列表中的编号，同时在辅助文件中说明文献将被引用。</p>
<p>如果要在列表中显示并不直接引用的文献，可以使用<code>\nocite</code>命令，一般是放在<code>\bibliography&#123;name&#125;</code>之前</p>
<p><strong>引用不仅局限于文献，图表、、公式的编号，只要事先设定了 label，同样可以通过<code>\ref</code>进行引用。实际中引用公式非常常用，数学宏包 <code>amsmath</code>就定义了<code>\eqref</code>命令，专用于公式的引用，并能产生括号。</strong></p>
<h2 id="设计文章格式">1.6 设计文章格式</h2>
<ul>
<li>设计页面尺寸可以使用<code>geometry</code>宏包</li>
</ul>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>&#123;geometry&#125;</span><br><span class="line"><span class="keyword">\geometry</span>&#123;a6paper,centering,scale=0.8&#125;</span><br><span class="line"><span class="comment">% 定义页面为 A6 纸大小，版心居中，长宽占页面的 0.8 倍</span></span><br></pre></td></tr></table></figure>
<ul>
<li>改变图表标题格式可以使用 <code>caption</code>宏包</li>
</ul>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>[format=hang,font=small.textfont=it]&#123;caption&#125;</span><br><span class="line"><span class="comment">% 设定图表标题使用悬挂式对齐方式（即编号向左突出），整体用小字号，而标题文本使用斜体（对汉字来说是楷书）</span></span><br></pre></td></tr></table></figure>
<ul>
<li>增加目录的项目可以用 <code>tocbibind</code>宏包</li>
</ul>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>[nottoc]&#123;tocbibind&#125;</span><br><span class="line"><span class="comment">% 默认会在目录中加入目录项本身、参考文献、索引等项目，使用 nottoc 选项取消了在目录中显示本身</span></span><br></pre></td></tr></table></figure>
<ul>
<li>标题和作者的字体更改：</li>
</ul>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\title</span>&#123;<span class="keyword">\heiti</span> 杂谈勾股定理&#125; <span class="comment">% 黑体</span></span><br><span class="line"><span class="keyword">\author</span>&#123;<span class="keyword">\kaishu</span> 张三&#125; <span class="comment">% 楷书</span></span><br><span class="line"><span class="keyword">\date</span>&#123;<span class="keyword">\today</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>修改 <code>quote</code>环境字体</li>
</ul>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\newenviroment</span>&#123;myquote&#125;</span><br><span class="line">&#123;<span class="keyword">\begin</span>&#123;quote&#125;<span class="keyword">\kaishu</span><span class="keyword">\zihao</span>&#123;-5&#125;&#125;</span><br><span class="line">&#123;<span class="keyword">\end</span>&#123;quote&#125;&#125;</span><br><span class="line"><span class="comment">% myquote 包含三个参数，第一个为环境名名字，后两个分别是在环境开始和末尾处的代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">\newcommand</span><span class="keyword">\degree</span>&#123;<span class="built_in">^</span><span class="keyword">\circ</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>取消连字（ligature）</p>
<p><span class="math inline">\(\LaTeX\)</span> 在排版中会将单词中的一些字母连写为一个字符，连字的有无和多少一般由使用的字体决定，偶尔出于美观的考虑，需要取消连字，可以用空的分组，或借用<code>\/</code>命令：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">shelfful shelf&#123;&#125;ful shelf<span class="keyword">\/</span>ful</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="organize-article">2 Organize article</h1>
<h2 id="标点">2.1 标点</h2>
<ul>
<li><p>引号 `<code></code> 和 <code>'</code></p>
<p>引号在 <span class="math inline">\(\LaTeX\)</span> 中使用 `<code></code> （左引号）或 <code>'</code>（右引号 表示，如果遇到单引号和双引号连续出现的情况，则在中间用<code>\</code> ,命令分开：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">``<span class="keyword">\,</span>`a&#x27; and `b&#x27;<span class="keyword">\,</span>&#x27;&#x27;</span><br></pre></td></tr></table></figure>
<p><code>\</code>, 命令会产生很小的间隔</p></li>
<li><p>减号<code>-</code></p>
<p><code>-</code> 在 <span class="math inline">\(\LaTeX\)</span> 正文中有多种用途</p>
<ul>
<li><p><code>-</code>：连字符（hyphen）</p></li>
<li><p><code>--</code>： en dash，用来表示数字范围，但按照中文的协作习惯，表示数字范围也常用符号：<span class="math inline">\(\sim\)</span></p></li>
<li><p><code>---</code>：em dash，即破折号</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">n inter-word dash or, hyphen, as in X-ray.</span><br><span class="line">  </span><br><span class="line">An medium dash for number range, like 1--2.</span><br><span class="line">  </span><br><span class="line">A punctuation dash---like this.</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><p>省略号<code>\ldots</code>和<code>\dots</code></p>
<p>西文的省略号（ellipsis）使用<code>\ldots</code>和<code>\dots</code>命令产生，相比直接输入三个句号，它所拉开的间距要合理的的：</p>
<p>Good: One, twe, three<span class="math inline">\(\dots\)</span></p>
<p>Bad: One, two, three...</p>
<p>西文的省略号在句中时，前后都需要加空格，而在句末时应该使用 4 个点。由于<code>\ldots</code>本身的后面也有间距，通常将其放入数学模式中，避免前后间距不一</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">She <span class="built_in">$</span><span class="keyword">\ldots</span><span class="built_in">$</span> she got it</span><br><span class="line">I&#x27;ve no idea <span class="keyword">\ldots</span></span><br></pre></td></tr></table></figure></li>
<li><p>不能直接录入的标点符号：</p>
<p>~, #, $, %, ^, &amp;, {, }, _, , x</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\#</span> <span class="keyword">\quad</span> <span class="keyword">\$</span> <span class="keyword">\quad</span> <span class="keyword">\%</span> <span class="keyword">\quad</span> <span class="keyword">\&amp;</span> <span class="keyword">\quad</span> <span class="keyword">\&#123;</span> <span class="keyword">\quad</span> <span class="keyword">\&#125;</span> <span class="keyword">\quad</span> <span class="keyword">\_</span> <span class="keyword">\quad</span> <span class="keyword">\textbackslash</span> <span class="keyword">\times</span></span><br></pre></td></tr></table></figure>
<p>可以使用没有字母的重音<code>\~&#123;&#125;</code>和<code>\^&#123;&#125;</code>输出<code>~</code>和<code>^</code>，但着连个符号一般不直接出现在普通正文中</p></li>
<li><p>标点格式</p>
<p><span class="math inline">\(\LaTeX\)</span> 并不会自动处理号汉字标点的宽度和间距，甚至不能保证标点的禁则（如娟红不允许出现在一行的开始）。</p>
<p>中文标点一般由<code>xeCJK</code>宏包控制，其提供了多种标点格式，默认时全角式，即所有标点占一个汉字宽度，只在行末和个别标点之间进行挤压。</p>
<p>还支持其他一些标点格式，可以使用<code>\punctstyle</code>命令修改：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\punctstyle</span>&#123;quanjiao&#125; 全角式，所有标点全角，有挤压。例如，“标点挤压”。又如《标点符号用法》。</span><br><span class="line"></span><br><span class="line"><span class="keyword">\punctstyle</span>&#123;banjiao&#125; 半角式，所有标点半角，有挤压。例如，“标点挤压”。又如《标点符号用法》。</span><br><span class="line"></span><br><span class="line"><span class="keyword">\punctstyle</span>&#123;kaiming&#125; 开明式，部分的标点半角，有挤压。例如，“标点挤压”。又如《标点符号用法》。</span><br><span class="line"></span><br><span class="line"><span class="keyword">\punctstyle</span>&#123;hangmobanjiao&#125; 行末半角式，仅行末挤压。例如，“标点挤压”。又如《标点符号用法》。</span><br><span class="line"></span><br><span class="line"><span class="keyword">\punctstyle</span>&#123;plain&#125; 无格式，只有禁则，无挤压。例如，“标点挤压”。又如《标点符号用法》。</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="空格和换行">2.2 空格和换行</h2>
<p>文本中的空格起分割单词的作用，任意多个空格与一个空格的功能相同；只有字符后面的空格式有效的，每行最前面的空格则会被忽略，这样有利于复杂代码的对其，单个换行也被视作一个空格。</p>
<ul>
<li><p>带空格的宏</p>
<p>以字母命名的宏，后面空格会被忽略。如果要在命令后面使用空格，可以在空格前加<code>\</code></p></li>
<li><p>带子<code>~</code></p>
<p>有一种不可打断的空格，在 <span class="math inline">\(\TeX\)</span> 中被称为带子（tties），用<code>~</code>表示。<span class="math inline">\(\TeX\)</span> 禁止在这种空格之间分行，因而可以用来表示一些不宜分开的情况</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">Question~1 <span class="comment">%名称与编号之间</span></span><br><span class="line">Donald~E. Knuth <span class="comment">% 教名之间，但姓可以断行</span></span><br><span class="line">Mr. Knuth <span class="comment">% 称谓缩写与名字间</span></span><br><span class="line">function~<span class="built_in">$</span>f(x)<span class="built_in">$</span> <span class="comment">% 名字后的短公式</span></span><br><span class="line">1，~2， and ~3 <span class="comment">% 序列的部分符号间</span></span><br></pre></td></tr></table></figure></li>
<li><p>幻影（phantom）</p>
<p><code>\phantom</code>有一个参数，作用是产生于参数内容一样大小的空盒子，没有内容，就像是参数的一个幻影一样，用来完成一些特殊的展位和对齐效果。</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">幻影<span class="keyword">\phantom</span>&#123;参数&#125;快速隐形</span><br><span class="line">幻影参数快速隐形</span><br></pre></td></tr></table></figure>
<p>类似的还有<code>\hphantom</code>和<code>\vphantom</code>，分别表示水平方向和垂直方向的幻影（另一个方向大小为零）</p></li>
<li><p>分段</p>
<p>通常用两个换行表示分段，段与段之间会自动得到何使的缩进。</p>
<p>分段也可以用<code>\par</code>命令生成，这种用法一般只在命令或环境定义的内部使用，普通正文中不宜出现。</p>
<p>另起一行不分段：</p>
<ul>
<li><p><code>\\</code>命令直接另起一行，上一行保持原来的样子；该命令可以带一个可选的长度参数，表示换行后增加的额外垂直间距，如<code>\\[2cm]</code>。如果<code>\\</code>后面需要使用方括号，则应加空的分组以示分隔。</p></li>
<li><p><code>\linebreak</code>指定一行的断点，上一行仍按完整一行分散对齐。可以带一个 0-4 的可选参数，表述允许断行的程度：0 表示允许断行，默认的 4 表示必须断行；类似的，也有一个<code>\nolinebreak</code>命令，参数意义与<code>\linebreak</code>相反。</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">这是一行文字<span class="keyword">\\</span> 另一行</span><br><span class="line">  </span><br><span class="line">这是一行文字<span class="keyword">\\</span>&#123;&#125;[] 另一行</span><br><span class="line">  </span><br><span class="line">这是一行文字<span class="keyword">\\</span>[1em] 另一行</span><br><span class="line">  </span><br><span class="line">这是一行文字<span class="keyword">\linebreak</span> 另一行</span><br><span class="line">这是一行文字<span class="keyword">\linebreak</span>[4] 另一行</span><br></pre></td></tr></table></figure>
<p><code>\\</code>一般用在特殊环境中，如排版诗歌的<code>verse</code>环境，特别是在对齐、表格和数学公式中使用广泛，很少出现在普通正文中。</p></li>
</ul></li>
<li><p>西文句末</p>
<p>西文的标点后面都会加空格，这可以保证正确的间隔，也能保证正确的换行。</p>
<p><span class="math inline">\(\LaTeX\)</span> 在西文句末（包括句号、问好和感叹号）后面使用的距离比单词间的距离大些。<span class="math inline">\(\LaTeX\)</span> 默认把大写字母后的点看作缩写标记，把小写字母后的点看作式句子结束，并对它们使用不同的间距。</p>
<p>偶尔也会有大写字母结束的句子，或小写字母的缩写，这是必须明确告诉 <span class="math inline">\(\LaTeX\)</span> 使用普通单词间的空格（空格前加<code>\</code>），或使用<code>\@.</code>指明式大写字母后的句末。</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">A sentence, And anotehr.</span><br><span class="line">U.S.A. means United States Army?</span><br><span class="line">Tinker et al.<span class="keyword">\ </span>mad the double play.</span><br><span class="line">Roman number XII<span class="keyword">\@</span>. Yes.</span><br></pre></td></tr></table></figure>
<ul>
<li>有时也需要整体<strong>禁止</strong>这种标点后的不同间距，<strong>法语排版</strong>的习惯就是如此，此时可以使用<code>\frenchspacing</code>命令来禁止标点后的额外间距。</li>
</ul></li>
<li><p>中英文混排</p>
<p>汉字后的空格会被忽略，使用<code>xelatex</code>编译中文文档时，汉字和其他内容之间如果没有空格，<code>xeCJK</code>宏包会自动添加。个别时候需要忽略汉字和其他内容之间由<code>xeCJK</code>产生的空格，这是可以把汉字放进一个盒子里：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\mbox</span>&#123;条目&#125;-a 不同于条目-b</span><br></pre></td></tr></table></figure>
<p>有时需要完全禁用汉字和其他内容之间的空格，这是可以使用<code>CJKsetecglue</code>手工设置汉字与其他内容之间的内容为空（默认为一个空格）。</p></li>
</ul>
<h2 id="字体">2.3 字体</h2>
<ul>
<li><p>更改字体</p>
<p><span class="math inline">\(\LaTeX\)</span>提供了带参数和命令、字体声明两种修改字体的命令，前者用于少量字体的更换，后者用于分组或环境中字体的整体更换。</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\textit</span>&#123;Italic font test&#125; <span class="comment">% 少量字体的更换</span></span><br><span class="line">&#123;<span class="keyword">\bfseries</span> Bond font test&#125; <span class="comment">% 分组或环境中字体的整体更换</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczRJS.md.png" /></p>
<p><span class="math inline">\(\LaTeX\)</span> 预定义命令中的字体信息如下：</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczcIf.png" /></p>
<center>
<p>fig. 4-1 预定义命令中的字体信息</p>
</center>
<p><img src="https://s3.ax1x.com/2021/01/19/scz6dP.md.png" /></p>
<center>
<p>fig. 4-2 字体坐标：族、形状和系列</p>
</center></li>
<li><p>字体恢复默认</p>
<p>除了上面列举的字体命令，还有<code>\textnormal&#123;&lt;text&gt;&#125;</code>和<code>\normalfont</code>命令，用来将字体设置为 ”普通“的格式，默认为<code>\rmfamily \mdseries \upshape</code>。</p>
<p>普通字体适用于复杂的字体环境中恢复普通的字体，尤其是在宏定义这类不知道外部字体设置的情况下，如：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">&#123;<span class="keyword">\sffamily</span><span class="keyword">\textbf</span>&#123;This is a paragraph of bold and <span class="keyword">\textit</span>&#123;italic font, sometimes returning to <span class="keyword">\textnormal</span>&#123;normal font&#125; is necessary.&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczrqI.md.png" /></p></li>
<li><p>斜体倾斜校正</p>
<p>使用斜体声明<code>\itshape</code>、<code>slshape</code>时，最后一个倾斜的字母会超出边界，使得后面的文字与它相距过紧，而使用带参数的命令<code>\textit</code>、<code>\textsl</code>可以自动修正距离，也可以手工使用<code>\/</code>命令进行这种倾斜校正（italic correction），会在字母后面加上一个小的距离，如：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">&#123;<span class="keyword">\itshape</span> M&#125;M</span><br><span class="line"><span class="keyword">\textit</span>&#123;M&#125;M</span><br><span class="line">&#123;<span class="keyword">\itshape</span> M<span class="keyword">\/</span>&#125;M</span><br><span class="line"><span class="keyword">\textit</span>&#123;M<span class="keyword">\nocorr</span>&#125;M <span class="comment">% 取消倾斜校正</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczWRg.md.png" /></p>
<p>很少情况下，<code>\textit</code>自动加入的倾斜校正时不必要的，此时可以使用<code>\nocorr</code>命令禁止校正。</p></li>
<li><p>中文字体</p>
<p>中文字体通常没有西文字体那样复杂的成套的 变体，各个字体之间一般都是独立的。对于中文字体，一般只使用不同的字体族进行区分。<code>xeCJK</code> 和 <code>CJK</code>宏包机制下， 中文字体的选择命令和西文字体是份力的，选择中文字体用<code>\CJKfamily</code>命令，如：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">&#123;<span class="keyword">\CJKfamily</span>&#123;zhehei&#125;这是黑体&#125;</span><br><span class="line">&#123;<span class="keyword">\CJKfamily</span>&#123;zhkai&#125;这是楷书&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>ctex</code>宏包及文档类下有一些预定义，在默认情况下（winfonts 选项）针对 Windows 常用字体配置了的四种字体族：zhsong（宋体）、zhhei（黑体）、zhkai（楷书）、zhfs（仿宋）。为了方便使用，<code>ctex</code>提供了简化的命令：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">&#123;<span class="keyword">\songti</span> 宋体&#125; <span class="keyword">\quad</span> &#123;<span class="keyword">\heiti</span> 黑体&#125; <span class="keyword">\quad</span> &#123;<span class="keyword">\fangsong</span> 仿宋&#125; <span class="keyword">\quad</span> &#123;<span class="keyword">\kaishu</span> 楷书&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>组合字体</p>
<p><code>ctex</code>宏包及文档类（如<code>ctexart</code>）另外定义了一些组合字体，可以让中文也具备使用粗体（<code>\bfsereies</code>）和意大利体（<code>\itshape</code>）的功能。默认中文字体族为 rm，其<strong>正常字体是宋体，粗体是黑体，意大利体是楷体</strong>。</p>
<p>类似的，<code>\sffamily</code>（对应 sf 中文字体族）和<code>\ttfamily</code>（对应 tt 中文字体族）也可以同时用作西文和中文，分别相当于<strong>幼圆和仿宋体</strong>。</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">&#123;<span class="keyword">\rmfamily</span> <span class="keyword">\textbackslash</span> rmfamily 中文字体族下，正常字体是宋体，其<span class="keyword">\textbf</span>&#123;粗体&#125;与<span class="keyword">\textit</span>&#123;斜体&#125;。&#125; 				</span><br><span class="line">&#123;<span class="keyword">\sffamily</span> <span class="keyword">\textbackslash</span> sffamily  中文字体族下，正常字体是幼圆，其<span class="keyword">\textbf</span>&#123;粗体&#125;与<span class="keyword">\textit</span>&#123;斜体&#125;。&#125;			</span><br><span class="line">&#123;<span class="keyword">\ttfamily</span> <span class="keyword">\textbackslash</span> ttfamily 中文字体族下，正常字体是宋体，其<span class="keyword">\textbf</span>&#123;粗体&#125;与<span class="keyword">\textit</span>&#123;斜体&#125;。&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://s3.ax1x.com/2021/01/19/scz4Mj.md.png" /></p></li>
<li><p>修改默认字体</p>
<p>通过fontspec 宏包的机制来调用字体，最基本的是设置正文罗马字体族、无衬线体字族和打字机字体族的命令：</p>
<p>​ <code>\setmainfont[&lt;可选选项&gt;]\&#123;&lt;字体名&gt;\&#125;</code></p>
<p>​ <code>\setsansfont[&lt;可选选项&gt;]\&#123;&lt;字体名&gt;\&#125;</code></p>
<p>​ <code>\setmnonofont[&lt;可选选项&gt;]\&#123;&lt;字体名&gt;\&#125;</code></p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 设置全文字体为 Windows 提供的 Timees New Roman, Verdana, Courier New 字体</span></span><br><span class="line"><span class="keyword">\usepackage</span>&#123;fontspec&#125;</span><br><span class="line"><span class="keyword">\setmainfont</span>&#123;Times New Roman&#125;</span><br><span class="line"><span class="keyword">\setsansfont</span>&#123;Verdana&#125;</span><br><span class="line"><span class="keyword">\setmonofont</span>&#123;Courier New&#125;</span><br></pre></td></tr></table></figure>
<p>此时 <code>\rmfamily</code>，<code>\sffamily</code>，<code>\ttfamily</code> 就分别对应设置的三种字体，而且 <code>fontspec</code>宏包会自动找到并匹配对应的粗体、斜体等编题，尽量使 <code>\bfseries</code>， <code>\itshap</code>等命令也有效。</p>
<p>除此之外，还可以定义新的字体族命令：</p>
<p>​ <code>\newfontfamily&lt;命令&gt;[&lt;可选选项&gt;]&#123;&lt;字体命&gt;&#125;</code></p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% preamble</span></span><br><span class="line"><span class="keyword">\newfontfamily</span><span class="keyword">\lucidasans</span>&#123;Lucida Sans&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 正文</span></span><br><span class="line">&#123;<span class="keyword">\lucidasans</span> This is Lucida Sans.&#125;</span><br></pre></td></tr></table></figure>
<p><code>xeCJK</code>宏包（<code>ctex</code>宏包或文档类会自动调用）提供了与<code>fontspec</code>对应的中文字体设置命令</p>
<p>​ <code>\setCJKmainfont[&lt;可选选项&gt;]\&#123;&lt;字体名&gt;\&#125;</code></p>
<p>​ <code>\setCJKsansfont[&lt;可选选项&gt;]\&#123;&lt;字体名&gt;\&#125;</code></p>
<p>​ <code>\setCJKmonofont[&lt;可选选项&gt;]\&#123;&lt;字体名&gt;\&#125;</code></p>
<p>​ <code>\setCJKfamilyfont[&lt;可选选项&gt;]\&#123;&lt;字体名&gt;\&#125;</code></p></li>
</ul></li>
</ul>
<h2 id="强调文字">2.4 强调文字</h2>
<ul>
<li><p><code>\emph&#123;&#125;</code> and <code>\em</code></p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;itemize&#125;</span><br><span class="line">	<span class="keyword">\item</span> 命令形式：</span><br><span class="line">		You <span class="keyword">\emph</span>&#123;should&#125; use fonts carefully.</span><br><span class="line">		<span class="comment">% 常使用意大利体表示夹在正文中的强调句					</span></span><br><span class="line">		<span class="keyword">\textit</span>&#123;You <span class="keyword">\emph</span>&#123;should&#125; use fonts carefully.&#125;</span><br><span class="line">		<span class="comment">% 常使用正文夹在意大利体中表示强调</span></span><br><span class="line">	<span class="keyword">\item</span> 声明形式：</span><br><span class="line">		This is &#123;<span class="keyword">\em</span> emphasized<span class="keyword">\/</span>&#125; text</span><br><span class="line">		<span class="comment">% \/ 为斜度校正</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczfzQ.md.png" /></p></li>
<li><p>重新定义<code>\Emph</code>命令</p>
<p>有时仍然使用大写、小型大写或粗体进行更醒目的强调，此时可以定义一个新的<code>\Emph</code>命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\newcommand\Emph&#123;\textbf&#125; % bold</span><br><span class="line">This is \Emph&#123;emphasized&#125; text.</span><br></pre></td></tr></table></figure>
<p>Result:<img src="https://s3.ax1x.com/2021/01/19/sczILn.md.png" /></p></li>
<li><p><code>\underline</code></p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\underline</span>&#123;Emphasized&#125; text and <span class="keyword">\underline</span>&#123;another&#125;.</span><br></pre></td></tr></table></figure>
<p>Result: <img src="https://s3.ax1x.com/2021/01/19/scz5ss.md.png" /></p>
<p><code>\underline</code>的一个很大确定是下划线部分不能换行，并且下划线与文字的距离参差不齐。</p></li>
<li><p><code>\uline</code></p>
<p><code>\ulem</code>宏包的<code>\uline</code>命令解决了上述<code>\underline</code>的命令，并把默认的<code>\emph</code>命令也改为使用下划线方式（texlive 2018）中并未修改），如果不希望用下划线线替代标准的<code>\emph</code>命令，可以给<code>\ulem</code>宏包加<code>normalem</code>参数，或使用<code>\normalem</code>和<code>\ULforem</code>命令切换两种强调</p>
<p>除了下划线，<code>ulem</code>宏包也提供了其他修饰文字的命令：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\uuline</span>&#123;urgent&#125; <span class="keyword">\qquad</span> <span class="keyword">\uwave</span>&#123;boat&#125; <span class="keyword">\qquad</span>&#125; <span class="keyword">\sout</span>&#123;wrong&#125; <span class="keyword">\qquaad</span> <span class="keyword">\xout</span>&#123;removed&#125; <span class="keyword">\qquad</span> <span class="keyword">\dashuline</span>&#123;dashing&#125; <span class="keyword">\qquda</span> <span class="keyword">\dotuline</span>&#123;dotty&#125;</span><br></pre></td></tr></table></figure>
<p>Result:<img src="https://s3.ax1x.com/2021/01/19/sczTZq.md.png" /></p>
<p><code>CJKfntef</code>宏包对汉字也提供了类似的功能，同时进行了一些扩充：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\CJKunderdot</span>&#123;汉字，下点线&#125; <span class="keyword">\phantom</span>&#123;汉字下点线&#125; <span class="keyword">\CJKunderline</span>&#123;汉字，单下划线&#125; <span class="keyword">\phantom</span>&#123;字下点线&#125; <span class="keyword">\CJKunderdblline</span>&#123;汉字，双下划线&#125; <span class="keyword">\\</span></span><br><span class="line"><span class="keyword">\CJKunderwave</span>&#123;汉字，下划波浪线&#125; <span class="keyword">\phantom</span>&#123;下点线&#125; <span class="keyword">\CJKsout</span>&#123;汉字，删除线&#125; <span class="keyword">\phantom</span>&#123;爱好下点线&#125; <span class="keyword">\CJKxout</span>&#123;汉字，斜删除线&#125;</span><br></pre></td></tr></table></figure>
<p>Result:<img src="https://s3.ax1x.com/2021/01/19/sczHoV.md.png" /></p>
<p>此外，<code>CJKfntef</code> 宏包，还提供了 <code>CJKfilltwosides</code> 环境，让汉字分散对齐：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;CJKfilltwosides&#125;&#123;5cm&#125;</span><br><span class="line">	汉字，分散对齐</span><br><span class="line"><span class="keyword">\end</span>&#123;CJKfilltwosides&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>ctex</code>宏包及文档中，可以使用<code>\CTEXunderline</code>等以<code>\CTEX</code>开头的命令代替以 <code>\CJK</code>命令开头的命令：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\CTEXunderdot</span>&#123;汉字，加点&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="字号">2.5 字号</h2>
<ul>
<li><p>西文字体大小</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczqiT.md.png" /></p>
<center>
<p>fig. 4-3 预定义的西文字体调整命令</p>
</center></li>
<li><p>中文字体大小</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sgpQBR.png" alt="image-20200817162304003" style="zoom:67%;" /></p>
<center>
<p>fig. 4-4 预定义中文字号</p>
</center>
<p>字号命令表示的具体尺寸随所使用的文档类和大小选项不同而不同。在标准 $$ 文档类 aritcle，report 和 book 中，可以设置文档类选项 10pt，11pt 和 12pt，全局地设置文档内的字号，默认为10pt，即<code>\normalsize</code>的大小为 10pt。</p></li>
<li><p>不同文档类选项下的字号命令</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczLJU.md.png" /></p>
<center>
<p>fig.4-5 不同文档类选项下的字号</p>
</center></li>
</ul>
<h2 id="水平间距">2.6 水平间距</h2>
<ul>
<li><p>水平间距</p>
<p><span class="math inline">\(\LaTeX\)</span> 中的长度有如下几种：</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczXz4.md.png" /></p>
<center>
<p>fig. 4-6 水平间距</p>
</center>
<p><img src="https://s3.ax1x.com/2021/01/19/scz2i8.md.jpg" /></p>
<center>
<p>fig. 4-7 水平间距</p>
</center>
<p>使用水平间距的命令要注意适用，如 <code>\,</code>是不可断行的，因而就不适用于分隔很长的内容，单用来代替逗号给长数字分段就很合适：1,234,567,890。</p>
<ul>
<li>负距离</li>
</ul>
<p>负距离<code>\negthinspace</code>则可以用来细调符号距离或拼接两个符号。</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\dag</span><span class="keyword">\negthinspace</span><span class="keyword">\dag</span> versus <span class="keyword">\dag</span><span class="keyword">\dag</span></span><br></pre></td></tr></table></figure>
<p>此外，还可以使用<code>\hspace&#123;距离&#125;</code>命令来产生指定的水平间距，该命令产生的距离是<strong>可断行</strong>的。</p>
<p>Space 1,cm</p>
<p>Result: <img src="https://s3.ax1x.com/2021/01/19/scz7d0.md.png" /></p>
<ul>
<li>强制段首空格</li>
</ul>
<p><code>\hspace</code>的作用是分隔左右的内容，在某些只有一边内容的地方（如强制断行的行首），<span class="math inline">\(\LaTeX\)</span> 会忽略产生的距离，此时可以用带星号的命令 <code>\hspace* &#123;distance&#125;</code>阻止命令被忽略。</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">Space<span class="keyword">\linebreak</span> <span class="keyword">\hspace</span>&#123;1cm&#125; 1<span class="keyword">\,</span>cm</span><br><span class="line"></span><br><span class="line">Space<span class="keyword">\linebreak</span> <span class="keyword">\hspace</span>*&#123;1cm&#125; 1<span class="keyword">\,</span>cm</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczvQJ.md.png" /></p></li>
<li><p>橡皮长度</p>
<p><code>\hspace</code>可以产生随内容可伸缩的长度，即橡皮长度，这样才能保证在分行行末的对齐，语法为：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">&lt;normal legnth&gt;plus&lt;可伸长长度&gt;minus&lt;可缩短长度&gt;</span><br></pre></td></tr></table></figure>
<p>有一种特殊的橡皮长度<code>\fill</code>，<code>\fill</code>可以从零开始无限延伸，此时橡皮长度就真的像一个弹簧，可以用来把几个内容均匀排列在一行之中：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">left <span class="keyword">\hspace</span>&#123;<span class="keyword">\fill</span>&#125; middle <span class="keyword">\hfill</span> left</span><br><span class="line">left <span class="keyword">\hspace</span>&#123;<span class="keyword">\fill</span>&#125; middle <span class="keyword">\dotfill</span> left</span><br><span class="line">left <span class="keyword">\hspace</span>&#123;<span class="keyword">\fill</span>&#125; middle <span class="keyword">\hrulefill</span> left</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczzLR.md.png" /></p>
<p><code>\hfill</code>是命令<code>\hspace\&#123;fill&#125;</code>的简写，还可以用<code>\stretcg&#123;&lt;times&gt;&#125;</code>产生具有指定“弹力”的橡皮长度，如<code>\stretch&#123;2&#125;</code>相当于两倍的<code>\fill</code>。<code>\hrulefill</code>和 <code>\dotfill</code> 与 <code>\hfill</code>功能类似，只是中间填充内容不一样（横线和点线）.</p></li>
<li><p>自定义长度变量<code>setlength</code></p>
<p><span class="math inline">\(\LaTeX\)</span> 预定义了一些长度变量控制排版的参数，可以通过<code>\setlength</code> 命令来设置，如段首缩进：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">%导言处</span></span><br><span class="line"><span class="keyword">\seglegth</span> <span class="keyword">\parindent</span><span class="keyword">\&#123;</span>8em<span class="keyword">\&#125;</span></span><br></pre></td></tr></table></figure></li>
<li><p>长度累加<code>addtolength</code></p>
<p>可以通过 <code>\addtolength</code>命令在长度变量上做累加，如</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">Para<span class="keyword">\par</span></span><br><span class="line"><span class="keyword">\addtolength</span><span class="keyword">\parindent</span>&#123;2em&#125;Para<span class="keyword">\par</span></span><br><span class="line"><span class="keyword">\addtolength</span><span class="keyword">\parindent</span>&#123;2em&#125;Para<span class="keyword">\par</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczxy9.md.png" /></p></li>
</ul>
<h2 id="盒子">2.7 盒子</h2>
<p>盒子 (box) 处理 <span class="math inline">\(\TeX\)</span> 中的基本处理单位，一个字符、一行文字、一个页面、一张表格在 <span class="math inline">\(\TeX\)</span> 中都是一个盒子。</p>
<ul>
<li><p>mbox and makebox</p>
<p>最简单的命令是 <code>\box&#123;&lt;text&gt;&#125;</code>，它产生一个内容以左右模式排列的盒子，可以用它表示<strong>不允许断行的内容</strong>，如果不在行末，其与普通内容无异，如：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\mbox</span>&#123;cannot be broken&#125;</span><br></pre></td></tr></table></figure>
<p><code>\makebox</code>与 <code>\mbox</code> 类似，但可以带两个可选参数，指定盒子的宽度和对齐方式(c(center, default), l(left), r(right), s(scatter))：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\textbackslash</span> makebox[&lt;width&gt;][&lt;loc&gt;]<span class="keyword">\&#123;</span>&lt;contex&gt;<span class="keyword">\&#125;</span></span><br></pre></td></tr></table></figure>
<p>还可以使用 <code>\makebox</code> 产生宽度为 0 的盒子，产生重叠(overlap) 的效果：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\makebox</span>[0pt][l]&#123;word&#125; 文字</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sgSpe1.md.png" /></p></li>
<li><p>overlap</p>
<p><span class="math inline">\(\LaTeX\)</span> 已经提供了两个命令来专门生成重叠的效果，即 <code>\llap</code>和 <code>\rlap</code>，分别表示把参数中的内容向当前位置的左侧和右侧重叠：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">语言文字 <span class="keyword">\llap</span>&#123;word&#125;<span class="keyword">\\</span>					</span><br><span class="line"><span class="keyword">\rlap</span>&#123;word&#125;语言文字</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sgS9dx.md.png" /></p></li>
<li><p>frame</p>
<p>命令 <code>\fbox</code> 和 <code>\framebox</code> 产生带边框的盒子，语法与<code>\mbox</code>和 <code>\makebox</code>类似：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\fbox</span>&#123;framed&#125; <span class="keyword">\qquad</span> <span class="keyword">\framebox</span>[3cm][s]&#123;framed box&#125;</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sgSCo6.md.png" /></p>
<p>边框与内容的距离由长度变量 <code>\fboxsep</code> 控制（默认为 3pt），边框线的粗细则由长度变量 <code>\fboxrule</code>控制（默认为 0.4 pt）。</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\setlength</span><span class="keyword">\fboxsep</span>&#123;0pt&#125; <span class="keyword">\fbox</span>&#123;tight&#125;</span><br><span class="line"><span class="keyword">\setlength</span><span class="keyword">\fboxsep</span>&#123;1em&#125; <span class="keyword">\fbox</span>&#123;loose&#125;</span><br></pre></td></tr></table></figure>
<p>Result:<img src="https://s3.ax1x.com/2021/01/19/sgSFJO.md.png" /></p>
<p>在<code>\makebox</code>、<code>\framebox</code> 等盒子命令的参数中，可以使用 <code>\width</code>、<code>\height</code>、<code>\depth</code>、<code>\totalheight</code>来分别表示盒子内容的<strong>自然宽度、深度、以及高度和深度之和</strong>。如下产生的盒子总宽度恰好是文字自然宽度的 3 倍:</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\framebox</span>[3<span class="keyword">\width</span>]&#123;带边框&#125;</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sgSiFK.md.png" /></p></li>
</ul>
<h1 id="玩转数学公式">4 玩转数学公式</h1>
<h2 id="mathematic-formula">4.1 Mathematic formula</h2>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\[</span></span><br><span class="line">a + b = b + a</span><br><span class="line"><span class="keyword">\]</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;equation&#125;</span><br><span class="line">	a + b = b + a <span class="keyword">\label</span>&#123;eq:commutative&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;equation&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>amsmath package（P 223，表 4.1）</li>
</ul>
<p>amsmath 提供的 命令可以用来在数学公式中插入数字</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="built_in">$</span> <span class="keyword">\text</span>&#123;被减数&#125; - <span class="keyword">\text</span>&#123;减数&#125; = <span class="keyword">\text</span>&#123;差&#125;<span class="built_in">$</span></span><br></pre></td></tr></table></figure>
<p>$  -  = $</p>
<p>Note：在普通的文本中使用数学公式时也应该注意随时在文本模式和数学模式下转换。例如，行内数学公式中逗号等标点处不能换行，因此列举多项公式时就应该把每项放在单独的数学环境中，项项之间用逗号或句号隔开：</p>
<p>已知的变量有 <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span> 和 <span class="math inline">\(T\)</span></p>
<h2 id="mathematic-structure">4.2 Mathematic structure</h2>
<ul>
<li><p>上下标：</p>
<p>$ A_{ij} = 2 ^ {i + j} <span class="math inline">\(，\)</span> A_i^j = B^k_i$， <span class="math inline">\(K_{n_i} = K_{2^i} = 2^{n_i}\)</span>，<span class="math inline">\(3^{3^{3^{\cdot^{\cdot^3}}}}\)</span></p></li>
<li><p>撇号<code>'</code>：</p>
<p>数学公式中的撇号<code>'</code>就是一种特殊的商标，表示用符号 <code>\prime</code>（即<code>'</code>）作上标。撇号可以与下标混用，也可以连续使用（普通上标不能连续使用），但不能与上标直接混用：</p>
<p>$ a = a' = a^{}<span class="math inline">\(，\)</span>b_0' = b_0''<span class="math inline">\(，\)</span>{c'}^2 = (c')^2$</p></li>
<li><p>角度：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="built_in">$</span> <span class="keyword">\angle</span> a = <span class="keyword">\angle</span> BAC = 90 <span class="built_in">^</span><span class="keyword">\circ</span> = <span class="keyword">\pi</span> / 2  <span class="built_in">$</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 或者定义一个意义明显的命令</span></span><br><span class="line"><span class="keyword">\newcommand</span><span class="keyword">\degree</span>&#123;<span class="built_in">^</span><span class="keyword">\circ</span>&#125;</span><br></pre></td></tr></table></figure>
<p>$ a = BAC = 90 ^= /2 $</p></li>
<li><p>特殊上下标</p>
<p><strong>数学算子：</strong> <span class="math display">\[
\max_n f(n) = \sum_{i=0}^n A_i
\]</span> <strong>积分算子：</strong> <span class="math display">\[
\int_0^1 f(t) \rm{d}t = \iint_D g(x,y) \mathrm{d}x \mathrm{d}y
\]</span></p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 多数数学算子的上下标，位置时正上或正下方，但行内公式仍在角标位置</span></span><br><span class="line"><span class="keyword">\[</span></span><br><span class="line">    <span class="keyword">\max</span><span class="built_in">_</span>n f(n) = <span class="keyword">\sum</span><span class="built_in">_</span>&#123;i=0&#125;<span class="built_in">^</span>n A<span class="built_in">_</span>i</span><br><span class="line"><span class="keyword">\]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 对于积分等个别算子，显示公式中的上下标在右上右下角</span></span><br><span class="line"><span class="comment">% 导言区 \DeclareMathOperator\dif&#123;d\!&#125;</span></span><br><span class="line"><span class="built_in">$</span><span class="keyword">\int</span><span class="built_in">_</span>o<span class="built_in">^</span>1 f(t) <span class="keyword">\dif</span> t = <span class="keyword">\iint</span><span class="built_in">_</span>D g(x,y) <span class="keyword">\dif</span> x <span class="keyword">\dif</span> y<span class="built_in">$</span></span><br></pre></td></tr></table></figure>
<p>在上下标前面使用<code>\limits</code>会使上下标在正上正下方，这是通常上下限（limits）的排版方式，而使用<code>\nolimits</code>则会使上下标在角标： <span class="math display">\[
\iiint\limits_D \mathrm{d}f = \max\nolimits_D g
\]</span> 有时需要在符号的左上、左下加角标，此时可以使用<code>$&#123;&#125;_m^n&#123;H&#125;_i^j$</code>的形式得到 <span class="math inline">\({}_m^n{H}_i^j\)</span>，但这种方式得到的效果不尽人意，间距和对齐都不合理，此时可以使用<code>amsmath</code>包提供的<code>\sideset</code>命令，如： <span class="math display">\[
\sideset{_m^n}{_i^j} H\limits_{i = 0}^n
\]</span></p>
<p><span class="math display">\[
\sideset{_m^n}{_c^d} \sum_{i = 0}^ n
\]</span></p>
<p>或者是<code>mathtools</code>宏包的<code>\prescript&lt;up&gt;&lt;down&gt;&lt;element&gt;</code>来处理</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% \usepackage&#123;mathtools&#125;</span></span><br><span class="line"><span class="built_in">$</span><span class="keyword">\prescript</span>&#123;n&#125;&#123;m&#125;&#123;H&#125;<span class="built_in">_</span>i<span class="built_in">^</span>j &lt; L <span class="built_in">$</span></span><br><span class="line"><span class="comment">% 或</span></span><br><span class="line"><span class="built_in">$</span> <span class="keyword">\sideset</span>&#123;<span class="built_in">_</span>m<span class="built_in">^</span>n&#125;&#123;<span class="built_in">_</span>i<span class="built_in">^</span>j&#125; H <span class="built_in">$</span></span><br></pre></td></tr></table></figure>
<p>此外，<code>amsmath</code>还提供了<code>\overset</code>，<code>\underset</code>命令，用来给任意符号的上下方添加标记，这种命令有点像是加了<code>\limits</code>的巨算符的上下标：<span class="math inline">\(\overset{*}{X}\)</span>，<span class="math inline">\(\underset{*}{X}\)</span></p>
<p><span class="math inline">\(A_m{}^n\)</span>或<span class="math inline">\(A_m^{\phantom{m}n}\)</span></p></li>
<li><p>化学式</p>
<p>将化学式直接作为数学式输入看起来十分笨拙，可以使用专业的化学宏包<code>mhchem</code>（使用最为广泛的化学宏包）</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% \usepackage&#123;mhchem&#125;</span></span><br><span class="line"></span><br><span class="line">醋中主要有 <span class="keyword">\ce</span>&#123;H2O&#125;，含有 <span class="keyword">\ce</span>&#123;CH3COO-&#125;。</span><br><span class="line"><span class="keyword">\ce</span>&#123;<span class="built_in">^</span>&#123;227&#125;<span class="built_in">_</span>&#123;90&#125;Th&#125; 元素具有强放射性</span><br><span class="line"></span><br><span class="line"><span class="keyword">\begin</span>&#123;equation&#125;</span><br><span class="line">	<span class="keyword">\ce</span>&#123;2H2 + O2 -&gt; [<span class="keyword">\text</span>&#123;燃烧&#125;] 2H2O&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;equation&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Result：</strong></p>
<p>醋中主要有$ $，含有 <span class="math inline">\(\ce{CH3COO-}\)</span>。 <span class="math inline">\(\ce{^{227}_{90}Th}\)</span> 元素具有强放射性</p>
<p>$ $</p></li>
<li><p>上下划线</p>
<p><code>\overline</code>和<code>\underline</code>命令可以用来在公式的上方和下方划横线，例如： <span class="math display">\[
\overline{a+b} = \overline a + \overline b
\]</span></p>
<p><span class="math display">\[
\underline a = (a_0, a_1, a_2, \dots)
\]</span></p>
<p><span class="math display">\[
\overline{\underline{\underline a} + \overline{b}^2} - c^{\overline n}
\]</span></p>
<p><code>amsmath</code>还提供了在公式上下加箭头的命令，使用方法与<code>\overline</code>和<code>\underline</code>类似：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="built_in">$</span><span class="keyword">\overleftarrow</span>&#123;a + b&#125;<span class="built_in">$</span>，</span><br><span class="line"><span class="built_in">$</span><span class="keyword">\overrightarrow</span>&#123;a+b&#125;<span class="built_in">$</span>，</span><br><span class="line"><span class="built_in">$</span><span class="keyword">\overleftrightarrow</span>&#123;a+b&#125;<span class="built_in">$</span>，</span><br><span class="line"><span class="built_in">$</span><span class="keyword">\underleftarrow</span>&#123;a+b&#125;<span class="built_in">$</span>，</span><br><span class="line"><span class="built_in">$</span><span class="keyword">\underrightarrow</span>&#123;a+b&#125;<span class="built_in">$</span>，</span><br><span class="line"><span class="built_in">$</span><span class="keyword">\underleftrightarrow</span>&#123;a+b&#125;<span class="built_in">$</span></span><br></pre></td></tr></table></figure>
<p>$ <span class="math inline">\(，\)</span><span class="math inline">\(，\)</span><span class="math inline">\(，\)</span><span class="math inline">\(，\)</span><span class="math inline">\(，\)</span>$</p>
<p><strong>向量：</strong><span class="math inline">\(\vec{a}\)</span></p></li>
<li><p>花括号 <span class="math display">\[
\overbrace{a+b+c} = \underbrace{1+2+3}
\]</span> 使用上下标在花括号上下作标注： <span class="math display">\[
\overbrace{a_0, a_1, \dots, a_n}^{\text{共}\ n+1\ \text{项}} = \underbrace{1+2+3}_{n}
\]</span> 类似的，<code>mathtools</code>宏包还提供了在数学公式上下加方括号的命令：</p>
<p><code>\underbracket[&lt;线宽&gt;][&lt;伸出高度&gt;]&#123;&lt;内容&gt;&#125;</code></p>
<p><code>\overbracket[&lt;线宽&gt;][&lt;伸出高度&gt;]&#123;&lt;内容&gt;&#125;</code></p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% \usepackage&#123;mathtools&#125;</span></span><br><span class="line"><span class="keyword">\[</span></span><br><span class="line">	<span class="keyword">\underbracket</span>&#123;<span class="keyword">\overbracket</span>&#123;1+2&#125;+3&#125;<span class="built_in">_</span>3</span><br><span class="line"><span class="keyword">\]</span></span><br></pre></td></tr></table></figure>
<p><code>\overbrace</code>和<code>\underbrace</code>等命令可以嵌套，但本身不能交错，如要实现交错可以分别生成两个括号：先为一部分公式的幻影<code>\phantom</code>加括号，为另一部分加括号，然后使用重叠<code>\rlap</code>的盒子将两部分合在一起： <span class="math display">\[
a+\rlap{\overbrace{\phantom{b+c+d}}^m}b+\underbrace{c+d+e}_n +f
\]</span></p></li>
<li><p>分式</p>
<p><code>\frac&lt;分子&gt;&lt;分母&gt;</code>： <span class="math display">\[
\frac{1}{2} + \frac 1{a} = \frac{2+a}{2a}
\]</span> <strong>行内公式会用较小的字号排版，以免超出文本高度：</strong><span class="math inline">\(\frac 12 + \frac 1a + \frac{2+a}{2a}\)</span></p>
<p><strong>已经在分子或分母中的分式，也会按行内公式的大小排版：</strong><span class="math inline">\(\frac 1{\frac 12(a+b)}\)</span></p>
<p>有时需要指定格式，可以使用<code>amsmath</code>提供的<code>\dfrac</code>和<code>\tfrac</code>分别指定显示格式（display style）和正文格式（text style）的分式： <span class="math display">\[
\tfrac 12 f(x) = \frac{1}{\dfrac 1a + \dfrac 1b + c}
\]</span> 连分式（continued fraction），<code>amsmath</code>提供的<code>\cfrac</code>专用于输入连分式，<code>\cfrac</code>可以带一个可选参数<code>l</code>或<code>r</code>，分别表示左、右对齐，默认居中对齐：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\cfrac</span>&#123;1&#125;&#123;1+<span class="keyword">\cfrac</span>&#123;2&#125;&#123;1+<span class="keyword">\cfrac</span>&#123;3&#125;&#123;1+x&#125;&#125;&#125; = <span class="keyword">\cfrac</span>[r]&#123;1&#125;&#123;1+<span class="keyword">\cfrac</span>&#123;2&#125;&#123;1+<span class="keyword">\cfrac</span>[l]&#123;3&#125;&#123;1+x&#125;&#125;&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="symbol-and-type">4.3 Symbol and type</h2>
<h3 id="希腊字母">4.3.2 希腊字母</h3>
<ul>
<li><p>小写希腊字母：</p>
<table>
<colgroup>
<col style="width: 28%" />
<col style="width: 24%" />
<col style="width: 25%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><code>\alpha</code>: <span class="math inline">\(\alpha\)</span></th>
<th style="text-align: center;"><code>\beta</code>: <span class="math inline">\(\beta\)</span></th>
<th style="text-align: center;"><code>\gamma</code>: <span class="math inline">\(\gamma\)</span></th>
<th style="text-align: center;"><code>\delta</code>: <span class="math inline">\(\delta\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>\epsilon</code>: <span class="math inline">\(\epsilon\)</span></td>
<td style="text-align: center;"><code>\zeta</code>: <span class="math inline">\(\zeta\)</span></td>
<td style="text-align: center;"><code>\eta</code>: <span class="math inline">\(\eta\)</span></td>
<td style="text-align: center;"><code>\theta</code>: <span class="math inline">\(\theta\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>\iota</code>: <span class="math inline">\(\iota\)</span></td>
<td style="text-align: center;"><code>\kappa</code>: <span class="math inline">\(\kappa\)</span></td>
<td style="text-align: center;"><code>\lambda</code>: <span class="math inline">\(\lambda\)</span></td>
<td style="text-align: center;"><code>\mu</code>:<span class="math inline">\(\mu\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>\nu</code>: <span class="math inline">\(\nu\)</span></td>
<td style="text-align: center;"><code>\xi</code>: <span class="math inline">\(\xi\)</span></td>
<td style="text-align: center;"><code>\pi</code>: <span class="math inline">\(\pi\)</span></td>
<td style="text-align: center;"><code>\rho</code>: <span class="math inline">\(\rho\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>\sigma</code>: <span class="math inline">\(\sigma\)</span></td>
<td style="text-align: center;"><code>\tau</code>: <span class="math inline">\(\tau\)</span></td>
<td style="text-align: center;"><code>\upsilon</code>: <span class="math inline">\(\upsilon\)</span></td>
<td style="text-align: center;"><code>\phi</code>: <span class="math inline">\(\phi\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>\chi</code>: <span class="math inline">\(\chi\)</span></td>
<td style="text-align: center;"><code>\psi</code>: <span class="math inline">\(\psi\)</span></td>
<td style="text-align: center;"><code>\omega</code>: <span class="math inline">\(\omega\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>\varepsilon</code>: <span class="math inline">\(\varepsilon\)</span></td>
<td style="text-align: center;"><code>\vartheta</code>: <span class="math inline">\(\vartheta\)</span></td>
<td style="text-align: center;"><code>\varkappa</code>: <span class="math inline">\(\varkappa\)</span>'</td>
<td style="text-align: center;"><code>\varpi</code>: <span class="math inline">\(\varpi\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>\varrho</code>: <span class="math inline">\(\varrho\)</span></td>
<td style="text-align: center;"><code>\varsigma</code>: <span class="math inline">\(\varsigma\)</span></td>
<td style="text-align: center;"><code>\varphi</code>: <span class="math inline">\(\varphi\)</span></td>
<td style="text-align: center;"><code>\digamma</code>: <span class="math inline">\(\digamma\)</span>'</td>
</tr>
</tbody>
</table>
<p>Note：前面带<code>var</code>的命令是原来字母的编题，<code>\digamma</code>（<span class="math inline">\(\digamma\)</span>）是<code>\gamma</code>（<span class="math inline">\(\gamma\)</span>）的变体；<code>'</code>标记的符号需要<code>amssymb</code>或类似的宏包</p></li>
<li><p>大学希腊字母：</p>
<table>
<colgroup>
<col style="width: 24%" />
<col style="width: 24%" />
<col style="width: 24%" />
<col style="width: 28%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><code>\Gamma</code>: <span class="math inline">\(\Gamma\)</span></th>
<th style="text-align: center;"><code>\Delta</code>: <span class="math inline">\(\Delta\)</span></th>
<th style="text-align: center;"><code>\Theta</code>: <span class="math inline">\(\Theta\)</span></th>
<th style="text-align: center;"><code>\Lambda</code>: <span class="math inline">\(\Lambda\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>\Xi</code>: <span class="math inline">\(\Xi\)</span></td>
<td style="text-align: center;"><code>\Pi</code>: <span class="math inline">\(\Pi\)</span></td>
<td style="text-align: center;"><code>\Sigma</code>: <span class="math inline">\(\Sigma\)</span></td>
<td style="text-align: center;"><code>\Upsilon</code>: <span class="math inline">\(\Upsilon\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>\Phi</code>: <span class="math inline">\(\Phi\)</span></td>
<td style="text-align: center;"><code>\Psi</code>: <span class="math inline">\(\Psi\)</span></td>
<td style="text-align: center;"><code>\Omega</code>: <span class="math inline">\(\Omega\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>\varGamma</code>: <span class="math inline">\(\varGamma\)</span></td>
<td style="text-align: center;"><code>\varDelta</code>: <span class="math inline">\(\varDelta\)</span></td>
<td style="text-align: center;"><code>\varTheta</code>: <span class="math inline">\(\varTheta\)</span></td>
<td style="text-align: center;"><code>\varLambda</code>: <span class="math inline">\(\varLambda\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>\varXi</code>: <span class="math inline">\(\varXi\)</span></td>
<td style="text-align: center;"><code>\varPi</code>: <span class="math inline">\(\varPi\)</span></td>
<td style="text-align: center;"><code>\varSigma</code>: <span class="math inline">\(\varSigma\)</span></td>
<td style="text-align: center;"><code>\varUpsilon</code>: <span class="math inline">\(\varUpsilon\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>\varPhi</code>: <span class="math inline">\(\varPhi\)</span></td>
<td style="text-align: center;"><code>\varPsi</code>: <span class="math inline">\(\varPsi\)</span></td>
<td style="text-align: center;"><code>\varOmega</code>: <span class="math inline">\(\varOmega\)</span></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table></li>
<li><p>特殊字符</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczyZt.md.png" /></p>
<center>
<p>fig. 4-8 特殊字符</p>
</center>
<p>表（3）中，不带<code>\text</code>前缀的是文本模式和数学模式通用的。</p>
<ul>
<li><p><code>\symbol</code>命令可以直接用符号在字体中的编码来输入符号，<code>\symbol&#123;num&#125;</code></p>
<table>
<thead>
<tr class="header">
<th>表示法</th>
<th style="text-align: center;">语法形式</th>
<th style="text-align: center;">例</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>十进制</td>
<td style="text-align: center;"><数字></td>
<td style="text-align: center;">90</td>
</tr>
<tr class="even">
<td>十六进制</td>
<td style="text-align: center;">''<数字></td>
<td style="text-align: center;">''5A</td>
</tr>
<tr class="odd">
<td>八进制</td>
<td style="text-align: center;">'<数字></td>
<td style="text-align: center;">'132</td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">|  表示法  | 语法形式  |  例  |</span><br><span class="line">|  十进制  |  &lt;数字&gt;  |  <span class="number">90</span>  |</span><br><span class="line">| 十六进制 | <span class="string">&#x27;&#x27;</span>&lt;数字&gt; | <span class="string">&#x27;&#x27;</span>5A |</span><br><span class="line">|  八进制  | <span class="string">&#x27;&lt;数字&gt;  | &#x27;</span><span class="number">132</span> |</span><br><span class="line">| 字符形式 | `&lt;字符&gt;  |  `Z  |</span><br></pre></td></tr></table></figure>
<pre><code>注：如果字符形式中的字符是特殊字符，则需要在前面加`\`进行转义。</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;% pdf ./Latex.pdf 600px %&#125;</span><br><span class="line">&lt;<span class="built_in">object</span> data=<span class="string">&quot;./Latex/Latex.pdf&quot;</span> <span class="built_in">type</span>=<span class="string">&quot;application/pdf&quot;</span> width=<span class="string">&quot;100%&quot;</span> height=<span class="string">&quot;877px&quot;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Latex</category>
      </categories>
      <tags>
        <tag>Latex</tag>
      </tags>
  </entry>
  <entry>
    <title>Influence</title>
    <url>/2021/01/18/Influence-1/</url>
    <content><![CDATA[<h1 id="引言">1. 引言</h1>
<p>影响力，一般认为指的是用一种为别人所乐于接受的方式，改变他人所乐于接受的方式，改变他人的思想和行动的能力。该书由著名社会心理学家 Robert B. Cialdini 所著， Cialdini 倾其职业生涯来研究影响力，在说服、顺从和谈判领域享有广泛的国际声誉。因其在商业道德和政策运用方面所作的前沿研究，常被称为“影响力教父”。</p>
<a id="more"></a>
<p>本书主要谈论了一些社会生活中常见，但我们通常容易忽视的小套路，从互惠、承诺和一致、社会认同、喜好、权威以及稀缺六个方面对这些套路进行归类，通过一番抽丝剥茧式的分析，来阐述人们面对这些套路时会陷入的思维定势以及应对措施。</p>
<p>在日常生活中，各种销售广告、推销手段层出不穷，一些经不起推敲的广告却有时能够取得奇效，一些看似损害商家自身利益的小套路却能够给商家带来更多利益……这些都是通过影响力这一手段来影响我们的决策。作者通过对影响力的作用方式进行剖析，解释了影响力的厉害关系。因为它，我们可能被无良商家诓骗而蒙受损失，甚至映射到社交生活中，前些年饱受诟病的“PUA”中也能看到影响力这一武器被滥用的影子。</p>
<p>作者的很多论述朴实无华，但却能在平凡的语言中让我有种感同身受的真实感。比如以承诺与一致为例，前段时间，偶然间翻看了两年前在简书上写的一篇文章《那些愿意永远坚守的执念》。我以前总是以信念、信仰之类的规诫自己，所以当时兴致偶发，记录了一些优秀的品质借以自勉。殊不知时过境迁，再次重温之时，竟发现这些执念已经在不知不觉之中已经深入记忆，成为了个人为人处世的一部分了。不免有些喟叹，如果当初没有记录的冲动，也许这些执念只会在人情世故中泯然消逝罢了。此外，还有其他许多因素，都能带给我发自内心的共鸣感，通过了解它们，可以帮助我更好地剖析遇到的问题，理解社会现象，避开一些本该能够避免的社会损失。</p>
<h2 id="按一下就播放">1.1 按一下就播放</h2>
<p>影响力对我们起作用的方式是作者称为“按一下就播放”的一种固定行为模式。这种模式最初是研究动物行为时所提，其基本特点是：构成模式的行为每次都是按照几乎无异的方式或相同的顺序发生，就好像这些方式是记录动物身体里内置的磁带上，只要到了特定环境，相应的行为就得到激活，进而按照标准的顺序展开一整套行为，就如同按下了播放键一样。最有意思的一点在于这个磁带的激活方式，促发者也许并不是对手这个整体，而是对手具备的一些特征。</p>
<p>而在人类社会中，同样存在按一下就播放的范式，比如别人在请求我们帮忙的时候，要是能给一个理由，我们通常会乐意提供帮助。“因为”这个词可以触发我我们的自动顺从反应，哪怕请求者并没有给出一个说得通的理由，但我们潜意识里会说服自己去帮助对方，就像是“因为”这个词语按下了我们顺从反应的按钮一般。</p>
<p>事实上，这种模式化的自动行为在人类活动中是相当普遍的。因为很多时候，它是最有效的行为方式。英国著名哲学家怀特海（Alfred North Whitehead） 曾断言：文明的进步，就是人们在不假思索中可以做的事情越来越多。我们都生活在一个极其复杂的环境中，为了应对社会生活的日新月异，我们需要捷径，因为我们没有足够的时间、精力和能力来对每一件事采取“谋定而后动”的策略。所以，我们需要频繁地根据少数关键特征把事情进行分类，以便下次碰到同样的触发特征，就可以不假思索地做出最为有利的反应。</p>
<h1 id="互惠">2 互惠</h1>
<h2 id="滴水之恩涌泉相报">2.1 滴水之恩，涌泉相报</h2>
<p>互惠原理指，当别人帮了我们的忙，给了我们好处，我们应当回报他，也即我们平时所说，滴水之恩，定当以涌泉相报。著名考古学家理查德·利基（Richard Leakey）认为：正是因为有了互惠体系，人类才成为人类。确实，倘若我们没有学会“有债必还”的道理，人类又如何会走上劳动分工的道路呢？更遑论让个体相互依赖，凝结成高效率的单位了。</p>
<p>该原理告诉我们，超市在希望消费者购买产品时，通常会先向向消费者施加小小的恩惠，如赠送样品，通过这种小技巧，就可以极大地提高消费者依其言行其事的概率。当然，在消费者不断被资本家割韭菜的今日，个人感觉这种小伎俩早已不足以打动消费者了。</p>
<p>此外，在无关金钱和商业交易的人际关系中，同样也受互惠原理的影响，他人通过硬塞给我们一些好处，就能触发我们的亏欠感。这份亏欠感会驱使我们对别人的付出进行弥补和偿还，而正是这份偿还义务构成了互惠原理的实质。古人云：滴水之恩，当涌泉相报。最初的小小善意会刺激人们报以大得多的恩惠，因为亏欠感会让我们心生内疚。</p>
<p>这一点让我倍感亲切，我妈从小教育我，不要贪图别人的小便宜，不要亏欠别人。我也一直践行着这一准则，总觉得自己不够强大，总觉得自己无以回报，哪怕自己真的需要，也会尽量避免找人帮忙，即便找人帮忙或者受人人情，最终也一定会以回报大于得到而终。因为我始终以高规格的精神标准要求自己，当心理亏欠的负担落在肩头，有时是比物质损失更难以忍受的折磨。</p>
<h2 id="互惠式让步">2.2 互惠式让步</h2>
<p>除了上述滴水之恩，涌泉相报的常规互惠范式之外，还有一种常见的套路“互惠式让步”。它的实现途径也比较简单，首先，它迫使接受了对方让步的人以同样的方式回应；其次，由于接受了让步的人有回报的义务，人们就乐意率先让步，从而启动有益的交换过程。</p>
<p>简单来说就是，假设你想让我答应你的某个请求，为了增加获胜的概率，你可以先向我提出一个大些的要求，等我拒绝之后，再提出一个稍小的要求，而这个要求才是你真正的目标。倘若你的要求设置巧妙，我会把你的第二个要求看成对我的让步，并有可能感到自己这边也应该让步，于是顺从了你的第二个要求。</p>
<p>这种手段也叫做“拒绝——后撤术”，常见于谈判和推销过程中，一些经验老道的销售员能够非常娴熟地使用这种手段，诱使消费者进入预先编织好的“陷阱”中，不但赢得了业绩，也引起了消费者对拒绝销售员最初的请求而使销售员蒙受顺势的愧疚中。而实际上也许蒙受损失的是我们自己，尽管该损失对我们造成的影响有时微乎其微。但如果我们能够识别这些伎俩，那么我们就有了更多的选择空间，而不会落入了别人的圈套中而不自知，被别人的话术引导我们做出与初心违背的决策。</p>
<h2 id="如何拒绝互惠">2.3 如何拒绝互惠</h2>
<p>正常情况下，我们都会屈从于互惠原理，顺从请求者的愿望；虽然我们也可能会拒绝服从，但这样以来，我们内心深处就会承受因违背互惠原理而带来的公平感和义务感的谴责。所以倘若别人的提议我们确实赞同，那就不妨大胆接受它；但如果该提议别有所图，那么我们就置之不理，并且可以有足够的理由在心理安慰自己。毕竟互惠原理只说要以善意回报善意，可没说用善意回报诡计。</p>
<p>比如说，有人给了我们恩惠，我们可以安心接受下来，同时认识到将来有回报他的义务，然而如果这个人企图通过互惠原理利用我们，那么我们就应该保持警惕，同时视情况心安理得的盘剥他之前给的恩惠，毕竟互惠原理也说了，公正的意思，就是盘剥的行为要还以盘剥。此外，通过这件事情，可以推测出其行事风格带有极强的目的性，在未来的相关人际交往中，应该敬而远之。</p>
<h1 id="承诺与一致">3 承诺与一致</h1>
<h2 id="言出必行">3.1 言出必行</h2>
<p>承诺和一致指的是，我们们个人都有一种言行一致的愿望。一旦做出了艰难的选择，我们就很乐意相信自己选对了，事实上，我们经常会一次次地欺骗自己，以便在做出选择之后，相信自己做的没错。这也跟社会认同有关，因为在社会中，言行前后不一致的人，很容易会被看成脑筋混乱、表里不一，甚至精神有毛病的人；而与之相对的，言行高度通常跟个性坚强、能力出众挂钩。</p>
<p>言行一致其实还跟人类进化过程中的经验有关，因为言行一致符合我们这一群体的最佳利益，所以在进化过程中，这些经验不断驱使我们养成保持一致的习惯，哪怕有时候这么做并不明智。在日新月异的信息化时代，我们面临的社会环境远远超过了我们大脑能够处理的维度，如果任何事情都经过深思熟虑之后，再做出与之相应的最优决策，这是不切实际的，所以为了适应复杂的现代生活，我们大脑很容易沉浸在舒适圈中，选择言行一致这样一条捷径。其次，机械地保持一致，有时也能够避免理性上的折磨，避免误入歧途。试想，当一系列重要性程度相差无几的事项需要我们去选择时，毫无疑问，我们会选择自己熟知或者承诺过的事项作优先处理。</p>
<h2 id="承诺">3.2 承诺</h2>
<p>一旦我们意识到，我们的行动要受到言行一致的潜在精神动力所指引，那么我们在日常生活中就更加应该注意到承诺的重要性。我们一旦进行了承诺，就有可能会影响自我认知。前一段时间，偶然间看到了两年前在简书上写的一篇文章《那些愿意永远坚守的执念》，写文章的初心假借文章来规诫自己，时过境迁，到现在再去看这篇文章时，发现这些信念已经在不知不觉中对我的为人处世的风格产生了潜移默化的影响，我自己也在不知不觉中成为了一个精神世界饱满的人，这些君子规诫也在不断影响我的言行举止。所以不要小看写作的力量，写作是一种书面宣言，它成了一个行为业已发生的物证，会让我们不自觉中朝着声明里的方向改变态度，不断暗示自己：我们真心相信所写下的事情。</p>
<p>在知晓了承诺的影响力之后，在日常生活中，我们在接受琐碎请求时务必小心谨慎，因为它不仅能提高我们对分量更大的类似请求的顺从度，还能使我们更乐意去做一些跟先前答应的小要求毫不相关的事情。每当我们当众选择了一种立场，便会产生维持它的动机，因为这样才能显得前后一致。而有时候，维持这一动机所要付出的努力并不轻松，这便牵扯到为承诺付出的额外的努力。</p>
<p>心理学告诉我们，当我们为一个承诺付出的努力越多，它对承诺的影响力也就越大。这很容易理解：费劲周折才得到某样东西的人，比轻轻松松就得到的人，对这件东西往往更为珍视。这就能够让人理解，在大学校园里，一些社团的凝聚力极强，宛如一捆绳将所有社员凝聚在一起，而有的社团却如一盘散沙。这其实或多或少跟入社团时所付出的努力以及在参与社团活动中的个人参与有关，当你在一个组织中参与度越高，你对其的认同感和归属感也就也强。所以对于组织管理者而言，要想让一个组织具有极强的凝聚力，这种在组织事物参与中形成的羁绊的作用不容忽视。</p>
<h2 id="内心抉择和抛低球">3.3 内心抉择和抛低球</h2>
<p>除了承诺之外，还有两种与之相关的现象较为常见。内心抉择是指，我们很容易相信，我们要对自己的所作所为负责，一旦做了就没有借口可找，没有退路可言。但人是理性的，很容易为自己的行为做理由和借口。当外界存在较为强大的压力时，我们很容易为自己的行为找借口。</p>
<p>就拿我自己来说，我平时爱好十分广泛，喜欢看各种领域的课外书。但是当一种领域内的知识成为我的专业课知识时，我就产生了抵触心理，会厌倦它，虽然我个人并不是很看重课程的成绩，会按照自己的处事风格去处理每一门课程，但终归在学习这一课程时体会不了那种扩充知识面的喜悦感，只会认为这种学习是一种应付，长久下来，心中所剩的只有满目疲倦。所以我很认同作者所说：只有当我们认为外界不存在强大的压力时，我们才会为自己的行为发自内心地负起责任，并对自己言行一致的事实产生骄傲和自豪。</p>
<p>抛低球行为则更常见了，指的是先给人一个甜头，诱使人做出有利的购买决定。而后，等决定做好了，交易还没最终排版，卖方巧妙地取消了最初的甜头。有点类似于言行不一致，这在人情世故中同样常见，但也同样让人厌恶，这种由得转失的心理落差只会让人心中更为郁闷，有一种被耍了还在帮别人数钱的感觉。我自己就遇见过两回这种事情，也许这种事情对于对方而言只是无关紧要的事情，但对我而言，这不仅仅是小事，而是关乎人性的问题。有时我在想，如果我看不透做个糊涂人多好，可偏偏看透了，之后还是得抬头不见低头见地继续打交道，着实折磨人。</p>
<h2 id="如何拒绝">3.4 如何拒绝</h2>
<p>虽然承诺和一致是十分重要的品质，但有时难免被别有用心的人利用，这在以前一般体现在推销过程中，但对于生活在信息化时代，饱受电话推销苦恼的我们而言，这种套路几乎不用过于担心。反而是在社会生活中，我们饱受这一原理的影响，为人所熟知的沉没成本就是这一原理的体现。人们很容易沉浸在已经付出的沉没成本中，无法痛下决心舍弃某一事物。</p>
<p>正如拉夫尔·沃尔多·爱默生所说：死脑筋地保持一致愚不可及。虽然在现实生活中，保持一致是有逻辑性和智力超群的表现，而缺乏这一特点，则会被看成脑筋不够用，智力有障碍。但我们不能在一件错误的事情上执迷不悟。为了应对这一原理，我们应该跟随直觉：知道了我现在掌握的这些情况，要是时间能够倒流，我还会做出同样的选择吗？如果答案是否定的话，那么我们应该有壮士断腕的胸襟，抛却过去所付出的努力，重新开始新的征程！</p>
<h1 id="社会认同">4 社会认同</h1>
<h2 id="模仿">4.1 模仿</h2>
<p>社会认同原理指出：在判断何为正确时，我们会根据别人的意见行事。大多数时候，我们对社会认同的方式完全是无意识的、条件反射式的。一个很常见的案例是邪教，有时候我们旁人看起来邪教宣扬的教义明显也站不住脚的，但仍然存在着许多教徒，其中很多教徒对邪教本身并没有归属感，而是见到了许多信仰程度极高的人，在“三人成虎”的影响下，这些缺乏主见的人逐渐会开始相信这种信仰，这就是社会认同原理。</p>
<p>有一个非常有意思的现象，一些邪教会主动创造一些末日预言，在应对预言的过程中，培养教徒对邪教的信赖感，当我们以为这种愚昧的预言落空时，这些教徒会重回正道，现实却并不如此，他们反而会朝着错误的方向渐行渐远。比如小时候有一些邪教大肆宣扬 2012，世界末日，而当我们以为 2013 年的钟声敲响时，这种愚昧的把戏会不攻自破，而邪教本身也会土崩瓦解，然而事实却并非如此。事实是之前大肆宣扬教义的信徒，在预言落空后，反而成为了更加坚定的信徒。</p>
<p>这其实也不难理解，根据上一节中所说的额外的努力可知，这些信徒心中十分坚定地相信着邪教本身，为了坚守其心中的坚定，他们抛弃了许多，甚至有的抛弃了家庭。当语言落空后，他们其实心中已经有了怀疑，然而沉没成本让他们心有不甘，更为重要的是，一旦确定自己一直以来所坚定的信仰本身就是错误的，那这种前景显得过于可怕。正如作者所说，在预言落空后，驱使信徒们宣扬其信仰的，并不是先前的确定感，而是一种逐渐扩散的怀疑。</p>
<h2 id="不确定性">4.2 不确定性</h2>
<p>销售顾问卡维特·罗伯特（Cavett Robert） 总结了社会认同原理：95%的人都爱模仿别人，只有5%的人能首先发起行动，所以要想把人说服，我们提供任何证据的效果都比不上别人的行动。我们模仿别人的初衷就是，当我们处于不确定时，我们很难主动地做出决定，这时我们大脑会不自觉地选择一条捷径 —— 模仿他人。因为我们潜意识里觉得，这些敢于行动的人知道的信息会比我们多，而在更多的先验信息条件下，他们的行为极有可能是正确的。</p>
<p>我们在观察力与我们相似的人的行为时，社会认同原理能发挥出最大的影响。我们会根据他人的行为来判断自己怎么做才合适，尤其是我们觉得这些人跟自己相似的时候。这有时候其实也会造成一些不利的影响—— <strong>多元无知效应</strong>。多元无知效应揭示了一种乱象：受害者迫切需要帮助，全体旁观者却无动于衷。也许这在法治社会的当下，显得有些过于遥远，但如果说一个熟知的事件：跌倒的老人，扶不扶？当然，在负面新闻的熏染下，这个问题已经不仅仅涉及社会心理了，还跟道德、法律等有关。</p>
<p><strong>多元无知效应</strong> 讲的是，当现场有大量其他旁观者在场时，人们对紧急情况伸出援手的可能性极低。这是因为： 1. 周围有其他可以帮忙的人，单个人要承担的责任就减少了。 2. 很多时候，紧急情况表面上看起来并不显得十分紧急。</p>
<p>在公共场合中，我们所有人都喜欢摆出从容不迫的模样来显示我们的成熟稳重，但其实很可能只是暗中瞟着周围的人，不动声色地寻找证据。如果所有人都选择袖手旁观，那么每个人很有可能都得出判断：既然没人在乎，那就应该没什么问题。所以很多时候，旁观者群体没能帮忙，不是因为现在的人变得更为冷漠了，而是因为他们不能确定。这也是为什么现在新闻十分重视宣扬见义勇为的好人好事，因为打破思维定势真的需要很大的勇气。</p>
<p>多元无知效应在陌生人里显得最为突出：因为我们喜欢在公众面前表现得优雅而成熟，又因为我们不熟悉陌生人的反应，所以，置身于一群素不相识的人里面，我们有可能无法流露出关切的表情，也无法正确地解读他人关切的表情。所以，在一个完全陌生的环境中，当我们需要紧急救助的时候，最佳策略是减少不确定性，让周围人注意到你的状况，搞清楚自己的责任。</p>
<h2 id="如何拒绝-1">4.3 如何拒绝</h2>
<p>乍一看，社会认同好像与商业领域并无关联，其实不然，社会认同原理为我们配备了一种奇妙的自动导航仪，而许多商家就会利用我们的导航仪，来为自己的门店营造出十分火爆的场面，比如互联网下的销量为王、刷单刷好评，都是这一原理应用的体现。由于自动导航仪的弊端主要处在系统输入数据错误的时候，所以识别储物数据，就是我们对抗其弊端的最佳方式。面对明显是伪造的社会证据时，我们只要多保持一点警惕感，就能很好的保护自己了。</p>
<p>总体而言，本章所讲的社会认同原理以及有样学样的模仿行为，为我们提供了一条捷径。虽然绝大多数时候，这个自动导航装置能够给我们带来很多便利，但我们绝对不能完全信任这种捷径，哪怕没有人故意往里面添加错误信息，装置也有可能会发生故障。所以在日常生活中，我们应该时刻保持警惕感，虽然不至于所有事项的决策都与社会认同原理反着来，但清楚了事物发展的背后原理之后再做决策，可以让我们减少蒙受损失的概率。</p>
<h1 id="喜好">5 喜好</h1>
<h2 id="喜好的因素">5.1 喜好的因素</h2>
<p>喜好原理无论是商业领域，还是社会交际过程中，都十分普遍。社会学家一直在研究产生好感的因素，为了获得消费者的好感，这些专业人士几乎把每一个因素都巧妙地运用上了。 - 外表</p>
<p>一个人的某个正面特征很容易主导他人的看法，这也是为什么我们很容易对外表姣好的人产生好感的原因，所以外表的光环很容易会为顺从专业人士所利用。比如大部分服务业在招聘服务人员时，会选择面容姣好的从业人员。因为这会在潜意识中收获消费者的好感。</p>
<ul>
<li><p>相似性</p>
<p>相似性原理也可以用感同身受来解释，当别人同我们有许多相似之处时，我们心中会不自觉地产生亲近之感。所以在销售领域，常用的套路就是将产品赋予特别的含义，来拉近与消费者之间的距离，从而获得消费者的好感。</p></li>
<li><p>恭维</p>
<p>虽然恭维这一词语乍一看仿佛带有贬义，其实不然，现如今很多商业品牌会给自己的品牌赋予一些头衔，比如情怀、富贵的象征等等，归根结底还是恭维原理在起作用。通过赋予品牌和使用品牌的人新的内涵，进而收获消费者的好感。</p></li>
<li><p>接触与合作</p>
<p>由于熟悉感会影响人的喜好，因为这种熟悉感会对我们的各种决定都产生着影响。接触与合作更多地是针对群体好感度的快速提升，许多公司会花大笔财力物力给员工举办团建活动，目的就是为了促进团队之间的好感度和对公司的归属感，通过这种好感度的提升，进而促进团队内部办事效率的提升。</p>
<p>还有一种较为常见的合作是唱红脸和唱白脸，这种手段多用在审讯犯人的时候。但其实在商业竞争中，我们也可以将两个寡头之间的竞争看作是这种手段的翻版。有了差异化的决策，就有了抉择，我们通常会对唱红脸的一方产生好感，所以在商业领域中，我们很容易看见“落井下石”的现象，就是为了在已有“白脸”的衬托下，自己做一回红脸。</p></li>
<li><p>条件反射和关联</p>
<p>制造商总是急着把自己的产品跟当前的文化热潮、名人、流行艺人联系起来。通过名人代言来收获好感。在社会交际中，这项原理同样适用，根据关联原理，倘若我们能用一些哪怕是非常表面的方式让自己跟成功联系起来，我们的公共形象也会显得光辉起来。所以我们经常听到别人公开吹嘘与其他成功者的关系，目的就是在于沾染反射而来的荣誉光彩。</p>
<p>虽然我们或多或少地想沾染一点荣耀的光彩，但有些人走的太远了。主要原因在于他们的自我适应太差。他们内心深处的个人价值感过低，没办法靠推动或实现自身成就来追求荣誉，只能靠着吹嘘自己与他人成就的关系来找回尊严，可悲亦可叹！</p></li>
</ul>
<h2 id="如何拒绝-2">5.2 如何拒绝</h2>
<p>虽然经济学告诉我们消费的目的是满足心中的效用，但我们也不能在被设计好的喜好中渐行渐远。应对喜好原理的关键点在于：把注意力放在效果上，而非成因上。在跟顺从专业人士接触的时候，我们只需关注跟好感有关的一件事就行：我们是不是觉得自己超乎寻常地、迅速地、热烈地喜欢上了对方？如果答案显而易见，那么我们就应该保持警惕了，也许对方只是为了博取你的好感，进而实现其目的罢了，而这些目的通常有可能是建立在你的损失之上的。</p>
<p>关注喜好原理的产生，并不是说要我们压抑好感因素产生的影响力，相反，我们应该听凭这些因素发挥力量，然后用这股力量反过来对付那些想从中获利的人。这股力量越大，其发作用也就越发明显，对我们的戒备防御也就越有帮助。</p>
<h1 id="权威">6 权威</h1>
<h2 id="权威的影响">6.1 权威的影响</h2>
<p>心理学教授 <a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1611393075&amp;ver=2846&amp;signature=qbwls350egVrZj372FInEd5SLaLArk5jDigKCXJqyBS1wmw8NAucXO2bdGRcCYSC9vj*te2U03nX3lh2bxX7Gt53EEhrlPEyufWVD4HnIncV7yaCEIlpgaNJOwDjhmZI&amp;new=1">米尔格拉姆的实验</a> 揭露了一个事实：在权威的命令下，人们几乎愿意干任何事情。权威表示教化下的敬重，在我们潜意识里，权威意味着正确。所以在不确定的情况下，我们很容易跟着权威走。然而这份顺从有时被别出心裁的商家所利用，让我们掉入商家精心设计的思维定势中。</p>
<p>每当面对人类行为背后的一种强力推动因素，我们都会很自然地想到，这种推动因素的存在是有着充分的理由的。服从权威人物的命令，总是能给我们带来一些实际的好处，因为它帮助我们节省了思考的时间。这也是为什么一些牙膏、药品广告中通常会出现一些身穿白大褂的人物形象，因为很多情况下，只要有正统的权威说了话，其他本来应该考虑的事情就变得不相关了，即便这种权威是伪装出来的，也会对我们的认知产生或多或少的影响。</p>
<p>将权威这一含义泛化一下，其实更容易理解。我们在写个人简历的时候，惯用的手法就是写上自身相关经历在上面，其实这也可以看作是权威原理起作用的表现方式之一，因为通过这种头衔、相关经历的阐述，可以传达一个自己在相关事项上的权威能力，这种“权威”通常能让我们在竞争中处于优势地位。除了头衔之外，面试时的衣着、身份标识（豪车、名表）等传达的也是类似的信息，通过这种公开信息，能够让我们在公众中收获特殊的尊重，哪怕这种尊重是单纯的畏惧，也会对当事人产生莫名的自豪和骄傲。</p>
<h2 id="如何拒绝-3">6.2 如何拒绝</h2>
<p>为了免受伪权威的误导，防御策略之一就是提前做好心理准备。我们通常会低估权威及其象征对自己行为的影响，然而事实是一旦它出现在要求顺从的场合，我们往往来不及提防。破解伪权威对我们决策的影响，我们只需在脑海中问自己两个问题： 1. 这个权威是真正的专家吗</p>
<p>这个问题能让我嗯我们把焦点放在：权威的资格，以及这些资格是否跟眼前的主题相关。帮助我们从兴许毫无意义的权威符号上挪开视线，转到真正的权威资格上。通过这种简单的方法，着眼于权威地位的证据，能让我们避免自动顺从带来的大部分问题。</p>
<ol start="2" type="1">
<li>这个专家说的是真话吗？</li>
</ol>
<p>哪怕是知识最丰富的权威，也不一定会开诚布公地把信息告知我们，因此，我们必须考虑一下他们在当前情形下的真实可信度。多思考一下专家会不会因为我们的顺从而得到好处，通过这样，我们就为自己又设立了一道安全网，防御权威不必要的影响。比较常见的一个小伎俩是——怀柔，即一些看似违背自己利益的做法。这无论是商业领域还是为人处世中，都会不自觉地被人们加以利用，通过这种看似违背自己利益的做法，可以拉近与对方的距离，增强对方对我们的好感度。</p>
<h1 id="稀缺">7 稀缺</h1>
<h2 id="物以稀为贵">7.1 物以稀为贵</h2>
<p>稀缺原理指的是，机会越少见，价值似乎就越高。对失去某种东西的恐惧通常比获得同一物品的渴望，更能激发我们的行动力。而有时，讽刺的地方也在这儿，倘若瑕疵把一样东西变得稀缺了，垃圾也能化身成值钱的宝贝，这在玩物收藏市场几乎是常态了。其实，现实生活中，我们最容易受稀缺原理的影响了，最常见的两种商业套路是： - 数量有限策略</p>
<ul>
<li>最后期限战术</li>
</ul>
<p>商家惯用的商业套路就是营造一些降价折扣的事由，来刺激消费者对商品进行购买，也许商品本身并不在消费者最初消费计划中，但是在稀缺性的刺激下，商品的认知价值在消费者心中突然有了大幅提升。其实降价也可以算在稀缺性原理中，因为相对于日常的高位价格，暂时性的降价折扣就显得颇为稀缺，错过了当下，以后可能需要花费更高额度的费用，这种期望落差通常会刺激消费者做出不理性的购买决策。</p>
<p>此外，另一种常见的套路就是有竞争性的稀缺资源，参与竞争稀缺资源的感觉，有着比单纯的稀有资源更为强大的吸引力。渴望拥有一件众人争抢的东西，几乎是出于本能的身体反应。所以在稀缺物品的竞拍中，我们通常能见到类似的现象，通过简单的心理博弈，能够让最终的成交价格朝着卖家预设的价位移动。</p>
<h2 id="逆反心理">7.2 逆反心理</h2>
<p>稀缺性原理起作用的力量主要来自两个方面。第一点它钻了我们思维捷径上的漏洞。在我们认知中，难以得到的东西，通常会让我们更为珍视。故此，我们基本可以根据获得一样东西的难易程度，迅速、准确地判断它质量，而这种判断在很大程度上是正确的。</p>
<p>第二点在于，机会越来越少的话，我们的自由也会随之丧失。每当有东西获取起来比以前难，我们拥有它的自由受了限制，我们就越发地想要得到它。我们痛恨失去本来拥有的自由，这种保住既得利益的愿望是心里逆反理论的核心。</p>
<p>詹姆斯·戴维斯（James Davies）曾指出，一个国家在经济和社会条件改善后，要是在短期内出现剧烈逆转，最有可能爆发革命。而且最容易企业的，不是那些传统上最受压迫的底层人民，而是品尝过了更美好生活的人。因为该群体得到了以前从来没有的自由，一点有人想要夺走这些自由，就注定要付出一些代价。</p>
<p>在实际生活中逆反心理也比较常见，最为人所熟知的一种现象就是青少年的叛逆期。通过上述阐述，我们知道自由这种东西，给一点又拿走，比完全不给更危险。所以管教前后不一的父母，更容易教出反叛心强的孩子。所以在教育孩子上，家长应该以身作则，给孩子树立良好的榜样，而不是严于律人，宽以待己。</p>
<h2 id="如何拒绝-4">7.3 如何拒绝</h2>
<p>在知晓我们如何拒绝稀缺原理影响我们决策时，我们应该知道一个道理：喜悦并非来自对稀缺商品的体验，而是来自对它的占有。稀缺的东西并不因为难以占有，就变得更好吃、好听、好看、好用了。所以一旦我们觉得我们在短缺影响下产生了高度的情绪波动，我们就应该把这种波动当成暂停的信号，并在心底询问自己，为什么我们想要那件东西，是为了拥有它，还是为了它的价值或功能。</p>
<p>谈若是因为想拥有它，那么我们应该利用它的稀缺性来判断改为它出多少钱，一旦价格超出该底线，我们应该心生警惕，因为这也许是商家在利用稀缺性原理在谋取的超额收益。如果是为了它的功能，那么我们应该牢记一点：该物品并不会因为稀缺而增强它的功能。换而言之，我们应该积极寻求它的等价替代产品，获取更多信息之后，在做出合理的决策。</p>
<h1 id="总结">8 总结</h1>
<p>作者写本书的目的并不是说，让我们对这些简单而常见的小套路避之不及，而是希望我们能洞悉事物发展背后的逻辑，至少在明事理之后，能让我们有了更多选择的权利，不至于让我们在被“戏耍”后而不自知。尽管只靠孤立数据容易做出愚蠢的决定，可现代生活的节奏又要求我们频繁使用这一捷径。</p>
<p>为了追求效率，有时候我们必须放弃耗时而复杂的全局决策过程，转而使用更简单、由单一特征出发的响应方式。它之所以最为常用，完全是因为它们的可靠性高，在我们人类进化过程中，通常都能指引我们做出正确决定，这也是为什么我们会潜意识里借助这些因素做出顺从决定。在没有意愿、时间、精力或认知资源对情况进行全面分析的时候，使用这些孤立的线索进行决策是简单而保险的决策方式。</p>
<p>正如作者所说一般，这种便捷的响应方式应当受到尊重。在日新月异的当下，技术的进步速度远远快于我们，所以我们处理信息的天然能力将有可能越来越难于应对当代生活中繁多的变化、选择和挑战。有时我们会发现自己陷入了跟低等动物一样的处境中：外界环境的错综复杂超出了我们心智的处理能力。从这个方面来说，我们的大脑潜意识里依赖可靠而合理的捷径和首选规则来应对生活的紧张节奏也是无可厚非的。</p>
<p>然而，我们真正值得警惕的是，那些知晓我们的响应机制，但通过别出心裁的设计来破坏我们的心理机制，或者说通过我们的响应机制来蒙蔽我们，来从我们身上谋取私利的人。虽然大多数时候，这种戏弄不会对我们造成太大的损失，但正如《三国志·蜀书·先主传》所说：“勿以善小而不为，勿以恶小而为之”，积小成多，聚沙成塔，终归会有一天对我们的反应机制产生不可逆的影响。</p>
<p>正如一直以来我对自己的要求：我可以不成为这一领域的专家，但其中的基本原理我得懂，这也是为什么这么多年来，我始终如一地扩充自己的知识面。一方面是因为获取知识的过程能给我带来确实的快感，另一方面则是因为，涉猎各领域的知识能够让我以更多的角度看待事物，不至于让自己的无知中变成一个智慧鹦鹉学舌而不会独立思考的人！</p>
<p>最后附上我最喜欢的一个著名投资家查理·芒格所说的一句话： &gt; 我这辈子遇到的聪明人（来自各行各业的聪明人）没有不每天阅读的 —— 没有，一个都没有。巴菲特读书之多，我读书之多，可能会让你感到吃惊。孩子们都笑话我，他们觉得我是一本长了两条腿的书。</p>
<p>很多人读书，追求的是干货，寻求的是立刻行之有效的解决方案。其实这是一种留在舒适区的阅读方法。在这个充满不确定的时代，答案不会简单地出现在书里，因为生活根本就没有标准确切的答案，你也不能期望过去的经验能够解决未来的问题。能简单地出现在书中的答案只有试卷，而这也是我不喜欢以考试来鞭策读书的原因之一，只可惜在现今成绩为王的时代，能做的只有在半顺从下坚持自己原则。除此之外，别无他法，可悲！</p>
<p>本书主要谈论了一些社会生活中常见，但我们通常容易忽视的小套路，从互惠、承诺和一致、社会认同、喜好、权威以及稀缺六个方面对这些套路进行归类，通过一番抽丝剥茧式的分析，来阐述人们面对这些套路时会陷入的思维定势以及应对措施。</p>
<p>在日常生活中，各种销售广告、推销手段层出不穷，一些经不起推敲的广告却有时能够取得奇效，一些看似损害商家自身利益的小套路却能够给商家带来更多利益……这些都是通过影响力这一手段来影响我们的决策。作者通过对影响力的作用方式进行剖析，解释了影响力的厉害关系。因为它，我们可能被无良商家诓骗而蒙受损失，甚至映射到社交生活中，前些年饱受诟病的“PUA”中也能看到影响力这一武器被滥用的影子。</p>
<p>作者的很多论述朴实无华，但却能在平凡的语言中让我有种感同身受的真实感。比如以承诺与一致为例，前段时间，偶然间翻看了两年前在简书上写的一篇文章《那些愿意永远坚守的执念》。我以前总是以信念、信仰之类的规诫自己，所以当时兴致偶发，记录了一些优秀的品质借以自勉。殊不知时过境迁，再次重温之时，竟发现这些执念已经在不知不觉之中已经深入记忆，成为了个人为人处世的一部分了。不免有些喟叹，如果当初没有记录的冲动，也许这些执念只会在人情世故中泯然消逝罢了。此外，还有其他许多因素，都能带给我发自内心的共鸣感，通过了解它们，可以帮助我更好地剖析遇到的问题，理解社会现象，避开一些本该能够避免的社会损失。</p>
<p>## 1.1 按一下就播放</p>
<p>影响力对我们起作用的方式是作者称为“按一下就播放”的一种固定行为模式。这种模式最初是研究动物行为时所提，其基本特点是：构成模式的行为每次都是按照几乎无异的方式或相同的顺序发生，就好像这些方式是记录动物身体里内置的磁带上，只要到了特定环境，相应的行为就得到激活，进而按照标准的顺序展开一整套行为，就如同按下了播放键一样。最有意思的一点在于这个磁带的激活方式，促发者也许并不是对手这个整体，而是对手具备的一些特征。</p>
<p>而在人类社会中，同样存在按一下就播放的范式，比如别人在请求我们帮忙的时候，要是能给一个理由，我们通常会乐意提供帮助。“因为”这个词可以触发我我们的自动顺从反应，哪怕请求者并没有给出一个说得通的理由，但我们潜意识里会说服自己去帮助对方，就像是“因为”这个词语按下了我们顺从反应的按钮一般。</p>
<p>事实上，这种模式化的自动行为在人类活动中是相当普遍的。因为很多时候，它是最有效的行为方式。英国著名哲学家怀特海（Alfred North Whitehead） 曾断言：文明的进步，就是人们在不假思索中可以做的事情越来越多。我们都生活在一个极其复杂的环境中，为了应对社会生活的日新月异，我们需要捷径，因为我们没有足够的时间、精力和能力来对每一件事采取“谋定而后动”的策略。所以，我们需要频繁地根据少数关键特征把事情进行分类，以便下次碰到同样的触发特征，就可以不假思索地做出最为有利的反应。</p>
<p># 2 互惠</p>
<p>## 2.1 滴水之恩，涌泉相报</p>
<p>互惠原理指，当别人帮了我们的忙，给了我们好处，我们应当回报他，也即我们平时所说，滴水之恩，定当以涌泉相报。著名考古学家理查德·利基（Richard Leakey）认为：正是因为有了互惠体系，人类才成为人类。确实，倘若我们没有学会“有债必还”的道理，人类又如何会走上劳动分工的道路呢？更遑论让个体相互依赖，凝结成高效率的单位了。</p>
<p>该原理告诉我们，超市在希望消费者购买产品时，通常会先向向消费者施加小小的恩惠，如赠送样品，通过这种小技巧，就可以极大地提高消费者依其言行其事的概率。当然，在消费者不断被资本家割韭菜的今日，个人感觉这种小伎俩早已不足以打动消费者了。</p>
<p>此外，在无关金钱和商业交易的人际关系中，同样也受互惠原理的影响，他人通过硬塞给我们一些好处，就能触发我们的亏欠感。这份亏欠感会驱使我们对别人的付出进行弥补和偿还，而正是这份偿还义务构成了互惠原理的实质。古人云：滴水之恩，当涌泉相报。最初的小小善意会刺激人们报以大得多的恩惠，因为亏欠感会让我们心生内疚。</p>
<p>这一点让我倍感亲切，我妈从小教育我，不要贪图别人的小便宜，不要亏欠别人。我也一直践行着这一准则，总觉得自己不够强大，总觉得自己无以回报，哪怕自己真的需要，也会尽量避免找人帮忙，即便找人帮忙或者受人人情，最终也一定会以回报大于得到而终。因为我始终以高规格的精神标准要求自己，当心理亏欠的负担落在肩头，有时是比物质损失更难以忍受的折磨。</p>
<p>## 2.2 互惠式让步</p>
<p>除了上述滴水之恩，涌泉相报的常规互惠范式之外，还有一种常见的套路“互惠式让步”。它的实现途径也比较简单，首先，它迫使接受了对方让步的人以同样的方式回应；其次，由于接受了让步的人有回报的义务，人们就乐意率先让步，从而启动有益的交换过程。</p>
<p>简单来说就是，假设你想让我答应你的某个请求，为了增加获胜的概率，你可以先向我提出一个大些的要求，等我拒绝之后，再提出一个稍小的要求，而这个要求才是你真正的目标。倘若你的要求设置巧妙，我会把你的第二个要求看成对我的让步，并有可能感到自己这边也应该让步，于是顺从了你的第二个要求。</p>
<p>这种手段也叫做“拒绝——后撤术”，常见于谈判和推销过程中，一些经验老道的销售员能够非常娴熟地使用这种手段，诱使消费者进入预先编织好的“陷阱”中，不但赢得了业绩，也引起了消费者对拒绝销售员最初的请求而使销售员蒙受顺势的愧疚中。而实际上也许蒙受损失的是我们自己，尽管该损失对我们造成的影响有时微乎其微。但如果我们能够识别这些伎俩，那么我们就有了更多的选择空间，而不会落入了别人的圈套中而不自知，被别人的话术引导我们做出与初心违背的决策。</p>
<p>## 2.3 如何拒绝互惠</p>
<p>正常情况下，我们都会屈从于互惠原理，顺从请求者的愿望；虽然我们也可能会拒绝服从，但这样以来，我们内心深处就会承受因违背互惠原理而带来的公平感和义务感的谴责。所以倘若别人的提议我们确实赞同，那就不妨大胆接受它；但如果该提议别有所图，那么我们就置之不理，并且可以有足够的理由在心理安慰自己。毕竟互惠原理只说要以善意回报善意，可没说用善意回报诡计。</p>
<p>比如说，有人给了我们恩惠，我们可以安心接受下来，同时认识到将来有回报他的义务，然而如果这个人企图通过互惠原理利用我们，那么我们就应该保持警惕，同时视情况心安理得的盘剥他之前给的恩惠，毕竟互惠原理也说了，公正的意思，就是盘剥的行为要还以盘剥。此外，通过这件事情，可以推测出其行事风格带有极强的目的性，在未来的相关人际交往中，应该敬而远之。</p>
<p># 3 承诺与一致</p>
<p>## 3.1 言出必行</p>
<p>承诺和一致指的是，我们们个人都有一种言行一致的愿望。一旦做出了艰难的选择，我们就很乐意相信自己选对了，事实上，我们经常会一次次地欺骗自己，以便在做出选择之后，相信自己做的没错。这也跟社会认同有关，因为在社会中，言行前后不一致的人，很容易会被看成脑筋混乱、表里不一，甚至精神有毛病的人；而与之相对的，言行高度通常跟个性坚强、能力出众挂钩。</p>
<p>言行一致其实还跟人类进化过程中的经验有关，因为言行一致符合我们这一群体的最佳利益，所以在进化过程中，这些经验不断驱使我们养成保持一致的习惯，哪怕有时候这么做并不明智。在日新月异的信息化时代，我们面临的社会环境远远超过了我们大脑能够处理的维度，如果任何事情都经过深思熟虑之后，再做出与之相应的最优决策，这是不切实际的，所以为了适应复杂的现代生活，我们大脑很容易沉浸在舒适圈中，选择言行一致这样一条捷径。其次，机械地保持一致，有时也能够避免理性上的折磨，避免误入歧途。试想，当一系列重要性程度相差无几的事项需要我们去选择时，毫无疑问，我们会选择自己熟知或者承诺过的事项作优先处理。</p>
<p>## 3.2 承诺</p>
<p>一旦我们意识到，我们的行动要受到言行一致的潜在精神动力所指引，那么我们在日常生活中就更加应该注意到承诺的重要性。我们一旦进行了承诺，就有可能会影响自我认知。前一段时间，偶然间看到了两年前在简书上写的一篇文章《那些愿意永远坚守的执念》，写文章的初心假借文章来规诫自己，时过境迁，到现在再去看这篇文章时，发现这些信念已经在不知不觉中对我的为人处世的风格产生了潜移默化的影响，我自己也在不知不觉中成为了一个精神世界饱满的人，这些君子规诫也在不断影响我的言行举止。所以不要小看写作的力量，写作是一种书面宣言，它成了一个行为业已发生的物证，会让我们不自觉中朝着声明里的方向改变态度，不断暗示自己：我们真心相信所写下的事情。</p>
<p>在知晓了承诺的影响力之后，在日常生活中，我们在接受琐碎请求时务必小心谨慎，因为它不仅能提高我们对分量更大的类似请求的顺从度，还能使我们更乐意去做一些跟先前答应的小要求毫不相关的事情。每当我们当众选择了一种立场，便会产生维持它的动机，因为这样才能显得前后一致。而有时候，维持这一动机所要付出的努力并不轻松，这便牵扯到为承诺付出的额外的努力。</p>
<p>心理学告诉我们，当我们为一个承诺付出的努力越多，它对承诺的影响力也就越大。这很容易理解：费劲周折才得到某样东西的人，比轻轻松松就得到的人，对这件东西往往更为珍视。这就能够让人理解，在大学校园里，一些社团的凝聚力极强，宛如一捆绳将所有社员凝聚在一起，而有的社团却如一盘散沙。这其实或多或少跟入社团时所付出的努力以及在参与社团活动中的个人参与有关，当你在一个组织中参与度越高，你对其的认同感和归属感也就也强。所以对于组织管理者而言，要想让一个组织具有极强的凝聚力，这种在组织事物参与中形成的羁绊的作用不容忽视。</p>
<p>## 3.3 内心抉择和抛低球</p>
<p>除了承诺之外，还有两种与之相关的现象较为常见。内心抉择是指，我们很容易相信，我们要对自己的所作所为负责，一旦做了就没有借口可找，没有退路可言。但人是理性的，很容易为自己的行为做理由和借口。当外界存在较为强大的压力时，我们很容易为自己的行为找借口。</p>
<p>就拿我自己来说，我平时爱好十分广泛，喜欢看各种领域的课外书。但是当一种领域内的知识成为我的专业课知识时，我就产生了抵触心理，会厌倦它，虽然我个人并不是很看重课程的成绩，会按照自己的处事风格去处理每一门课程，但终归在学习这一课程时体会不了那种扩充知识面的喜悦感，只会认为这种学习是一种应付，长久下来，心中所剩的只有满目疲倦。所以我很认同作者所说：只有当我们认为外界不存在强大的压力时，我们才会为自己的行为发自内心地负起责任，并对自己言行一致的事实产生骄傲和自豪。</p>
<p>抛低球行为则更常见了，指的是先给人一个甜头，诱使人做出有利的购买决定。而后，等决定做好了，交易还没最终排版，卖方巧妙地取消了最初的甜头。有点类似于言行不一致，这在人情世故中同样常见，但也同样让人厌恶，这种由得转失的心理落差只会让人心中更为郁闷，有一种被耍了还在帮别人数钱的感觉。我自己就遇见过两回这种事情，也许这种事情对于对方而言只是无关紧要的事情，但对我而言，这不仅仅是小事，而是关乎人性的问题。有时我在想，如果我看不透做个糊涂人多好，可偏偏看透了，之后还是得抬头不见低头见地继续打交道，着实折磨人。</p>
<p>## 3.4 如何拒绝</p>
<p>虽然承诺和一致是十分重要的品质，但有时难免被别有用心的人利用，这在以前一般体现在推销过程中，但对于生活在信息化时代，饱受电话推销苦恼的我们而言，这种套路几乎不用过于担心。反而是在社会生活中，我们饱受这一原理的影响，为人所熟知的沉没成本就是这一原理的体现。人们很容易沉浸在已经付出的沉没成本中，无法痛下决心舍弃某一事物。</p>
<p>正如拉夫尔·沃尔多·爱默生所说：死脑筋地保持一致愚不可及。虽然在现实生活中，保持一致是有逻辑性和智力超群的表现，而缺乏这一特点，则会被看成脑筋不够用，智力有障碍。但我们不能在一件错误的事情上执迷不悟。为了应对这一原理，我们应该跟随直觉：知道了我现在掌握的这些情况，要是时间能够倒流，我还会做出同样的选择吗？如果答案是否定的话，那么我们应该有壮士断腕的胸襟，抛却过去所付出的努力，重新开始新的征程！</p>
<p># 4 社会认同</p>
<p>## 4.1 模仿</p>
<p>社会认同原理指出：在判断何为正确时，我们会根据别人的意见行事。大多数时候，我们对社会认同的方式完全是无意识的、条件反射式的。一个很常见的案例是邪教，有时候我们旁人看起来邪教宣扬的教义明显也站不住脚的，但仍然存在着许多教徒，其中很多教徒对邪教本身并没有归属感，而是见到了许多信仰程度极高的人，在“三人成虎”的影响下，这些缺乏主见的人逐渐会开始相信这种信仰，这就是社会认同原理。</p>
<p>有一个非常有意思的现象，一些邪教会主动创造一些末日预言，在应对预言的过程中，培养教徒对邪教的信赖感，当我们以为这种愚昧的预言落空时，这些教徒会重回正道，现实却并不如此，他们反而会朝着错误的方向渐行渐远。比如小时候有一些邪教大肆宣扬 2012，世界末日，而当我们以为 2013 年的钟声敲响时，这种愚昧的把戏会不攻自破，而邪教本身也会土崩瓦解，然而事实却并非如此。事实是之前大肆宣扬教义的信徒，在预言落空后，反而成为了更加坚定的信徒。</p>
<p>这其实也不难理解，根据上一节中所说的额外的努力可知，这些信徒心中十分坚定地相信着邪教本身，为了坚守其心中的坚定，他们抛弃了许多，甚至有的抛弃了家庭。当语言落空后，他们其实心中已经有了怀疑，然而沉没成本让他们心有不甘，更为重要的是，一旦确定自己一直以来所坚定的信仰本身就是错误的，那这种前景显得过于可怕。正如作者所说，在预言落空后，驱使信徒们宣扬其信仰的，并不是先前的确定感，而是一种逐渐扩散的怀疑。</p>
<p>## 4.2 不确定性</p>
<p>销售顾问卡维特·罗伯特（Cavett Robert） 总结了社会认同原理：95%的人都爱模仿别人，只有5%的人能首先发起行动，所以要想把人说服，我们提供任何证据的效果都比不上别人的行动。我们模仿别人的初衷就是，当我们处于不确定时，我们很难主动地做出决定，这时我们大脑会不自觉地选择一条捷径 —— 模仿他人。因为我们潜意识里觉得，这些敢于行动的人知道的信息会比我们多，而在更多的先验信息条件下，他们的行为极有可能是正确的。</p>
<p>我们在观察力与我们相似的人的行为时，社会认同原理能发挥出最大的影响。我们会根据他人的行为来判断自己怎么做才合适，尤其是我们觉得这些人跟自己相似的时候。这有时候其实也会造成一些不利的影响—— <strong>多元无知效应</strong>。多元无知效应揭示了一种乱象：受害者迫切需要帮助，全体旁观者却无动于衷。也许这在法治社会的当下，显得有些过于遥远，但如果说一个熟知的事件：跌倒的老人，扶不扶？当然，在负面新闻的熏染下，这个问题已经不仅仅涉及社会心理了，还跟道德、法律等有关。</p>
<p><strong>多元无知效应</strong> 讲的是，当现场有大量其他旁观者在场时，人们对紧急情况伸出援手的可能性极低。这是因为：</p>
<p>\1. 周围有其他可以帮忙的人，单个人要承担的责任就减少了。</p>
<p>\2. 很多时候，紧急情况表面上看起来并不显得十分紧急。</p>
<p>在公共场合中，我们所有人都喜欢摆出从容不迫的模样来显示我们的成熟稳重，但其实很可能只是暗中瞟着周围的人，不动声色地寻找证据。如果所有人都选择袖手旁观，那么每个人很有可能都得出判断：既然没人在乎，那就应该没什么问题。所以很多时候，旁观者群体没能帮忙，不是因为现在的人变得更为冷漠了，而是因为他们不能确定。这也是为什么现在新闻十分重视宣扬见义勇为的好人好事，因为打破思维定势真的需要很大的勇气。</p>
<p>多元无知效应在陌生人里显得最为突出：因为我们喜欢在公众面前表现得优雅而成熟，又因为我们不熟悉陌生人的反应，所以，置身于一群素不相识的人里面，我们有可能无法流露出关切的表情，也无法正确地解读他人关切的表情。所以，在一个完全陌生的环境中，当我们需要紧急救助的时候，最佳策略是减少不确定性，让周围人注意到你的状况，搞清楚自己的责任。</p>
<p>## 4.3 如何拒绝</p>
<p>乍一看，社会认同好像与商业领域并无关联，其实不然，社会认同原理为我们配备了一种奇妙的自动导航仪，而许多商家就会利用我们的导航仪，来为自己的门店营造出十分火爆的场面，比如互联网下的销量为王、刷单刷好评，都是这一原理应用的体现。由于自动导航仪的弊端主要处在系统输入数据错误的时候，所以识别储物数据，就是我们对抗其弊端的最佳方式。面对明显是伪造的社会证据时，我们只要多保持一点警惕感，就能很好的保护自己了。</p>
<p>总体而言，本章所讲的社会认同原理以及有样学样的模仿行为，为我们提供了一条捷径。虽然绝大多数时候，这个自动导航装置能够给我们带来很多便利，但我们绝对不能完全信任这种捷径，哪怕没有人故意往里面添加错误信息，装置也有可能会发生故障。所以在日常生活中，我们应该时刻保持警惕感，虽然不至于所有事项的决策都与社会认同原理反着来，但清楚了事物发展的背后原理之后再做决策，可以让我们减少蒙受损失的概率。</p>
<p># 5 喜好</p>
<p>## 5.1 喜好的因素</p>
<p>喜好原理无论是商业领域，还是社会交际过程中，都十分普遍。社会学家一直在研究产生好感的因素，为了获得消费者的好感，这些专业人士几乎把每一个因素都巧妙地运用上了。</p>
<p>- 外表</p>
<p>一个人的某个正面特征很容易主导他人的看法，这也是为什么我们很容易对外表姣好的人产生好感的原因，所以外表的光环很容易会为顺从专业人士所利用。比如大部分服务业在招聘服务人员时，会选择面容姣好的从业人员。因为这会在潜意识中收获消费者的好感。</p>
<p>- 相似性</p>
<p>相似性原理也可以用感同身受来解释，当别人同我们有许多相似之处时，我们心中会不自觉地产生亲近之感。所以在销售领域，常用的套路就是将产品赋予特别的含义，来拉近与消费者之间的距离，从而获得消费者的好感。</p>
<p>- 恭维</p>
<p>虽然恭维这一词语乍一看仿佛带有贬义，其实不然，现如今很多商业品牌会给自己的品牌赋予一些头衔，比如情怀、富贵的象征等等，归根结底还是恭维原理在起作用。通过赋予品牌和使用品牌的人新的内涵，进而收获消费者的好感。</p>
<p>- 接触与合作</p>
<p>由于熟悉感会影响人的喜好，因为这种熟悉感会对我们的各种决定都产生着影响。接触与合作更多地是针对群体好感度的快速提升，许多公司会花大笔财力物力给员工举办团建活动，目的就是为了促进团队之间的好感度和对公司的归属感，通过这种好感度的提升，进而促进团队内部办事效率的提升。</p>
<p>还有一种较为常见的合作是唱红脸和唱白脸，这种手段多用在审讯犯人的时候。但其实在商业竞争中，我们也可以将两个寡头之间的竞争看作是这种手段的翻版。有了差异化的决策，就有了抉择，我们通常会对唱红脸的一方产生好感，所以在商业领域中，我们很容易看见“落井下石”的现象，就是为了在已有“白脸”的衬托下，自己做一回红脸。</p>
<p>- 条件反射和关联</p>
<p>制造商总是急着把自己的产品跟当前的文化热潮、名人、流行艺人联系起来。通过名人代言来收获好感。在社会交际中，这项原理同样适用，根据关联原理，倘若我们能用一些哪怕是非常表面的方式让自己跟成功联系起来，我们的公共形象也会显得光辉起来。所以我们经常听到别人公开吹嘘与其他成功者的关系，目的就是在于沾染反射而来的荣誉光彩。</p>
<p>虽然我们或多或少地想沾染一点荣耀的光彩，但有些人走的太远了。主要原因在于他们的自我适应太差。他们内心深处的个人价值感过低，没办法靠推动或实现自身成就来追求荣誉，只能靠着吹嘘自己与他人成就的关系来找回尊严，可悲亦可叹！</p>
<p>## 5.2 如何拒绝</p>
<p>虽然经济学告诉我们消费的目的是满足心中的效用，但我们也不能在被设计好的喜好中渐行渐远。应对喜好原理的关键点在于：把注意力放在效果上，而非成因上。在跟顺从专业人士接触的时候，我们只需关注跟好感有关的一件事就行：我们是不是觉得自己超乎寻常地、迅速地、热烈地喜欢上了对方？如果答案显而易见，那么我们就应该保持警惕了，也许对方只是为了博取你的好感，进而实现其目的罢了，而这些目的通常有可能是建立在你的损失之上的。</p>
<p>关注喜好原理的产生，并不是说要我们压抑好感因素产生的影响力，相反，我们应该听凭这些因素发挥力量，然后用这股力量反过来对付那些想从中获利的人。这股力量越大，其发作用也就越发明显，对我们的戒备防御也就越有帮助。</p>
<p># 6 权威</p>
<p>## 6.1 权威的影响</p>
<p>心理学教授 <a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1611393075&amp;ver=2846&amp;signature=qbwls350egVrZj372FInEd5SLaLArk5jDigKCXJqyBS1wmw8NAucXO2bdGRcCYSC9vj*te2U03nX3lh2bxX7Gt53EEhrlPEyufWVD4HnIncV7yaCEIlpgaNJOwDjhmZI&amp;new=1">米尔格拉姆的实验</a> 揭露了一个事实：在权威的命令下，人们几乎愿意干任何事情。权威表示教化下的敬重，在我们潜意识里，权威意味着正确。所以在不确定的情况下，我们很容易跟着权威走。然而这份顺从有时被别出心裁的商家所利用，让我们掉入商家精心设计的思维定势中。</p>
<p>每当面对人类行为背后的一种强力推动因素，我们都会很自然地想到，这种推动因素的存在是有着充分的理由的。服从权威人物的命令，总是能给我们带来一些实际的好处，因为它帮助我们节省了思考的时间。这也是为什么一些牙膏、药品广告中通常会出现一些身穿白大褂的人物形象，因为很多情况下，只要有正统的权威说了话，其他本来应该考虑的事情就变得不相关了，即便这种权威是伪装出来的，也会对我们的认知产生或多或少的影响。</p>
<p>将权威这一含义泛化一下，其实更容易理解。我们在写个人简历的时候，惯用的手法就是写上自身相关经历在上面，其实这也可以看作是权威原理起作用的表现方式之一，因为通过这种头衔、相关经历的阐述，可以传达一个自己在相关事项上的权威能力，这种“权威”通常能让我们在竞争中处于优势地位。除了头衔之外，面试时的衣着、身份标识（豪车、名表）等传达的也是类似的信息，通过这种公开信息，能够让我们在公众中收获特殊的尊重，哪怕这种尊重是单纯的畏惧，也会对当事人产生莫名的自豪和骄傲。</p>
<p>## 6.2 如何拒绝</p>
<p>为了免受伪权威的误导，防御策略之一就是提前做好心理准备。我们通常会低估权威及其象征对自己行为的影响，然而事实是一旦它出现在要求顺从的场合，我们往往来不及提防。破解伪权威对我们决策的影响，我们只需在脑海中问自己两个问题：</p>
<p>\1. 这个权威是真正的专家吗</p>
<p>这个问题能让我嗯我们把焦点放在：权威的资格，以及这些资格是否跟眼前的主题相关。帮助我们从兴许毫无意义的权威符号上挪开视线，转到真正的权威资格上。通过这种简单的方法，着眼于权威地位的证据，能让我们避免自动顺从带来的大部分问题。</p>
<p>\2. 这个专家说的是真话吗？</p>
<p>哪怕是知识最丰富的权威，也不一定会开诚布公地把信息告知我们，因此，我们必须考虑一下他们在当前情形下的真实可信度。多思考一下专家会不会因为我们的顺从而得到好处，通过这样，我们就为自己又设立了一道安全网，防御权威不必要的影响。比较常见的一个小伎俩是——怀柔，即一些看似违背自己利益的做法。这无论是商业领域还是为人处世中，都会不自觉地被人们加以利用，通过这种看似违背自己利益的做法，可以拉近与对方的距离，增强对方对我们的好感度。</p>
<p># 7 稀缺</p>
<p>## 7.1 物以稀为贵</p>
<p>稀缺原理指的是，机会越少见，价值似乎就越高。对失去某种东西的恐惧通常比获得同一物品的渴望，更能激发我们的行动力。而有时，讽刺的地方也在这儿，倘若瑕疵把一样东西变得稀缺了，垃圾也能化身成值钱的宝贝，这在玩物收藏市场几乎是常态了。其实，现实生活中，我们最容易受稀缺原理的影响了，最常见的两种商业套路是：</p>
<p>- 数量有限策略</p>
<p>- 最后期限战术</p>
<p>商家惯用的商业套路就是营造一些降价折扣的事由，来刺激消费者对商品进行购买，也许商品本身并不在消费者最初消费计划中，但是在稀缺性的刺激下，商品的认知价值在消费者心中突然有了大幅提升。其实降价也可以算在稀缺性原理中，因为相对于日常的高位价格，暂时性的降价折扣就显得颇为稀缺，错过了当下，以后可能需要花费更高额度的费用，这种期望落差通常会刺激消费者做出不理性的购买决策。</p>
<p>此外，另一种常见的套路就是有竞争性的稀缺资源，参与竞争稀缺资源的感觉，有着比单纯的稀有资源更为强大的吸引力。渴望拥有一件众人争抢的东西，几乎是出于本能的身体反应。所以在稀缺物品的竞拍中，我们通常能见到类似的现象，通过简单的心理博弈，能够让最终的成交价格朝着卖家预设的价位移动。</p>
<p>## 7.2 逆反心理</p>
<p>稀缺性原理起作用的力量主要来自两个方面。第一点它钻了我们思维捷径上的漏洞。在我们认知中，难以得到的东西，通常会让我们更为珍视。故此，我们基本可以根据获得一样东西的难易程度，迅速、准确地判断它质量，而这种判断在很大程度上是正确的。</p>
<p>第二点在于，机会越来越少的话，我们的自由也会随之丧失。每当有东西获取起来比以前难，我们拥有它的自由受了限制，我们就越发地想要得到它。我们痛恨失去本来拥有的自由，这种保住既得利益的愿望是心里逆反理论的核心。</p>
<p>詹姆斯·戴维斯（James Davies）曾指出，一个国家在经济和社会条件改善后，要是在短期内出现剧烈逆转，最有可能爆发革命。而且最容易企业的，不是那些传统上最受压迫的底层人民，而是品尝过了更美好生活的人。因为该群体得到了以前从来没有的自由，一点有人想要夺走这些自由，就注定要付出一些代价。</p>
<p>在实际生活中逆反心理也比较常见，最为人所熟知的一种现象就是青少年的叛逆期。通过上述阐述，我们知道自由这种东西，给一点又拿走，比完全不给更危险。所以管教前后不一的父母，更容易教出反叛心强的孩子。所以在教育孩子上，家长应该以身作则，给孩子树立良好的榜样，而不是严于律人，宽以待己。</p>
<p>## 7.3 如何拒绝</p>
<p>在知晓我们如何拒绝稀缺原理影响我们决策时，我们应该知道一个道理：喜悦并非来自对稀缺商品的体验，而是来自对它的占有。稀缺的东西并不因为难以占有，就变得更好吃、好听、好看、好用了。所以一旦我们觉得我们在短缺影响下产生了高度的情绪波动，我们就应该把这种波动当成暂停的信号，并在心底询问自己，为什么我们想要那件东西，是为了拥有它，还是为了它的价值或功能。</p>
<p>谈若是因为想拥有它，那么我们应该利用它的稀缺性来判断改为它出多少钱，一旦价格超出该底线，我们应该心生警惕，因为这也许是商家在利用稀缺性原理在谋取的超额收益。如果是为了它的功能，那么我们应该牢记一点：该物品并不会因为稀缺而增强它的功能。换而言之，我们应该积极寻求它的等价替代产品，获取更多信息之后，在做出合理的决策。</p>
<p># 8 总结</p>
<p>作者写本书的目的并不是说，让我们对这些简单而常见的小套路避之不及，而是希望我们能洞悉事物发展背后的逻辑，至少在明事理之后，能让我们有了更多选择的权利，不至于让我们在被“戏耍”后而不自知。尽管只靠孤立数据容易做出愚蠢的决定，可现代生活的节奏又要求我们频繁使用这一捷径。</p>
<p>为了追求效率，有时候我们必须放弃耗时而复杂的全局决策过程，转而使用更简单、由单一特征出发的响应方式。它之所以最为常用，完全是因为它们的可靠性高，在我们人类进化过程中，通常都能指引我们做出正确决定，这也是为什么我们会潜意识里借助这些因素做出顺从决定。在没有意愿、时间、精力或认知资源对情况进行全面分析的时候，使用这些孤立的线索进行决策是简单而保险的决策方式。</p>
<p>正如作者所说一般，这种便捷的响应方式应当受到尊重。在日新月异的当下，技术的进步速度远远快于我们，所以我们处理信息的天然能力将有可能越来越难于应对当代生活中繁多的变化、选择和挑战。有时我们会发现自己陷入了跟低等动物一样的处境中：外界环境的错综复杂超出了我们心智的处理能力。从这个方面来说，我们的大脑潜意识里依赖可靠而合理的捷径和首选规则来应对生活的紧张节奏也是无可厚非的。</p>
<p>然而，我们真正值得警惕的是，那些知晓我们的响应机制，但通过别出心裁的设计来破坏我们的心理机制，或者说通过我们的响应机制来蒙蔽我们，来从我们身上谋取私利的人。虽然大多数时候，这种戏弄不会对我们造成太大的损失，但正如《三国志·蜀书·先主传》所说：“勿以善小而不为，勿以恶小而为之”，积小成多，聚沙成塔，终归会有一天对我们的反应机制产生不可逆的影响。</p>
<p>正如一直以来我对自己的要求：我可以不成为这一领域的专家，但其中的基本原理我得懂，这也是为什么这么多年来，我始终如一地扩充自己的知识面。一方面是因为获取知识的过程能给我带来确实的快感，另一方面则是因为，涉猎各领域的知识能够让我以更多的角度看待事物，不至于让自己的无知中变成一个智慧鹦鹉学舌而不会独立思考的人！</p>
<p>最后附上我最喜欢的一个著名投资家查理·芒格所说的一句话：</p>
<p>&gt; 我这辈子遇到的聪明人（来自各行各业的聪明人）没有不每天阅读的 —— 没有，一个都没有。巴菲特读书之多，我读书之多，可能会让你感到吃惊。孩子们都笑话我，他们觉得我是一本长了两条腿的书。</p>
<p>很多人读书，追求的是干货，寻求的是立刻行之有效的解决方案。其实这是一种留在舒适区的阅读方法。在这个充满不确定的时代，答案不会简单地出现在书里，因为生活根本就没有标准确切的答案，你也不能期望过去的经验能够解决未来的问题。能简单地出现在书中的答案只有试卷，而这也是我不喜欢以考试来鞭策读书的原因之一，只可惜在现今成绩为王的时代，能做的只有在半顺从下坚持自己原则。除此之外，别无他法，可悲！</p>
]]></content>
      <categories>
        <category>Book review</category>
        <category>Influence</category>
        <category>Introduction</category>
      </categories>
      <tags>
        <tag>Book review</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux notes</title>
    <url>/2020/11/23/Linux/</url>
    <content><![CDATA[<h1 id="command">1. Command</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cd / pwd / ls</span><br><span class="line">mkdir / rmdir</span><br><span class="line">cp / rm / mv</span><br><span class="line">tar / <span class="built_in">zip</span> / unzip</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="cd">1.1 cd</h2>
<p>即 current directory，切换目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cd /home/YangSu/Desktop <span class="comment">#按TAB键可以自动补全</span></span><br><span class="line">cd ~/Desktop <span class="comment">#其中~特指用户的主目录</span></span><br><span class="line">cd.. <span class="comment"># 回到上一个目录</span></span><br><span class="line">cd <span class="comment">#回到用户目录位置</span></span><br></pre></td></tr></table></figure>
<h4 id="绝对路径">绝对路径</h4>
<p>/home/YangSu/Desktop</p>
<h4 id="相对路径">相对路径</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">. 当前目录</span><br><span class="line">.. 上级目录</span><br><span class="line">../Videos 上级目录下的Videos子目录</span><br></pre></td></tr></table></figure>
<h2 id="pwd">1.2 pwd</h2>
<p>即 print working directory 显示当前工作目录</p>
<h2 id="ls">1.3 ls</h2>
<p>即 list，列出文件和目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ls</span><br><span class="line">ls ~/Desktop</span><br><span class="line">ls -l ~/Desktop <span class="comment">#其中，-l参数表示详细模式</span></span><br></pre></td></tr></table></figure>
<h2 id="mkdir">1.4 mkdir</h2>
<p>即 make directory，创建目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mkdir abc</span><br><span class="line">mkdir -p abc/<span class="number">123</span>/test </span><br><span class="line"><span class="comment">#使用-p参数，可以将路径的层次目录全部创建</span></span><br></pre></td></tr></table></figure>
<h2 id="touch">1.5 touch</h2>
<p>新建一个文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">touch index.js</span><br><span class="line"><span class="comment"># 在当前目录下新建一个 index.js 文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># windows terminal中</span></span><br><span class="line">new-item index.js</span><br></pre></td></tr></table></figure>
<h2 id="rm">1.6 rm</h2>
<h3 id="rm-1">rm</h3>
<p>即 remove 删除文件或目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rm -rf abc <span class="comment">#删除abc目录，和子项一并删除</span></span><br><span class="line"><span class="comment">#其中，r:recursive, f:force</span></span><br></pre></td></tr></table></figure>
<h3 id="rmdir">rmdir</h3>
<p>即 remove directory，删除空目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rmdir abc <span class="comment">#删除空目录，如果目录非空，则会删除失败</span></span><br></pre></td></tr></table></figure>
<h2 id="cp">1.7 cp</h2>
<p>即 copy，复制文件或者目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cp -rf Test Test1</span><br></pre></td></tr></table></figure>
<h2 id="mv">1.8 mv</h2>
<p>即 move，移动文件或目录（重命名）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mv Test1 HelloWorld</span><br></pre></td></tr></table></figure>
<h2 id="tar">1.9 tar</h2>
<p>即 tape archive档案打包</p>
<h3 id="创建档案包">创建档案包</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tar -cvf example.tar example</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">c: create</span></span><br><span class="line"><span class="string">v: verbose，显示详情</span></span><br><span class="line"><span class="string">f: file</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 也可以多个目录打包</span></span><br><span class="line">tar -cvd xxx.tar file1 file2 file3</span><br></pre></td></tr></table></figure>
<h4 id="还原档案包">还原档案包</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tar -xvf example.tar</span><br><span class="line">tar -xvf example.tar -C outdir</span><br></pre></td></tr></table></figure>
<h4 id="归档并压缩">归档并压缩</h4>
<p>上述的tar格式并没有对文件进行压缩，体积较大</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 并档并压缩</span></span><br><span class="line">tar -czvf example.tar.gz example</span><br><span class="line"><span class="comment"># 解压缩</span></span><br><span class="line">tar -xzvf example.tar.gz -C outdir</span><br></pre></td></tr></table></figure>
<h2 id="man">1.10 man</h2>
<p>即 manual，手册</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">man tar</span><br></pre></td></tr></table></figure>
<h2 id="ln">1.11 ln</h2>
<p>软链接，即Windows中的 “ 快捷方式 ”</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ln -s source link</span><br><span class="line"><span class="comment"># s: soft</span></span><br><span class="line">ls -l <span class="comment"># 查看软链接，显示为：test -&gt; Test/</span></span><br><span class="line">ls -l / <span class="comment">#详细列出根目录</span></span><br></pre></td></tr></table></figure>
<h2 id="other">1.12 other</h2>
<ul>
<li>reset：重新初始化终端，即清屏</li>
<li>clear：清屏</li>
<li>history：查看命令历史</li>
<li>help：帮助</li>
<li>exit：推出</li>
<li>#：表示注释</li>
</ul>
<h1 id="management">2 Management</h1>
<h2 id="switch-user">2.1 Switch user</h2>
<ul>
<li>su</li>
</ul>
<p>即 switch user，切换用户。用户管理需要以管理员身份执行，所以，要先切换账户到 <strong>root</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">su root</span><br><span class="line">su <span class="comment"># 默认为 root</span></span><br></pre></td></tr></table></figure>
<h2 id="user-operation">2.2 User operation</h2>
<ul>
<li>useradd</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">useradd username</span><br></pre></td></tr></table></figure>
<ul>
<li>passwd</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">passwd username</span><br></pre></td></tr></table></figure>
<ul>
<li>userdel</li>
</ul>
<p>即 user delete</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">userdel username</span><br></pre></td></tr></table></figure>
<h2 id="group-operation">2.3 Group operation</h2>
<ul>
<li>groupadd</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">groupadd boys <span class="comment"># 创建用户组</span></span><br></pre></td></tr></table></figure>
<ul>
<li>groupdel</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">groupdel boys <span class="comment"># 删除用户组</span></span><br></pre></td></tr></table></figure>
<ul>
<li>useradd</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">useradd -g boys ming <span class="comment"># -g表示添加用户，同时添加到boys中</span></span><br></pre></td></tr></table></figure>
<ul>
<li>usermod</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">usermod -g boys YangSu <span class="comment"># 修改用户信息</span></span><br></pre></td></tr></table></figure>
<ul>
<li>cat</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cat /etc/group <span class="comment"># 查看用户组，每一行表示一个group的信息</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出为：名称 + ID</span></span><br><span class="line"><span class="string">YangSu:x:1000:</span></span><br><span class="line"><span class="string">boys:x:1001:</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">cat /etc/passwd <span class="comment"># 查看用户列表，每一行表示一个user信息</span></span><br></pre></td></tr></table></figure>
<h2 id="file-permission">2.4 File permission</h2>
<ul>
<li>View Permission</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ls -l test.txt</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">-rw-------</span></span><br><span class="line"><span class="string">第一个字母，如果是文件夹，则为d，文件则为-</span></span><br><span class="line"><span class="string">后面九个字符分为三部分：自己 | 同组 | 别人</span></span><br><span class="line"><span class="string">rwx------ # 自己可读可写可执行</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>chmod</li>
</ul>
<p>即 Change file mode，修改文件的访问权限</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chmod o+w test.txt</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">o: other</span></span><br><span class="line"><span class="string">a: all</span></span><br><span class="line"><span class="string">u: user # 省略怎默认修改自己和本组的权限</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">+w: add write permission</span></span><br><span class="line"><span class="string">-w: delete write permission</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>chown</li>
</ul>
<p>即 Change owner，修改文件的属主，一般每个用户只操作自己用户目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">su</span><br><span class="line">mkdir /opt/source <span class="comment"># 在/opt目录下创建一个文件夹source</span></span><br><span class="line">chown -R YangSu /opt/source <span class="comment"># 将source目录分配给YangSu</span></span><br><span class="line">ls -ld /opt/source</span><br></pre></td></tr></table></figure>
<h2 id="script">2.5 Script</h2>
<ul>
<li>Shell 脚本： *.sh</li>
<li>Perl 脚本： *.pl</li>
<li>Python 脚本：*.py</li>
</ul>
<p>脚本程序本质上是一个文本文件，具有可执行权限</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Shell 脚本解释器：/<span class="built_in">bin</span>/sh</span><br><span class="line">Perl 脚本解释器：/<span class="built_in">bin</span>/perl</span><br><span class="line">Python 脚本解释器：/usr/<span class="built_in">bin</span>/python3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行一个脚本时，以下两种方式等效</span></span><br><span class="line">./hello.py</span><br><span class="line">/usr/<span class="built_in">bin</span>/python3 hello.py</span><br></pre></td></tr></table></figure>
<ul>
<li>Shell 脚本</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编辑一个文本文件</span></span><br><span class="line"><span class="comment">#!/bin/sh # 申明解释器</span></span><br><span class="line">echo <span class="string">&quot;Hello World!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存为Hello.sh</span></span><br><span class="line"><span class="comment"># 添加可执行权限，必须要有x权限，才能够执行</span></span><br><span class="line">chmod +x Hello.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行程序</span></span><br><span class="line">./Hello.sh <span class="comment"># 执行程序时，必须加上路径</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">./表示当前路径</span></span><br><span class="line"><span class="string">/home/YangSu/Test/Hello.sh</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Perl 脚本</li>
<li>Py 脚本</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python3</span></span><br></pre></td></tr></table></figure>
<h2 id="shell">2.6 Shell</h2>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 定义变量，NAME=value</span></span><br><span class="line">JAVA_HOME=/opt/java #中间不能有空格</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 调用命令</span></span><br><span class="line">echo $&#123;JAVA_HOME&#125;/bin</span><br><span class="line">ls $&#123;JAVA_HOME&#125; #使用变量</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 逻辑控制</span></span><br><span class="line">if ... while ...</span><br></pre></td></tr></table></figure>
<h1 id="enviroment">3 Enviroment</h1>
<h2 id="enviromental-viriables">3.1 Enviromental Viriables</h2>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/opt/jdk1.8 # 定义临时的环境变量</span><br><span class="line">echo $JAVA_HOME # 显示环境变量</span><br><span class="line">printenv #查看所有环境变量</span><br></pre></td></tr></table></figure>
<p>使用环境变量：</p>
<ul>
<li>在当前命令行中使用</li>
<li>在 Shell 脚本中使用</li>
</ul>
<h2 id="user-viriables">3.2 User Viriables</h2>
<p>用户环境变量定义在：~/.bash_profile 中（注：在 Linux 下，以 . 开头的文件为 <strong>隐藏文件</strong> ）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -la # a 表示 all，显示所有文件</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 用户环境变量，g 表示 GNU</span></span><br><span class="line">gedit ~/.bash_profile</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加</span></span><br><span class="line">export JAVA_HOME=/opt/jdk1.8</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注销当前用户，再次登陆时生效</span></span><br><span class="line">echo $&#123;JAVA_HOME&#125;</span><br></pre></td></tr></table></figure>
<h2 id="system-variables">3.3 System Variables</h2>
<p>系统环境变量定义在：/etc/profile 中，其中的环境变量对 <strong>所有用户</strong> 有效</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 以 root 登录或执行</span></span><br><span class="line">gedit /etc/profile</span><br><span class="line"></span><br><span class="line">:&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash">在 CentOS 中，一般不可以直接修改 /etc/profile，而是在 /etc/profile.d 创建一个自定义的脚本</span></span><br><span class="line">&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 用 gedit 创建一个脚本</span></span><br><span class="line">gedit /etc/profile.d/myprofile.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义环境变量</span></span><br><span class="line">export TOMCAT=/opt/tomcat</span><br><span class="line"><span class="meta">#</span><span class="bash"> 注销并重新登录</span></span><br></pre></td></tr></table></figure>
<h2 id="path-variables">3.4 PATH Variables</h2>
<p>PATH，最常见的环境变量，用来描述可执行程序的搜索路径</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo $PATH </span><br><span class="line"><span class="meta">#</span><span class="bash"> OUTPUT:/home/YangSu/.<span class="built_in">local</span>/bin:/home/YangSu/bin:/home/YangSu/.<span class="built_in">local</span>/bin:/home/YangSu/bin:/home/YangSu/.<span class="built_in">local</span>/bin:/home/YangSu/bin:/usr/<span class="built_in">local</span>/bin:/usr/<span class="built_in">local</span>/sbin:/usr/bin:/usr/sbin</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 多个路径之间用冒号分隔</span></span><br></pre></td></tr></table></figure>
<h2 id="network">3.5 Network</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ifconfig <span class="comment"># 检查IP地址，Windows 为ipconfig</span></span><br><span class="line">ping www.baidu.com <span class="comment"># 测试外网</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">虚拟机和宿主机时互相连通的</span></span><br><span class="line"><span class="string">虚拟机：192.168.11.128</span></span><br><span class="line"><span class="string">宿主机：192.168.11.1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h1 id="centos8-图形界面和命令行切换">4 CentOS8 图形界面和命令行切换</h1>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看目前默认的启动默认</span></span><br><span class="line">systemctl get-default</span><br><span class="line"><span class="meta">#</span><span class="bash"> 命令行模式:multi-user.target</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 图形界面模式:graphical.target</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置为图形界面模式</span></span><br><span class="line">systemctl set-default graphical.target</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置为命令行模式</span></span><br><span class="line">systemctl set-default multi-user.target</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Notes</category>
        <category>OS</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown</title>
    <url>/2021/01/19/Markdown/</url>
    <content><![CDATA[<h1 id="markdown">Markdown</h1>
<h2 id="title">1. Title</h2>
<h3 id="三级标题">三级标题</h3>
<h4 id="四级标题">四级标题</h4>
<p>格式及快捷键如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Markdown</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 1. Title</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 三级标题</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### 四级标题</span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="font">2. Font</h2>
<p><strong>加粗 </strong></p>
<p><em>斜体</em></p>
<p><u>下划线</u></p>
<p><del>删除线</del></p>
<p>==高亮==</p>
<p><code>底纹</code></p>
<p>$ _i = w x_i + b $ <span class="math display">\[
\hat{y}_i = w x_i + b
\]</span></p>
<p>格式及快捷键如下（其中 <code>#</code> 开头的行为注释行）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">**加粗 ** (快捷键 ctrl + B)</span><br><span class="line">*斜体* (快捷键 ctrl + I)</span><br><span class="line">&lt;u&gt;下划线&lt;/u&gt;  (快捷键 ctrl + U)</span><br><span class="line">~~删除线~~</span><br><span class="line">==高亮==</span><br><span class="line">`底纹`</span><br><span class="line"></span><br><span class="line"><span class="comment"># 行内公式 (In-line formula)</span></span><br><span class="line">$ \hat&#123;y&#125;_i = w x_i + b $ </span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示公式 (Display formula)</span></span><br><span class="line">$$</span><br><span class="line">\hat&#123;y&#125;_i = w x_i + b</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>
<h2 id="citation">3. Citation</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 引用语法</span></span><br><span class="line">&gt; Author</span><br><span class="line">&gt;&gt; Author</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<blockquote>
<p>Author</p>
<blockquote>
<p>Author</p>
</blockquote>
</blockquote>
<h2 id="分割线">4. 分割线</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 分割线1</span></span><br><span class="line">---</span><br><span class="line"><span class="comment"># 分割线2</span></span><br><span class="line">***</span><br></pre></td></tr></table></figure>
<hr />
<hr />
<h2 id="inset-image">5. Inset image</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在线图片/本地图片</span></span><br><span class="line">![My image1](/image/me.png) --image <span class="built_in">dir</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s3.ax1x.com/2021/01/19/sczP2Q.png" /></p>
<center>
Fig. 1 Image demo
</center>
<p>注：Typora 支持直接复制粘贴图片，可以省去敲格式的环节，但注意在复制粘贴之前将图片储存的设置为自动保存，设置如下：</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczkKs.png" /></p>
<center>
Fig. 2 Typora image auto-save setting
</center>
<h2 id="link">6. Link</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 超链接语法，其中 [] 中为文字内容，()内为想要插入的连接</span></span><br><span class="line">[My link](https://www.bilibili.com/)</span><br></pre></td></tr></table></figure>
<p><a href="https://www.bilibili.com/">My bilibili</a></p>
<h2 id="list">7. List</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 无序列表</span></span><br><span class="line">- 目录<span class="number">1</span></span><br><span class="line">- 目录<span class="number">2</span></span><br><span class="line">- 目录<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 有序列表，在目录 4 后键入回车，会自动生成有序列表</span></span><br><span class="line"><span class="number">1.</span> 目录<span class="number">4</span></span><br><span class="line"><span class="number">2.</span> 目录<span class="number">5</span></span><br></pre></td></tr></table></figure>
<ul>
<li>目录1</li>
<li>目录2</li>
<li>目录3</li>
</ul>
<ol type="1">
<li>目录4</li>
<li>目录5</li>
</ol>
<h2 id="grid">8. Grid</h2>
<p>在 Typora 中按 <code>Ctrl + T</code> 快捷键，会出现对话框，便可以快速插入表格，如下：</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczivj.png" />)</p>
<center>
Fig. 3 Insert table
</center>
<table>
<thead>
<tr class="header">
<th>成绩</th>
<th>语文</th>
<th>数学</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>45</td>
<td>35</td>
</tr>
</tbody>
</table>
<h2 id="段落格式">9. 段落格式</h2>
<p>以下为一下 <code>html</code> 语法，<code>Markdown</code> 可以兼容 <span class="math inline">\(\TeX\)</span> 数学公式和 <code>html</code> 语法，可以扩充已有的功能。</p>
<ul>
<li>居中</li>
</ul>
<center>
center
</center>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">center</span>&gt;</span> 内容居中 <span class="tag">&lt;/<span class="name">center</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>字体</li>
</ul>
<p><font face = "黑体">我是黑体</font></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">face</span> = <span class="string">&quot;黑体&quot;</span>&gt;</span>我是黑体<span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><font face="黑体" size=10>我是黑体10号字体</font></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">face</span>=<span class="string">&quot;黑体&quot;</span> <span class="attr">size</span>=<span class="string">10</span>&gt;</span>我是黑体10号字体<span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br><span class="line"></span><br><span class="line"># 字体颜色更改为红色</span><br><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">red</span> <span class="attr">size</span>=<span class="string">10</span>&gt;</span>我是黑体10号字体<span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>Html 标签</p>
<p><img src="https://s3.ax1x.com/2021/01/19/sczC8g.png" /></p>
<center>
<p>Fig. 4 HTML Label</p>
</center></li>
</ul>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Matplotlib</title>
    <url>/2020/11/30/Matplotlib/</url>
    <content><![CDATA[<h1 id="introduction">1 Introduction</h1>
<ul>
<li>中文显示乱码问题</li>
</ul>
<p>Matplotlib 库缺少中文字体，因此在图标上显示中文会出现乱码，解决办法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyplt <span class="keyword">import</span> mpl</span><br><span class="line">mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h1 id="steps">2 Steps</h1>
<ul>
<li>import module and set font style to avoid messy code</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span></span><br></pre></td></tr></table></figure>
<ul>
<li>step one: create figure and fix size (inch)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>)) <span class="comment"># length x width</span></span><br></pre></td></tr></table></figure>
<ul>
<li>setp two: generate data</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">start_val = <span class="number">0</span> <span class="comment"># start value</span></span><br><span class="line">stop_val = <span class="number">10</span> <span class="comment"># end value</span></span><br><span class="line">num_val = <span class="number">1000</span> <span class="comment"># samples number</span></span><br><span class="line">x = np.linspace(start_val, stop_val, num_val)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;--g,&#x27;</span>, lw = <span class="number">2</span>, label = <span class="string">&#x27;$sin(x)$&#x27;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>step three: adjust axis and set label</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 调整坐标范围</span></span><br><span class="line">x_min, y_max = <span class="number">0</span>, <span class="number">10</span></span><br><span class="line">y_min, y_max = <span class="number">0</span>, <span class="number">1.5</span></span><br><span class="line">plt.xlim(x_min, x_max)</span><br><span class="line">plt.ylim(y_min, y_max)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set axis label</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;x轴&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y轴&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ticks: 刻度线</span></span><br><span class="line">x_location = np.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">x_labels = [<span class="string">&#x27;2019-01-01&#x27;</span>, <span class="string">&#x27;2019-02-01&#x27;</span>, <span class="string">&#x27;2019-03-01&#x27;</span>, <span class="string">&#x27;2019-04-01&#x27;</span>, <span class="string">&#x27;2019-05-01&#x27;</span>]</span><br><span class="line">y_location = np.arange(-<span class="number">1</span>, <span class="number">1.5</span>, <span class="number">1</span>)</span><br><span class="line">y_labels = [<span class="string">u&#x27;minimum&#x27;</span>, <span class="string">u&#x27;zero&#x27;</span>, <span class="string">u&#x27;maximum&#x27;</span>]</span><br><span class="line">plt.xticks(x_location, x_labels, rotation = <span class="number">45</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.yticks(y_location, y_labels, fontsize = <span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>step four: set grid and legend</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># grid</span></span><br><span class="line">plt.grid(<span class="literal">True</span>, ls = <span class="string">&#x27;:&#x27;</span>, color = <span class="string">&#x27;r&#x27;</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># title</span></span><br><span class="line">plt.title(<span class="string">&#x27;函数式绘图 vs 对象式绘图&#x27;</span>, fontsize = <span class="number">25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># legend</span></span><br><span class="line">plt.legend(loc = <span class="string">&#x27;upper right&#x27;</span>, fontsize  = <span class="number">15</span>)</span><br><span class="line">plt.show(</span><br></pre></td></tr></table></figure>
<h2 id="函数式绘图">2.1 函数式绘图</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># step one: create figure and fix size</span></span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>, <span class="number">6</span>)) <span class="comment"># length x width</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># step two: generate data</span></span><br><span class="line">start_val = <span class="number">0</span> <span class="comment"># start value</span></span><br><span class="line">stop_val = <span class="number">10</span> <span class="comment"># end value</span></span><br><span class="line">num_val = <span class="number">1000</span> <span class="comment"># samples number</span></span><br><span class="line">x = np.linspace(start_val, stop_val, num_val)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;--g,&#x27;</span>, lw = <span class="number">2</span>, label = <span class="string">&#x27;$sin(x)$&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step three: adjust axis</span></span><br><span class="line">x_min = <span class="number">0</span></span><br><span class="line">x_max = <span class="number">10</span></span><br><span class="line">y_min = <span class="number">0</span></span><br><span class="line">y_max = <span class="number">1.5</span></span><br><span class="line">plt.xlim(x_min, x_max)</span><br><span class="line">plt.ylim(y_min, y_max)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step four: set axis label</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;x轴&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y轴&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">x_location = np.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">x_labels = [<span class="string">&#x27;2019-01-01&#x27;</span>, <span class="string">&#x27;2019-02-01&#x27;</span>, <span class="string">&#x27;2019-03-01&#x27;</span>, <span class="string">&#x27;2019-04-01&#x27;</span>, <span class="string">&#x27;2019-05-01&#x27;</span>]</span><br><span class="line">y_location = np.arange(-<span class="number">1</span>, <span class="number">1.5</span>, <span class="number">1</span>)</span><br><span class="line">y_labels = [<span class="string">u&#x27;minimum&#x27;</span>, <span class="string">u&#x27;zero&#x27;</span>, <span class="string">u&#x27;maximum&#x27;</span>]</span><br><span class="line">plt.xticks(x_location, x_labels, rotation = <span class="number">45</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.yticks(y_location, y_labels, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step five: set grid</span></span><br><span class="line"><span class="comment"># ls: linestyle</span></span><br><span class="line">plt.grid(<span class="literal">True</span>, ls = <span class="string">&#x27;:&#x27;</span>, color = <span class="string">&#x27;r&#x27;</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;函数式绘图&#x27;</span>, fontsize = <span class="number">25</span>)</span><br><span class="line">plt.legend(loc = <span class="string">&#x27;upper right&#x27;</span>, fontsize  = <span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWKVf.md.png" /></p>
<center>
fig 2-1 函数式绘图
</center>
<h2 id="对象式绘图">2.2 对象式绘图</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对象式绘图</span></span><br><span class="line"><span class="comment"># pyplot 模块中的 figure() 函数创建名为 fig 的 Figure 对象</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 Figure 对象中创建一个 Axes 对象，每个 Axes 对象即为一个绘图区域</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># generate data</span></span><br><span class="line">start_val, stop_val, num_val = <span class="number">0</span>, <span class="number">10</span>, <span class="number">1000</span></span><br><span class="line">x = np.linspace(start_val, stop_val, num_val)</span><br><span class="line">y = np.sin(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># y = sin(x)</span></span><br><span class="line"><span class="comment"># &#x27;--g,&#x27;: format_string, equals with a combination of linestyle, color, market, 即折线、绿色、像素点</span></span><br><span class="line">ax.plot(x, y, <span class="string">&#x27;--g&#x27;</span>, lw = <span class="number">2</span>, label = <span class="string">&#x27;sin(x)&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整坐标范围</span></span><br><span class="line">x_min, x_max = <span class="number">0</span>, <span class="number">10</span></span><br><span class="line">y_min, y_max = <span class="number">0</span>, <span class="number">1.5</span></span><br><span class="line">ax.set_xlim(x_min, x_max)</span><br><span class="line">ax.set_ylim(y_min, y_max)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置坐标轴标签</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;x轴&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y轴&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">x_location = np.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">x_labels = [<span class="string">&#x27;2019-01-01&#x27;</span>, <span class="string">&#x27;2019-02-01&#x27;</span>, <span class="string">&#x27;2019-03-01&#x27;</span>, <span class="string">&#x27;2019-04-01&#x27;</span>, <span class="string">&#x27;2019-05-01&#x27;</span>]</span><br><span class="line">y_location = np.arange(-<span class="number">1</span>, <span class="number">1.5</span>, <span class="number">1</span>)</span><br><span class="line">y_labels = [<span class="string">u&#x27;minimum&#x27;</span>, <span class="string">u&#x27;zero&#x27;</span>, <span class="string">u&#x27;maximum&#x27;</span>]</span><br><span class="line">plt.xticks(x_location, x_labels, rotation = <span class="number">45</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.yticks(y_location, y_labels, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ls: linestyle</span></span><br><span class="line">plt.grid(<span class="literal">True</span>, ls = <span class="string">&#x27;:&#x27;</span>, color = <span class="string">&#x27;r&#x27;</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;函数式绘图 vs 对象式绘图&#x27;</span>, fontsize = <span class="number">25</span>)</span><br><span class="line">plt.legend(loc = <span class="string">&#x27;upper right&#x27;</span>, fontsize  = <span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgW1Pg.md.png" /></p>
<center>
fig 2-2 对象式绘图
</center>
<h1 id="figure-types">3 Figure types</h1>
<h2 id="line-attributes">3.1 Line attributes</h2>
<p>plot() 函数中，可设置参数以调整线条的属性：</p>
<ul>
<li>linestyle: 设定线条类型</li>
<li>color: 指定线条的颜色</li>
<li>marker: 指定线条的标记风格</li>
<li>linewidth: 设定线条的宽度</li>
<li>label: 设置线条的标签</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">start_val, stop_val, num_val = <span class="number">0</span>, <span class="number">10</span>, <span class="number">1000</span></span><br><span class="line">x = np.linspace(start_val, stop_val, num_val)</span><br><span class="line">y = np.sin(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># y = sin(x)</span></span><br><span class="line"><span class="comment"># &#x27;--g,&#x27;: format_string, equals with a combination of linestyle, color, market, 即折线、绿色、像素点</span></span><br><span class="line">ax.plot(x, y, <span class="string">&#x27;--g&#x27;</span>, lw = <span class="number">2</span>, label = <span class="string">&#x27;$sin(x)$&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="标注点的绘制">3.2 标注点的绘制</h2>
<p>当要在图形上给数据添加指向性注释文本时，可以使用 Matplotlib 的 annotate() 函数，支持箭头指示，方便在合适的位置添加描述信息。关键参数如下：</p>
<ul>
<li>s：注释文本内容</li>
<li>xy：备注是的坐标点，二维元组格式 (x, y)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> xy : (<span class="built_in">float</span>, <span class="built_in">float</span>)</span><br><span class="line"><span class="comment"># The point *(x,y)* to annotate.</span></span><br></pre></td></tr></table></figure>
<ul>
<li>xytext：注释文本的坐标点，二维元组格式 (x, y)</li>
<li>xycoords：被注释点的坐标系属性，默认为 'data'</li>
<li>textcoords：设置注释文本的坐标系属性，默认与 xycoords 属性值相同，通常设置为 'offset points' or 'offset pixels'， 即相对于被注释点 xy 的偏移量</li>
<li>arrowprops：设置箭头的样式，dict 格式</li>
</ul>
<p>If 'arrowprops' does not contain the key ' arrowstyle', the allowed keys are:</p>
<center>
tab 5-1 arrowstyle key-1
</center>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Key</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">width</td>
<td style="text-align: left;">The width of the arrow in points</td>
</tr>
<tr class="even">
<td style="text-align: center;">headwidth</td>
<td style="text-align: left;">The width of the base of the arrow head in points</td>
</tr>
<tr class="odd">
<td style="text-align: center;">headlength</td>
<td style="text-align: left;">The length of the arrow head in points</td>
</tr>
<tr class="even">
<td style="text-align: center;">shrink</td>
<td style="text-align: left;">Fraction of total length to shrink from both ends</td>
</tr>
<tr class="odd">
<td style="text-align: center;">?</td>
<td style="text-align: left;">Any key to <code>matplotlib.patches.FancyArrowPatch</code></td>
</tr>
</tbody>
</table>
<p>如果 arrowprops 包含了关键词 ' arrowstyle'， the above keys are forbidden. The allowed values of 'arrowstyle' are:</p>
<center>
tab 5-2 arrowstyle key-2
</center>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Name</th>
<th style="text-align: center;">Attrs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>'-'</code></td>
<td style="text-align: center;">None</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'-&gt;'</code></td>
<td style="text-align: center;">head_length=0.4,head_width=0.2</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'-['</code></td>
<td style="text-align: center;">widthB=1.0,lengthB=0.2,angleB=None</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'|-|'</code></td>
<td style="text-align: center;">widthA=1.0,widthB=1.0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'-|&gt;'</code></td>
<td style="text-align: center;">head_length=0.4,head_width=0.2</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'&lt;-'</code></td>
<td style="text-align: center;">head_length=0.4,head_width=0.2</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'&lt;-&gt;'</code></td>
<td style="text-align: center;">head_length=0.4,head_width=0.2</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'&lt;|-'</code></td>
<td style="text-align: center;">head_length=0.4,head_width=0.2</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'&lt;|-|&gt;'</code></td>
<td style="text-align: center;">head_length=0.4,head_width=0.2</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'fancy'</code></td>
<td style="text-align: center;">head_length=0.4,head_width=0.4,tail_width=0.4</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'simple'</code></td>
<td style="text-align: center;">head_length=0.5,head_width=0.5,tail_width=0.2</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'wedge'</code></td>
<td style="text-align: center;">tail_width=0.3,shrink_factor=0.5</td>
</tr>
</tbody>
</table>
<p>Valid keys for <code>~matplotlib.patches.FancyArrowPatch</code> are:</p>
<center>
tab 5-3 ~matplotlib.patches.FancyArrowPatch
</center>
<table>
<thead>
<tr class="header">
<th>Key</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>arrowstyle</td>
<td>the arrow style</td>
</tr>
<tr class="even">
<td>connectionstyle</td>
<td>the connection style</td>
</tr>
<tr class="odd">
<td>relpos</td>
<td>default is (0.5, 0.5)</td>
</tr>
<tr class="even">
<td>patchA</td>
<td>default is bounding box of the text</td>
</tr>
<tr class="odd">
<td>patchB</td>
<td>default is None</td>
</tr>
<tr class="even">
<td>shrinkA</td>
<td>default is 2 points</td>
</tr>
<tr class="odd">
<td>shrinkB</td>
<td>default is 2 points</td>
</tr>
<tr class="even">
<td>mutation_scale</td>
<td>default is text size (in points)</td>
</tr>
<tr class="odd">
<td>mutation_aspect</td>
<td>default is 1</td>
</tr>
<tr class="even">
<td>?</td>
<td>any key for <code>matplotlib.patches.PathPatch</code></td>
</tr>
</tbody>
</table>
<ul>
<li>bbox：设置文本周围所添加的外框属性</li>
</ul>
<p>Case 1:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># add annotation</span></span><br><span class="line">ax.annotate(<span class="string">u&#x27;The top point&#x27;</span>,</span><br><span class="line">            xy = (np.pi/<span class="number">2</span>, <span class="number">1</span>), <span class="comment"># 箭头指向点的坐标</span></span><br><span class="line">            xytext = (np.pi/<span class="number">2</span>, <span class="number">1.3</span>), <span class="comment"># 注释文本左端的坐标</span></span><br><span class="line">            weight = <span class="string">&#x27;regular&#x27;</span>, <span class="comment"># 注释文本的字体粗细风格，bold：粗体，regular：正常粗细</span></span><br><span class="line">            color = <span class="string">&#x27;g&#x27;</span>, <span class="comment"># 注释文本颜色，green</span></span><br><span class="line">            fontsize = <span class="number">15</span>, <span class="comment"># 注释文本字体大小</span></span><br><span class="line">            arrowprops = &#123; <span class="comment"># arrowprops： arrow properties，以字典格式设置箭头属性</span></span><br><span class="line">                <span class="string">&#x27;arrowstyle&#x27;</span>: <span class="string">&#x27;-&gt;&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;connectionstyle&#x27;</span>: <span class="string">&#x27;arc3&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;g&#x27;</span></span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">ax.annotate(<span class="string">u&#x27;The low point&#x27;</span>,</span><br><span class="line">            xy = (np.pi*<span class="number">3</span>/<span class="number">2</span>, -<span class="number">1</span>), </span><br><span class="line">            xytext = (np.pi*<span class="number">3</span>/<span class="number">2</span>, -<span class="number">1.3</span>),</span><br><span class="line">            weight = <span class="string">&#x27;regular&#x27;</span>, </span><br><span class="line">            color = <span class="string">&#x27;r&#x27;</span>, <span class="comment"># red</span></span><br><span class="line">            fontsize = <span class="number">15</span>, </span><br><span class="line">            arrowprops = &#123; </span><br><span class="line">                <span class="string">&#x27;arrowstyle&#x27;</span>: <span class="string">&#x27;-&gt;&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;connectionstyle&#x27;</span>: <span class="string">&#x27;arc3&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;r&#x27;</span></span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s3.ax1x.com/2020/11/30/DgWeKI.md.png" /></p>
<center>
fig 3-1 Annotation case1
</center>
<p>Case 2：绘制以下四种样式的标注点</p>
<ul>
<li>注释文本 'annotate1' 所对应的样式配置：在 arrowprops 参数中使用关键字 'arrowstyle' 设置 <strong>箭头样式</strong> '-&gt;'，关键字 connectionstyle 设置连接线的样式</li>
<li>注释文本 'annotate2' 所对应的样式配置：在 arrowprops 参数中使用关键字 'arrowstyle' ，允许配置箭头的宽度 width、 箭头两端收缩的百分比 shrink 等</li>
<li>注释文本 'annotate3' 所对应的样式配置：使用 bbox 参数在文本周围添加外框，设置外框为 round 格式</li>
<li>注释文本 'annotate1' 所对应的样式配置：使用 bbox 参数在文本周围添加外框， 设置外框为 round 样式</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 Figure 对象中创建一个 Axes 对象，每个 Axes 对象即为一个绘图区域</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">x = np.arange(<span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">y = np.around(np.log(x), <span class="number">2</span>)</span><br><span class="line">ax.plot(x, y, marker = <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax.annotate(<span class="string">u&#x27;样式1&#x27;</span>, xy = (x[<span class="number">1</span>], y[<span class="number">1</span>]), xytext = (<span class="number">80</span>, <span class="number">10</span>), textcoords = <span class="string">&#x27;offset points&#x27;</span>, </span><br><span class="line">            arrowprops = <span class="built_in">dict</span>(arrowstyle = <span class="string">&#x27;-&gt;&#x27;</span>, connectionstyle = <span class="string">&#x27;angle3, angleA = 80, angleB = 50&#x27;</span>))</span><br><span class="line"></span><br><span class="line">ax.annotate(<span class="string">u&#x27;样式2&#x27;</span>, xy = (x[<span class="number">3</span>], y[<span class="number">3</span>]), xytext = (<span class="number">80</span>, <span class="number">10</span>), textcoords = <span class="string">&#x27;offset points&#x27;</span>, </span><br><span class="line">            arrowprops = <span class="built_in">dict</span>(facecolor = <span class="string">&#x27;black&#x27;</span>, shrink = <span class="number">0.05</span>, width = <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">ax.annotate(<span class="string">u&#x27;样式3&#x27;</span>, xy = (x[<span class="number">5</span>], y[<span class="number">5</span>]), xytext = (<span class="number">80</span>, <span class="number">10</span>), textcoords = <span class="string">&#x27;offset points&#x27;</span>, </span><br><span class="line">            arrowprops = <span class="built_in">dict</span>(facecolor = <span class="string">&#x27;green&#x27;</span>, headwidth = <span class="number">5</span>, headlength = <span class="number">10</span>),</span><br><span class="line">            bbox = <span class="built_in">dict</span>(boxstyle = <span class="string">&#x27;circle, pad = 0.5&#x27;</span>, fc = <span class="string">&#x27;yellow&#x27;</span>, ec = <span class="string">&#x27;k&#x27;</span>, lw = <span class="number">1</span>, alpha = <span class="number">0.5</span>))</span><br><span class="line"><span class="comment"># fc: facecolor, ec: edegcolor, lw: lineweight</span></span><br><span class="line"></span><br><span class="line">ax.annotate(<span class="string">u&#x27;样式4&#x27;</span>, xy = (x[<span class="number">7</span>], y[<span class="number">7</span>]), xytext = (<span class="number">80</span>, <span class="number">10</span>), textcoords = <span class="string">&#x27;offset points&#x27;</span>, </span><br><span class="line">            arrowprops = <span class="built_in">dict</span>(facecolor = <span class="string">&#x27;blue&#x27;</span>, headwidth = <span class="number">5</span>, headlength = <span class="number">10</span>),</span><br><span class="line">            bbox = <span class="built_in">dict</span>(boxstyle = <span class="string">&#x27;round, pad = 0.5&#x27;</span>, fc = <span class="string">&#x27;gray&#x27;</span>, ec = <span class="string">&#x27;k&#x27;</span>, lw = <span class="number">1</span>, alpha = <span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWMa8.png" /></p>
<center>
fig 3-2 annoatation case2
</center>
<h2 id="参考线区域的绘制">3.3 参考线/区域的绘制</h2>
<ul>
<li>axhline(), axvline()</li>
</ul>
<p>使用 Matplotlib 的 axhline() 函数、axvline() 函数分别在图形中添加水平参考线和垂直参考线，使用 axhline() 函数时给定 y 轴上的位置，同理axvline() 使用时需要给定 x 轴上的位置</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.axhline(y = <span class="built_in">min</span>(y), c = <span class="string">&#x27;blue&#x27;</span>, ls = <span class="string">&#x27;:&#x27;</span>, lw = <span class="number">2</span>)</span><br><span class="line">ax.axvline(x = np.pi*<span class="number">3</span>/<span class="number">2</span>, c = <span class="string">&#x27;blue&#x27;</span>, ls = <span class="string">&#x27;-.&#x27;</span>, lw = <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>result:</p>
<p><img src="https://s3.ax1x.com/2020/11/30/DgW3GQ.png" /></p>
<center>
fig 3-3 Reference line
</center>
<ul>
<li>axhspan(), axvspan()</li>
</ul>
<p>使用 axhspan() 函数、axvspan() 函数分别在图形中添加 sin() 函数平行于 x 轴的参考区域和平行于 y 轴的参考区域，axhspan() 函数需给定 y 轴上的区间位置，同理在 axvspan() 中需给定 x 轴上的区间位置</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.axhspan(ymin = <span class="number">0</span>, ymax = <span class="number">1</span>, facecolor = <span class="string">&#x27;purple&#x27;</span>, alpha = <span class="number">0.3</span>)</span><br><span class="line">ax.axvspan(xmin = np.pi *<span class="number">2</span>, xmax = np.pi * <span class="number">5</span>/<span class="number">2</span>, facecolor = <span class="string">&#x27;g&#x27;</span>, alpha = <span class="number">0.3</span>)</span><br></pre></td></tr></table></figure>
<p>result:</p>
<p><img src="https://s3.ax1x.com/2020/11/30/DgW82j.png" /></p>
<center>
fig 3-4 Reference interval
</center>
<h2 id="双-y-轴图表的绘制">3.4 双 Y 轴图表的绘制</h2>
<ul>
<li>twinx(), twiny()</li>
</ul>
<p>如果要在同一个 x 轴上显示两个不同数量级别的序列， 可以将第二个序列绘制在右侧辅助的 y 轴上，借助 Matplotlib 的 twinx() 和 twiny() 可以实现两个 y 或 x 轴</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax_aux = ax.twinx()</span><br><span class="line">ax_aux.plot(x, np.arange(<span class="number">1000</span>), color = <span class="string">&#x27;blue&#x27;</span>, label = <span class="string">&#x27;line 1000&#x27;</span>)</span><br><span class="line"></span><br><span class="line">y_location1 = np.arange(<span class="number">0</span>, <span class="number">1000</span>, <span class="number">100</span>)</span><br><span class="line">y_labels1 = np.arange(<span class="number">0</span>, <span class="number">1000</span>, <span class="number">100</span>)</span><br><span class="line">ax_aux.set_yticks(y_location1) <span class="comment"># 刻度</span></span><br><span class="line">ax_aux.set_yticklabels(y_labels1, fontsize= <span class="number">15</span>) <span class="comment"># 刻度标签</span></span><br><span class="line"></span><br><span class="line">ax_aux.set_ylabel(<span class="string">&#x27;Y 轴 - 辅助&#x27;</span>, fontsize= <span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<p>result:</p>
<p><img src="https://s3.ax1x.com/2020/11/30/DgWGxs.md.png" /></p>
<center>
fig 3-5 双 Y 轴 图表
</center>
<ul>
<li>添加图例</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig.legend(loc = <span class="string">&#x27;upper right&#x27;</span>, bbox_to_anchor = (<span class="number">1</span>, <span class="number">1</span>), bbox_transform = ax.transAxes, fontsize = <span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<h2 id="条形图的绘制">3.5 条形图的绘制</h2>
<ul>
<li>bar()</li>
</ul>
<p>条形图时通过相同宽度条形的高度/宽度来表现数据差异的图表，可利用 bar() 函数绘制</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 Figure 对象中创建一个 Axes 对象，每个 Axes 对象即为一个绘图区域</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pandas 生成时间序列</span></span><br><span class="line">date_index = pd.date_range(<span class="string">&#x27;2019-01-01&#x27;</span>, freq = <span class="string">&#x27;D&#x27;</span>, periods = <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">y_location = np.arange(<span class="number">0</span>, <span class="number">1000</span>, <span class="number">200</span>)</span><br><span class="line">y_labels = np.arange(<span class="number">0</span>, <span class="number">1000</span>, <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别模拟生成跌涨时的成交量数据</span></span><br><span class="line">red_bar = [<span class="number">1000</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">879</span>, <span class="number">986</span>, <span class="number">213</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">green_bar = [<span class="number">0</span>, <span class="number">200</span>, <span class="number">599</span>, <span class="number">567</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">234</span>, <span class="number">998</span>, <span class="number">489</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制条形图</span></span><br><span class="line">ax.bar(date_index, red_bar, facecolor = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">ax.bar(date_index, green_bar, facecolor = <span class="string">&#x27;green&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置轴标签</span></span><br><span class="line">ax.set_xlabel(<span class="string">u&#x27;交易日&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">u&#x27;手&#x27;</span>,fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置标题</span></span><br><span class="line">ax.set_title(<span class="string">u&#x27;成交量&#x27;</span>, fontsize = <span class="number">25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:</p>
<p><img src="https://s3.ax1x.com/2020/11/30/DgWYMn.png" /></p>
<center>
fig 3-6 条形图
</center>
<h2 id="直方图">3.6 直方图</h2>
<ul>
<li>hist()</li>
</ul>
<p>绘制直方图，首先要将全部样本数据按照不同的区间范围划分为若干组，每个组为直方图的柱子，柱子宽度表示该组的区间，柱子的高度表示数据出现的次数</p>
<ul>
<li>x：绘制直方图的数据（一维数组形式），例如服从正态分布的随机数组</li>
<li>bins：直方图的柱数</li>
<li>desity：是否将直方图的频数（数据出现的次数）转换成频率（数据所占的比例）的表示，默认为 False，True表示显示频数统计结果</li>
<li>n：直方图中每一个 bar 区间数据的频数或频率， 由参数 density 设定</li>
<li>bins：用于返回各个 bin 的区间范围</li>
<li>patches：；列表形式返回每个 bin 的图形对象</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制直方图</span></span><br><span class="line">ax.hist(np.random.normal(loc = <span class="number">0</span>, scale = <span class="number">1</span>, size = <span class="number">1000</span>), bins = <span class="number">50</span>, density = <span class="literal">False</span>, color = <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置轴标签</span></span><br><span class="line">ax.set_xlabel(<span class="string">u&#x27;样本值&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">u&#x27;频数&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置标题</span></span><br><span class="line">ax.set_title(<span class="string">u&#x27;正态分布直方图&#x27;</span>, fontsize = <span class="number">25</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWtrq.md.png" /></p>
<center>
fig 3-7 直方图
</center>
<h2 id="饼图">3.7 饼图</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> *</span><br><span class="line">rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"></span><br><span class="line">labels=[<span class="string">&quot;东部&quot;</span>,<span class="string">&quot;南部&quot;</span>,<span class="string">&quot;北部&quot;</span>,<span class="string">&quot;中部&quot;</span>]</span><br><span class="line">sizes=[<span class="number">5</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">15</span>]</span><br><span class="line">colors=[<span class="string">&quot;red&quot;</span>,<span class="string">&quot;green&quot;</span>,<span class="string">&quot;blue&quot;</span>,<span class="string">&quot;yellow&quot;</span>]</span><br><span class="line">explode=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.05</span>,<span class="number">0</span>) <span class="comment"># 突出</span></span><br><span class="line">plt.pie(sizes, explode = explode, labels = labels, colors = colors, labeldistance = <span class="number">1.1</span>,autopct = <span class="string">&quot;%3.1f%%&quot;</span>, shadow = <span class="literal">True</span>, startangle = <span class="number">90</span>, pctdistance = <span class="number">0.5</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;equal&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWwIU.png" /></p>
<center>
fig 3-8 饼图
</center>
<h2 id="k-线图">3.8 K 线图</h2>
<ul>
<li>candlestick_ochl(), candlestick2_ochl()</li>
</ul>
<p>股票的 K 线记录着一个时间段的开盘价、最高价、最低价、收盘价这 4 个数据，定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> mpl_finance <span class="keyword">as</span> mpf</span><br><span class="line">candlestick2_ochl(ax, opens, closea, highs, lows, width = <span class="number">4</span>, colorup = <span class="string">&#x27;k&#x27;</span>, colordown = <span class="string">&#x27;r&#x27;</span>, alpha = <span class="number">0.75</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>ochl: opens, closes, highs, lows, 分别表示开盘价、收盘价、最高价、最低价的序列</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> mpl_finance <span class="keyword">as</span> mpf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对象式绘图</span></span><br><span class="line"><span class="comment"># pyplt 模块中的 figure() 函数创建名为</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制 K 线图</span></span><br><span class="line">opens = [<span class="number">2320.36</span>, <span class="number">2300</span>, <span class="number">2295.35</span>, <span class="number">2347.22</span>, <span class="number">2360.75</span>, <span class="number">2385.43</span>, <span class="number">2376.41</span>, <span class="number">2424.92</span>, <span class="number">2411</span>, <span class="number">2432.68</span>]</span><br><span class="line">closes = [<span class="number">2320.26</span>, <span class="number">2291.3</span>, <span class="number">2347.5</span>, <span class="number">2358.98</span>, <span class="number">2382.48</span>, <span class="number">2385.42</span>, <span class="number">2419.02</span>, <span class="number">2428.15</span>, <span class="number">2433.13</span>, <span class="number">2334.48</span>]</span><br><span class="line">lows = [<span class="number">2287.3</span>, <span class="number">2288.26</span>, <span class="number">2295.35</span>, <span class="number">2337.35</span>, <span class="number">2347.89</span>, <span class="number">2371.23</span>, <span class="number">2369.57</span>, <span class="number">2417.58</span>, <span class="number">2403.3</span>, <span class="number">2427.7</span>]</span><br><span class="line">highs = [<span class="number">2362.94</span>, <span class="number">2308.38</span>, <span class="number">2345.92</span>, <span class="number">2363.8</span>, <span class="number">2382.48</span>, <span class="number">2383.76</span>, <span class="number">2391.82</span>, <span class="number">2421.15</span>, <span class="number">2440.38</span>, <span class="number">2441.73</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制 K 线走势</span></span><br><span class="line">mpf.candlestick2_ochl(ax, opens, closes, highs, lows, width = <span class="number">0.5</span>, colorup = <span class="string">&#x27;r&#x27;</span>, colordown = <span class="string">&#x27;g&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pandas 生成实践序列</span></span><br><span class="line">date_index = pd.date_range(<span class="string">&#x27;2019-01-01&#x27;</span>, freq = <span class="string">&#x27;D&#x27;</span>, periods = <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 x 轴的范围</span></span><br><span class="line">ax.set_xlim(<span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># x 轴刻度设定，每15天标一个日期</span></span><br><span class="line">ax.set_xticks(np.arange(<span class="number">0</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># 标签设置为日期</span></span><br><span class="line">ax.set_xticklabels([date_index.strftime(<span class="string">&#x27;%Y-%m-%d&#x27;</span>)[index] <span class="keyword">for</span> index <span class="keyword">in</span> ax.get_xticks()])</span><br><span class="line"><span class="comment"># 设置轴标签</span></span><br><span class="line">ax.set_xlabel(<span class="string">u&#x27;Date&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">u&#x27;Price&#x27;</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_title(<span class="string">u&#x27;日 K 线图&#x27;</span>, fontsize = <span class="number">25</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWNq0.png" /></p>
<center>
fig 3-9 K 线图
</center>
<h2 id="time-series">3.9 Time series</h2>
<p>当横轴时间过长，不利于展示图片信息时，可以通过 matplotlib.datas 模块和<code>ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))</code>来调整仅显示年份</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.dates <span class="keyword">as</span> mdates</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ticks</span></span><br><span class="line">data_ticks = pd.date_range(start = <span class="string">&#x27;1985-12&#x27;</span>, freq = <span class="string">&#x27;Y&#x27;</span>, end = <span class="string">&#x27;2019-01&#x27;</span>)</span><br><span class="line">data_labels = np.arange(<span class="number">1985</span>, <span class="number">2019</span>)</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">r&#x27;D:\Demo\University\XMU\Thesis\Master\WTI.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># date_index = data.loc[:, &#x27;日期&#x27;]</span></span><br><span class="line">x_index = pd.date_range(start = <span class="string">&#x27;1986-01&#x27;</span>, freq = <span class="string">&#x27;M&#x27;</span>, end = <span class="string">&#x27;2019-01&#x27;</span>)</span><br><span class="line">data1 = data.loc[:, <span class="string">&#x27;收盘&#x27;</span>]</span><br><span class="line">data_pt = data1.to_list()</span><br><span class="line"></span><br><span class="line">petrol_price = pd.DataFrame(data_pt, index = x_index, columns = [<span class="string">&#x27;Pt_price&#x27;</span>])</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line">ax.plot(petrol_price, color = <span class="string">&#x27;b&#x27;</span>, lw = <span class="number">0.8</span>, label = <span class="string">&#x27;WTI现货离岸价格&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置时间显示格式，%Y%m%d%H 年月日时显示</span></span><br><span class="line">ax.xaxis.set_major_formatter(mdates.DateFormatter(<span class="string">&#x27;%Y&#x27;</span>))</span><br><span class="line"><span class="comment"># plt.xlim((1988, 2019))</span></span><br><span class="line">plt.xticks(ticks = data_ticks, label = data_labels, rotation = <span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;1986-2018年油价（WTI现货离岸价格）趋势图&#x27;</span>, fontsize = <span class="number">16</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWgqx.md.png" /></p>
<center>
fig 3-10 WTI油价趋势表
</center>
<h1 id="subplot">4 Subplot</h1>
<p>当需要在图表上显示多个子图时，可以在 Figure 对象中创建 Axes 对象，于是每个 Axes 对象即为一个独立的绘图区域，创建子图的方法主要有 subplot()、add_subplot()、add_axes() 三种方法</p>
<h2 id="create-subplot">4.1 Create subplot</h2>
<h3 id="add_subplot">4.1.1 add_subplot()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">12</span>,  <span class="number">8</span>))</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">211</span>) <span class="comment"># 子图以 2 行 1 列排布</span></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">212</span>) <span class="comment"># 创建另一个 Axes 对象</span></span><br><span class="line"></span><br><span class="line">ax1.plot(np.arange(<span class="number">100</span>), np.random.randint(<span class="number">0</span>, <span class="number">10</span>, <span class="number">100</span>), label = <span class="string">u&#x27;0-10 随机数&#x27;</span>, ls = <span class="string">&#x27;-&#x27;</span>, c =<span class="string">&#x27;r&#x27;</span>, lw = <span class="number">1</span>)</span><br><span class="line">ax1.set_title(<span class="string">u&#x27;0-10 随机数&#x27;</span>, fontsize = <span class="number">12</span>)</span><br><span class="line">ax1.legend(loc = <span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2.plot(np.arange(<span class="number">100</span>), np.random.randint(<span class="number">10</span>, <span class="number">20</span>, <span class="number">100</span>), label = <span class="string">u&#x27;10-20 随机数&#x27;</span>, ls = <span class="string">&#x27;-&#x27;</span>, c =<span class="string">&#x27;y&#x27;</span>, lw = <span class="number">1</span>)</span><br><span class="line">ax2.set_title(<span class="string">u&#x27;10-20 随机数&#x27;</span>, fontsize = <span class="number">12</span>)</span><br><span class="line">ax2.legend(loc = <span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWsz9.png" /></p>
<center>
fig 4-1 subplot
</center>
<p>add_subplot() 本质上是以坐标来定位子图位置的，左下角坐标位置时子图在整个 Figure 对象上的绝对坐标，如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(ax1, ax2)</span><br><span class="line"><span class="comment"># AxesSubplot(0.125,0.536818;0.775x0.343182)</span></span><br><span class="line"><span class="comment"># AxesSubplot(0.125,0.125;0.775x0.343182)</span></span><br></pre></td></tr></table></figure>
<h3 id="add_axes">4.1.2 add_axes()</h3>
<p>使用 add_axes() 创建子图与 add_subplot() 有所不同，add_axes() 函数中需要给定子图在整个 Figure 对象上的绝对坐标[x0, y0, width, height]，即左下角的坐标 (x0, y0) 及其宽度和高度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax1 = fig.add_axes([<span class="number">0.125</span>, <span class="number">0.536818</span>, <span class="number">0.775</span>, <span class="number">0.343182</span>])</span><br><span class="line">ax2 = fig.add_axes([<span class="number">0.125</span>, <span class="number">0.125</span>, <span class="number">0.775</span>, <span class="number">0.343182</span>])</span><br><span class="line">ax1.plot(np.arange(<span class="number">100</span>), np.random.randint(<span class="number">0</span>, <span class="number">10</span>, <span class="number">100</span>), label = <span class="string">u&#x27;0-10 随机数&#x27;</span>, ls = <span class="string">&#x27;-&#x27;</span>, c =<span class="string">&#x27;r&#x27;</span>, lw = <span class="number">1</span>)</span><br><span class="line">ax1.set_title(<span class="string">u&#x27;0-10 随机数&#x27;</span>, fontsize = <span class="number">12</span>)</span><br><span class="line">ax1.legend(loc = <span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2.plot(np.arange(<span class="number">100</span>), np.random.randint(<span class="number">10</span>, <span class="number">20</span>, <span class="number">100</span>), label = <span class="string">u&#x27;10-20 随机数&#x27;</span>, ls = <span class="string">&#x27;-&#x27;</span>, c =<span class="string">&#x27;y&#x27;</span>, lw = <span class="number">1</span>)</span><br><span class="line">ax2.set_title(<span class="string">u&#x27;10-20 随机数&#x27;</span>, fontsize = <span class="number">12</span>)</span><br><span class="line">ax2.legend(loc = <span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWrRJ.png" /></p>
<center>
fig 4-2 add_axes
</center>
<p>当需要精确定位子图时，可使用 add_axes()，但获取子图精确的位置信息较繁琐</p>
<h3 id="subplot-1">4.1.3 subplot()</h3>
<p>add_subplot() 和 add_axes() 是对象式创建子图的方法，而 subplot() 是函数式创建子图的方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">100</span>), np.random.randint(<span class="number">0</span>, <span class="number">10</span>, <span class="number">100</span>), label = <span class="string">u&#x27;0-10 随机数&#x27;</span>, ls = <span class="string">&#x27;-&#x27;</span>, c =<span class="string">&#x27;r&#x27;</span>, lw = <span class="number">1</span>)</span><br><span class="line">plt.legend(loc = <span class="number">1</span>)</span><br><span class="line">plt.subplot(<span class="number">212</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">100</span>), np.random.randint(<span class="number">10</span>, <span class="number">20</span>, <span class="number">100</span>), label = <span class="string">u&#x27;10-20 随机数&#x27;</span>, ls = <span class="string">&#x27;-&#x27;</span>, c =<span class="string">&#x27;y&#x27;</span>, lw = <span class="number">1</span>)</span><br><span class="line">plt.legend(loc = <span class="number">1</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result is same as above figure.</p>
<ul>
<li>Demo: 使用 subplot 创建 2 行 3 列 排布的多子图，以遍历方式在子图上绘制折线图</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">fig_ps, axes_ps = plt.subplots(<span class="number">2</span>, <span class="number">3</span>) </span><br><span class="line"><span class="comment"># subplots 返回两个值，fig_ps 表示图像大小信息， axes_ps 表示子图位置信息</span></span><br><span class="line">print(fig_ps, axes_ps)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        axes_ps[i, j].plot(np.arange(<span class="number">100</span>), np.random.randint(<span class="number">0</span>, <span class="number">10</span>, <span class="number">100</span>), c =<span class="string">&#x27;y&#x27;</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWBiF.png" /></p>
<center>
fig 4-3 mul-subplot
</center>
<h2 id="布局多子图对象">4.2 布局多子图对象</h2>
<ul>
<li>GridSpec module</li>
</ul>
<p>有时不仅要在多个子图上显示图形，而且也要协调多个子图的位置和比例。三种创建子图的方法中，使用较多的是 add_plot() 方法，而该方法所创建的子图是堆成的子图，因此该方法并不满足非对称子图的应用。 若要创建非对称的子图，可以使用 matplotlib 的 GridSpec 模块。GridSpec 可以自定义子图的位置和调整子图行和列的相对高度和宽度</p>
<p>Import module</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec <span class="comment"># 分割子图</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># gridspec.GridSpec 的构造函数</span></span><br><span class="line">gridspec.GridSpec(nrows, ncols, figure = <span class="literal">None</span>, left = <span class="literal">None</span>, bottom = <span class="literal">None</span>, right = <span class="literal">None</span>, top = <span class="literal">None</span>, wspace = <span class="literal">None</span>, hspace = <span class="literal">None</span>, width_ratios = <span class="literal">None</span>, height_ratios = <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数 nrows 和 ncols 分别表示网格的行列数。用 plt.figure() 创建图表，通过 gridspec.GridSpec() 将整个图表划分为多个区域。由于 GridSpec 返回的实例支持切片方式选取网格区域，因此可以结合 add_subplot() 方法更灵活地添加跨度不同网格大小的子图</p>
<p>left, bottom, right, top 分别控制子图与 Figure 左边、底部、右边、顶部的距离比例。gs[0, : ] 表示该子图占第 0 行和所有列</p>
<h3 id="创建多子图布局">4.2.1 创建多子图布局</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>), dpi = <span class="number">100</span>, facecolor = <span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">gs = gridspec.GridSpec(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">graph_ax1 = fig.add_subplot(gs[<span class="number">0</span>, :])</span><br><span class="line">graph_ax2 = fig.add_subplot(gs[<span class="number">1</span>, <span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">graph_ax3 = fig.add_subplot(gs[<span class="number">1</span>:<span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">graph_ax4 = fig.add_subplot(gs[<span class="number">2</span>, <span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgW6MR.png" /></p>
<center>
fig 4-4 多子图布局图
</center>
<h3 id="微调">4.2.2 微调</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">12</span>, <span class="number">8</span>), dpi = <span class="number">100</span>, facecolor = <span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">gs = gridspec.GridSpec(<span class="number">3</span>, <span class="number">3</span>, left = <span class="number">0.08</span>, bottom = <span class="number">0.15</span>, right = <span class="number">0.99</span>, </span><br><span class="line">                       top = <span class="number">0.96</span>, wspace = <span class="number">0.5</span>, hspace = <span class="number">0.5</span>, width_ratios = [<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                      height_ratios = [<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">graph_ax1 = fig.add_subplot(gs[<span class="number">0</span>, :])</span><br><span class="line">graph_ax2 = fig.add_subplot(gs[<span class="number">1</span>, <span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">graph_ax3 = fig.add_subplot(gs[<span class="number">1</span>:<span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">graph_ax4 = fig.add_subplot(gs[<span class="number">2</span>, <span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWcs1.md.png" /></p>
<center>
fig 4-5 微调之后的多子图布局
</center>
<h1 id="figure-properties">5 Figure properties</h1>
<h2 id="plot">5.1 plot()</h2>
<p>Function definition:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 单线条：</span></span><br><span class="line">plot([x], y [, fmt], data = <span class="literal">None</span>, **kwargs)</span><br><span class="line"><span class="comment"># 多线条</span></span><br><span class="line">plot([x], y [, fmt], [x2], y2 [fmt2], ..., **kwargs)</span><br><span class="line"><span class="comment"># fmt = &#x27;[color][marker][line]&#x27;</span></span><br></pre></td></tr></table></figure>
<p>其中，[fmt]为可选参数，用一个字符串来定义图形的基本属性，包括颜色（color），点型（marker），线性（linestyle），具体如下：</p>
<ul>
<li>Colors</li>
</ul>
<center>
tab 5-4 color properties
</center>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Character</th>
<th style="text-align: center;">Color</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>'b'</code></td>
<td style="text-align: center;">blue</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'g'</code></td>
<td style="text-align: center;">green</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'r'</code></td>
<td style="text-align: center;">red</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'c'</code></td>
<td style="text-align: center;">cyan（蓝绿色）</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'m'</code></td>
<td style="text-align: center;">magenta（品红）</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'y'</code></td>
<td style="text-align: center;">yellow</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'k'</code></td>
<td style="text-align: center;">black</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'w'</code></td>
<td style="text-align: center;">white</td>
</tr>
</tbody>
</table>
<ul>
<li>Markers</li>
</ul>
<center>
tab 5-5 marker properties
</center>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Character</th>
<th style="text-align: center;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>'.'</code></td>
<td style="text-align: center;">point marker</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>','</code></td>
<td style="text-align: center;">pixel marker</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'o'</code></td>
<td style="text-align: center;">circle marker</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'v'</code></td>
<td style="text-align: center;">triangle_down marker</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'^'</code></td>
<td style="text-align: center;">triangle_up marker</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'&lt;'</code></td>
<td style="text-align: center;">triangle_left marker</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'&gt;'</code></td>
<td style="text-align: center;">triangle_right marker</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'1'</code></td>
<td style="text-align: center;">tri_down marker</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'2'</code></td>
<td style="text-align: center;">tri_up marker</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'3'</code></td>
<td style="text-align: center;">tri_left marker</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'4'</code></td>
<td style="text-align: center;">tri_right marker</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'s'</code></td>
<td style="text-align: center;">square marker</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'p'</code></td>
<td style="text-align: center;">pentagon marker（五角形）</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'*'</code></td>
<td style="text-align: center;">star marker</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'h'</code></td>
<td style="text-align: center;">hexagon1 marker（六角形）</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'H'</code></td>
<td style="text-align: center;">hexagon2 marker</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'+'</code></td>
<td style="text-align: center;">plus marker</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'x'</code></td>
<td style="text-align: center;">x marker</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'D'</code></td>
<td style="text-align: center;">diamond marker</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'d'</code></td>
<td style="text-align: center;">thin_diamond marker</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'|'</code></td>
<td style="text-align: center;">vline marker</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'_'</code></td>
<td style="text-align: center;">hline marker</td>
</tr>
</tbody>
</table>
<ul>
<li>Line Styles</li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Character</th>
<th style="text-align: center;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>'-'</code></td>
<td style="text-align: center;">solid line style</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'--'</code></td>
<td style="text-align: center;">dashed line style（虚线）</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'-.'</code></td>
<td style="text-align: center;">dash-dot line style</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>':'</code></td>
<td style="text-align: center;">dotted line style</td>
</tr>
</tbody>
</table>
<ul>
<li>Examples format strings:</li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Character</th>
<th style="text-align: center;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>'b'</code></td>
<td style="text-align: center;">blue markers with default shape</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'ro'</code></td>
<td style="text-align: center;">red circles</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'g-'</code></td>
<td style="text-align: center;">green solid line</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>'--'</code></td>
<td style="text-align: center;">dashed line with default color</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>'k^:'</code></td>
<td style="text-align: center;">black triangle_up markers connected by a dotted line</td>
</tr>
</tbody>
</table>
<p>Case:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.plot([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>], <span class="string">&#x27;go--&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], color = <span class="string">&#x27;green&#x27;</span>, marker = <span class="string">&#x27;o&#x27;</span>, linestyle = <span class="string">&#x27;dashed&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], color = <span class="string">&#x27;g&#x27;</span>, marker = <span class="string">&#x27;o&#x27;</span>, linestyle = <span class="string">&#x27;dashed&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWaZV.png" /></p>
<center>
fig 5-1 plot parameter
</center>
<h2 id="abbreviation">5.2 Abbreviation</h2>
<p>Matplotlib 支持一些属性的关键词简写：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;linewidth&#x27;</span>: [<span class="string">&#x27;lw&#x27;</span>]</span><br><span class="line"><span class="string">&#x27;linestyle&#x27;</span>: [<span class="string">&#x27;ls&#x27;</span>]</span><br><span class="line"><span class="string">&#x27;facecolor&#x27;</span>: [<span class="string">&#x27;fc&#x27;</span>]</span><br><span class="line"><span class="string">&#x27;edgecolor&#x27;</span>: [<span class="string">&#x27;ec&#x27;</span>]</span><br><span class="line"><span class="string">&#x27;markerfacecolor&#x27;</span>: [<span class="string">&#x27;mfc&#x27;</span>]</span><br><span class="line"><span class="string">&#x27;markeredgecolor&#x27;</span>: [<span class="string">&#x27;mec&#x27;</span>]</span><br><span class="line"><span class="string">&#x27;markeredgewidth&#x27;</span>: [<span class="string">&#x27;mew&#x27;</span>]</span><br><span class="line"><span class="string">&#x27;markersize&#x27;</span>: [<span class="string">&#x27;ms&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>eg:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.plot([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], color = <span class="string">&#x27;green&#x27;</span>, marker = <span class="string">&#x27;o&#x27;</span>, linestyle = <span class="string">&#x27;dashed&#x27;</span>, linewidth = <span class="number">2</span>)</span><br><span class="line">plt.plot([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], c = <span class="string">&#x27;g&#x27;</span>, marker = <span class="string">&#x27;o&#x27;</span>, linestyle = <span class="string">&#x27;dashed&#x27;</span>, lw = <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWdaT.png" /></p>
<center>
fig 5-2 Abbreviation
</center>
<h2 id="ticks">5.3 Ticks</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span> * x + <span class="number">1</span></span><br><span class="line">y2 = x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure(num = <span class="number">1</span>)</span><br><span class="line">plt.plot(x, y1, color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.plot(x, y2, color = <span class="string">&#x27;green&#x27;</span>, linewidth = <span class="number">1.0</span>, linestyle = <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim((-<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">plt.ylim((-<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;I am x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;I am y&#x27;</span>)</span><br><span class="line"></span><br><span class="line">new_ticks = np.linspace(-<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">print(new_ticks)</span><br><span class="line">plt.xticks(new_ticks) <span class="comment"># 刻度</span></span><br><span class="line">plt.yticks([-<span class="number">2</span>, -<span class="number">1.8</span>, -<span class="number">1</span>, <span class="number">1.22</span>, <span class="number">3</span>],</span><br><span class="line">           [<span class="string">r&#x27;$relly\ bad\ \alpha$&#x27;</span>, <span class="string">r&#x27;$bad$&#x27;</span>, <span class="string">r&#x27;$normal$&#x27;</span>, <span class="string">r&#x27;$good$&#x27;</span>, <span class="string">r&#x27;$really\ good$&#x27;</span>])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://s3.ax1x.com/2020/11/30/DgWA8H.png" /></p>
<center>
fig 5-3 Ticks demo
</center>
<h2 id="axis-position">5.4 Axis position</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span> * x + <span class="number">1</span></span><br><span class="line">y2 = x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure(num = <span class="number">1</span>)</span><br><span class="line">plt.plot(x, y1, color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.plot(x, y2, color = <span class="string">&#x27;green&#x27;</span>, linewidth = <span class="number">1.0</span>, linestyle = <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim((-<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">plt.ylim((-<span class="number">2</span>, <span class="number">4</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;I am x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;I am y&#x27;</span>)</span><br><span class="line"></span><br><span class="line">new_ticks = np.linspace(-<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">print(new_ticks)</span><br><span class="line">plt.xticks(new_ticks)</span><br><span class="line">plt.yticks([-<span class="number">2</span>, -<span class="number">1.8</span>, -<span class="number">1</span>, <span class="number">1.22</span>, <span class="number">3</span>],</span><br><span class="line">           [<span class="string">r&#x27;$relly\ bad\ \alpha$&#x27;</span>, <span class="string">r&#x27;$bad$&#x27;</span>, <span class="string">r&#x27;$normal$&#x27;</span>, <span class="string">r&#x27;$good$&#x27;</span>, <span class="string">r&#x27;$really\ good$&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># gca = get current axis</span></span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:</p>
<p><img src="https://s3.ax1x.com/2020/11/30/DgWkPe.png" /></p>
<center>
fig 5-4 Modify axis position
</center>
<h2 id="legend">5.5 legend()</h2>
<ul>
<li>loc</li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Location String</th>
<th style="text-align: center;">Location Code</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">'best'</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">'upper right'</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">'upper left'</td>
<td style="text-align: center;">2</td>
</tr>
<tr class="even">
<td style="text-align: center;">'lower left'</td>
<td style="text-align: center;">3</td>
</tr>
<tr class="odd">
<td style="text-align: center;">'lower right'</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;">'right'</td>
<td style="text-align: center;">5</td>
</tr>
<tr class="odd">
<td style="text-align: center;">'center left'</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">'center right'</td>
<td style="text-align: center;">7</td>
</tr>
<tr class="odd">
<td style="text-align: center;">'lower center'</td>
<td style="text-align: center;">8</td>
</tr>
<tr class="even">
<td style="text-align: center;">'upper center'</td>
<td style="text-align: center;">9</td>
</tr>
<tr class="odd">
<td style="text-align: center;">'center'</td>
<td style="text-align: center;">10</td>
</tr>
</tbody>
</table>
<h2 id="add-text">5.6 Add text</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.text(<span class="number">0</span>, <span class="number">2</span>, <span class="string">&#x27;This is a test text.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://s3.ax1x.com/2020/11/30/DgWRZ6.png" /></p>
<center>
fig 5-5 Add text on figure
</center>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Python module</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Data analysis</tag>
        <tag>Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>PDF_test</title>
    <url>/2020/12/01/PDF-test/</url>
    <content><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;% pdf https://yangsuoly.com/file/Latex-Notes.pdf %&#125;</span><br></pre></td></tr></table></figure>
<a id="more"></a>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Latex</category>
      </categories>
      <tags>
        <tag>Latex</tag>
      </tags>
  </entry>
  <entry>
    <title>Numpy</title>
    <url>/2020/11/29/Numpy/</url>
    <content><![CDATA[<h1 id="numpy-version">1 NumPy version</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">print(np.__version__) <span class="comment"># 查看 numpy 版本</span></span><br></pre></td></tr></table></figure>
<p>NumPy( Numerical Python) 是 Python 数值计算最重要的基础库，核心是 N 维数组对象 ndarray ( N-dimensional array )。</p>
<a id="more"></a>
<h1 id="create-ndarray">2 Create ndarray</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">array_1x6 = np.array([<span class="number">1.0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], dtype = np.float64) <span class="comment"># 用 list 创建 array，可以通过 dtype 参数指定元素的类型  </span></span><br><span class="line"></span><br><span class="line">print(array_1x6.dtype)</span><br><span class="line"></span><br><span class="line"><span class="comment"># number of dimension</span></span><br><span class="line">print(<span class="string">&#x27;number of dim: &#x27;</span>,array_1x6.ndim)</span><br><span class="line">print(<span class="string">&#x27;shape: &#x27;</span>,array_1x6.shape)</span><br><span class="line">print(<span class="string">&#x27;size: &#x27;</span>,array_1x6.size)</span><br><span class="line"><span class="comment"># total number of elements</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(array_1x6) <span class="comment"># 空格分隔元素</span></span><br><span class="line">[<span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span>]</span><br></pre></td></tr></table></figure>
<h1 id="special-ndarray">4 Special ndarray</h1>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br></pre></td></tr></table></figure>
<ul>
<li><p>零矩阵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a1 = np.zeros((<span class="number">3</span>,<span class="number">4</span>)) <span class="comment"># 零矩阵</span></span><br></pre></td></tr></table></figure></li>
<li><p>矩阵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a2 = np.ones((<span class="number">3</span>,<span class="number">4</span>)) <span class="comment"># 1 矩阵</span></span><br></pre></td></tr></table></figure></li>
<li><p>空矩阵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a3 = np.empty((<span class="number">3</span>,<span class="number">4</span>)) <span class="comment"># 未初始化的空矩阵</span></span><br></pre></td></tr></table></figure></li>
<li><p>对角矩阵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a7 = np.identity(<span class="number">5</span>) <span class="comment"># 5x5 的对角矩阵</span></span><br><span class="line">a8 = np.mat(np.identity(<span class="number">5</span>))</span><br></pre></td></tr></table></figure></li>
<li><p>线段</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a5 = np.arange(<span class="number">12</span>)</span><br><span class="line">a6 = np.linspace(<span class="number">1</span>, <span class="number">10</span>, <span class="number">5</span>) <span class="comment"># 5 个元素的线段</span></span><br><span class="line">print(a6 &lt; <span class="number">5</span>) <span class="comment"># 返回布尔类型的矩阵</span></span><br></pre></td></tr></table></figure></li>
<li><p>对角矩阵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a7 = np.identity(<span class="number">5</span>) <span class="comment"># 5x5 的对角矩阵</span></span><br><span class="line">a8 = np.mat(np.identity(<span class="number">5</span>))</span><br></pre></td></tr></table></figure></li>
<li><p>随机矩阵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.random.random((<span class="number">2</span>, <span class="number">4</span>)) <span class="comment"># 0-1的随机数</span></span><br><span class="line">print(np.<span class="built_in">sum</span>(a), np.<span class="built_in">min</span>(a), np.<span class="built_in">max</span>(a))</span><br><span class="line">np.<span class="built_in">sum</span>(a, axis = <span class="number">0</span>) <span class="comment"># 列操作，axis = 1行操作，the default, axis = None，will sum all of the elements of the input array</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="array-operations">4 Array operations</h1>
<h2 id="preparation">4.1 Preparation</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([[<span class="number">10</span>, <span class="number">20</span>], [<span class="number">30</span>, <span class="number">40</span>]])</span><br><span class="line">b = np.arange(<span class="number">4</span>).reshape(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">print(a, b, sep = <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[[<span class="number">10</span> <span class="number">20</span>]</span><br><span class="line"> [<span class="number">30</span> <span class="number">40</span>]]</span><br><span class="line">[[<span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">3</span>]]</span><br></pre></td></tr></table></figure></p>
<h2 id="mathematical-operation">4.2 Mathematical operation</h2>
<ul>
<li><p>Plus &amp; minus <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">c1 = a + b</span><br><span class="line">c2 = a - b</span><br></pre></td></tr></table></figure></p></li>
<li><p>Multiply &amp; divide</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">c3 = a * b <span class="comment"># 对应元素相乘</span></span><br><span class="line">c4 = b / a</span><br></pre></td></tr></table></figure></li>
<li><p><code>dot</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">c5 = np.dot(a, b) <span class="comment"># 矩阵相乘，点乘</span></span><br><span class="line">c6 = a.dot(b) <span class="comment"># 和上式相同，a 值不改变</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="conditional-selection">4.3 Conditional selection</h2>
<ul>
<li><p><code>where</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([[<span class="number">10</span>, <span class="number">20</span>], [<span class="number">30</span>, <span class="number">40</span>]])</span><br><span class="line">row, col = np.where(a == <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">print(row, col, sep = <span class="string">&#x27;\t&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Reuslt: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">0</span>]     [<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h1 id="array-basic-methods">5 Array basic methods</h1>
<ul>
<li><p>导入模块 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure></p></li>
<li><p>统计特征 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># find elements</span></span><br><span class="line">A = np.arange(<span class="number">2</span>, <span class="number">14</span>).reshape(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">index = np.argmax(A)  <span class="comment"># 最大值索引or argmin</span></span><br><span class="line">mean = np.mean(A) <span class="comment"># 均值</span></span><br><span class="line">median = np.median(A) <span class="comment"># 中位数</span></span><br><span class="line">print(index, mean, median, sep = <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure> 上述函数皆默认 <code>axis = None, the index is into the flattened array</code>，若添加参数：<code>axis = 1</code> 则返回每一行的相关操作，<code>axis = 0</code> 则返回每一列的相关操作，具体参照: <code>help(np.mean)</code>。</p></li>
<li><p>累加和差分 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># A：3x4 的数组</span></span><br><span class="line">cumsum = np.cumsum(A)</span><br><span class="line"><span class="comment"># 累加，axis默认为None，输出1x12数组</span></span><br><span class="line">diff = np.diff(A)</span><br><span class="line"><span class="comment"># 差分，默认axis=-1，即行操作与axis=1效果相同，返回3X3的数组，axis=0，返回2x4数组</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>查找数据 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">non = np.nonzero(A)</span><br></pre></td></tr></table></figure> 查找非零元素的索引，返回两个array，第一个为行索引，第二个为列索引，输出： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], dtype=int64),</span><br><span class="line"> array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=int64))</span><br></pre></td></tr></table></figure></p></li>
<li><p>矩阵转置 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 矩阵转置, transpose array</span></span><br><span class="line">transpose1 = np.transpose(A)</span><br><span class="line">transpose2 = A.T</span><br><span class="line">print(transpose1, transpose2, sep = <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">print(transpose1.dot(A)) <span class="comment"># $&#123;A * A^T&#125;$</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>数据裁剪<code>clip</code> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">2</span>, <span class="number">14</span>).reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">clip = np.clip(a, <span class="number">5</span>, <span class="number">9</span>)</span><br><span class="line">print(a, clip, sep = <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure> Given an interval [5, 9], values outside this interval are clipped to this interval edges, namely 5 and 9. Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">array([[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>],</span><br><span class="line">       [<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>]])</span><br></pre></td></tr></table></figure></p></li>
<li><p>迭代输出 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">2</span>, <span class="number">14</span>).reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 行迭代输出</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> a:</span><br><span class="line">    print(row)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列迭代输出    </span></span><br><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> a.T:</span><br><span class="line">    print(column.T)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 元素迭代, flat返回迭代器，flatten()返回array</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> a.flat: <span class="comment"># or a.flatten()</span></span><br><span class="line">    print(item)</span><br></pre></td></tr></table></figure> Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Row</span></span><br><span class="line">array([[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>],</span><br><span class="line">       [<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>]])</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h1 id="array-joint">6 Array joint</h1>
<h2 id="vstack-and-hstack">6.1 vstack and hstack</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">b = np.array([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">c = np.vstack((a, b)) <span class="comment">#vertical stack 纵向</span></span><br><span class="line">d = np.hstack((a, b)) <span class="comment"># horizontal stack 横</span></span><br><span class="line">print(a.shape, c.shape) <span class="comment"># a 的shape为序列</span></span><br><span class="line">print(c, d, sep = <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">print(a.T.shape) <span class="comment"># 并未改变shape，0x3维</span></span><br><span class="line">a1 = a[:, np.newaxis] <span class="comment"># 在后面加维度，3x1维</span></span><br><span class="line">a2 = a[np.newaxis, :] <span class="comment"># add before, 1x3</span></span><br><span class="line">c= np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],[<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]]) <span class="comment"># 2x3</span></span><br><span class="line">c1 = c[np.newaxis, :] <span class="comment"># add before 1x2x3</span></span><br><span class="line">c2 = c[:, np.newaxis] <span class="comment"># same as c3</span></span><br><span class="line">c3 = c[:, np.newaxis, :] <span class="comment"># 2x1x3</span></span><br><span class="line">c4 = c[:, :, np.newaxis] <span class="comment"># 2x3x1</span></span><br></pre></td></tr></table></figure>
<h2 id="concatenate">6.2 concatenate</h2>
<p>Join a sequence of arrays along a existing axis, default axis is o, if axis = None, arrays will be flattened before use.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])[:, np.newaxis]</span><br><span class="line">b = np.array([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])[:, np.newaxis]</span><br><span class="line"></span><br><span class="line">c1 = np.concatenate((a,b,b,a)) <span class="comment"># same as c2</span></span><br><span class="line">c2 = np.concatenate((a,b,b,a), axis = <span class="number">0</span>)</span><br><span class="line">c3 = np.concatenate((a,b,b,a), axis = <span class="number">1</span>)</span><br><span class="line">c4 = np.concatenate((a,b,b,a), axis = <span class="literal">None</span>)</span><br><span class="line">print(c1, c2, c3, c4, sep=<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="array-split">7 Array split</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="number">2</span>, <span class="number">14</span>).reshape(<span class="number">3</span>, <span class="number">4</span>) <span class="comment"># 3x4</span></span><br><span class="line">print(a)</span><br><span class="line">print(np.split(a, <span class="number">3</span>, axis = <span class="number">0</span>)) <span class="comment"># vertical</span></span><br><span class="line">print(np.split(a, <span class="number">2</span>, axis = <span class="number">1</span>)) <span class="comment">#horizontal</span></span><br><span class="line"><span class="comment"># 只能进行相等的分割</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>np.split(ary, indices_or sections, axis = 0)</strong></li>
</ul>
<p>Array to be divided into multiple sub-arrays along the given 'axis ', if such split is not possible, then an error will be rasied.</p>
<h1 id="array-copy">8 Array copy</h1>
<ul>
<li><strong>Copy and deep copy</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">b = a <span class="comment"># shallow copy</span></span><br><span class="line">a[<span class="number">0</span>] = <span class="number">10</span></span><br><span class="line">print(a, b)</span><br><span class="line">b1 = a.copy() <span class="comment"># deep copy</span></span><br><span class="line">a[<span class="number">0</span>] = <span class="number">20</span></span><br><span class="line">print(a, b1)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Python module</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Data analysis</tag>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>Prediction methods</title>
    <url>/2020/12/05/Prediction-methods/</url>
    <content><![CDATA[<h1 id="differential-equation-model">1 Differential equation model</h1>
<h2 id="introduction">1.1 Introduction</h2>
<ul>
<li>特点</li>
</ul>
<p>当描述实际对象的某些特征随时间（或空间）而演变的过程、分析它的变化规律、预测它的未来形态、研究它的控制手段时，通常需要建立对象的 <strong>动态微分方程模型</strong>。</p>
<p>微分模型求解的结果就是问题的答案，该答案是 <strong>唯一</strong> 的。</p>
<ul>
<li>典型的模型：
<ul>
<li>传染病的预测模型</li>
<li>经济增长预测模型</li>
<li>兰彻斯特（Lanchester）战争预测模型</li>
<li>药物在体内的分布于排除预测模型</li>
<li>人口的预测模型</li>
<li>烟雾的扩散与消失模型</li>
</ul></li>
</ul>
<p>模型的基本规律随着时间的增长趋势呈指数形式，根据变量的个数建立微分方程。</p>
<a id="more"></a>
<ul>
<li><strong>优点</strong></li>
</ul>
<p>短、中、长期的预测都能适用，既能反应 <strong>内部规律</strong> 以及 <strong>事物的内在关系</strong>，也能分析两个因素的 <strong>相关关系</strong>，精度相应的比较高，另外对模型的改进也比较容易理解和实现。</p>
<ul>
<li><strong>缺点</strong></li>
</ul>
<p>虽然反应的是内部规律，但由于方程的建立是以局部规律的独立性假定为基础，故中长期预测 <strong>偏差有点大</strong>，且 <strong>解较难得到</strong>。</p>
<h2 id="case">1.2 Case</h2>
<ul>
<li><p>Problem</p>
<p>硫黄岛位于东京以南 660 英里的海面上，是日军的重要空军基地。美军在1945 年2 月开始进攻，激烈的战斗持续了一个月，双方伤亡惨重，日方守军21500 人全部阵亡或被俘，美方投入兵力73000 人，伤亡20265 人，战争进行到28 天时美军宣布占领该岛，实际战斗到36 天才停止。美军的战地记录有按天统计的战斗减员和增援情况。日军没有后援，战地记录则全部遗失。</p></li>
<li><p>Solution Code</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">dxy=@(t,x)[<span class="number">-0.0544</span>*x(<span class="number">2</span>)+<span class="number">54000</span>*(t&gt;=<span class="number">0</span> &amp; t&lt;<span class="number">1</span>)+<span class="number">6000</span>*(t&gt;=<span class="number">2</span> &amp; t&lt;<span class="number">3</span>)+<span class="number">13000</span>*(t&gt;=<span class="number">5</span> &amp; t&lt;<span class="number">6</span>)</span><br><span class="line">    <span class="number">-0.0106</span>*x(<span class="number">1</span>)];  <span class="comment">%用匿名函数定义方程右端项，这里用逻辑语句定义分段函数</span></span><br><span class="line">[t,xy]=ode45(dxy,[<span class="number">0</span>:<span class="number">36</span>],[<span class="number">0</span>,<span class="number">21500</span>])</span><br><span class="line">subplot(<span class="number">211</span>), <span class="built_in">plot</span>(t,xy(:,<span class="number">1</span>),<span class="string">&#x27;r*&#x27;</span>,t,xy(:,<span class="number">2</span>),<span class="string">&#x27;gD&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;时间t&#x27;</span>),  ylabel(<span class="string">&#x27;人数&#x27;</span>), <span class="built_in">legend</span>(<span class="string">&#x27;美军&#x27;</span>,<span class="string">&#x27;日军&#x27;</span>)</span><br><span class="line">subplot(<span class="number">212</span>),  <span class="built_in">plot</span>(xy(:,<span class="number">1</span>),xy(:,<span class="number">2</span>))  <span class="comment">%画微分方程组的轨线</span></span><br><span class="line">xlabel(<span class="string">&#x27;美军人数x&#x27;</span>),  ylabel(<span class="string">&#x27;日军人数y&#x27;</span>)  </span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/12/05/DLrAIJ.png" /></p>
<center>
<p>Fig. 1-1 Result of case 1</p>
</center></li>
</ul>
<h1 id="grey-model">2 Grey model</h1>
<h2 id="introduction-1">2.1 Introduction</h2>
<ul>
<li><p>主要特点</p>
<p>模型使用的不是原始数据序列，而是生成的数据序列，其核心体系是 <strong>灰色模型（Grey model, GM）</strong>， 即对原始数据作 <strong>累加生成</strong> 得到近似的 <strong>指数规律 </strong>再进行建模的方法。</p></li>
<li><p><strong>优点</strong></p>
<ul>
<li>不需要很多的数据，一般只需要4个数据，就能解决<strong>历史数据少、序列的完整性及可靠性低</strong>的问题；</li>
<li>能利用微分方程来充分挖掘系统的本质，精度高；</li>
<li>能将无规律的原始数据进行生成得到规律性较强的生成序列，预算简便，易于检验，不考虑分布规律，不考虑变化趋势。</li>
</ul></li>
<li><p><strong>缺点</strong></p>
<p>只适用于 <strong>中短期的预测</strong>，只适合 <strong>指数增长的预测</strong>。</p></li>
</ul>
<h2 id="categories">2.2 Categories</h2>
<h3 id="gm1-1-forecasting-model">2.2.1 GM(1, 1) forecasting model</h3>
<p>GM(1, 1) denotes the grey model is a <strong>first order difference equation</strong> and only include <strong>one variable</strong>.</p>
<p>Not finished, to be continued...</p>
<h3 id="gm2-1-dgm-and-verhulst-model">2.2.2 GM(2, 1), DGM and Verhulst model</h3>
<p>GM(1, 1) 模型适用于具有较强 <strong>指数规律</strong> 的序列，只能描述单调的变化过程，对于<strong>非单调的摆动发展序列</strong>或 <strong>有饱和的 S 形序列</strong>，可以考虑建立 GM(2, 1), DGM and Verhulst model。</p>
<ul>
<li><p>灰色 Verhulst 预测模型</p>
<p>Verhulst 模型主要用来描述具有剥和状态的过程，即 S 形过程，常用于</p>
<ul>
<li>人口预测</li>
<li>生物生长</li>
<li>繁殖预测</li>
<li>产品经济寿命预测</li>
</ul></li>
</ul>
<h1 id="difference-equation">3 Difference equation</h1>
<h2 id="introduction-2">3.1 Introduction</h2>
<p>在利用差分方程建模研究实际问题时，常需要根据统计数据用 <strong>最小二乘法</strong> 来 <strong>拟合 </strong>出差分方程的 <strong>系数</strong>。其系统稳定性讨论要用到代数方程的求根。</p>
<h3 id="一阶自回归ar1">3.1.1 一阶自回归（AR(1)）</h3>
<p>由于时间序列一般存在自相关，故最简单的预测方法为，使用过去值 <span class="math inline">\(y_{t-1}\)</span> 来预测当前值 <span class="math inline">\(y_{t}\)</span> ，即一阶自回归模型（AR(1)） <span class="math display">\[
y_t = \beta_0 + \beta_1 y_{t-1} + \varepsilon_t \ \ (t = 2, \dots, T)
\]</span> 其中，扰动项 <span class="math inline">\(\varepsilon_t\)</span> 为白噪声，故无自相关，即 <span class="math inline">\(\rm{Cov}(\varepsilon_t,\ \varepsilon_s) = 0, \forall t \neq s\)</span>。假设自回归系数 $|_1| &lt; 1 $，则 $ {y_t}$ 为渐进独立的平稳过程。</p>
<h3 id="高阶自回归arp">3.1.2 高阶自回归（AR(p)）</h3>
<p>在 AR(1) 模型中，假设扰动项为无自相关，故可用 <span class="math inline">\(OLS\)</span> 进行一致的估计。<strong>然而</strong>， 如果模型为 AR(2)，但却被误设为 AR(1)，则意味着二阶滞后项 <span class="math inline">\(\beta_2 y_{t-2}\)</span> 被纳入扰动项： <span class="math display">\[
y_t = \beta_0 + \beta_1 y_{t-1} + (\beta_2 y_{t-2} + \varepsilon_t)
\]</span> 其中，由于扰动项为 $(<em>2 y</em>{t-2} + _t) $，故扰动项与解释变量 <span class="math inline">\(y_{t-1}\)</span> 相关，因为 <span class="math inline">\(\rm{Cov}(y_{t-1},\ y_{t-2}) \neq 0\)</span>。此时，扰动项存在自相关，<span class="math inline">\(OLS\)</span> 不再一致，需引入 <span class="math inline">\(\beta_2 y_{t-2}\)</span> 才能得到一致估计。</p>
<p>另外，从预测的角度来看，更高阶的滞后项也可能包含有用的信息。为此，更一般地，考虑 $ p$ 阶自回归模型，记为 <span class="math inline">\(AR(p)\)</span>： <span class="math display">\[
y_t = \beta_0 + \beta_1 y_{t-1} + \dots + \beta_p y_{t-p} + \varepsilon_t
\]</span> 其中，扰动项 <span class="math inline">\(\varepsilon_t\)</span> 为白噪声，无自相关，故 <span class="math inline">\(OLS\)</span> 为一致估计。然而，通常我们并不知道滞后期 <span class="math inline">\(p\)</span>。</p>
<p>估计 <span class="math inline">\(\hat{p}\)</span> 的方法：</p>
<ul>
<li><p>设一个最大滞后期 <span class="math inline">\(p_{\max}\)</span>，然后令 $ = p_{} $ 进行估计，并对最后一个滞后期系数的显著性进行 <span class="math inline">\(t\)</span> 检验。</p>
<p>如果接受该系数为 0，则令 $ = p_{} -1 $，重新进行估计，再对最后一个滞后期的系数进行 <span class="math inline">\(t\)</span> 检验。</p></li>
<li><p>使用信息准则，选择 <span class="math inline">\(\hat{p}\)</span> 使得 <span class="math inline">\(AIC\)</span> 或 <span class="math inline">\(BIC\)</span> 最小化，分别记为 <span class="math inline">\(\hat{p}_{AIC}\)</span> 与 <span class="math inline">\(\hat{p}_{BIC}\)</span>。</p></li>
</ul>
<h3 id="自回归分布滞后模型adl">3.1.3 自回归分布滞后模型（ADL）</h3>
<p>在自回归 <span class="math inline">\(AR(p)\)</span> 中，为提高预测力或解释力，可引入其他解释变量，构成 <strong>自回归分布滞后模型</strong>（Autoregressive Distributed Lag Model, ADL(p, 1) or ARDL(p, q)）。 <span class="math display">\[
y_t = \beta_o + \beta_1 y_{t-1} + \dots + \beta_p y_{t-p} + \gamma_1 x_{t-1} + \dots + \gamma_q x_{t-q} + \varepsilon_t
\]</span> 其中，<span class="math inline">\(p\)</span> 为解释变量 <span class="math inline">\(y\)</span> 的自回归阶数，<span class="math inline">\(q\)</span> 为解释变量 <span class="math inline">\(x\)</span> 的滞后阶数。假定扰动项 <span class="math inline">\(\varepsilon_t\)</span> 为白噪声，则 <span class="math inline">\(OLS\)</span> 为一致估计。</p>
<h3 id="误差修正模型ecm">3.1.4 误差修正模型（ECM）</h3>
<p>ADL 是一种动态模型。从经济理论而言，<strong>相关变量之间可能存在长期的均衡关系，而变量的短期变动则是向着这个长期均衡关系的调整</strong>。ECM 正是这一思想在计量经济学中的体现。</p>
<p>考虑 ADL(1, 1) 模型： <span class="math display">\[
y_t = \beta_o + \beta_1 y_{t-1} + \gamma_1 x_{t-1} + \varepsilon_t
\]</span> 其中，<span class="math inline">\(|\beta_1| &lt; 1\)</span>，故为平稳过程。假设经济理论 认为 <span class="math inline">\((y,\ x)\)</span> 之间存在长期均衡关系： <span class="math display">\[
y = \phi + \theta x
\]</span> 其中，<span class="math inline">\(\phi\)</span> 和 <span class="math inline">\(\theta\)</span> 为待定参数。对方程两边求期望，并令 <span class="math inline">\(y^\star = \rm{E}(y_t) = \rm{E}(y_{t-1})\)</span>， <span class="math inline">\(x^\star = \rm{E}(x_t) = \rm{E}(x_{t-1})\)</span>，可得： <span class="math display">\[
y^\star = \frac{\beta_0}{1-\beta_1} + \frac{\gamma_1}{1-\beta_1} x^\star
\]</span> 所以，<span class="math inline">\(\phi = \frac{\beta_0}{1-\beta_1}\)</span>， <span class="math inline">\(\theta = \frac{\gamma_0}{1-\beta_1}\)</span>。其中 $ $ 即为长期程数，衡量当 <span class="math inline">\(x\)</span> 永久性变化 1 单位时，将导致 <span class="math inline">\(y\)</span> 的永久变化幅度。在方程（5）两边同时减去 <span class="math inline">\(y_{t-1}\)</span> 得： <span class="math display">\[
\Delta y_t = (\beta_1 -1)(y_{t-1} - \phi - \theta x_{t-1}) + \varepsilon_t
\]</span> 其中，<span class="math inline">\((y_{t-1} - \phi - \theta x_{t-1})\)</span> 衡量上一期对均衡条件 <span class="math inline">\(y = \phi + \theta x\)</span> 的偏离（误差），而 <span class="math inline">\((\beta_1 -1)(y_{t-1} - \phi - \theta x_{t-1})\)</span> 为根据上期的误差做的反向修正，成为 <code>误差修正项</code>。</p>
<ul>
<li><p>ECM 优点</p>
<p>一般 ADL 模型都可转化为 ECM 模型。ECM 模型经济含义十分明确，而且可以分别考察长期效益（长期均衡关系）与短期效应（误差修正效应）。</p></li>
</ul>
<h1 id="markov-model">4 Markov model</h1>
<h2 id="defination-of-markov-chain">4.1 Defination of Markov Chain</h2>
<p>现实生活中有很多这样的现象，某一系统在已知现在情况的条件下，系统未来时刻的情况只与现在有关，而与过去的历史无直接关系。</p>
<p>如，研究一个商店的累计销售额，如果现在时刻的累计销售额已知，未来某一时刻的累计销售额与现在时刻以前的任一时刻累计销售额无关。</p>
<p>描述这类 <strong>随机现象</strong> 的数学模型称为 <strong>马尔科夫模型</strong>，简称马氏模型</p>
<ul>
<li><strong>定义 1</strong></li>
</ul>
<p>设 <span class="math inline">\(\{\xi_n,\ n = 1,\ 2,\dots \}\)</span> 是一个随机序列，状态空间 <span class="math inline">\(E\)</span> 为有限或可列集，对于任意的正整数 $m, n $，若 <span class="math inline">\(i,\ j,\ ,\ i_k \in E\ (k=1, \dots, n-1)\)</span>，有： <span class="math display">\[
P\{\xi_{n+m} = j | \xi_n = i,\ \xi_{n-1} = i_{n-1}, \dots, \xi_1 = i_1\} = P\{\xi_{n+m} = j | \xi_n = i\}
\]</span> 则称 <span class="math inline">\(\{\xi_{n} , n = 1,\ 2, \dots\}\)</span> 是一个马尔可夫链。式 (9) 也被称为马氏性。</p>
<p>式 (9) 中，可以证明，对于 <span class="math inline">\(m = 1\)</span> 时成立，则它对 <strong>任意</strong> 的正整数 <span class="math inline">\(m\)</span> 都成立。因此，只要当 <span class="math inline">\(m=1\)</span> 式，式 (9) 成立，就可以称随机序列 <span class="math inline">\(\{\xi_n,\ n=1,\ 2, \dots\}\)</span> 具有 <strong>马氏性</strong>，即 <span class="math inline">\(\{\xi_{n} , n = 1,\ 2, \dots\}\)</span> 是一个马尔可夫链。</p>
<ul>
<li><strong>定义 2</strong></li>
</ul>
<p>设 <span class="math inline">\(\{\xi_n,\ n = 1,\ 2,\dots \}\)</span> 是一个马尔科夫链，如果式 (9) 右边的条件概率与 <span class="math inline">\(n\)</span> 无关，即： <span class="math display">\[
P\{\xi_{n+m} = j | \xi_n = i \} = p_{ij}(m)
\]</span> 则称 <span class="math inline">\(\{\xi_n,\ n = 1,\ 2,\dots \}\)</span> 为时齐的马尔可夫链。称 <span class="math inline">\(p_{ij}(m)\)</span> 为系统由状态 <span class="math inline">\(i\)</span> 经过 <span class="math inline">\(m\)</span> 个时间间隔（或 <span class="math inline">\(m\)</span> 步）转移到状态 <span class="math inline">\(j\)</span> 的转移概率。式 (10) 称为时齐性，它的含义式系统由状态 <span class="math inline">\(i\)</span> 到 状态 <span class="math inline">\(j\)</span> 的转移概率 <strong>只依赖与时间间隔的长短</strong>，与起始时刻无关。本章介绍的马尔可夫链都是时齐的，因此省略 <code>时齐</code> 二字。</p>
<h2 id="转移概率矩阵及柯尔莫哥洛夫定理">4.2 转移概率矩阵及柯尔莫哥洛夫定理</h2>
<h3 id="转移概率矩阵">4.2.1 转移概率矩阵</h3>
<p>对于马尔科夫链 <span class="math inline">\(\{\xi_n,\ n = 1,\ 2,\dots \}\)</span> ，称以 <span class="math inline">\(m\)</span> 步转移概率 <span class="math inline">\(p_{ij}(m)\)</span> 为元素的矩阵 <span class="math inline">\(P (m) = p_{ij}(m)\)</span> 为马尔科夫链的 <strong>$ m$ 步转移概率矩阵</strong>。当 <span class="math inline">\(m = 1\)</span>时，记 <span class="math inline">\(P(1) = P\)</span> 称为马尔可夫链的 <strong>一步转移矩阵</strong>，或简称 <strong>转移矩阵</strong>。</p>
<p>转移矩阵具有如下性质：</p>
<ul>
<li>对一切 $i, j E, 0 p_{ij}(m)  $，</li>
<li>对一切 $i E, <em> p</em>{ij}(m) = 1 $，-</li>
<li>对一切 <span class="math inline">\(i,\ j \in E, p_{ij}(0) = \delta_{ij} = \left\{\begin{array}{k}1,\ (i = j) \\ 0,\ (i \neq j) \end{array}\right.\)</span></li>
</ul>
<p>当实际问题可以用马尔可夫链来描述时，首先要确定它的 <strong>状态空间及参数集合</strong>，然后确定它的 <strong>一步转移概率</strong>。该概率的确定，可以由问题的 <strong>内在规律</strong> 得到，也可以由过去的经验给出，还可以根据 <strong>预测数据</strong> 来估计。案例可见 4.4 Cases 的 Case 1。</p>
<h3 id="柯尔莫哥洛夫定理">4.2.2 柯尔莫哥洛夫定理</h3>
<ul>
<li>柯尔莫哥洛夫- 开普曼定理</li>
</ul>
<p>设 <span class="math inline">\(\{\xi_n,\ n = 1,\ 2,\dots \}\)</span> 是一个马尔可夫链，其状态空间 <span class="math inline">\(E = \{1,\ 2,\dots\}\)</span>，则对任意正整数 <span class="math inline">\(m,\ n\)</span>，有： <span class="math display">\[
p_{ij}(n+m) = \sum_{k \in E} p_{ik}(n)p_{kj}(m)
\]</span> 其中：<span class="math inline">\(i,\ j \in E\)</span>。</p>
<ul>
<li><strong>定理</strong></li>
</ul>
<p>设 <span class="math inline">\(P\)</span> 是一步马尔科夫链转移矩阵（ <span class="math inline">\(P\)</span> 的行向量是概率向量），<span class="math inline">\(P^{(0)}\)</span> 是初始分布行向量，则第 <span class="math inline">\(n\)</span> 步的 <strong>概率分布</strong> 为： <span class="math display">\[
P^{(n)} = P^{(0)} P^n
\]</span></p>
<h2 id="转移概率的渐近性质极限概率分布">4.3 转移概率的渐近性质—极限概率分布</h2>
<h3 id="introduction-3">4.3.1 Introduction</h3>
<ul>
<li>随着 <span class="math inline">\(n\)</span> 的增大，<span class="math inline">\(P^n\)</span> 是否会趋于某以固定矩阵？</li>
</ul>
<p>先考虑一个简单的例子：</p>
转移矩阵 $ P =
<span class="math display">\[\begin{bmatrix}
0.5 &amp; 0.5 \\
0.7 &amp; 0.3 \\
\end{bmatrix}\]</span>
<p>$，当 <span class="math inline">\(n \rightarrow + \infty\)</span>，有： <span class="math display">\[
P^n \rightarrow \begin{bmatrix} \frac{7}{12} &amp; \frac{5}{12}\\
\frac{7}{12} &amp; \frac{5}{12} \\
\end{bmatrix}
\]</span> 若取 <span class="math display">\[
\begin{align*}
u = \begin{bmatrix} \frac{7}{12} &amp; \frac{5}{12}\\
\frac{7}{12} &amp; \frac{5}{12} \\
\end{bmatrix}
\end{align*}
\]</span> 则 <span class="math inline">\(uP = u\)</span>，<span class="math inline">\(u^T\)</span> 为矩阵 <span class="math inline">\(P^T\)</span> 的对应于特征值为 <span class="math inline">\(\lambda = 1\)</span> 的特征（概率）向量，<span class="math inline">\(u\)</span> 也称为 <span class="math inline">\(P\)</span> 的不动点向量。</p>
<ul>
<li><p>哪些转移矩阵具有不动点向量？</p>
<p><strong>定义：</strong>马尔可夫链的转移矩阵 <span class="math inline">\(P\)</span> 是正则 <span class="math inline">\(\Leftrightarrow \ \exist\ k \in N^+\)</span>，使 <span class="math inline">\(P^k\)</span> 任一元素都为正</p>
<p><strong>定理：</strong>若 <span class="math inline">\(P\)</span> 是一个马尔科夫链的正则阵，则：</p>
<ul>
<li><span class="math inline">\(P\)</span> 有 <strong>唯一</strong> 的不动点向量 <span class="math inline">\(W,\ W\)</span> 的每个分量都为正；</li>
<li><span class="math inline">\(P\)</span> 的 <span class="math inline">\(n\)</span> 次幂 <span class="math inline">\(P^n\)</span>（ <span class="math inline">\(n\)</span> 为正整数）随 <span class="math inline">\(n\)</span> 的增加趋于矩阵 <span class="math inline">\(\overline{W},\ \overline{W}\)</span> 的每一行向量<strong>均等于不动点向量</strong> <span class="math inline">\(W\)</span>。</li>
</ul></li>
</ul>
<p>设时齐马尔科夫链的状态空间为 <span class="math inline">\(E\)</span>，如果对于所有 <span class="math inline">\(i,\ j \in E\)</span>，转移概率 <span class="math inline">\(p_{ij}(n)\)</span> 存在极限： <span class="math display">\[
\lim_{n\to \infty}p_{ij}(n) = \pi_j\quad (\text{不依赖于 }i)
\]</span> 或： <span class="math display">\[
P(n) = P^n \underset{(n\to \infty)}{\longrightarrow} \begin{bmatrix} \pi_1 &amp; \pi_2 &amp; \dots &amp; \pi_j &amp; \dots \\
\pi_1 &amp; \pi_2 &amp; \dots &amp; \pi_j &amp; \dots \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \ddots \\
\pi_1 &amp; \pi_2 &amp; \ddots &amp; \pi_j &amp; \dots \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \ddots \\
\end{bmatrix}
\]</span> 则称此链具有 <strong>遍历性</strong>。若 <span class="math inline">\(\sum_\limits j \pi_j = 1\)</span>，则同时称 <span class="math inline">\(\vec {\pi} = [\pi_1,\  \pi_2, \dots]\)</span> 为链的 <strong>极限分布</strong>。</p>
<ul>
<li><p>就有限链的遍历性给出一个充分条件：</p>
<p><strong>定理：</strong>设时齐马尔可夫链 <span class="math inline">\(\{\xi_n,\ n = 1,\ 2,\dots \}\)</span> 的状态空间为 <span class="math inline">\(E = \{a_1,\dots,\ a_N\},\ P = (p_{ij})\)</span> 是它的一步转移矩阵，如果存在正整数 <span class="math inline">\(m\)</span>，使对任意的 <span class="math inline">\(a_i,\ a_j \in E\)</span>，都有： <span class="math display">\[
p_{ij}(m) &gt; 0,\ i, j = 1, 2, \dots, N
\]</span> 则此链具有 <strong>遍历性</strong>；且有极限分布 <span class="math inline">\(\vec \pi = [\pi_i, \dots, \pi_N]\)</span>，他是方程组： <span class="math display">\[
\pi = \pi P\quad \mathrm{or\quad} \pi_j = \sum_{i=1}^N \pi_i p_{ij}, \ j = 1, \dots,\ N
\]</span> 的满足条件 <span class="math inline">\(\pi_j &gt; 0,\ \sum_\limits{j=1}^N \pi_j = 1\)</span> 的唯一解。</p></li>
</ul>
<h2 id="cases">4.4 Cases</h2>
<ul>
<li><strong>Case 1:</strong></li>
</ul>
<p>某计算机机房的一台计算机经常出故障，研究者每隔15 分钟观察一次计算 机的运行状态，收集了24 小时的数据（共作97 次观察）。用1 表示正常状态，用0 表示不正常状态，所得的数据序列如下：</p>
<p>1110010011111110011110111111001111111110001101101 111011011010111101110111101111110011011111100111</p>
<p><strong>解：</strong>设 <span class="math inline">\(X_n (n = 1,\dots,97)\)</span> 为第 <span class="math inline">\(n\)</span> 个时段的计算机状态，可以认为它是一个时齐马氏链，状态空间 <span class="math inline">\(E = \{0,\ 1\}\)</span>，编写如下 <span class="math inline">\(Matlab\)</span> 程序：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">a1=<span class="string">&#x27;1110010011111110011110111111001111111110001101101&#x27;</span>;</span><br><span class="line">a2=<span class="string">&#x27;111011011010111101110111101111110011011111100111&#x27;</span>;</span><br><span class="line">a=[a1 a2];</span><br><span class="line">f00=<span class="built_in">length</span>(findstr(<span class="string">&#x27;00&#x27;</span>,a))</span><br><span class="line">f01=<span class="built_in">length</span>(findstr(<span class="string">&#x27;01&#x27;</span>,a))</span><br><span class="line">f10=<span class="built_in">length</span>(findstr(<span class="string">&#x27;10&#x27;</span>,a))</span><br><span class="line">f11=<span class="built_in">length</span>(findstr(<span class="string">&#x27;11&#x27;</span>,a))</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p>求得 96 次的转移情况是： <span class="math display">\[
\left\{
\begin{array}{c}
0 \rightarrow 0,\ \ 8 \text{次}; \qquad\ 0 \rightarrow 1,\ 18 \text{次} \\
1 \rightarrow 0,\ 18 \text{次}; \qquad 1 \rightarrow 1,\ 52 \text{次}
\end{array}
\right.
\]</span> 因此，一步转移概率可用频率近似地表示为： <span class="math display">\[
\left\{
\begin{array}{c}
P_{00} = P\{X_{n+1} = 0 | X_n = 0 \} \approx \frac{8}{8 + 18} = \frac{4}{13} \\
P_{01} = P\{X_{n+1} = 1 | X_n = 0 \} \approx \frac{18}{8 + 18} = \frac{9}{13} \\
P_{10} = P\{X_{n+1} = 0 | X_n = 1 \} \approx \frac{18}{18 + 52} = \frac{9}{35} \\
P_{11} = P\{X_{n+1} = 1 | X_n = 1 \} \approx \frac{52}{18 + 52} = \frac{26}{35} 
\end{array}
\right.
\]</span></p>
<ul>
<li><strong>Case 2:</strong></li>
</ul>
<p>若顾客的购买是无记忆的，即已知现在顾客购买情况，未来顾客的购买情况不受过去购买历史的影响，而只与现在购买情况有关。现在市场上供应 <span class="math inline">\(A,\ B,\ C\)</span> 三个不同厂家生产的 50 克袋装味精，用 <span class="math inline">\(\xi_n = 1,\ \xi_n, \ \xi_n = 3\)</span> 分别表示”顾客第 <span class="math inline">\(n\)</span> 次购买 <span class="math inline">\(A,\ B,\ C\)</span> 厂的味精”。显然，<span class="math inline">\(\{\xi_n, n = 1,\ 2,\dots\}\)</span> 是一个马氏链。若已知第一次顾客购买三个厂味精的概率依次为 <span class="math inline">\(0.2,\ 0.4,\ 0.4\)</span>。又知道一般顾客购买的倾向由表2给出。求</p>
<p>1）顾客第四次购买各家味精的概率；</p>
<p>2）预测经过长期的多次购买滞后，顾客的购买倾向如何？</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">C</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">A</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr class="even">
<td style="text-align: center;">B</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.4</td>
</tr>
<tr class="odd">
<td style="text-align: center;">C</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">0.2</td>
</tr>
</tbody>
</table>
<p>解：</p>
<p>1）第一次购买的概率分布为：<span class="math inline">\(P^{(1)} = [0.2,\ 0.4,\ 0.4]\)</span>，一步状态转移矩阵为：</p>
<p><span class="math inline">\(P = \begin{bmatrix}0.8 &amp; 0.1 &amp; 0.1 \\ 0.5 &amp; 0.1 &amp; 0.4 \\ 0.5 &amp; 0.3 &amp; 0.2\\\end{bmatrix}\)</span>，则顾客第四次购买各家味精的概率为： <span class="math display">\[
P^{(4)} = P^{(1)} P^3 = [0.7004, 0.136, 0.1636]
\]</span> 2）这个马尔可夫链的转移矩阵 <span class="math inline">\(P\)</span> 满足 <span class="math inline">\(p_{ij}(m) &gt; 0,\ i,\ j = 1, 2,\dots, N\)</span>，可以求出其极限概率分布。为此，解下列方程组： <span class="math display">\[
\left\{
\begin{array}{l}
p_1 = 0.2p_1 + 0.8p_2 + 0.1p_3,\\
p_2 = 0.8p_1 + 0.3p_3, \\
p_3 = 0.2p_2 + 0.6p_3, \\
p_1 + p_2 + p_3 = 1,
\end{array}
\right.
\]</span> 求得 <span class="math inline">\(p_1 = \frac{5}{7},\ p_2 = \frac{11}{84},\ p_3 = \frac{13}{84}\)</span>。这说明，无论第一次顾客购买的情况如何，经过长期多次购买后，<span class="math inline">\(A\)</span> 厂产的味精占有市场的 <span class="math inline">\(\frac{5}{7}\)</span>，<span class="math inline">\(B,\ C\)</span> 两厂的产品分别占有市场的 <span class="math inline">\(\frac{11}{84}\)</span> 和 <span class="math inline">\(\frac{13}{84}\)</span>。</p>
<p>Relative codes:</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">format <span class="built_in">rat</span></span><br><span class="line">p=[<span class="number">0.8</span> <span class="number">0.1</span> <span class="number">0.1</span>;<span class="number">0.5</span> <span class="number">0.1</span> <span class="number">0.4</span>;<span class="number">0.5</span> <span class="number">0.3</span> <span class="number">0.2</span>];</span><br><span class="line">a=[p&#x27;-<span class="built_in">eye</span>(<span class="number">3</span>);<span class="built_in">ones</span>(<span class="number">1</span>,<span class="number">3</span>)];</span><br><span class="line">b=[<span class="built_in">zeros</span>(<span class="number">3</span>,<span class="number">1</span>);<span class="number">1</span>];</span><br><span class="line">p_limit=a\b</span><br></pre></td></tr></table></figure>
<p>或者利用求转移矩阵 <span class="math inline">\(P\)</span> 的转置矩阵 <span class="math inline">\(P^T\)</span> 的特征值 1 对应的特征(概率)向量，求得极 限概率。编写程序如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clc,clear</span><br><span class="line">p=[<span class="number">0.8</span> <span class="number">0.1</span> <span class="number">0.1</span>;<span class="number">0.5</span> <span class="number">0.1</span> <span class="number">0.4</span>;<span class="number">0.5</span> <span class="number">0.3</span> <span class="number">0.2</span>];</span><br><span class="line">p=sym(p&#x27;);</span><br><span class="line">[x,y]=eig(p)</span><br><span class="line">y=<span class="built_in">diag</span>(y);y=double(y);</span><br><span class="line">ind=<span class="built_in">find</span>(y==<span class="built_in">max</span>(y));</span><br><span class="line">p=x(:,ind)/sum(x(:,ind))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Class Notes</category>
        <category>Methods</category>
      </categories>
      <tags>
        <tag>Prediction</tag>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas</title>
    <url>/2020/11/27/Pandas/</url>
    <content><![CDATA[<h1 id="series">1 Series</h1>
<h2 id="preparation">1.1 Preparation</h2>
<ul>
<li>Import modules <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="different-data-type">1.2 Different data type</h2>
<ul>
<li><p>Time type <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = pd.Timestamp(<span class="string">&#x27;20180901&#x27;</span>) <span class="comment"># time type</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t</span><br><span class="line">Timestamp(<span class="string">&#x27;2018-09-01 00:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>Created by means of <code>data_range</code>. <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dates = pd.date_range(<span class="string">&#x27;20200101&#x27;</span>, periods = <span class="number">6</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dates</span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2020-01-01&#x27;</span>, <span class="string">&#x27;2020-01-02&#x27;</span>, <span class="string">&#x27;2020-01-03&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;2020-01-04&#x27;</span>,<span class="string">&#x27;2020-01-05&#x27;</span>, <span class="string">&#x27;2020-01-06&#x27;</span>],</span><br><span class="line">           dtype=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure> <a id="more"></a></p></li>
</ul>
<h2 id="create-dataframe">1.3 Create DataFrame</h2>
<ul>
<li><p>By dict <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create a dataframe based on dict</span></span><br><span class="line">df3 = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>:<span class="number">1.</span>, <span class="string">&#x27;B&#x27;</span>:pd.Timestamp(<span class="string">&#x27;20160901&#x27;</span>),</span><br><span class="line">      <span class="string">&#x27;C&#x27;</span>:pd.Series(<span class="number">1</span>,index=<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">4</span>)),dtype=<span class="string">&#x27;float32&#x27;</span>),</span><br><span class="line">      <span class="string">&#x27;D&#x27;</span>:np.array([<span class="number">3</span>]*<span class="number">4</span>, dtype =<span class="string">&#x27;int32&#x27;</span>),</span><br><span class="line">      <span class="string">&#x27;E&#x27;</span>:pd.Categorical([<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>]),</span><br><span class="line">      <span class="string">&#x27;F&#x27;</span>:<span class="string">&#x27;foo&#x27;</span>&#125;)</span><br><span class="line">print(df3)</span><br></pre></td></tr></table></figure> Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    A       B         C    D     E      F</span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span>  <span class="number">2016</span>-09-01   <span class="number">1.0</span>   <span class="number">3</span>    test   foo</span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span>  <span class="number">2016</span>-09-01   <span class="number">1.0</span>   <span class="number">3</span>   train   foo</span><br><span class="line"><span class="number">2</span>  <span class="number">1.0</span>  <span class="number">2016</span>-09-01   <span class="number">1.0</span>   <span class="number">3</span>    test   foo</span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span>  <span class="number">2016</span>-09-01   <span class="number">1.0</span>   <span class="number">3</span>   train   foo</span><br></pre></td></tr></table></figure></p></li>
<li><p>By Series <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># np.nan means NaN</span></span><br><span class="line">s = pd.Series([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, np.nan, <span class="number">44</span>, <span class="number">1</span>])</span><br><span class="line">print(s)</span><br></pre></td></tr></table></figure> Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">0</span>     <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>     <span class="number">3.0</span></span><br><span class="line"><span class="number">2</span>     <span class="number">5.0</span></span><br><span class="line"><span class="number">3</span>     NaN</span><br><span class="line"><span class="number">4</span>    <span class="number">44.0</span></span><br><span class="line"><span class="number">5</span>     <span class="number">1.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p></li>
<li><p>By np.array <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create a dataframe based on imported array</span></span><br><span class="line">df0 = pd.DataFrame(np.random.randn(<span class="number">6</span>,<span class="number">4</span>), index = dates, columns = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line">df1 = pd.DataFrame(np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">print(df1, df3, sep = <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="basic-information">1.4 Basic information</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df3 = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>:<span class="number">1.</span>, <span class="string">&#x27;B&#x27;</span>:pd.Timestamp(<span class="string">&#x27;20160901&#x27;</span>),</span><br><span class="line">      <span class="string">&#x27;C&#x27;</span>:pd.Series(<span class="number">1</span>,index=<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">4</span>)),dtype=<span class="string">&#x27;float32&#x27;</span>),</span><br><span class="line">      <span class="string">&#x27;D&#x27;</span>:np.array([<span class="number">3</span>]*<span class="number">4</span>, dtype =<span class="string">&#x27;int32&#x27;</span>),</span><br><span class="line">      <span class="string">&#x27;E&#x27;</span>:pd.Categorical([<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>]),</span><br><span class="line">      <span class="string">&#x27;F&#x27;</span>:<span class="string">&#x27;foo&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Dtype of each dimensional <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df3.dtypes <span class="comment"># dimensional type</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>Row and column index <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df3.index <span class="comment"># row index name</span></span><br><span class="line">df3.columns <span class="comment"># column name</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>Statistical description</p>
<p>Describe numerical characteristics, including count, mean, std, min etc. <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df3.describe() <span class="comment"># describe numerical characteristics, including count, mean, std, min etc.</span></span><br></pre></td></tr></table></figure> Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">        A    C    D</span><br><span class="line">count  <span class="number">4.0</span>  <span class="number">4.0</span>  <span class="number">4.0</span></span><br><span class="line">mean   <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">3.0</span></span><br><span class="line">std    <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="built_in">min</span>    <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">3.0</span></span><br><span class="line"><span class="number">25</span>%    <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">3.0</span></span><br><span class="line"><span class="number">50</span>%    <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">3.0</span></span><br><span class="line"><span class="number">75</span>%    <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">3.0</span></span><br><span class="line"><span class="built_in">max</span>    <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">3.0</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>information <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df3.info()</span><br></pre></td></tr></table></figure> Result: <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;</span><br><span class="line">Int64Index: 4 entries, 0 to 3</span><br><span class="line">Data columns (total 6 columns):</span><br><span class="line"> #   Column  Non-Null Count  Dtype         </span><br><span class="line">---  ------  --------------  -----         </span><br><span class="line"> 0   A       4 non-null      float64       </span><br><span class="line"> 1   B       4 non-null      datetime64[ns]</span><br><span class="line"> 2   C       4 non-null      float32       </span><br><span class="line"> 3   D       4 non-null      int32         </span><br><span class="line"> 4   E       4 non-null      category      </span><br><span class="line"> 5   F       4 non-null      object        </span><br><span class="line">dtypes: category(1), datetime64[ns](1), float32(1), float64(1), int32(1), object(1)</span><br><span class="line">memory usage: 288.0+ bytes</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="data-type">1.5 Data type</h2>
<ul>
<li><p>Specifies the type when creation <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">dfx = pd.DataFrame([[<span class="string">&#x27;11&#x27;</span>, <span class="number">1.2</span>, <span class="number">3</span>], [<span class="string">&#x27;22&#x27;</span>, <span class="number">4.8</span>, <span class="number">5</span>],],</span><br><span class="line">    columns = <span class="built_in">list</span>(<span class="string">&#x27;abc&#x27;</span>), dtype = np.<span class="built_in">object</span>)</span><br><span class="line">dfx.dtypes</span><br></pre></td></tr></table></figure> Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a       <span class="built_in">object</span></span><br><span class="line">b       <span class="built_in">object</span></span><br><span class="line">c       <span class="built_in">object</span></span><br><span class="line">dtype:  <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>Coercion <code>df.astype()</code> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dfx[[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]] = dfx[[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]].astype(<span class="string">&#x27;float&#x27;</span>))</span><br><span class="line">dfx.dtypes</span><br></pre></td></tr></table></figure> Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a       float64</span><br><span class="line">b       float64</span><br><span class="line">c       float64</span><br><span class="line">dtype:  <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>Turn into numeric <code>pd.to_numeric()</code> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dfy = pd.DataFrame([[<span class="string">&#x27;11&#x27;</span>, <span class="number">1.2</span>, <span class="number">3</span>], [<span class="string">&#x27;22&#x27;</span>, <span class="number">4.8</span>, <span class="string">&#x27;?&#x27;</span>], ],</span><br><span class="line">        columns = <span class="built_in">list</span>(<span class="string">&#x27;abc&#x27;</span>), dtype = np.<span class="built_in">object</span>)</span><br><span class="line">dfy[<span class="string">&#x27;a&#x27;</span>] = pd.to_numeric(dfy[<span class="string">&#x27;a&#x27;</span>])</span><br><span class="line">print(dfy.dtypes)</span><br></pre></td></tr></table></figure></p>
<p>Use <code>pd.apply</code> to apply it to the entire dataframe. <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dfy1 = dfy.apply(pd.to_numeric, errors = <span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"> <span class="comment"># Igonre and don&#x27;t change this column when meet errors,</span></span><br><span class="line">dfy2 = dfy.apply(pd.to_numeric, errors = <span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"> <span class="comment"># Transfer the value into NaN when meet errors.</span></span><br><span class="line">print(dfy.dtypes)</span><br><span class="line">print(<span class="string">&#x27;-------------------------&#x27;</span>)</span><br><span class="line">print(dfy2)</span><br></pre></td></tr></table></figure> Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a       int64</span><br><span class="line">b       float64</span><br><span class="line">c       float64</span><br><span class="line">dtype:  <span class="built_in">object</span></span><br><span class="line">-------------------------</span><br><span class="line">    a   b    c</span><br><span class="line"><span class="number">0</span>  <span class="number">11</span>  <span class="number">1.2</span>  <span class="number">3.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">22</span>  <span class="number">4.8</span>  NaN</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h1 id="choose-data">2 Choose data</h1>
<h2 id="basic-operation">2.1 Basic operation</h2>
<ul>
<li><p>Import modules and generate datas <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>:<span class="number">1.</span>, <span class="string">&#x27;B&#x27;</span>:pd.Timestamp(<span class="string">&#x27;20160901&#x27;</span>),</span><br><span class="line">       <span class="string">&#x27;C&#x27;</span>:pd.Series(<span class="number">1</span>,index=<span class="built_in">list</span>(arange(<span class="number">4</span>)),dtype=<span class="string">&#x27;float32&#x27;</span>),</span><br><span class="line">       <span class="string">&#x27;D&#x27;</span>:np.array([<span class="number">3</span>]*<span class="number">4</span>, dtype =<span class="string">&#x27;int32&#x27;</span>),</span><br><span class="line">       <span class="string">&#x27;E&#x27;</span>:pd.Categorical([<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>]),</span><br><span class="line">       <span class="string">&#x27;F&#x27;</span>:<span class="string">&#x27;foo&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure></p></li>
<li><p>Row operation <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df2 = df[<span class="number">0</span>:<span class="number">3</span>] <span class="comment"># row operation, 0-3 row</span></span><br><span class="line">df2_1 = df[<span class="number">0</span>:<span class="number">1</span>] <span class="comment"># single row</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>Column operation <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df1 = df.A <span class="comment"># same sa df.[&#x27;A&#x27;]</span></span><br><span class="line">df2_2 = df[<span class="string">&#x27;A&#x27;</span>] <span class="comment"># single column</span></span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="index-methods">2.2 Index methods</h2>
<ul>
<li><p><code>loc</code></p>
<p>Select datas by label based index. <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># select by label based index: loc</span></span><br><span class="line">df3 = df.loc[<span class="number">1</span>] <span class="comment"># the second row</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><code>iloc</code></p>
<p>Select datas by postitional index. <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># selct by postitional index: iloc</span></span><br><span class="line">df4 = df.iloc[:,<span class="number">1</span>:<span class="number">3</span>] <span class="comment"># 1-3 column</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><code>ix</code></p>
<p>Select datas by mixed selection. <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mixed selection: ix</span></span><br><span class="line">df5 = df.ix[:<span class="number">2</span>,[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;D&#x27;</span>]] <span class="comment"># deprecated</span></span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="conditional-operation">2.3 Conditional operation</h2>
<ul>
<li>Logic expression <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df6 = df[df[<span class="string">&#x27;A&#x27;</span>] &gt; <span class="number">4</span>]</span><br></pre></td></tr></table></figure> <code>df['A'] &gt; 4</code> return the row index which number is bigger than 4, let me name this index as <code>iRow</code>, then <code>df[iRow]</code> return the row date that meets above filter condition.</li>
</ul>
<h2 id="functional-methods">2.4 Functional methods</h2>
<ul>
<li><code>tail</code> <code>df.tail(n)</code> returns last <code>n</code> rows from the DataFrame object based on position. It is useful for quickly verifying data. For negative values of <code>n</code>, it returns all rows except the first <code>n</code> rows, equivalent to <code>df[n:]</code>. <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.tail() <span class="comment"># Default n is 5</span></span><br><span class="line">df.tail(<span class="number">3</span>) <span class="comment"># Return last 3 rows</span></span><br><span class="line">df.tail(-<span class="number">5</span>) <span class="comment"># Return all rows except the first 5 row.</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="dataframe-operation">3 DataFrame operation</h1>
<ul>
<li>Preparation <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>:<span class="number">1.</span>, <span class="string">&#x27;B&#x27;</span>:pd.Timestamp(<span class="string">&#x27;20160901&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;C&#x27;</span>:pd.Series(<span class="number">1</span>,index=<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">4</span>)),dtype=<span class="string">&#x27;float32&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;D&#x27;</span>:np.array([<span class="number">3</span>]*<span class="number">4</span>, dtype =<span class="string">&#x27;int32&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;E&#x27;</span>:pd.Categorical([<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>]),</span><br><span class="line">    <span class="string">&#x27;F&#x27;</span>:<span class="string">&#x27;foo&#x27;</span>&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="value-operation">3.1 Value operation</h2>
<ul>
<li><p>Set value</p>
<p>Pay attention to the difference. <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.iloc[<span class="number">2</span>, <span class="number">2</span>] = <span class="number">111</span></span><br><span class="line">df.loc[<span class="number">0</span>,<span class="string">&#x27;B&#x27;</span>] = pd.Timestamp(<span class="string">&#x27;20180901&#x27;</span>)</span><br><span class="line"><span class="comment"># Note: below command will create a new column named (0, &#x27;B&#x27;) which values are given</span></span><br><span class="line">df[<span class="number">0</span>,<span class="string">&#x27;B&#x27;</span>] = pd.Timestamp(<span class="string">&#x27;20180901&#x27;</span>)</span><br></pre></td></tr></table></figure></p></li>
<li><p>Change value</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.iloc[<span class="number">2</span>, <span class="number">2</span>] = <span class="number">111</span></span><br><span class="line">df.loc[<span class="number">0</span>,<span class="string">&#x27;C&#x27;</span>] = np.nan</span><br></pre></td></tr></table></figure></li>
<li><p>Fillna <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Fill NaN, can&#x27;t do it with df.fillna(0)</span></span><br><span class="line">df[<span class="string">&#x27;C&#x27;</span>] = df[<span class="string">&#x27;C&#x27;</span>].fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># maybe below command also can work?</span></span><br><span class="line">df_1 = df.fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p></li>
<li><p>Dropna <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Drop NaN</span></span><br><span class="line">df.dropna(axis =<span class="number">0</span>, how = <span class="string">&#x27;any&#x27;</span>)</span><br><span class="line"><span class="comment"># how = [&#x27;any, &#x27;all&#x27;], default is any</span></span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="advance-operation">3.2 Advance operation</h2>
<ul>
<li><p>isnull <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.isnull() <span class="comment"># find which position is null, return a dataframe same size as df</span></span><br><span class="line">np.<span class="built_in">any</span>(df.isnull()) == <span class="literal">True</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>Transpose <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.T</span><br><span class="line">df.transpose() <span class="comment"># transpose array</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>Sort <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.sort_index(axis = <span class="number">1</span>, ascending = <span class="literal">False</span>)</span><br><span class="line"><span class="comment"># horizontal descending sort</span></span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="delete-values">3.3 Delete values</h2>
<p>Deleting one columns from DataFrame. Preparation: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>:<span class="number">1.</span>, <span class="string">&#x27;B&#x27;</span>:pd.Timestamp(<span class="string">&#x27;20160901&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;C&#x27;</span>:pd.Series(<span class="number">1</span>,index=<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">4</span>)),dtype=<span class="string">&#x27;float32&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;D&#x27;</span>:np.array([<span class="number">3</span>]*<span class="number">4</span>, dtype =<span class="string">&#x27;int32&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;E&#x27;</span>:pd.Categorical([<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>]),</span><br><span class="line">    <span class="string">&#x27;F&#x27;</span>:<span class="string">&#x27;foo&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure> Representing: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">     A          B    C  D      E    F</span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span> <span class="number">2016</span>-09-01  <span class="number">1.0</span>  <span class="number">3</span>   test  foo</span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span> <span class="number">2016</span>-09-01  <span class="number">1.0</span>  <span class="number">3</span>  train  foo</span><br><span class="line"><span class="number">2</span>  <span class="number">1.0</span> <span class="number">2016</span>-09-01  <span class="number">1.0</span>  <span class="number">3</span>   test  foo</span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span> <span class="number">2016</span>-09-01  <span class="number">1.0</span>  <span class="number">3</span>  train  foo</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p><code>del</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">del</span> df[<span class="string">&#x27;A&#x27;</span>] <span class="comment"># Delete A column from A, and A will change</span></span><br></pre></td></tr></table></figure>
<p>Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">           B    C  D      E    F</span><br><span class="line"><span class="number">0</span> <span class="number">2016</span>-09-01  <span class="number">1.0</span>  <span class="number">3</span>   test  foo</span><br><span class="line"><span class="number">1</span> <span class="number">2016</span>-09-01  <span class="number">1.0</span>  <span class="number">3</span>  train  foo</span><br><span class="line"><span class="number">2</span> <span class="number">2016</span>-09-01  <span class="number">1.0</span>  <span class="number">3</span>   test  foo</span><br><span class="line"><span class="number">3</span> <span class="number">2016</span>-09-01  <span class="number">1.0</span>  <span class="number">3</span>  train  foo</span><br></pre></td></tr></table></figure></p></li>
<li><p><code>drop</code></p></li>
</ul>
<p>Adopting <code>drop</code> function, there are three equivalent expression.</p>
<p>直接输入 <code>df.drop('column', 1)</code>，不会改变内存，再次输入 <code>df</code> 时，还是显示原数据。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>:<span class="number">1.</span>, <span class="string">&#x27;B&#x27;</span>:pd.Timestamp(<span class="string">&#x27;20160901&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;C&#x27;</span>:pd.Series(<span class="number">1</span>,index=<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">4</span>)),dtype=<span class="string">&#x27;float32&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;D&#x27;</span>:np.array([<span class="number">3</span>]*<span class="number">4</span>, dtype =<span class="string">&#x27;int32&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;E&#x27;</span>:pd.Categorical([<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>]),</span><br><span class="line">    <span class="string">&#x27;F&#x27;</span>:<span class="string">&#x27;foo&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">df1 = df.drop(<span class="string">&#x27;A&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line">df2 = df.drop(<span class="string">&#x27;column_name&#x27;</span>, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure> 注：<code>aixs = 1</code> 表示该命令的操作聚焦于列这一维度。<code>inplace</code> 表示是否改变内存。默认为 <code>False</code>。</p>
<h1 id="merge-dataframes">4 Merge dataframes</h1>
<ul>
<li>Preparation <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 array multiply o is o</span></span><br><span class="line">df1 = pd.DataFrame(np.ones((<span class="number">3</span>, <span class="number">4</span>)) * <span class="number">0</span>, columns = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line">df2 = pd.DataFrame(np.ones((<span class="number">3</span>, <span class="number">4</span>)) * <span class="number">1</span>, columns = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line">df3 = pd.DataFrame(np.ones((<span class="number">3</span>, <span class="number">4</span>)) * <span class="number">2</span>, columns = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="concatenation">4.1 Concatenation</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = pd.concat([df1, df2, df3], axis = <span class="number">0</span>, ignore_index = <span class="literal">True</span>) <span class="comment"># default don&#x27;t ignore index, the difference seen in below pic</span></span><br></pre></td></tr></table></figure>
<p><img src="https://z3.ax1x.com/2020/11/25/DamaCR.png" /></p>
<center>
fig. 1 difference of ignoring index
</center>
<ul>
<li><p><strong>join = ['inner', 'outer']</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">df1 = pd.DataFrame(np.ones((<span class="number">3</span>, <span class="number">4</span>)) * <span class="number">0</span>, columns = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>], index = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">df2 = pd.DataFrame(np.ones((<span class="number">3</span>, <span class="number">4</span>)) * <span class="number">1</span>, columns = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>], index = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># default join is outer, fill the null space with NaN</span></span><br><span class="line">df3 = pd.concat([df1, df2], axis = <span class="number">0</span>, join = <span class="string">&#x27;outer&#x27;</span>, sort=<span class="literal">False</span>, ignore_index = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># inner will take the intersection index of two arrays</span></span><br><span class="line">df4 = pd.concat([df1, df2], axis = <span class="number">0</span>, join = <span class="string">&#x27;inner&#x27;</span>, sort=<span class="literal">False</span>, ignore_index = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 df2 合并到 df1，并基于 index 去掉 df2 中有而 df1 没有的数据， 并填充 NaN</span></span><br><span class="line">df5 = pd.concat([df1, df2], axis = <span class="number">1</span>, join_axes = [df1.index])</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="append">4.2 append</h2>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">df1 &#x3D; pd.DataFrame(np.ones((3, 4)) * 0, columns &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])</span><br><span class="line">df2 &#x3D; pd.DataFrame(np.ones((3, 4)) * 1, columns &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])</span><br><span class="line">df3 &#x3D; pd.DataFrame(np.ones((3, 4)) * 1, columns &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])</span><br><span class="line"></span><br><span class="line">res &#x3D; df1.append([df2, df3], ignore_index &#x3D; True)</span><br><span class="line"></span><br><span class="line"># add a row series into a df</span><br><span class="line">s1 &#x3D; pd.Series([1, 2, 3, 4], index &#x3D; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])</span><br><span class="line">res1 &#x3D; df1.append(s1, ignore_index &#x3D; True)</span><br></pre></td></tr></table></figure></p>
<h2 id="merge">4.3 merge</h2>
<ul>
<li><p>merged by single key</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">left = pd.DataFrame(&#123;<span class="string">&#x27;key&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K2&#x27;</span>, <span class="string">&#x27;K3&#x27;</span>],<span class="string">&#x27;A&#x27;</span>: [<span class="string">&#x27;A0&#x27;</span>, <span class="string">&#x27;A1&#x27;</span>, <span class="string">&#x27;A2&#x27;</span>, <span class="string">&#x27;A3&#x27;</span>],<span class="string">&#x27;B&#x27;</span>: [<span class="string">&#x27;B0&#x27;</span>, <span class="string">&#x27;B1&#x27;</span>, <span class="string">&#x27;B2&#x27;</span>, <span class="string">&#x27;B3&#x27;</span>]&#125;)</span><br><span class="line">right = pd.DataFrame(&#123;<span class="string">&#x27;key&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K2&#x27;</span>, <span class="string">&#x27;K3&#x27;</span>],<span class="string">&#x27;C&#x27;</span>: [<span class="string">&#x27;C0&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;C2&#x27;</span>, <span class="string">&#x27;C3&#x27;</span>],<span class="string">&#x27;D&#x27;</span>: [<span class="string">&#x27;D0&#x27;</span>, <span class="string">&#x27;D1&#x27;</span>, <span class="string">&#x27;D2&#x27;</span>, <span class="string">&#x27;D3&#x27;</span>]&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># merge two dfs based on the same key value</span></span><br><span class="line">res = pd.merge(left, right, on = <span class="string">&#x27;key&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>merged by multiple keys</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">left = pd.DataFrame(&#123;<span class="string">&#x27;key1&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K2&#x27;</span>],<span class="string">&#x27;key2&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>],<span class="string">&#x27;A&#x27;</span>: [<span class="string">&#x27;A0&#x27;</span>, <span class="string">&#x27;A1&#x27;</span>, 		<span class="string">&#x27;A2&#x27;</span>, <span class="string">&#x27;A3&#x27;</span>],<span class="string">&#x27;B&#x27;</span>: [<span class="string">&#x27;B0&#x27;</span>, <span class="string">&#x27;B1&#x27;</span>, <span class="string">&#x27;B2&#x27;</span>, <span class="string">&#x27;B3&#x27;</span>]&#125;)</span><br><span class="line">right = pd.DataFrame(&#123;<span class="string">&#x27;key1&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K2&#x27;</span>],<span class="string">&#x27;key2&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K0&#x27;</span>],<span class="string">&#x27;C&#x27;</span>: [<span class="string">&#x27;C0&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, 		<span class="string">&#x27;C2&#x27;</span>, <span class="string">&#x27;C3&#x27;</span>],<span class="string">&#x27;D&#x27;</span>: [<span class="string">&#x27;D0&#x27;</span>, <span class="string">&#x27;D1&#x27;</span>, <span class="string">&#x27;D2&#x27;</span>, <span class="string">&#x27;D3&#x27;</span>]&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># merge two dfs based the same key value, default how = inner</span></span><br><span class="line">res1 = pd.merge(left, right, on = [<span class="string">&#x27;key1&#x27;</span>,<span class="string">&#x27;key2&#x27;</span>])</span><br><span class="line">res2 = pd.merge(left, right, on = [<span class="string">&#x27;key1&#x27;</span>,<span class="string">&#x27;key2&#x27;</span>], how = <span class="string">&#x27;inner&#x27;</span>)</span><br><span class="line">res2 = pd.merge(left, right, on = [<span class="string">&#x27;key1&#x27;</span>,<span class="string">&#x27;key2&#x27;</span>], indicator = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><code>how = ['inner, 'outer','left','right']</code>, if <code>how = 'right'</code>, this operation will fill left void space with NaN when left haven't same key value with right, then merge into right.</p>
<p>default <code>indicator</code> is <code>False</code>, this parameter will create a new column named _merge(indicator = 'indicator_column', then the new column's name is indicator_column), which show if both arrays have a meanful value.</p></li>
<li><p>merged by index</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">left = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>: [<span class="string">&#x27;A0&#x27;</span>, <span class="string">&#x27;A1&#x27;</span>, <span class="string">&#x27;A2&#x27;</span>, <span class="string">&#x27;A3&#x27;</span>],<span class="string">&#x27;B&#x27;</span>: [<span class="string">&#x27;B0&#x27;</span>, <span class="string">&#x27;B1&#x27;</span>, <span class="string">&#x27;B2&#x27;</span>, <span class="string">&#x27;B3&#x27;</span>]&#125;, index = [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K2&#x27;</span>,<span class="string">&#x27;K4&#x27;</span>])</span><br><span class="line">right = pd.DataFrame(&#123;<span class="string">&#x27;C&#x27;</span>: [<span class="string">&#x27;C0&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;C2&#x27;</span>, <span class="string">&#x27;C3&#x27;</span>],<span class="string">&#x27;D&#x27;</span>: [<span class="string">&#x27;D0&#x27;</span>, <span class="string">&#x27;D1&#x27;</span>, <span class="string">&#x27;D2&#x27;</span>, <span class="string">&#x27;D3&#x27;</span>]&#125;, index = [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K3&#x27;</span>,<span class="string">&#x27;K5&#x27;</span>])</span><br><span class="line">print(left, right, sep = <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># left_index and right_index</span></span><br><span class="line">res1 = pd.merge(left, right, left_index = <span class="literal">True</span>, right_index = <span class="literal">True</span>, how = <span class="string">&#x27;inner&#x27;</span>) <span class="comment"># based on left_index = right_index</span></span><br><span class="line">res2 = pd.merge(left, right, left_index = <span class="literal">True</span>, right_index = <span class="literal">True</span>, how = <span class="string">&#x27;outer&#x27;</span>) <span class="comment"># fill the blank with NaN</span></span><br></pre></td></tr></table></figure></li>
<li><p>suffixes para</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">boys = pd.DataFrame(&#123;<span class="string">&#x27;K&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K2&#x27;</span>,<span class="string">&#x27;K4&#x27;</span>],<span class="string">&#x27;age&#x27;</span>: [<span class="number">11</span>, <span class="number">23</span>, <span class="number">32</span>, <span class="number">12</span>]&#125;)</span><br><span class="line">girls = pd.DataFrame(&#123;<span class="string">&#x27;K&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K2&#x27;</span>,<span class="string">&#x27;K4&#x27;</span>],<span class="string">&#x27;age&#x27;</span>: [<span class="number">14</span>, <span class="number">43</span>, <span class="number">12</span>, <span class="number">22</span>]&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># suffixex means the named methods of same positional column</span></span><br><span class="line">res = pd.merge(boys, girls, on = <span class="string">&#x27;K&#x27;</span>, suffixes = [<span class="string">&#x27;_boys&#x27;</span>, <span class="string">&#x27;_girls&#x27;</span>], how = <span class="string">&#x27;inner&#x27;</span>)</span><br><span class="line">print(res) <span class="comment">#  age_boys  age_girls</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="read-and-save-file">5 Read and save file</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;xx.csv&#x27;</span>) <span class="comment"># read</span></span><br><span class="line">data.to_csv(<span class="string">&#x27;xxx.csv&#x27;</span>) <span class="comment"># save file</span></span><br></pre></td></tr></table></figure>
<h1 id="matplotlib">6 matplotlib</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">data1 = pd.Series(np.random.randn(<span class="number">1000</span>), index = np.arange(<span class="number">1000</span>))</span><br><span class="line">data2 = pd.DataFrame(np.random.randn(<span class="number">1000</span>, <span class="number">4</span>), index = np.arange(<span class="number">1000</span>), columns = <span class="built_in">list</span>(<span class="string">&#x27;ABCD&#x27;</span>))</span><br><span class="line"><span class="comment"># print(data1, data2, sep = &#x27;\n&#x27;)</span></span><br><span class="line">data1 = data1.cumsum()</span><br><span class="line">data2 = data2.cumsum()</span><br><span class="line"><span class="comment"># print(data)</span></span><br><span class="line">data1.plot()</span><br><span class="line">data2.plot()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<ul>
<li><p>plot methods</p>
<p>bar, hist, box, kde, area, scatter, hexbin, pie</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">data = pd.DataFrame(np.random.randn(<span class="number">1000</span>, <span class="number">4</span>), index = np.arange(<span class="number">1000</span>), columns = <span class="built_in">list</span>(<span class="string">&#x27;ABCD&#x27;</span>))</span><br><span class="line"></span><br><span class="line">data = data.cumsum()</span><br><span class="line"></span><br><span class="line">ax = data.plot.scatter(x = <span class="string">&#x27;A&#x27;</span>, y = <span class="string">&#x27;B&#x27;</span>,color = <span class="string">&#x27;DarkBlue&#x27;</span>, label = <span class="string">&#x27;Class1&#x27;</span>)</span><br><span class="line">data.plot.scatter(x = <span class="string">&#x27;A&#x27;</span>, y = <span class="string">&#x27;C&#x27;</span>,color = <span class="string">&#x27;DarkGreen&#x27;</span>,label = <span class="string">&#x27;Class2&#x27;</span>,ax = ax)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://z3.ax1x.com/2020/11/25/Damd81.png" /></p>
<center>
<p>fig. 2 scatter figure</p>
</center></li>
</ul>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Python module</category>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Data analysis</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Figuration</title>
    <url>/2020/11/23/Python-Figuration/</url>
    <content><![CDATA[<h1 id="show-channel">1 Show channel</h1>
<p><code>conda config --show</code>显示所有的 conda 的config 信息，<code>conda config --show channels</code>显示所有 channel 信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>conda config --show channels</span><br><span class="line">channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/win-<span class="number">64</span>/</span><br><span class="line">  - defaults</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p><code>pip</code> ：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip config <span class="built_in">list</span></span><br></pre></td></tr></table></figure>
<h1 id="delete-channel">2 Delete channel</h1>
<p>Using <code>conda config --remove channels</code> to delete channels from config</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br></pre></td></tr></table></figure>
<h1 id="add-channel">3 Add channel</h1>
<h2 id="conda-add-channel">3.1 Conda add channel</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 从 channel 中安装包时显示channel 的url，这样就可以知道包的安装来源</span></span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装确认中，不默认yes，而是由我来决定</span></span><br><span class="line">conda config --<span class="built_in">set</span> always_yes false</span><br></pre></td></tr></table></figure>
<h2 id="pip">3.2 pip</h2>
<h3 id="temporary-configuration">3.2.1 Temporary configuration</h3>
<p>可以利用 <code>pip</code> 从镜像源安装第三方库，只需安装后加入 <code>-i source</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Install pandas</span></span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pandas</span><br><span class="line">    </span><br><span class="line"><span class="comment"># python-docx</span></span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple python-docx</span><br></pre></td></tr></table></figure>
<p>国内还有其他镜像可供选择：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 豆瓣</span></span><br><span class="line">http://pypi.douban.com/simple/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 阿里</span></span><br><span class="line">http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 中国科学技术大学</span></span><br><span class="line">http://pypi.mirrors.ustc.edu.cn/simple/</span><br></pre></td></tr></table></figure>
<h3 id="permanently-configuration">3.2.2 Permanently configuration</h3>
<ul>
<li><p>自动配置镜像源</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 清华源</span></span><br><span class="line">pip config <span class="built_in">set</span> <span class="keyword">global</span>.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure></li>
<li><p>手动配置镜像源</p>
<p>在 <code>windows</code> 下，直接在 <code>user</code> 目录中创建一个 <code>pip</code> 目录，再新建文件 <code>pip.ini</code>，接着打开 <code>pip.ini</code> 文件，复制粘贴以下内容并保存。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="keyword">global</span>]</span><br><span class="line"> index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="install-package-offline">4 Install package offline</h1>
<h3 id="conda-install">4.1 Conda install</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda install --offline &lt; package &gt;</span><br><span class="line"></span><br><span class="line">conda install &lt;包名&gt; <span class="comment">#安装指定包</span></span><br><span class="line">conda remove &lt;包名&gt; <span class="comment">#移除指定包</span></span><br><span class="line">conda update &lt;包名&gt; <span class="comment">#更新指定包</span></span><br></pre></td></tr></table></figure>
<h3 id="pip-install-.whl-package">4.2 pip install '.whl' package</h3>
<p>再命令行窗口用 <code>cd</code> 命令跳转到 <code>whl</code> 文件所在目录，然后使用命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install ***.whl</span><br></pre></td></tr></table></figure>
<h1 id="virtual-environment">5 Virtual environment</h1>
<h2 id="steps">5.1 Steps</h2>
<ul>
<li><p>Open <code>terminal</code> or <code>Command prompt</code></p></li>
<li><p>Input <code>D:</code> to enter drive D</p></li>
<li><p>Then input <code>cd project_dir</code></p></li>
<li><p>Create a virtual environment</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python -m venv &lt;venv name&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="activate-venv">5.2 Activate venv</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">.\&lt;venv name&gt;\Scripts\activate <span class="comment"># activate venv</span></span><br><span class="line"></span><br><span class="line">.\venv\Scripts\deactivate <span class="comment"># exit the current venv</span></span><br></pre></td></tr></table></figure>
<h2 id="import-module">5.3 Import module</h2>
<ul>
<li><p>主程序和模块程序在同一目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">`-- src</span><br><span class="line">    |-- mod1.py</span><br><span class="line">    `-- test.py</span><br></pre></td></tr></table></figure>
<p><code>test.py</code>导入模块 <code>mod1</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> mod1</span><br><span class="line"><span class="keyword">from</span> mod1 <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure></li>
<li><p>主程序所在目录是模块所在目录的父(或祖辈)目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">`-- src</span><br><span class="line">    |-- mod1.py</span><br><span class="line">    |-- mod2</span><br><span class="line">    |   `-- mod2.py</span><br><span class="line">    `-- test1.py</span><br></pre></td></tr></table></figure>
<p><code>test1.py</code>中导入模块<code>mod2</code>，需要在<code>mod2</code>文件夹中创建<code>__init__.py</code>文件:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> mod2.mod2 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> mod2.mod2</span><br></pre></td></tr></table></figure></li>
<li><p>主程序导入上层目录中模块或其他目录(平级)下的模块</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">`-- src</span><br><span class="line">    |-- mod1.py</span><br><span class="line">    |-- mod2</span><br><span class="line">    |   `-- mod2.py</span><br><span class="line">    |-- sub</span><br><span class="line">    |   `-- test2.py</span><br><span class="line">    `-- test1.py</span><br></pre></td></tr></table></figure>
<p><code>test2.py</code> 中导入模块 <code>mod1</code> 和 <code>mod2</code>，首先需要在 <code>mod2</code> 下建立 <code>__init__.py</code> 文件，<code>src</code> 下不必建立该文件:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&quot;..&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> mod1</span><br><span class="line"><span class="keyword">import</span> mod2.mod2</span><br></pre></td></tr></table></figure></li>
</ul>
<p>从上面可以看出，导入模块关键是能够根据sys.path环境变量的值，找到具体模块的路径</p>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Software</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Anaconda</tag>
      </tags>
  </entry>
  <entry>
    <title>Python</title>
    <url>/2020/11/29/Python/</url>
    <content><![CDATA[<h1 id="python-数据类型">1. Python 数据类型</h1>
<h2 id="string">1.1 String</h2>
<ul>
<li>字符串的换行</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 长字符串的换行</span></span><br><span class="line">s2 = <span class="string">&#x27;It took me six months to write this Python tutorial. \</span></span><br><span class="line"><span class="string">    Please give me more support. \</span></span><br><span class="line"><span class="string">    I will keep it updated.&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 表达式的换行</span></span><br><span class="line">num = <span class="number">20</span> + <span class="number">3</span> / <span class="number">4</span> + \</span><br><span class="line">    <span class="number">2</span> * <span class="number">3</span></span><br><span class="line">print(num)</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<ul>
<li>长字符串</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 长字符串中的换行，缩进等会如实输出</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Long string information</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>原始字符串</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rstr = <span class="string">r&#x27;D:\Program Files\Python 3.8\python.exe&#x27;</span></span><br><span class="line">print(rstr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原始字符串中的引号童谣要进行转义处理</span></span><br><span class="line">str2 = <span class="string">r&#x27;I\&#x27;m a great coder!&#x27;</span></span><br><span class="line">print(str1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串结尾的反斜杠，如表达：D:\Program Files\Python 3.8\</span></span><br><span class="line">str3 = <span class="string">r&#x27;D:\Program Files\Python 3.8&#x27;</span> + <span class="string">&#x27;\\&#x27;</span></span><br><span class="line">print(str1)</span><br></pre></td></tr></table></figure>
<h2 id="bytes">1.2 Bytes</h2>
<p>Bytes 类型表示一个字节串，时Python 3 新增的， python 2 中不存在</p>
<p>Bytes 和 string 的对比：</p>
<ul>
<li>string由若干个字符组成，以字符为单位进行操作；Bytes由字节组成</li>
<li>除了操作的处理单元不同，它们支持的所有方法基本相同</li>
<li>都是不可变序列，不能随意增加和删除数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通过构造函数创建空 bytes</span></span><br><span class="line">b1 = <span class="built_in">bytes</span>()</span><br><span class="line"><span class="comment"># 通过空字符串创建空 bytes</span></span><br><span class="line">b2 = <span class="string">b&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 通过b前缀将字符串转换成 bytes</span></span><br><span class="line">b3 = <span class="string">b&#x27;http://c.biancheng.net/python/&#x27;</span></span><br><span class="line">print(<span class="string">&quot;b3: &quot;</span>, b3)</span><br><span class="line">print(b3[<span class="number">3</span>])</span><br><span class="line">print(b3[<span class="number">7</span>:<span class="number">22</span>])</span><br><span class="line"><span class="comment"># 为 bytes() 方法指定字符集</span></span><br><span class="line">b4 = <span class="built_in">bytes</span>(<span class="string">&#x27;C语言中文网8岁了&#x27;</span>, encoding=<span class="string">&#x27;UTF-8&#x27;</span>)</span><br><span class="line">print(<span class="string">&quot;b4: &quot;</span>, b4)</span><br><span class="line"><span class="comment"># 通过 encode() 方法将字符串转换成 bytes</span></span><br><span class="line">b5 = <span class="string">&quot;C语言中文网8岁了&quot;</span>.encode(<span class="string">&#x27;UTF-8&#x27;</span>)</span><br><span class="line">print(<span class="string">&quot;b5: &quot;</span>, b5)</span><br><span class="line"><span class="comment"># 通过 decode() 方法将 bytes 转化为字符串</span></span><br><span class="line">str1 = b5.decode(<span class="string">&#x27;UTF-8&#x27;</span>)</span><br><span class="line">print(<span class="string">&quot;str1: &quot;</span>, str1)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b3:  <span class="string">b&#x27;http://c.biancheng.net/python/&#x27;</span></span><br><span class="line"><span class="number">112</span></span><br><span class="line"><span class="string">b&#x27;c.biancheng.net&#x27;</span></span><br><span class="line">b4:  <span class="string">b&#x27;C\xe8\xaf\xad\xe8\xa8\x80\xe4\xb8\xad\xe6\x96\x87\xe7\xbd\x918\xe5\xb2\x81\xe4\xba\x86&#x27;</span></span><br><span class="line">b5:  <span class="string">b&#x27;C\xe8\xaf\xad\xe8\xa8\x80\xe4\xb8\xad\xe6\x96\x87\xe7\xbd\x918\xe5\xb2\x81\xe4\xba\x86&#x27;</span></span><br><span class="line">str1:  C语言中文网<span class="number">8</span>岁了</span><br></pre></td></tr></table></figure>
<p>从运行结果可以发现，对于非 ASCII 字符，print 输出的是它的字符编码值（十六进制形式），而不是字符本身。非 ASCII 字符一般占用两个字节以上的内存，而 bytes 是按照单个字节来处理数据的，所以不能一次处理多个字节。</p>
<h2 id="list">1.3 list</h2>
<h3 id="创建列表">1.3.1 创建列表</h3>
<ul>
<li>使用 [] 创建列表</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可支持不同数据类型</span></span><br><span class="line">program = [<span class="string">&quot;C语言&quot;</span>, <span class="string">&quot;Python&quot;</span>, <span class="string">&quot;Java&quot;</span>]</span><br><span class="line"><span class="comment"># 支持创建空列表</span></span><br><span class="line">emptylist = [ ]</span><br></pre></td></tr></table></figure>
<ul>
<li>使用 list() 函数创建列表</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将字符串转换成列表</span></span><br><span class="line">list1 = <span class="built_in">list</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">print(list1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将元组转换成列表</span></span><br><span class="line">tuple1 = (<span class="string">&#x27;Python&#x27;</span>, <span class="string">&#x27;Java&#x27;</span>, <span class="string">&#x27;C++&#x27;</span>, <span class="string">&#x27;JavaScript&#x27;</span>)</span><br><span class="line">list2 = <span class="built_in">list</span>(tuple1)</span><br><span class="line">print(list2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将字典转换成列表</span></span><br><span class="line">dict1 = &#123;<span class="string">&#x27;a&#x27;</span>:<span class="number">100</span>, <span class="string">&#x27;b&#x27;</span>:<span class="number">42</span>, <span class="string">&#x27;c&#x27;</span>:<span class="number">9</span>&#125;</span><br><span class="line">list3 = <span class="built_in">list</span>(dict1)</span><br><span class="line">print(list3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将区间转换成列表</span></span><br><span class="line">range1 = <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>)</span><br><span class="line">list4 = <span class="built_in">list</span>(range1)</span><br><span class="line">print(list4)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建空列表</span></span><br><span class="line">print(<span class="built_in">list</span>())</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;Python&#x27;</span>, <span class="string">&#x27;Java&#x27;</span>, <span class="string">&#x27;C++&#x27;</span>, <span class="string">&#x27;JavaScript&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">[]</span><br></pre></td></tr></table></figure>
<h3 id="访问列表元素">1.3.2 访问列表元素</h3>
<ul>
<li><p>使用索引访问列表元素</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">listname[i]</span><br></pre></td></tr></table></figure></li>
<li><p>使用切片访问列表元素</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">listname[start : end : step]</span><br></pre></td></tr></table></figure>
<h3 id="删除列表操作">1.3.3 删除列表操作</h3>
<ul>
<li>del 关键词删除列表</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">del</span> listname</span><br><span class="line"><span class="comment"># listname 表示要删除列表的名称</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> listname[index]</span><br><span class="line"><span class="keyword">del</span> listname[start : end]</span><br><span class="line"><span class="comment"># 删除从索引 start 到 end 之间的元素，不包括 end 位置的元素</span></span><br></pre></td></tr></table></figure>
<ul>
<li>pop() 方法：根据索引值删除元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">listname.pop(index)</span><br><span class="line"><span class="comment"># index 表示索引值，如果不写 index 参数，默认会删除列表中的最后一个元素，类似于数据结构中“出栈”操作</span></span><br></pre></td></tr></table></figure>
<ul>
<li>remove() 方法：根据元素本身的值来进行删除操作</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># remove() 方法只会删除第一个与指定值相同的元素，而且必须保证该元素是存在的，否则会报ValueError 错误</span></span><br><span class="line"></span><br><span class="line">nums = [<span class="number">40</span>, <span class="number">36</span>, <span class="number">89</span>, <span class="number">2</span>, <span class="number">36</span>, <span class="number">100</span>, <span class="number">7</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一次删除36</span></span><br><span class="line">nums.remove(<span class="number">36</span>)</span><br><span class="line">print(nums)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二次删除36</span></span><br><span class="line">nums.remove(<span class="number">36</span>)</span><br><span class="line">print(nums)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除78</span></span><br><span class="line">nums.remove(<span class="number">78</span>)</span><br><span class="line">print(nums)</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">40</span>, <span class="number">89</span>, <span class="number">2</span>, <span class="number">36</span>, <span class="number">100</span>, <span class="number">7</span>]</span><br><span class="line">[<span class="number">40</span>, <span class="number">89</span>, <span class="number">2</span>, <span class="number">100</span>, <span class="number">7</span>]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line"></span><br><span class="line">  File <span class="string">&quot;D:\Demo\Python\Test\Test1.py&quot;</span>, line <span class="number">493</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    nums.remove(<span class="number">78</span>)</span><br><span class="line"></span><br><span class="line">ValueError: <span class="built_in">list</span>.remove(x): x <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">list</span></span><br></pre></td></tr></table></figure>
<ul>
<li>clear()方法：删除列表所有元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="built_in">list</span>(<span class="string">&quot;http://c.biancheng.net/python/&quot;</span>)</span><br><span class="line">url.clear()</span><br><span class="line">print(url)</span><br><span class="line"><span class="comment"># clear() 会清空列表</span></span><br></pre></td></tr></table></figure>
<p>​ 运行结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[]</span><br></pre></td></tr></table></figure>
<h3 id="列表添加元素">1.3.4 列表添加元素</h3>
<ul>
<li>用 '+' 进行拼接</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">language = [<span class="string">&quot;Python&quot;</span>, <span class="string">&quot;C++&quot;</span>, <span class="string">&quot;Java&quot;</span>]</span><br><span class="line">birthday = [<span class="number">1991</span>, <span class="number">1998</span>, <span class="number">1995</span>]</span><br><span class="line">info = language + birthday</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;language =&quot;</span>, language)</span><br><span class="line">print(<span class="string">&quot;birthday =&quot;</span>, birthday)</span><br><span class="line">print(<span class="string">&quot;info =&quot;</span>, info)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">+ 运算符可以将多个修了连接起来，相当于在第一个列表的末尾添加了另一个列表</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>append() 方法添加元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">listname.append(obj)</span><br><span class="line"><span class="comment"># 用于在列表的末尾追加元素，obj 可以是单个元素，也可以是列表、元组等</span></span><br></pre></td></tr></table></figure>
<ul>
<li>inser() 方法插入元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">listname.insert(index, obj)</span><br><span class="line"><span class="comment"># index 表示指定位置的索引值</span></span><br></pre></td></tr></table></figure>
<h3 id="列表修改元素">1.3.5 列表修改元素</h3>
<ul>
<li>修改单个元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = [<span class="number">40</span>, <span class="number">36</span>, <span class="number">89</span>, <span class="number">2</span>, <span class="number">36</span>, <span class="number">100</span>, <span class="number">7</span>]</span><br><span class="line">nums[<span class="number">2</span>] = -<span class="number">26</span>  <span class="comment">#使用正数索引</span></span><br><span class="line">nums[-<span class="number">3</span>] = -<span class="number">66.2</span>  <span class="comment">#使用负数索引</span></span><br><span class="line">print(nums)</span><br></pre></td></tr></table></figure>
<ul>
<li>修改一组元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = [<span class="number">40</span>, <span class="number">36</span>, <span class="number">89</span>, <span class="number">2</span>, <span class="number">36</span>, <span class="number">100</span>, <span class="number">7</span>]</span><br><span class="line"><span class="comment"># 修改第 1~4 个元素的值（不包括第4个元素）</span></span><br><span class="line">nums[<span class="number">1</span>: <span class="number">4</span>] = [<span class="number">45.25</span>, -<span class="number">77</span>, -<span class="number">52.5</span>]</span><br><span class="line">print(nums)</span><br><span class="line">·</span><br><span class="line">nums = [<span class="number">40</span>, <span class="number">36</span>, <span class="number">89</span>, <span class="number">2</span>, <span class="number">36</span>, <span class="number">100</span>, <span class="number">7</span>]</span><br><span class="line"><span class="comment"># 在4个位置插入元素</span></span><br><span class="line">nums[<span class="number">4</span>: <span class="number">4</span>] = [-<span class="number">77</span>, -<span class="number">52.5</span>, <span class="number">999</span>]</span><br><span class="line">print(nums)</span><br><span class="line"></span><br><span class="line">nums = [<span class="number">40</span>, <span class="number">36</span>, <span class="number">89</span>, <span class="number">2</span>, <span class="number">36</span>, <span class="number">100</span>, <span class="number">7</span>]</span><br><span class="line"><span class="comment"># 使用切片语法赋值不支持单个值，会报TypeError</span></span><br><span class="line">nums[<span class="number">4</span>: <span class="number">4</span>] = -<span class="number">77</span></span><br><span class="line"></span><br><span class="line">nums = [<span class="number">40</span>, <span class="number">36</span>, <span class="number">89</span>, <span class="number">2</span>, <span class="number">36</span>, <span class="number">100</span>, <span class="number">7</span>]</span><br><span class="line"><span class="comment"># 步长为2，为第1、3、5个元素赋值</span></span><br><span class="line">nums[<span class="number">1</span>: <span class="number">6</span>: <span class="number">2</span>] = [<span class="number">0.025</span>, -<span class="number">99</span>, <span class="number">20.5</span>]</span><br><span class="line">print(nums)</span><br></pre></td></tr></table></figure>
<h3 id="列表查找元素">1.3.6 列表查找元素</h3>
<ul>
<li>index() 方法</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">listname.index(obj,start,end)</span><br><span class="line"><span class="comment"># 查找某个元素在列表中出现的位置，不存在则报ValueError错误，查找之前最好使用count()判断一下</span></span><br><span class="line">nums = [<span class="number">40</span>, <span class="number">36</span>, <span class="number">89</span>, <span class="number">2</span>, <span class="number">36</span>, <span class="number">100</span>, <span class="number">7</span>, -<span class="number">20.5</span>, -<span class="number">999</span>]</span><br><span class="line"><span class="comment"># 检索列表中的所有元素</span></span><br><span class="line">print( nums.index(<span class="number">2</span>) )</span><br><span class="line"><span class="comment"># 检索3~7之间的元素</span></span><br><span class="line">print( nums.index(<span class="number">100</span>, <span class="number">3</span>, <span class="number">7</span>) )</span><br><span class="line"><span class="comment"># 检索4之后的元素</span></span><br><span class="line">print( nums.index(<span class="number">7</span>, <span class="number">4</span>) )</span><br><span class="line"><span class="comment"># 检索一个不存在的元素</span></span><br><span class="line">print( nums.index(<span class="number">55</span>) )</span><br></pre></td></tr></table></figure>
<ul>
<li>count() 方法：统计某个元素在列表中出现的次数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">listname.count(obj)</span><br><span class="line"><span class="comment"># count() 防回0，则表示列表中不存在该元素</span></span><br></pre></td></tr></table></figure>
<h2 id="tuple">1.4 tuple</h2>
<h3 id="创建元组">1.4.1 创建元组</h3>
<ul>
<li>使用 () 直接创建</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tuplename = (element1, element2, ... )</span><br></pre></td></tr></table></figure>
<ul>
<li>使用 tuple() 函数创建元组</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">tuple</span>(data)</span><br><span class="line"><span class="comment"># data 表示可以转化为元组的数据，包括字符串、元组、range 对象等</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将字符串转换成元组</span></span><br><span class="line">tup1 = <span class="built_in">tuple</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">print(tup1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将列表转换成元组</span></span><br><span class="line">list1 = [<span class="string">&#x27;Python&#x27;</span>, <span class="string">&#x27;Java&#x27;</span>, <span class="string">&#x27;C++&#x27;</span>, <span class="string">&#x27;JavaScript&#x27;</span>]</span><br><span class="line">tup2 = <span class="built_in">tuple</span>(list1)</span><br><span class="line">print(tup2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将字典转换成元组</span></span><br><span class="line">dict1 = &#123;<span class="string">&#x27;a&#x27;</span>:<span class="number">100</span>, <span class="string">&#x27;b&#x27;</span>:<span class="number">42</span>, <span class="string">&#x27;c&#x27;</span>:<span class="number">9</span>&#125;</span><br><span class="line">tup3 = <span class="built_in">tuple</span>(dict1)</span><br><span class="line">print(tup3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将区间转换成元组</span></span><br><span class="line">range1 = <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>)</span><br><span class="line">tup4 = <span class="built_in">tuple</span>(range1)</span><br><span class="line">print(tup4)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建空元组</span></span><br><span class="line">print(<span class="built_in">tuple</span>())</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(<span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">(<span class="string">&#x27;Python&#x27;</span>, <span class="string">&#x27;Java&#x27;</span>, <span class="string">&#x27;C++&#x27;</span>, <span class="string">&#x27;JavaScript&#x27;</span>)</span><br><span class="line">(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>)</span><br><span class="line">(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">()</span><br></pre></td></tr></table></figure>
<h3 id="访问元组元素">1.4.2 访问元组元素</h3>
<ul>
<li>使用索引访问元组元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tuplename[i]</span><br></pre></td></tr></table></figure>
<ul>
<li>使用切片访问元组元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tuplename[start: end: step]</span><br></pre></td></tr></table></figure>
<h3 id="修改元组">1.4.3 修改元组</h3>
<p>元组是不可变序列，元组中的元素不能被修改</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tup = (<span class="number">100</span>, <span class="number">0.5</span>, -<span class="number">36</span>, <span class="number">73</span>)</span><br><span class="line">print(tup)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用新的元组去替代旧的元组</span></span><br><span class="line">tup = (<span class="string">&#x27;Shell脚本&#x27;</span>,<span class="string">&quot;http://c.biancheng.net/shell/&quot;</span>)</span><br><span class="line">print(tup)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 + 运算符拼接形成新的元组</span></span><br></pre></td></tr></table></figure>
<h3 id="删除元组">1.4.4 删除元组</h3>
<ul>
<li>del 关键字</li>
</ul>
<h2 id="dict">1.5 dict</h2>
<p>dict 是一种无序的、可变的序列，他的元素以“键值对（key - value）”的形式存储</p>
<p><img src="https://s3.ax1x.com/2020/11/30/Dg2hm6.gif" alt="reflect1" style="zoom:80%;" /></p>
<center>
Fig. 1-1 字典数据结构
</center>
<h3 id="创建字典">1.5.1 创建字典</h3>
<ul>
<li>使用 {} 创建字典</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dictname = &#123;<span class="string">&#x27;key&#x27;</span>:<span class="string">&#x27;value1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>:<span class="string">&#x27;value2&#x27;</span>, ..., <span class="string">&#x27;keyn&#x27;</span>:valuen&#125;</span><br><span class="line"><span class="comment"># 同义字典中的各个键必须唯一，不能重复</span></span><br></pre></td></tr></table></figure>
<ul>
<li>通过 fromkeys() 方法创建字典</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dictname = <span class="built_in">dict</span>.fromkeys(<span class="built_in">list</span>, value = <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># list 参数表示字典中的所有键的列表，value参数表示默认值，如果不写，则为空值None</span></span><br><span class="line"></span><br><span class="line">knowledge = &#123;<span class="string">&#x27;语文&#x27;</span>, <span class="string">&#x27;数学&#x27;</span>, <span class="string">&#x27;英语&#x27;</span>&#125;</span><br><span class="line">scores = <span class="built_in">dict</span>.fromkeys(knowledge, <span class="number">60</span>)</span><br><span class="line">print(scores)</span><br></pre></td></tr></table></figure>
<ul>
<li>通过 dict() 映射函数创建字典</li>
</ul>
<center>
表1-1 dict() 函数创建字典
</center>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>创建格式</th>
<th>注意事项</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>a = dict(str1=value1, str2=value2, str3=value3)</td>
<td>str 表示字符串类型的键，value 表示键对应的值。使用此方式创建字典时，字符串不能带引号。</td>
</tr>
<tr class="even">
<td>#方式1<br />demo = [('two',2), ('one',1), ('three',3)] <br />#方式2<br /> demo = [['two',2], ['one',1], ['three',3]] <br />#方式3 <br />demo = (('two',2), ('one',1), ('three',3)) <br />#方式4 <br />demo = (['two',2], ['one',1], ['three',3]) a = dict(demo)</td>
<td>向 dict() 函数传入列表或元组，而它们中的元素又各自是包含 2 个元素的列表或元组，其中第一个元素作为键，第二个元素作为值。</td>
</tr>
<tr class="odd">
<td>keys = ['one', 'two', 'three'] <br />#还可以是字符串或元组 <br />values = [1, 2, 3] <br />#还可以是字符串或元组 <br />a = dict( zip(keys, values) )</td>
<td>通过应用 dict() 函数和 zip() 函数，可将前两个列表转换为对应的字典。</td>
</tr>
</tbody>
</table>
<p>如果不为 dict() 函数传入任何参数，则表示创建空字典</p>
<h3 id="访问字典">1.5.2 访问字典</h3>
<ul>
<li>利用索引</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dictname[key]</span><br><span class="line"><span class="comment"># 由于字典中的元素是无序的，每个元素的位置都不固定，所以字典也不能像列表和元组那样，采用切片的方式一次性访问多个元素</span></span><br><span class="line"></span><br><span class="line">tup = ([<span class="string">&#x27;two&#x27;</span>,<span class="number">26</span>], [<span class="string">&#x27;one&#x27;</span>,<span class="number">88</span>], [<span class="string">&#x27;three&#x27;</span>,<span class="number">100</span>], [<span class="string">&#x27;four&#x27;</span>,-<span class="number">59</span>])</span><br><span class="line">dic = <span class="built_in">dict</span>(tup)</span><br><span class="line">print(dic[<span class="string">&#x27;one&#x27;</span>])  <span class="comment">#键存在</span></span><br><span class="line">print(dic[<span class="string">&#x27;five&#x27;</span>])  <span class="comment">#键不存在</span></span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">88</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">    File <span class="string">&quot;C:\Users\mozhiyan\Desktop\demo.py&quot;</span>, line <span class="number">4</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">        print(dic[<span class="string">&#x27;five&#x27;</span>])  <span class="comment">#键不存在</span></span><br><span class="line">KeyError: <span class="string">&#x27;five&#x27;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>get() 方法</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dictname.get(key[,default])</span><br><span class="line"><span class="comment"># default 用于指定要查询的键不存在时，此方法返回的默认值，如果不指定，则返回 None</span></span><br><span class="line"></span><br><span class="line">a = <span class="built_in">dict</span>(two=<span class="number">0.65</span>, one=<span class="number">88</span>, three=<span class="number">100</span>, four=-<span class="number">59</span>)</span><br><span class="line">print( a.get(<span class="string">&#x27;one&#x27;</span>) )</span><br><span class="line">print( a.get(<span class="string">&#x27;five&#x27;</span>, <span class="string">&#x27;该键不存在&#x27;</span>) )</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">88</span></span><br><span class="line">该键不存在</span><br></pre></td></tr></table></figure>
<h3 id="字典操作">1.6.3 字典操作</h3>
<ul>
<li>删除字典</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">del</span> dictname</span><br></pre></td></tr></table></figure>
<ul>
<li>添加键值对</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dictname[key] = value</span><br></pre></td></tr></table></figure>
<ul>
<li>修改键值对</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dictname[key] = new value</span><br><span class="line"><span class="comment"># key值不能被修改，只能修改value</span></span><br></pre></td></tr></table></figure>
<ul>
<li>删除键值对</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">del</span> dictname[key]</span><br></pre></td></tr></table></figure>
<ul>
<li>判断字典中是否存在指定键值对( in 或 not in 运算符)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="string">&#x27;数学&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;语文&#x27;</span>: <span class="number">89</span>, <span class="string">&#x27;英语&#x27;</span>: <span class="number">90</span>&#125;</span><br><span class="line"><span class="comment"># 判断 a 中是否包含名为&#x27;数学&#x27;的key</span></span><br><span class="line">print(<span class="string">&#x27;数学&#x27;</span> <span class="keyword">in</span> a) <span class="comment"># True</span></span><br><span class="line"><span class="comment"># 判断 a 是否包含名为&#x27;物理&#x27;的key</span></span><br><span class="line">print(<span class="string">&#x27;物理&#x27;</span> <span class="keyword">in</span> a) <span class="comment"># False</span></span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h3 id="字典方法">1.6.4 字典方法</h3>
<ul>
<li><p>keys() : 返回字典的所有key</p></li>
<li><p>values() : 返回字典所有键值对应的value</p></li>
<li><p>items() : 防回字典中所有的键值对</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scores = &#123;<span class="string">&#x27;数学&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;语文&#x27;</span>: <span class="number">89</span>, <span class="string">&#x27;英语&#x27;</span>: <span class="number">90</span>&#125;</span><br><span class="line">print(scores.keys())</span><br><span class="line">print(scores.values())</span><br><span class="line">print(scores.items())</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dict_keys([<span class="string">&#x27;数学&#x27;</span>, <span class="string">&#x27;语文&#x27;</span>, <span class="string">&#x27;英语&#x27;</span>])</span><br><span class="line">dict_values([<span class="number">95</span>, <span class="number">89</span>, <span class="number">90</span>])</span><br><span class="line">dict_items([(<span class="string">&#x27;数学&#x27;</span>, <span class="number">95</span>), (<span class="string">&#x27;语文&#x27;</span>, <span class="number">89</span>), (<span class="string">&#x27;英语&#x27;</span>, <span class="number">90</span>)])</span><br><span class="line"><span class="comment"># keys()、values() 和 items() 返回值的类型分别为 dict_keys、dict_values 和 dict_items</span></span><br></pre></td></tr></table></figure>
<p>在 Python 2.x 中，上面三个方法的返回值都是列表（list）类型。但在 Python 3.x 中，它们的返回值并不是我们常见的列表或者元组类型，因为 Python 3.x 不希望用户直接操作这几个方法的返回值。</p>
<p>在 Python 3.x 中如果想使用这三个方法返回的数据，一般有下面两种方案：</p>
<ol type="1">
<li>使用 list() 函数，将他们转化为列表</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="string">&#x27;数学&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;语文&#x27;</span>: <span class="number">89</span>, <span class="string">&#x27;英语&#x27;</span>: <span class="number">90</span>&#125;</span><br><span class="line">b = <span class="built_in">list</span>(a.keys())</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="string">&#x27;数学&#x27;</span>, <span class="string">&#x27;语文&#x27;</span>, <span class="string">&#x27;英语&#x27;</span>]</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>使用 for in 循环遍历</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="string">&#x27;数学&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;语文&#x27;</span>: <span class="number">89</span>, <span class="string">&#x27;英语&#x27;</span>: <span class="number">90</span>&#125;</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> a.keys():</span><br><span class="line">    print(k,end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">print(<span class="string">&quot;\n---------------&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> a.values():</span><br><span class="line">    print(v,end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">print(<span class="string">&quot;\n---------------&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> a.items():</span><br><span class="line">    print(<span class="string">&quot;key:&quot;</span>,k,<span class="string">&quot; value:&quot;</span>,v)</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">数学 语文 英语</span><br><span class="line">---------------</span><br><span class="line"><span class="number">95</span> <span class="number">89</span> <span class="number">90</span></span><br><span class="line">---------------</span><br><span class="line">key: 数学  value: <span class="number">95</span></span><br><span class="line">key: 语文  value: <span class="number">89</span></span><br><span class="line">key: 英语  value: <span class="number">90</span></span><br></pre></td></tr></table></figure>
<ul>
<li>update() 方法</li>
</ul>
<p>update方法可以使用一个字典所包含的简直对来更新已有的字典。</p>
<p>在执行 update（）方法是，如果被更新的字典中已包含对应的键值对，那么原 value会被覆盖；如果不包含对应的键值对，则该键值对被添加进去</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="string">&#x27;one&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;two&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;three&#x27;</span>: <span class="number">3</span>&#125;</span><br><span class="line">a.update(&#123;<span class="string">&#x27;one&#x27;</span>:<span class="number">4.5</span>, <span class="string">&#x27;four&#x27;</span>: <span class="number">9.3</span>&#125;)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;one&#x27;</span>: <span class="number">4.5</span>, <span class="string">&#x27;two&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;three&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;four&#x27;</span>: <span class="number">9.3</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>pop() 和 popitem() 方法</li>
</ul>
<p>都是用来删除字典中键值对，不同的是，pop() 用来删除指定的键值对，而 popitem() 用来随机删除一个键值对</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dictname.pop(key)</span><br><span class="line">dictname.popitem()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="string">&#x27;数学&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;语文&#x27;</span>: <span class="number">89</span>, <span class="string">&#x27;英语&#x27;</span>: <span class="number">90</span>, <span class="string">&#x27;化学&#x27;</span>: <span class="number">83</span>, <span class="string">&#x27;生物&#x27;</span>: <span class="number">98</span>, <span class="string">&#x27;物理&#x27;</span>: <span class="number">89</span>&#125;</span><br><span class="line">print(a)</span><br><span class="line">a.pop(<span class="string">&#x27;化学&#x27;</span>)</span><br><span class="line">print(a)</span><br><span class="line">a.popitem()</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;数学&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;语文&#x27;</span>: <span class="number">89</span>, <span class="string">&#x27;英语&#x27;</span>: <span class="number">90</span>, <span class="string">&#x27;化学&#x27;</span>: <span class="number">83</span>, <span class="string">&#x27;生物&#x27;</span>: <span class="number">98</span>, <span class="string">&#x27;物理&#x27;</span>: <span class="number">89</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;数学&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;语文&#x27;</span>: <span class="number">89</span>, <span class="string">&#x27;英语&#x27;</span>: <span class="number">90</span>, <span class="string">&#x27;生物&#x27;</span>: <span class="number">98</span>, <span class="string">&#x27;物理&#x27;</span>: <span class="number">89</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;数学&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;语文&#x27;</span>: <span class="number">89</span>, <span class="string">&#x27;英语&#x27;</span>: <span class="number">90</span>, <span class="string">&#x27;生物&#x27;</span>: <span class="number">98</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>setdefault() 方法：返回某个 key 对应的 value</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dictname.setdefault(key, defaultvalue)</span><br><span class="line"><span class="comment"># defaultvalue 表示默认值（可以不写，不写的话是 None）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">当指定的 key 不存在时，setdefault() 会先为这个不存在的 key 设置一个默认的 defaultvalue，然后再返回 defaultvalue</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">也就是说，setdefault() 方法总能返回指定 key 对应的 value：</span></span><br><span class="line"><span class="string">1) 如果该 key 存在，那么直接返回该 key 对应的 value；</span></span><br><span class="line"><span class="string">2) 如果该 key 不存在，那么先为该 key 设置默认的 defaultvalue，然后再返回该 key 对应的 defaultvalue。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="字典拷贝">1.6.5 字典拷贝</h3>
<p>copy() 返回一个字典的拷贝，即一个具有相同键值对的新字典</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="string">&#x27;one&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;two&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;three&#x27;</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]&#125;</span><br><span class="line">b = a.copy()</span><br><span class="line">print(b)</span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;one&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;two&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;three&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;</span><br></pre></td></tr></table></figure>
<p>copy() 方法所遵循的拷贝原理，既有深拷贝，也有浅拷贝。</p>
<p>拿拷贝字典 a 为例，copy() 方法只会对最表层的键值对进行深拷贝，也就是说，它会再申请一块内存用来存放 {'one': 1, 'two': 2, 'three': []}；而对于某些列表类型的值来说，此方法对其做的是浅拷贝，也就是说，b 中的 [1,2,3] 的值不是自己独有，而是和 a 共有。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="string">&#x27;one&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;two&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;three&#x27;</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]&#125;</span><br><span class="line">b = a.copy()</span><br><span class="line"><span class="comment"># 向 a 中添加新键值对，由于b已经提前将 a 所有键值对都深拷贝过来，因此 a 添加新键值对，不会影响 b。</span></span><br><span class="line"></span><br><span class="line">a[<span class="string">&#x27;four&#x27;</span>]=<span class="number">100</span></span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于 b 和 a 共享[1,2,3]（浅拷贝），因此移除 a 中列表中的元素，也会影响 b。</span></span><br><span class="line">a[<span class="string">&#x27;three&#x27;</span>].remove(<span class="number">1</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;one&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;two&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;three&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;four&#x27;</span>: <span class="number">100</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;one&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;two&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;three&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;</span><br><span class="line">&#123;<span class="string">&#x27;one&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;two&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;three&#x27;</span>: [<span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;four&#x27;</span>: <span class="number">100</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;one&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;two&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;three&#x27;</span>: [<span class="number">2</span>, <span class="number">3</span>]&#125;</span><br></pre></td></tr></table></figure>
<h2 id="set">1.6 set</h2>
<p>同一集合中，只能存储 <strong>不可变</strong> 的数据类型，包括整形、浮点型、字符串、元组，无法存储列表、字典、集合这些<strong>可变</strong> 的数据类型，否则会抛出 TypeError 错误。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;element1,element2,...,elementn&#125;</span><br><span class="line"><span class="comment"># Python 中有两种集合类型，一种是 set 类型的集合，另一种是 frozenset 类型的集合，它们唯一的区别是，set 类型集合可以做添加、删除元素的操作，而 forzenset 类型集合不行</span></span><br></pre></td></tr></table></figure>
<h3 id="创建-set-集合">1.6.1 创建 set 集合</h3>
<ul>
<li>使用 {} 创建</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setname = &#123;element1,element2,...&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>set() 函数创建集合</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setname = <span class="built_in">set</span>(iteration)</span><br><span class="line"></span><br><span class="line"><span class="comment"># for example</span></span><br><span class="line">set1 = <span class="built_in">set</span>(<span class="string">&quot;c.biancheng.net&quot;</span>)</span><br><span class="line">set2 = <span class="built_in">set</span>([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">set3 = <span class="built_in">set</span>((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line">print(<span class="string">&quot;set1:&quot;</span>,set1)</span><br><span class="line">print(<span class="string">&quot;set2:&quot;</span>,set2)</span><br><span class="line">print(<span class="string">&quot;set3:&quot;</span>,set3)</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">set1: &#123;<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;i&#x27;</span>, <span class="string">&#x27;e&#x27;</span>&#125;</span><br><span class="line">set2: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line">set3: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br></pre></td></tr></table></figure>
<h3 id="遍历-set-集合元素">1.6.2 遍历 set 集合元素</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="number">1</span>,<span class="string">&#x27;c&#x27;</span>,<span class="number">1</span>,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),<span class="string">&#x27;c&#x27;</span>&#125;</span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> a:</span><br><span class="line">    print(ele,end=<span class="string">&#x27; &#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="删除-set-集合">1.6.3 删除 set 集合</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="number">1</span>,<span class="string">&#x27;c&#x27;</span>,<span class="number">1</span>,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),<span class="string">&#x27;c&#x27;</span>&#125;</span><br><span class="line">print(a)</span><br><span class="line"><span class="keyword">del</span>(a)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure>
<h3 id="集合的基本操作">1.6.4 集合的基本操作</h3>
<ul>
<li>添加元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setname.add(element)</span><br><span class="line"><span class="comment"># 使用 add() 方法添加的元素，只能是数字、字符串、元组或者布尔类型（True 和 False）值，不能添加列表、字典、集合这类可变的数据，否则 Python 解释器会报 TypeError 错误</span></span><br></pre></td></tr></table></figure>
<ul>
<li>删除指定元素</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setname.remove(element)</span><br></pre></td></tr></table></figure>
<ul>
<li>布尔运算（交集、并集、差集以及对称差集运算）</li>
</ul>
<p><img src="https://s3.ax1x.com/2020/11/30/DgR9hQ.gif" alt="booleanpic" style="zoom:80%;" /></p>
<center>
Fig. 1-2 集合的布尔运算
</center>
<center>
表 1-2 集合的布尔运算
</center>
<table>
<thead>
<tr class="header">
<th>运算操作</th>
<th>Python运算符</th>
<th>含义</th>
<th>例子</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>交集</td>
<td>&amp;</td>
<td>取两集合公共的元素</td>
<td>&gt;&gt;&gt; set1 &amp; set2 {3}</td>
</tr>
<tr class="even">
<td>并集</td>
<td>|</td>
<td>取两集合全部的元素</td>
<td>&gt;&gt;&gt; set1 | set2 {1,2,3,4,5}</td>
</tr>
<tr class="odd">
<td>差集</td>
<td>-</td>
<td>取一个集合中另一集合没有的元素</td>
<td>&gt;&gt;&gt; set1 - set2 {1,2}</td>
</tr>
<tr class="even">
<td>对称差集</td>
<td>^</td>
<td>取集合 A 和 B 中不属于 A&amp;B 的元素</td>
<td>&gt;&gt;&gt; set1 ^ set2 {1,2,4,5}</td>
</tr>
</tbody>
</table>
<h3 id="set-集合方法详解">1.6.5 set 集合方法详解</h3>
<p><a href="http://c.biancheng.net/view/4402.html">set 集合方法详解</a></p>
<h1 id="python-函数操作">2. Python 函数操作</h1>
<h2 id="系统函数">2.1 系统函数</h2>
<h3 id="input">2.1.1 input()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span> = <span class="built_in">input</span>(tipmsg)</span><br></pre></td></tr></table></figure>
<ul>
<li>str 表示一个字符串类型的变量，input 会将读取到的字符串放入 str 中</li>
<li>tipmsg 表示提示信息，它会显示在控制台上，告诉用户应该输入什么样的内容；如果不写 tipmsg，就不会有任何提示信息</li>
</ul>
<h3 id="pirnt">2.1.2 pirnt()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(value,..., sep =<span class="string">&#x27;&#x27;</span>, end = <span class="string">&#x27;\n&#x27;</span>, file = sys.stdout, flush = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>value 参数可以接受任意多个变量或值，如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">user_name = <span class="string">&#x27;Charlie&#x27;</span></span><br><span class="line">user_age = <span class="number">8</span></span><br><span class="line"><span class="comment">#同时输出多个变量和字符串</span></span><br><span class="line">print(<span class="string">&quot;读者名：&quot;</span>,user_name,<span class="string">&quot;年龄：&quot;</span>,user_age, sep = <span class="string">&#x27;|&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="字符串方法">2.2 字符串方法</h2>
<h3 id="字符串拼接">2.2.1 字符串拼接</h3>
<ul>
<li>字符串和数字的拼接</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span>(obj)</span><br><span class="line"><span class="built_in">repr</span>(obj)</span><br><span class="line"><span class="comment">#  Python 不允许直接拼接数字和字符串，需要借助str() 和 repr() 函数将数字转换为字符串</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>str() 和 repr() 的区别</strong></p>
<p>str() 和 repr() 函数虽然都可以将数字转换成字符串，但它们之间是有区别的： 1) str() 将数据转换成适合人类阅读的字符串形式 2) repr() 将数据转换成适合解释器阅读的字符串形式（Python 表达式的形式），适合在开发和调试阶段使用；如果没有等价的语法，则会发生 SyntaxError 异常。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = <span class="string">&quot;http://c.biancheng.net/shell/&quot;</span></span><br><span class="line">s_str = <span class="built_in">str</span>(s)</span><br><span class="line">s_repr = <span class="built_in">repr</span>(s)</span><br><span class="line">print( <span class="built_in">type</span>(s_str) )</span><br><span class="line"><span class="built_in">print</span> (s_str)</span><br><span class="line">print( <span class="built_in">type</span>(s_repr) )</span><br><span class="line"><span class="built_in">print</span> (s_repr)</span><br></pre></td></tr></table></figure>
<p>​ 运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">str</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">http</span>:</span>//c.biancheng.net/shell/</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">str</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">&#x27;<span class="title">http</span>:</span>//c.biancheng.net/shell/<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="截取字符串">2.2.2 截取字符串</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">strname[index]</span><br><span class="line">strname[start : end : step]</span><br></pre></td></tr></table></figure>
<h3 id="len">2.2.3 len()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">len</span>（<span class="built_in">str</span>）</span><br><span class="line"><span class="comment"># 在 Python 中，不同的字符所占的字节数不同，数字、英文字母、小数点、下划线以及空格，各占一个字节，而一个汉字可能占 2~4 个字节，具体占多少个，取决于采用的编码方式。例如，汉字在 GBK/GB2312 编码中占用 2 个字节，而在 UTF-8 编码中一般占用 3 个字节</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s3.ax1x.com/2020/11/30/DgRPpj.gif" /></p>
<center>
图 2-1 UTF-8
</center>
<h3 id="split">2.2.4 split()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span>.split(sep,maxsplit)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">str: 表示要分割的字符串</span></span><br><span class="line"><span class="string">sep: 用于指定分隔符，可以包含多个字符，默认为 None，表示所有空字符</span></span><br><span class="line"><span class="string">maxsplit：可选参数，用于指定分割的次数，最后列表中子串的个数最多为 maxsplit+1。如果不指定或者指定为 -1，则表示分割次数没有限制。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="join">2.2.5 join()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">newstr = <span class="built_in">str</span>.join(iterable)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">newstr：表示合并后生成的新字符串；</span></span><br><span class="line"><span class="string">str：用于指定合并时的分隔符；</span></span><br><span class="line"><span class="string">iterable：做合并操作的源字符串数据，允许以列表、元组等形式提供。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">list</span> = [<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;biancheng&#x27;</span>,<span class="string">&#x27;net&#x27;</span>]</span><br><span class="line"><span class="string">&#x27;.&#x27;</span>.join(<span class="built_in">list</span>)</span><br><span class="line"><span class="comment"># 运行结果： &#x27;c.biancheng.net&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="count">2.2.6 count()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span>.count(sub[,start[,end]])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">str：表示原字符串；</span></span><br><span class="line"><span class="string">sub：表示要检索的字符串；</span></span><br><span class="line"><span class="string">start：指定检索的起始位置，也就是从什么位置开始检测。如果不指定，默认从头开始检索；</span></span><br><span class="line"><span class="string">end：指定检索的终止位置，如果不指定，则表示一直检索到结尾。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">str</span> = <span class="string">&quot;c.biancheng.net&quot;</span></span><br><span class="line"><span class="built_in">str</span>.count(<span class="string">&#x27;.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="find">2.2.7 find()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span>.find(sub[,start[,end]])</span><br></pre></td></tr></table></figure>
<h3 id="index">2.2.8 index()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span>.index(sub[,start[,end]])</span><br><span class="line"><span class="comment"># 同 find() 方法类似，index() 方法也可以用于检索是否包含指定的字符串，不同之处在于，当指定的字符串不存在时，index() 方法会抛出异常</span></span><br></pre></td></tr></table></figure>
<h3 id="对齐">2.2.9 对齐</h3>
<ul>
<li>ljust()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">S.ljust(width[, fillchar])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">S：表示要进行填充的字符串；</span></span><br><span class="line"><span class="string">width：表示包括本身长度在内，字符串要占的总长度；</span></span><br><span class="line"><span class="string">fillchar：作为可选参数，用来指定填充字符串时所用的字符，默认情况使用空格。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>rjust()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">S.rjust(width[, fillchar])</span><br></pre></td></tr></table></figure>
<ul>
<li>center()</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">S.center(width[, fillchar])</span><br></pre></td></tr></table></figure>
<h3 id="startswith-和-endswith">2.2.10 startswith() 和 endswith()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span>.startswith(sub[,start[,end]])</span><br><span class="line"><span class="comment"># 检索字符串是否以指定字符串开头，如果是返回 True；反之返回 False</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">str</span>.endswith(sub[,start[,end]])</span><br><span class="line"><span class="comment"># endswith() 方法用于检索字符串是否以指定字符串结尾，如果是则返回 True；反之则返回 False</span></span><br></pre></td></tr></table></figure>
<h3 id="大小写转换">2.2.11 大小写转换</h3>
<ul>
<li>title()</li>
<li>lower()</li>
<li>upper()</li>
</ul>
<h3 id="strip">2.2.12 strip()</h3>
<ul>
<li>strip()：删除串前后（左右两侧）的空格或特殊字符</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span> = <span class="string">&quot;  c.biancheng.net \t\n\r&quot;</span></span><br><span class="line"><span class="built_in">str</span>.strip()</span><br><span class="line"><span class="comment"># &#x27;c.biancheng.net&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">str</span>.strip(<span class="string">&quot; ,\r&quot;</span>)</span><br><span class="line"><span class="comment"># &#x27;c.biancheng.net \t\n&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">str</span></span><br><span class="line"><span class="comment"># &#x27;  c.biancheng.net \t\n\r&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># strip() 并没有改变字符本身</span></span><br></pre></td></tr></table></figure>
<ul>
<li>lstrip()：删除字符串前面（左边）的空格或特殊字符</li>
<li>rstrip()：删除字符串后面（右边）的空格或特殊字符</li>
</ul>
<h3 id="format">2.2.13 format()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span>.<span class="built_in">format</span>(args)</span><br><span class="line"><span class="comment"># str 用于指定字符串的显示样式；args 用于指定要进行格式转换的项，如果有多项，之间有逗号进行分割</span></span><br></pre></td></tr></table></figure>
<p>学习 format() 方法的难点，在于搞清楚 str 显示样式的书写格式。在创建显示样式模板时，需要使用<code>&#123;&#125;</code>和<code>：</code>来指定占位符，其完整的语法格式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123; [index][ : [ [fill] align] [sign] [<span class="comment">#] [width] [.precision] [type] ] &#125;</span></span><br></pre></td></tr></table></figure>
<p>具体参照：<a href="http://c.biancheng.net/view/4301.html">format完整</a></p>
<h3 id="encode-和-decode">2.2.14 encode() 和 decode()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span>.encode([encoding=<span class="string">&quot;utf-8&quot;</span>][,errors=<span class="string">&quot;strict&quot;</span>])</span><br><span class="line"><span class="comment"># encoding=&quot;GBK&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">bytes</span>.decode([encoding=<span class="string">&quot;utf-8&quot;</span>][,errors=<span class="string">&quot;strict&quot;</span>])</span><br></pre></td></tr></table></figure>
<center>
表 2-2 encode() 参数
</center>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 76%" />
</colgroup>
<thead>
<tr class="header">
<th>参数</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>str</td>
<td>表示要进行转换的字符串。</td>
</tr>
<tr class="even">
<td>encoding = "utf-8"</td>
<td>指定进行编码时采用的字符编码，该选项默认采用 utf-8 编码。例如，如果想使用简体中文，可以设置 gb2312。<br /> 当方法中只使用这一个参数时，可以省略前边的“encoding=”，直接写编码格式，例如 str.encode("UTF-8")。</td>
</tr>
<tr class="odd">
<td>errors = "strict"</td>
<td>指定错误处理方式，其可选择值可以是：<br />1) strict：遇到非法字符就抛出异常。<br />2) ignore：忽略非法字符。<br />3) replace：用“？”替换非法字符。<br />4) xmlcharrefreplace：使用 xml 的字符引用。该参数的默认值为 strict。</td>
</tr>
</tbody>
</table>
<h3 id="dir-和-help">2.2.15 dir() 和 help()</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">dir</span>(obj)</span><br><span class="line"><span class="built_in">help</span>(obj)</span><br></pre></td></tr></table></figure>
<h1 id="python-运算符">3. Python 运算符</h1>
<h2 id="escape-character">3.1 Escape character</h2>
<p>转义字符以 <code>\0、\x</code> 开头，以 <code>\x</code> 开头表示后跟十六进制形势的编码值，Python中的转义字符只能使用八进制或十六进制</p>
<p>ASCII编码共收录了128个字符，<code>\0</code> 、<code>\x</code> 后面最多只能跟两位数字，所以八进制形势并不能表示所有的ASCII字符，只有十六进制才能表示所有的ASCII字符</p>
<center>
表3-1 转义字符一览表
</center>
<table>
<thead>
<tr class="header">
<th>转义字符</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>换行符，将光标位置移到下一行开头。</td>
</tr>
<tr class="even">
<td> 回车符，将光标位置移到本行开头。</td>
<td></td>
</tr>
<tr class="odd">
<td> 水平制表符，也即 Tab 键，一般相当于四个空格。</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>蜂鸣器响铃。注意不是喇叭发声，现在的计算机很多都不带蜂鸣器了，所以响铃不一定有效。</td>
</tr>
<tr class="odd">
<td> 退格（Backspace），将光标位置移到前一列。</td>
<td></td>
</tr>
<tr class="even">
<td>\\</td>
<td>反斜线</td>
</tr>
<tr class="odd">
<td>\'</td>
<td>单引号</td>
</tr>
<tr class="even">
<td>\"</td>
<td>双引号</td>
</tr>
<tr class="odd">
<td>\</td>
<td>在字符串行尾的续行符，即一行未完，转到下一行继续写。</td>
</tr>
</tbody>
</table>
<h2 id="位运算符">3.2 位运算符</h2>
<p>位运算符是指按照数据在内存中的二进制位进行操作</p>
<center>
表3-2 位运算符一览表
</center>
<table>
<thead>
<tr class="header">
<th>位运算符</th>
<th>说明</th>
<th>适用形式</th>
<th>举例</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&amp;</td>
<td>按位与</td>
<td>a &amp; b</td>
<td>4 &amp; 5</td>
</tr>
<tr class="even">
<td>|</td>
<td>按位或</td>
<td>a | b</td>
<td>4 | 5</td>
</tr>
<tr class="odd">
<td>^</td>
<td>按位异或</td>
<td>a ^ b</td>
<td>4 ^ 5</td>
</tr>
<tr class="even">
<td>~</td>
<td>按位取反</td>
<td>~a</td>
<td>~4</td>
</tr>
<tr class="odd">
<td>&lt;&lt;</td>
<td>按位左移</td>
<td>a &lt;&lt; b</td>
<td>4 &lt;&lt; 2，表示整数 4 按位左移 2 位</td>
</tr>
<tr class="even">
<td>&gt;&gt;</td>
<td>按位右移</td>
<td>a &gt;&gt; b</td>
<td>4 &gt;&gt; 2，表示整数 4 按位右移 2 位</td>
</tr>
</tbody>
</table>
<h2 id="比较运算符">3.3 比较运算符</h2>
<center>
表3-3 比较运算符一览表
</center>
<table>
<thead>
<tr class="header">
<th>比较运算符</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&gt;</td>
<td>大于，如果<code>&gt;</code>前面的值大于后面的值，则返回 True，否则返回 False。</td>
</tr>
<tr class="even">
<td>&lt;</td>
<td>小于，如果<code>&lt;</code>前面的值小于后面的值，则返回 True，否则返回 False。</td>
</tr>
<tr class="odd">
<td>==</td>
<td>等于，如果<code>==</code>两边的值相等，则返回 True，否则返回 False。</td>
</tr>
<tr class="even">
<td>&gt;=</td>
<td>大于等于（等价于数学中的 ≥），如果<code>&gt;=</code>前面的值大于或者等于后面的值，则返回 True，否则返回 False。</td>
</tr>
<tr class="odd">
<td>&lt;=</td>
<td>小于等于（等价于数学中的 ≤），如果<code>&lt;=</code>前面的值小于或者等于后面的值，则返回 True，否则返回 False。</td>
</tr>
<tr class="even">
<td>!=</td>
<td>不等于（等价于数学中的 ≠），如果<code>!=</code>两边的值不相等，则返回 True，否则返回 False。</td>
</tr>
<tr class="odd">
<td>is</td>
<td>判断两个变量所引用的对象是否相同，如果相同则返回 True，否则返回 False。</td>
</tr>
<tr class="even">
<td>is not</td>
<td>判断两个变量所引用的对象是否不相同，如果不相同则返回 True，否则返回 False。</td>
</tr>
</tbody>
</table>
<ul>
<li>== 和 is 的区别</li>
</ul>
<p>== 用来比较两个变量的值是否相等，而 is 则用来比对两个变量引用的是否是同一个对象</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time  <span class="comment">#引入time模块</span></span><br><span class="line">t1 = time.gmtime() <span class="comment"># gmtime()用来获取当前时间</span></span><br><span class="line">t2 =  time.gmtime()</span><br><span class="line">print(t1 == t2) <span class="comment">#输出True</span></span><br><span class="line">print(t1 <span class="keyword">is</span> t2) <span class="comment">#输出False</span></span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">time 模块的 gmtime() 方法用来获取当前的系统时间，精确到秒级，因为程序运行非常快，所以 t1 和 t1 得到的时间是一样的。== 用来判断 t1 和 t2 的值是否相等，所以返回 True。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="逻辑运算符">3.4 逻辑运算符</h2>
<center>
表3-4 逻辑运算符一览表
</center>
<table>
<colgroup>
<col style="width: 9%" />
<col style="width: 27%" />
<col style="width: 7%" />
<col style="width: 55%" />
</colgroup>
<thead>
<tr class="header">
<th>逻辑运算符</th>
<th>含义</th>
<th>基本格式</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>and</td>
<td>逻辑与运算，等价于数学中的“且”</td>
<td>a and b</td>
<td>当 a 和 b 两个表达式都为真时，a and b 的结果才为真，否则为假。</td>
</tr>
<tr class="even">
<td>or</td>
<td>逻辑或运算，等价于数学中的“或”</td>
<td>a or b</td>
<td>当 a 和 b 两个表达式都为假时，a or b 的结果才是假，否则为真。</td>
</tr>
<tr class="odd">
<td>not</td>
<td>逻辑非运算，等价于数学中的“非”</td>
<td>not a</td>
<td>如果 a 为真，那么 not a 的结果为假；如果 a 为假，那么 not a 的结果为真。相当于对 a 取反。</td>
</tr>
</tbody>
</table>
<h2 id="三目运算符">3.5 三目运算符</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">max</span> = a <span class="keyword">if</span> a&gt;b <span class="keyword">else</span> b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上述代码实现如下功能</span></span><br><span class="line"><span class="keyword">if</span> a&gt;b:</span><br><span class="line">    <span class="built_in">max</span> = a;</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">max</span> = b;</span><br></pre></td></tr></table></figure>
<h2 id="数字操作符">3.6 数字操作符</h2>
<center>
表 3-5 数字操作符（优先级递减）
</center>
<table>
<thead>
<tr class="header">
<th>操作符</th>
<th>操作</th>
<th>示例</th>
<th>值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>**</td>
<td>指数</td>
<td>2**3</td>
<td>8</td>
</tr>
<tr class="even">
<td>%</td>
<td>取模/取余数</td>
<td>22%8</td>
<td>6</td>
</tr>
<tr class="odd">
<td>//</td>
<td>整除/商数取整</td>
<td>22//8</td>
<td>2</td>
</tr>
<tr class="even">
<td>/</td>
<td>除法</td>
<td>22/8</td>
<td>2.75</td>
</tr>
<tr class="odd">
<td>*</td>
<td>乘法</td>
<td>3*5</td>
<td>15</td>
</tr>
<tr class="even">
<td>*</td>
<td>字符串复制</td>
<td>['s'] * 4</td>
<td>['s', ',s', 's', 's']</td>
</tr>
<tr class="odd">
<td>-</td>
<td>减法</td>
<td>5-2</td>
<td>3</td>
</tr>
<tr class="even">
<td>+</td>
<td>加法</td>
<td>2+2</td>
<td>4</td>
</tr>
</tbody>
</table>
<h1 id="python-流程控制">4. Python 流程控制</h1>
<h2 id="pass">4.1 pass</h2>
<p><strong>pass</strong> 是 Python 中的关键字，用来让解释器跳过此处，什么都不做</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">age = <span class="built_in">int</span>( <span class="built_in">input</span>(<span class="string">&quot;请输入你的年龄：&quot;</span>) )</span><br><span class="line"><span class="keyword">if</span> age &lt; <span class="number">12</span> :</span><br><span class="line">    print(<span class="string">&quot;婴幼儿&quot;</span>)</span><br><span class="line"><span class="keyword">elif</span> age &gt;= <span class="number">12</span> <span class="keyword">and</span> age &lt; <span class="number">18</span>:</span><br><span class="line">    print(<span class="string">&quot;青少年&quot;</span>)</span><br><span class="line"><span class="keyword">elif</span> age &gt;= <span class="number">18</span> <span class="keyword">and</span> age &lt; <span class="number">30</span>:</span><br><span class="line">    print(<span class="string">&quot;成年人&quot;</span>)</span><br><span class="line"><span class="keyword">elif</span> age &gt;= <span class="number">30</span> <span class="keyword">and</span> age &lt; <span class="number">50</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">&quot;老年人&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="assert-断言">4.2 assert 断言</h2>
<p>assert 语句，又称断言语句，可看做是功能缩小版的 if 语句，用于判断某个表达式的值，如果值为真，则程序可以继续往下执行；反之，会报 AssertionError 错误</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">assert</span> 表达式</span><br><span class="line"></span><br><span class="line"><span class="comment"># 功能与下式类似</span></span><br><span class="line"><span class="keyword">if</span> 表达式==<span class="literal">True</span>:</span><br><span class="line">    程序继续执行</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    程序报 AssertionError 错误</span><br></pre></td></tr></table></figure>
<h2 id="break-和-continue">4.3 break 和 continue</h2>
<ul>
<li><p>break 语句，可以完全终止当前循环</p></li>
<li><p>continue 语句，可以跳过执行本次循环体中剩余的代码，转而执行下一次的循环</p></li>
</ul>
<h2 id="zip">4.4 zip()</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">zip</span>(iterable, ...)</span><br><span class="line"><span class="comment">#  iterable,... 表示多个列表、元组、字典、集合、字符串，甚至还可以为 range() 区间</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">my_list = [<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>]</span><br><span class="line">my_tuple = (<span class="number">21</span>,<span class="number">22</span>,<span class="number">23</span>)</span><br><span class="line"></span><br><span class="line">print([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">zip</span>(my_list,my_tuple)])</span><br><span class="line"></span><br><span class="line">my_dic = &#123;<span class="number">31</span>:<span class="number">2</span>,<span class="number">32</span>:<span class="number">4</span>,<span class="number">33</span>:<span class="number">5</span>&#125;</span><br><span class="line">my_set = &#123;<span class="number">41</span>,<span class="number">42</span>,<span class="number">43</span>,<span class="number">44</span>&#125;</span><br><span class="line"></span><br><span class="line">print([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">zip</span>(my_dic)])</span><br><span class="line"></span><br><span class="line">my_pychar = <span class="string">&quot;python&quot;</span></span><br><span class="line">my_shechar = <span class="string">&quot;shell&quot;</span></span><br><span class="line"></span><br><span class="line">print([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">zip</span>(my_pychar,my_shechar)])</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[(<span class="number">11</span>, <span class="number">21</span>), (<span class="number">12</span>, <span class="number">22</span>), (<span class="number">13</span>, <span class="number">23</span>)]</span><br><span class="line">[(<span class="number">31</span>,), (<span class="number">32</span>,), (<span class="number">33</span>,)]</span><br><span class="line">[(<span class="string">&#x27;p&#x27;</span>, <span class="string">&#x27;s&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;h&#x27;</span>), (<span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;e&#x27;</span>), (<span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;l&#x27;</span>), (<span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;l&#x27;</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="reversed">4.5 reversed()</h2>
<p>reserved() 可以返回一个给定序列的逆序序列</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将列表进行逆序</span></span><br><span class="line">print([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">reversed</span>([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将元组进行逆序</span></span><br><span class="line">print([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">reversed</span>((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将字符串进行逆序</span></span><br><span class="line">print([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="string">&quot;abcdefg&quot;</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 range() 生成的区间列表进行逆序</span></span><br><span class="line">print([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="number">10</span>))])</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">[<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">[<span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;f&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>]</span><br><span class="line">[<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h2 id="sorted">4.6 sorted()</h2>
<p>sorted() 用于给序列（列表、元组、字典、集合、字符串）进行排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">list</span> = <span class="built_in">sorted</span>(iterable, key=<span class="literal">None</span>, reverse=<span class="literal">False</span>)  </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">key 参数可以自定义排序规则</span></span><br><span class="line"><span class="string">reverse 参数指定以升序（False，默认）还是降序（True）进行排序</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h1 id="python-程序打包">5 Python 程序打包</h1>
<h2 id="需求分析">5.1 需求分析</h2>
<p>在写 <code>python</code> 程序时，难免会遇到一些需求，比如给别人写一个小工具什么的但是除了写 <code>Python</code> 的，绝大多数人电脑里都没有<code>Python</code> 编译器，所以打包成 <code>exe</code>，让 <code>Windows</code> 用户双击就可以打开，就非常方便了。</p>
<p>打包最常用的工具有 <code>py2exe</code>, <code>cxfree</code>, <code>pyinstaller</code> 等多种方法，不同方法的优缺点自行谷歌，经过多次尝试和对比，笔者觉得 <code>pyintaller</code> 是最方便使用的，因此本节以 <code>pyintaller</code> 为例介绍如何将 <code>py</code> 文件打包为 <code>exe</code> 可执行文件。</p>
<h2 id="直接打包">5.2 直接打包</h2>
<ul>
<li><p>安装 pyinstaller</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install pyinstaller</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接安装比较慢，建议从国内镜像站进行安装</span></span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pyinstaller</span><br></pre></td></tr></table></figure></li>
<li><p>打包命令</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pyinstaller -F -w py-file-path --distpath=outputpath</span><br><span class="line"><span class="comment"># py-file-path 为需要打包为exe文件的位置</span></span><br><span class="line"><span class="comment"># outputpath 为输出位置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For example</span></span><br><span class="line">pyinstaller -F -w <span class="string">&quot;./excel_to_word.py&quot;</span> --distpath=<span class="string">&quot;./output&quot;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p>虽然这种方式较为简单，但是打包过程非常缓慢，同时结果文件非常大，笔者写了一个十几行的代码，打包出来的代码有足足 <code>387M</code>。</p>
<p>有人说，这是因为 <code>Anaconda</code> 里内置了很多库，打包的时候打包了很多不必要的模块进去，要用纯净的 <code>Python</code> 来打包。因此介绍如何给 <code>exe</code> 文件瘦身。</p>
<h2 id="利用虚拟环境打包">5.2 利用虚拟环境打包</h2>
<ul>
<li><p>代码规范</p>
<p>在写代码时尽量使用 <code>from * import *</code> 的命令，而不是直接使用 <code>import</code> 命令，这样打包时会少导入一些模块内容。</p></li>
<li><p>创建虚拟环境</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cd <span class="string">&quot;D:\Program Datas\Python\Venv&quot;</span> <span class="comment"># 存放虚拟环境的目录</span></span><br><span class="line"></span><br><span class="line">python -m venv pyintall <span class="comment">#创建名为 pyintall 的虚拟环境</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入虚拟环境目录</span></span><br><span class="line">cd <span class="string">&quot;.\pyintall\Scripts\&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 激活虚拟环境</span></span><br><span class="line"><span class="string">activate.abat</span></span><br></pre></td></tr></table></figure></li>
<li><p>安装代码中需要的模块</p>
<p>该安装是在上述创建的虚拟环境中安装，后面的步骤也是在虚拟环境中进行处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 建议使用镜像安装和 pyinstaller</span></span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pakage-name</span><br></pre></td></tr></table></figure></li>
<li><p>打包</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pyinstaller -F -w <span class="string">&quot;./excel_to_word.py&quot;</span> --distpath=<span class="string">&quot;./output&quot;</span></span><br></pre></td></tr></table></figure></li>
<li><p>退出虚拟环境</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 退出当前虚拟环境</span></span><br><span class="line">.\venv\Scripts\deactivate.bat</span><br></pre></td></tr></table></figure>
<p>如要删除虚拟环境，仅需将该文件夹直接删除就可。</p></li>
</ul>
<p>最后打包出来的文件足足缩小了十几倍，仅剩十几兆，因此，虽然该方法会麻烦些，但建议使用该方法进行打包。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cd <span class="string">&quot;D:\Program Datas\Python\Venv&quot;</span> <span class="comment"># 存放虚拟环境的目录</span></span><br><span class="line"></span><br><span class="line">python -m venv pyintall <span class="comment">#创建名为 pyintall 的虚拟环境</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入虚拟环境目录</span></span><br><span class="line">cd <span class="string">&quot;.\pyintall\Scripts\&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 激活虚拟环境</span></span><br><span class="line"><span class="string">activate.abat</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 退出当前虚拟环境</span></span><br><span class="line"><span class="string">.\venv\Scripts\deactivate.bat</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch-1-Introduction</title>
    <url>/2021/08/03/Pytorch-1-Introduction/</url>
    <content><![CDATA[<p>Statement: This series of post records the personal notes and experiences of learning the <a href="https://www.bilibili.com/">BiliBili</a> video tutorial <a href="https://www.bilibili.com/video/BV12741177Cu?p=1">"Pytorch 入门学习"</a>, most of code and pictures are from the courseware <a href="https://github.com/ZeweiChu/PyTorch-Course">PyTorch-Course</a>. All posted content is for personal study only, do not use for other purposes. If there is infringement, please contact <code>e-mail:yangsuoly@qq.com</code> to delete. <a id="more"></a></p>
<h1 id="introduction-to-deep-learning-models">1. Introduction to deep learning models</h1>
<h2 id="definition">1.1 Definition</h2>
<p><strong>Q</strong>: What is machine learning?<br />
<strong>A</strong>: Study of algorithms that: - Improve their <em>performance</em> P - At some <em>task</em> T - With <em>experience</em> E</p>
<p><strong>Conclusion</strong>: Modeling, Inference, learning <img src="https://z3.ax1x.com/2021/08/03/fi7u38.png" /></p>
<ul>
<li>Modeling: define score function</li>
<li>Inference: solve argmax</li>
<li>Learning: choose w</li>
</ul>
<p><span class="math display">\[ \text{classify} (x, w) = \mathop{\text{argmax}}\limits_{y} \  \text{score} (x, y, w)\]</span></p>
<p><strong>Q</strong>: What is deep learning? <strong>A</strong>: <img src="https://z3.ax1x.com/2021/08/03/fi7KgS.md.png" /></p>
<p><strong>Q</strong>: What is neural network? <strong>A</strong>: <img src="https://z3.ax1x.com/2021/08/03/fi7Mjg.png" /></p>
<h2 id="activation-function">1.2 Activation function</h2>
<p><img src="https://z3.ax1x.com/2021/08/03/fi7GEn.png" /></p>
<h3 id="commonly-used-activation-functions">1.2.1 Commonly used activation functions:</h3>
<ul>
<li><p><span class="math inline">\(sigmoid\)</span>: <span class="math display">\[
\sigma(x) = \frac{1}{1+e^{-x}}
\]</span></p></li>
<li><p><span class="math inline">\(tanh\)</span>: <span class="math display">\[
tanh(x) = 2 \sigma(2x) - 1
\]</span></p></li>
<li><p><span class="math inline">\(ReLU\)</span>: <span class="math display">\[
ReLU(x) = max(0, x)
\]</span></p></li>
<li><p><span class="math inline">\(Softmax\)</span>: <span class="math display">\[
z_i \rightarrow \frac{e^{z_i}}{\sum_{j=1}^{k} e^{z_j}}
\]</span></p></li>
</ul>
<h3 id="code-implementation">1.2.2 Code implementation</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = torch.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">200</span>)</span><br><span class="line">x = Variable(x)</span><br><span class="line">x_np = x.data.numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># four activation function</span></span><br><span class="line">y_relu = F.relu(x).data.numpy()</span><br><span class="line">y_sigmoid = torch.sigmoid(x).data.numpy()</span><br><span class="line">y_tanh = F.tanh(x).data.numpy()</span><br><span class="line">y_softplus = F.softplus(x).data.numpy()</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.plot(x_np, y_relu, c=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">plt.ylim((-<span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.plot(x_np, y_sigmoid, c=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">plt.ylim((-<span class="number">0.2</span>, <span class="number">1.2</span>))</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(x_np, y_tanh, c=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">plt.ylim((-<span class="number">1.2</span>, <span class="number">1.2</span>))</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.plot(x_np, y_softplus, c=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;softplus&#x27;</span>)</span><br><span class="line">plt.ylim((-<span class="number">0.2</span>, <span class="number">6</span>))</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://z3.ax1x.com/2021/08/03/fi7VAI.png" /></p>
<h2 id="examples-of-nn">1.3 examples of NN</h2>
<ul>
<li><p>Standard feedforward NN <img src="https://z3.ax1x.com/2021/08/03/fi71Bj.png" /></p></li>
<li><p>Convolutional NN <img src="https://z3.ax1x.com/2021/08/03/fi7JNq.png" /></p></li>
<li><p>Recurrent NN <img src="https://z3.ax1x.com/2021/08/03/fi7ZNt.png" /></p></li>
<li><p>Seq2Seq with Attention <img src="https://z3.ax1x.com/2021/08/03/fi7Y40.png" /> <strong>Reference</strong>: <a href="https://arxiv.org/abs/1508.04025">Effective Approaches to Attention-based Neural Machine Translation</a></p></li>
</ul>
<h1 id="introduction-to-pytorch">2. Introduction to PyTorch</h1>
<h2 id="framework-for-deep-learning">2.1 Framework for deep learning</h2>
<p><img src="https://z3.ax1x.com/2021/08/03/fi7U3T.png" /></p>
<p>Difference between PyTorch and Tensorflow: - PyTorch: 动态计算图 Dynamic Computation Graph - Tensorflow: 静态计算图 Static Computation Graph</p>
<p>PyTorch 代码通俗易懂，非常接近 Python 原生代码，不会让人感觉是完全在学习一门新的语言。拥有 Facebook 支持，社区活跃。</p>
<p><strong>Q</strong>: What does the PyTorch do? <strong>A</strong>: <img src="https://z3.ax1x.com/2021/08/03/fi7agU.png" /></p>
<h2 id="some-interesting-project-with-pytorch">2.2. Some interesting project with PyTorch</h2>
<ul>
<li><p>ResNet <img src="https://z3.ax1x.com/2021/08/03/fi7e4P.md.png" /> Image classification: <a href="https://github.com/floydhub/imagenet">ResNet</a></p></li>
<li><p>Object Detection <img src="https://z3.ax1x.com/2021/08/03/fi7n9f.md.png" /> Project address: <a href="https://github.com/amdegroot/ssd.pytorch">Here</a></p></li>
<li><p>Image Style Transfer <img src="https://z3.ax1x.com/2021/08/03/fi7Db9.md.png" /> Project address: <a href="https://github.com/zhanghang1989/PyTorch-Multi-Style-Transfer">Here</a></p></li>
<li><p>CycleGAN <img src="https://z3.ax1x.com/2021/08/03/fi7luQ.png" /> Project address: <a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">Here</a></p></li>
<li><p>Image Captioning <img src="https://z3.ax1x.com/2021/08/03/fi7sER.md.png" /> Project address: <a href="https://github.com/ruotianluo/ImageCaptioning.pytorch">Here</a></p></li>
<li><p>Sentiment Analysis <img src="https://z3.ax1x.com/2021/08/03/fi7dvF.png" /> Project address: <a href="https://github.com/bentrevett/pytorch-sentiment-analysis">Here</a></p></li>
<li><p>Question Answering <img src="https://z3.ax1x.com/2021/08/03/fi7yU1.png" /> Project address: <a href="https://github.com/allenai/document-qa">Here</a></p></li>
<li><p>Translation: OpenNMT-py <img src="https://z3.ax1x.com/2021/08/03/fi7BDJ.png" /> Project address: <a href="https://github.com/OpenNMT/OpenNMT-py">Here</a></p></li>
<li><p>ChatBot <img src="https://z3.ax1x.com/2021/08/03/fi764x.png" /> Project address: <a href="https://github.com/czs0x55aa/pytorch-chatbot">Here</a></p></li>
<li><p>Deep Reinforcement Learning</p>
<p>Project address: <a href="https://github.com/jingweiz/pytorch-rl">Project 1</a>, <a href="https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html">Project 2</a></p></li>
</ul>
<h2 id="how-to-learn-pytorch">2.3 How to learn PyTorch</h2>
<ul>
<li>Basics of deep learning;</li>
<li>Pytorch official <a href="https://pytorch.org/tutorials/">tutorial</a>;</li>
<li>Learn tutorials on GitHub and various blogs;</li>
<li>Documentation and <a href="https://discuss.pytorch.org/">BBS</a></li>
<li>Re-creat the open source PyTorch project;</li>
<li>Read papers about deep learning model and implement them;</li>
<li>Create your own model.</li>
</ul>
<h1 id="note-content">3. Note content</h1>
<ol type="1">
<li>Pytorch framework with autograd introduction, simple forward neural networks;</li>
<li>Word vector;</li>
<li>Image classification, CNN, Transfer learning;</li>
<li>Language Model, Sentiment Classification, RNN, LSTM, GRU;</li>
<li>Translation Model, Seq2Seq, Attention;</li>
<li>Reading Comprehension, EIMo, BERT, GPT-2;</li>
<li>ChatBot;</li>
<li>GAN, Face generation, Style Transfer.</li>
</ol>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Python module</category>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Deep learning</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch-2-Autogradient</title>
    <url>/2021/08/04/Pytorch-2-Autogradient/</url>
    <content><![CDATA[<h1 id="什么是pytorch">1. 什么是PyTorch?</h1>
<p>PyTorch是一个基于Python的科学计算库，它有以下特点:</p>
<ul>
<li>类似于 NumPy，但是它可以使用 GPU</li>
<li>可以用它定义深度学习模型，可以灵活地进行深度学习模型的训练和使用</li>
</ul>
<a id="more"></a>
<h2 id="tensors">1.1 Tensors</h2>
<p>Tensor 类似与 NumPy 的 ndarray，唯一的区别是 Tensor 可以在 GPU 上加速运算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<ul>
<li><p>构造一个未初始化的 5x3 矩阵:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.empty(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[1.0194e-38, 9.1837e-39, 8.4490e-39],
        [9.6429e-39, 8.4490e-39, 9.6429e-39],
        [9.2755e-39, 1.0286e-38, 9.0919e-39],
        [8.9082e-39, 9.2755e-39, 8.4490e-39],
        [1.0194e-38, 9.0919e-39, 8.4490e-39]])</code></pre></li>
<li><p>构建一个随机初始化的矩阵:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[0.1782, 0.5218, 0.1660],
        [0.4009, 0.0275, 0.8139],
        [0.6904, 0.4813, 0.7811],
        [0.4067, 0.6289, 0.5081],
        [0.0305, 0.9687, 0.0834]])</code></pre></li>
<li><p>构建一个全部为 0，类型为 long 的矩阵:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.zeros(<span class="number">5</span>,<span class="number">3</span>,dtype=torch.long)</span><br><span class="line">x1 = torch.zeros(<span class="number">5</span>,<span class="number">3</span>).long() <span class="comment"># Equals</span></span><br><span class="line">x</span><br><span class="line">x2.dtype</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
torch.int64</code></pre></li>
<li><p>从数据直接直接构建 tensor:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">5.5</span>,<span class="number">3</span>])</span><br><span class="line">x</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([5.5000, 3.0000])</code></pre></li>
<li><p>1 矩阵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = x.new_ones(<span class="number">5</span>,<span class="number">3</span>, dtype=torch.double)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float64)</code></pre></li>
<li><p>randn_like</p>
<p>也可以从一个已有的tensor构建一个tensor。这些方法会重用原来tensor的特征，例如，数据类型，除非提供新的数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn_like(x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[-0.3863, -1.4149, -0.1054],
        [ 2.3531,  0.2044, -1.5104],
        [ 0.2127, -0.5231, -0.7806],
        [-0.9173, -0.0242,  0.1667],
        [-1.3101,  1.2451, -0.3665]])</code></pre></li>
<li><p>得到 tensor 的形状:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x.shape</span><br><span class="line">x.size()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>torch.Size([5, 3])
torch.Size([5, 3])</code></pre></li>
</ul>
<strong>Notes</strong>: <code>torch.Size</code> 返回的是一个tuple
</p>
</div>
<h2 id="operations">1.2 Operations</h2>
<p>有很多种tensor运算。我们先介绍加法运算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = torch.rand(<span class="number">5</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>加法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x + y <span class="comment"># Way 1</span></span><br><span class="line">torch.add(x, y) <span class="comment"># Way 2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Store the Results into a new variable</span></span><br><span class="line">result = torch.empty(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">torch.add(x, y, out=result)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[-0.0267, -1.1529,  0.7544],
        [ 2.8445,  1.0922, -1.3458],
        [ 0.6769, -0.2879, -0.7209],
        [-0.1200,  0.8094,  0.3603],
        [-0.3267,  2.1897, -0.3474]])</code></pre></li>
<li><p>in-place加法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y.add_(x)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[-0.0267, -1.1529,  0.7544],                [ 2.8445,  1.0922, -1.3458],                [ 0.6769, -0.2879, -0.7209],                [-0.1200,  0.8094,  0.3603],                [-0.3267,  2.1897, -0.3474]])</code></pre>
<p><strong>Note</strong>: 任何 <code>in-place</code> 的运算都会以 <code>_</code> 结尾。举例来说：<code>x.copy_(y)</code>, <code>x.t_()</code>, 这些 <code>in-place</code> 方法会改变变量 <code>x</code>。</p></li>
<li><p>Index</p>
<p>各种类似 NumPy 的 indexing 都可以在 PyTorch tensor 上面使用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x[<span class="number">1</span>:, <span class="number">1</span>:]</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[ 0.2044, -1.5104],        [-0.5231, -0.7806],        [-0.0242,  0.1667],        [ 1.2451, -0.3665]])</code></pre></li>
<li><p>Resizing</p>
<p>如果希望 <code>resize/reshape</code> 一个 <code>tensor</code>，可以使用 <code>torch.view</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>,<span class="number">8</span>)</span><br><span class="line">z</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[ 1.1355, -1.1149, -0.1322, -0.8217,  0.7920,  0.6061,  0.7453,  1.1177],
        [ 0.7566,  1.3975, -0.8014,  0.5999, -0.1476, -0.5695, -1.3861, -0.4741]])</code></pre></li>
<li><p>取得数值</p>
<p>如果你有一个只有一个元素的 <code>tensor</code>，使用 <code>.item()</code> 方法可以把里面的 value 变成 Python 数值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line">x</span><br><span class="line">x.item()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([-1.4227])
-1.422684907913208</code></pre></li>
<li><p>转置</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">z.transpose(<span class="number">1</span>, <span class="number">0</span>)z.t()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([[ 1.1355,  0.7566],        [-1.1149,  1.3975],        [-0.1322, -0.8014],        [-0.8217,  0.5999],        [ 0.7920, -0.1476],        [ 0.6061, -0.5695],        [ 0.7453, -1.3861],        [ 1.1177, -0.4741]])</code></pre></li>
</ul>
<p><strong>更多阅读</strong></p>
<p>各种 Tensor operations, 包括 transposing, indexing, slicing, mathematical operations, linear algebra, random numbers 在 <a href="https://pytorch.org/docs/torch">PyTorch Documentation</a>.</p>
<h2 id="numpy-和-tensor-之间的转化">1.3 Numpy 和 Tensor 之间的转化</h2>
<p>在 Torch Tensor 和 NumPy array 之间相互转化非常容易。</p>
<p><strong>Note</strong>: Torch Tensor和 NumPy array 会共享内存，所以改变其中一项也会改变另一项。</p>
<ul>
<li><p>Tensor to ndarray</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.ones(<span class="number">5</span>) <span class="comment"># a = tensor([1., 1., 1., 1., 1.])b = a.numpy() # b = array([1., 1., 1., 1., 1.], dtype=float32)</span></span><br></pre></td></tr></table></figure>
<p>改变numpy array里面的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b[<span class="number">1</span>] = <span class="number">2</span> <span class="comment"># b = array([1., 2., 1., 1., 1.], dtype=float32)         # a = tensor([1., 2., 1., 1., 1.])</span></span><br></pre></td></tr></table></figure></li>
<li><p>ndarray to Tensor</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.ones(<span class="number">5</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">np.add(a, <span class="number">1</span>, out=a)</span><br><span class="line">print(a)</span><br><span class="line">pirnt(a)</span><br></pre></td></tr></table></figure>
<pre><code>[2. 2. 2. 2. 2.]
[2. 2. 2. 2. 2.]</code></pre>
<p><strong>Note</strong>: 所有 <code>CPU</code> 上的 Tensor 都支持转成 numpy 或者从 numpy 转成 Tensor。</p></li>
</ul>
<h2 id="cuda-tensors">1.4 CUDA Tensors</h2>
<p>使用<code>.to</code>方法，Tensor可以被移动到别的device上。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)    </span><br><span class="line">    y = torch.ones_like(x, device=device)    </span><br><span class="line">    x = x.to(device)    </span><br><span class="line">    z = x + y    </span><br><span class="line">    print(z)    </span><br><span class="line">    print(z.to(<span class="string">&quot;cpu&quot;</span>, torch.double))    </span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([-0.4227], device=&#39;cuda:0&#39;)
tensor([-0.4227], dtype=torch.float64)</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y.to(<span class="string">&quot;cpu&quot;</span>).data.numpy()y.cpu().data.numpy()</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>array([1.], dtype=float32)</code></pre>
<h1 id="bi-linear-nn-with-numpy">2. Bi-Linear NN with numpy</h1>
<p>一个全连接ReLU神经网络，一个隐藏层，没有 bias。用来从 x 预测 y，使用 L2 Loss。</p>
<ul>
<li><span class="math inline">\(h = W_1X\)</span></li>
<li><span class="math inline">\(a = max(0, h)\)</span></li>
<li><span class="math inline">\(y_{hat} = W_2a\)</span></li>
</ul>
<p>这一实现完全使用numpy来计算前向神经网络，loss，和反向传播。</p>
<ul>
<li>forward pass</li>
<li>loss</li>
<li>backward pass</li>
</ul>
<p>numpy ndarray 是一个普通的 n 维 array。它不知道任何关于深度学习或者梯度 ( <code>gradient</code>) 的知识，也不知道计算图 (<code>computation graph</code>)，只是一种用来计算数学运算的数据结构。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span><span class="comment"># 随机创建一些训练数据x = np.random.randn(N, D_in)y = np.random.randn(N, D_out)w1 = np.random.randn(D_in, H)w2 = np.random.randn(H, D_out)learning_rate = 1e-6for it in range(500):    # Forward pass    h = x.dot(w1) # N * H    h_relu = np.maximum(h, 0) # N * H    y_pred = h_relu.dot(w2) # N * D_out    # compute loss    loss = np.square(y_pred - y).sum()    if it%50 == 0:        print(it, loss)    # Backward pass    # compute the gradient    grad_y_pred = 2.0 * (y_pred - y)    grad_w2 = h_relu.T.dot(grad_y_pred)    grad_h_relu = grad_y_pred.dot(w2.T)    grad_h = grad_h_relu.copy()    grad_h[h&lt;0] = 0    grad_w1 = x.T.dot(grad_h)    # update weights of w1 and w2    w1 -= learning_rate * grad_w1    w2 -= learning_rate * grad_w2</span></span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>0 30767183.85959570550 19309.70472025325100 927.7120364511059150 65.96723021925985200 5.451127574769099250 0.4979445419484826300 0.04972286885320139350 0.0053918752712101775400 0.0006287349147432031450 7.778529921424317e-05</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">h = x.dot(w1)h_relu = np.maximum(h, <span class="number">0</span>) <span class="comment"># N * Hy_pred = h_relu.dot(w2) # N * D_outab_loss = y_pred - yab_loss[:1]</span></span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>array([[-2.31700647e-05, -6.28731777e-05,  4.77222071e-05,         1.18624504e-05, -4.80998287e-05,  1.52820208e-06,         6.16901569e-06, -8.37944967e-05, -2.06058305e-06,         1.23783963e-06]])</code></pre>
<p>可以发现，两者相差非常小，模型训练较为成功。</p>
<h1 id="bi-linear-nn-with-pytorch">3. Bi-Linear NN with PyTorch</h1>
<h2 id="implementation">3.1 Implementation</h2>
<p>这次我们使用 PyTorch tensors 来创建前向神经网络，计算损失，以及反向传播。</p>
<p>一个 PyTorch Tensor 很像一个 numpy 的 ndarray。但是它和 numpy ndarray 最大的区别是，PyTorch Tensor 可以在 CPU 或者 GPU 上运算。如果想要在 GPU 上运算，就需要把 Tensor 换成 cuda 类型。</p>
<p>与 numpy 不同的方法：</p>
<ul>
<li><code>mm</code>: 矩阵相乘，对应于 <code>dot</code></li>
<li><code>clamp</code>: 夹子，将值夹在两者之间，对应于 <code>maximum</code></li>
<li><code>pow</code>: 平方，对应于 <code>np.square</code></li>
<li><code>t</code>: 转置，对应于 <code>.t</code></li>
<li><code>clone</code>: 复制，对应于 <code>copy</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span><span class="comment"># 随机创建一些训练数据x = torch.randn(N, D_in)y = torch.randn(N, D_out)w1 = torch.randn(D_in, H)w2 = torch.randn(H, D_out)learning_rate = 1e-6for it in range(500):    # Forward pass    h = x.mm(w1) # N * H    h_relu = h.clamp(min=0) # N * H    y_pred = h_relu.mm(w2) # N * D_out    # compute loss    loss = (y_pred - y).pow(2).sum().item()    if it%50 == 0:        print(it, loss)    # Backward pass    # compute the gradient    grad_y_pred = 2.0 * (y_pred - y)    grad_w2 = h_relu.t().mm(grad_y_pred)    grad_h_relu = grad_y_pred.mm(w2.t())    grad_h = grad_h_relu.clone()    grad_h[h&lt;0] = 0    grad_w1 = x.t().mm(grad_h)    # update weights of w1 and w2    w1 -= learning_rate * grad_w1    w2 -= learning_rate * grad_w2</span></span><br></pre></td></tr></table></figure>
<pre><code>0 31964224.050 8884.4111328125100 245.90003967285156150 12.271601676940918200 0.7670953273773193250 0.05322442948818207300 0.0041369786486029625350 0.0005290982662700117400 0.00013705584569834173450 5.566925392486155e-05</code></pre>
<p>简单的autograd</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.tensor(<span class="number">1.</span>, requires_grad=<span class="literal">True</span>)w = torch.tensor(<span class="number">2.</span>, requires_grad=<span class="literal">True</span>)b = torch.tensor(<span class="number">3.</span>, requires_grad=<span class="literal">True</span>)y = w*x + b<span class="comment"># y = 2*1+3y.backward()# dy / dw = xprint(w.grad)print(x.grad)print(b.grad)</span></span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor(1.)tensor(2.)tensor(1.)</code></pre>
<h2 id="pytorch-tensor-and-autograd">3.2 PyTorch: Tensor and autograd</h2>
<p>PyTorch 的一个重要功能就是 autograd，也就是说只要定义了 forward pass (前向神经网络)，计算了 loss 之后，PyTorch 可以自动求导计算模型所有参数的梯度。</p>
<p>一个 PyTorch 的 Tensor 表示计算图中的一个节点。如果 <code>x</code> 是一个 Tensor 并且 <code>x.requires_grad=True</code> 那么 <code>x.grad</code> 是另一个储存着 <code>x</code> 当前梯度(相对于一个 scalar，常常是 loss)的向量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span><span class="comment"># 随机创建一些训练数据x = torch.randn(N, D_in)y = torch.randn(N, D_out)w1 = torch.randn(D_in, H, requires_grad=True)w2 = torch.randn(H, D_out, requires_grad=True)learning_rate = 1e-6for it in range(500):    # Forward pass    y_pred = x.mm(w1).clamp(min=0).mm(w2)    # compute loss    loss = (y_pred - y).pow(2).sum() # computation graph    if it%50 == 0:        print(it, loss.item())    # Backward pass    loss.backward()    # update weights of w1 and w2    with torch.no_grad():        w1 -= learning_rate * w1.grad        w2 -= learning_rate * w2.grad        w1.grad.zero_() # gradient 清零        w2.grad.zero_()</span></span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>0 40281260.050 16265.544921875100 770.28857421875150 60.70436477661133200 5.996867656707764250 0.6809620261192322300 0.08519172668457031350 0.011621471494436264400 0.0019496456952765584450 0.0004842539201490581</code></pre>
<h2 id="pytorch-nn">3.3 PyTorch: nn</h2>
<p>这次我们使用 PyTorch 中 nn 这个库来构建网络。用 PyTorch autograd 来构建计算图和计算 gradients，然后 PyTorch 会帮我们自动计算 gradient。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nnN, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span><span class="comment"># 随机创建一些训练数据x = torch.randn(N, D_in)y = torch.randn(N, D_out)model = torch.nn.Sequential(    torch.nn.Linear(D_in, H, bias=False), # w_1 * x + b_1    torch.nn.ReLU(),    torch.nn.Linear(H, D_out, bias=False), # default bias is True)# 初始化权值torch.nn.init.normal_(model[0].weight)torch.nn.init.normal_(model[2].weight)# model = model.cuda()loss_fn = nn.MSELoss(reduction=&#x27;sum&#x27;)learning_rate = 1e-6for it in range(500):    # Forward pass    y_pred = model(x) # model.forward()    # compute loss    loss = loss_fn(y_pred, y) # computation graph    if it% 50 == 0:        print(it, loss.item())    # Backward pass    loss.backward()    # update weights of w1 and w2    with torch.no_grad():        for param in model.parameters(): # param (tensor, grad)            param -= learning_rate * param.grad    model.zero_grad()</span></span><br></pre></td></tr></table></figure>
<p>Results：</p>
<pre><code>0 37942064.050 13557.75390625100 482.86322021484375150 27.34326934814453200 1.863478183746338250 0.1420218050479889300 0.01187755074352026350 0.0013162594987079501400 0.00026860935031436384450 9.016783587867394e-05</code></pre>
<p><code>model[0].weight</code> 可得到模型中第一层的权重，<code>bia</code> 可得到偏置项。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model[<span class="number">0</span>].weight</span><br></pre></td></tr></table></figure>
<p>Results：</p>
<pre><code>Parameter containing:tensor([[-0.0218,  0.0212,  0.0243,  ...,  0.0230,  0.0247,  0.0168],    [-0.0144,  0.0177, -0.0221,  ...,  0.0161,  0.0098, -0.0172],    [ 0.0086, -0.0122, -0.0298,  ..., -0.0236, -0.0187,  0.0295],    ...,    [ 0.0266, -0.0008, -0.0141,  ...,  0.0018,  0.0319, -0.0129],    [ 0.0296, -0.0005,  0.0115,  ...,  0.0141, -0.0088, -0.0106],    [ 0.0289, -0.0077,  0.0239,  ..., -0.0166, -0.0156, -0.0235]],   requires_grad=True)</code></pre>
<h2 id="pytorch-optim">3.4 PyTorch: optim</h2>
<p>这一次我们不再手动更新模型的 weights,而是使用 optim 这个包来帮助我们更新参数。 optim 这个 package 提供了各种不同的模型优化方法，包括 SGD+momentum, RMSProp, Adam 等等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nnN, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span><span class="comment"># 随机创建一些训练数据x = torch.randn(N, D_in)y = torch.randn(N, D_out)model = torch.nn.Sequential(    torch.nn.Linear(D_in, H, bias=False), # w_1 * x + b_1    torch.nn.ReLU(),    torch.nn.Linear(H, D_out, bias=False),)torch.nn.init.normal_(model[0].weight)torch.nn.init.normal_(model[2].weight)# model = model.cuda()loss_fn = nn.MSELoss(reduction=&#x27;sum&#x27;)# Adam 则可以不用参数初始化# learning_rate = 1e-4# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)learning_rate = 1e-6optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)for it in range(500):    # Forward pass    y_pred = model(x) # model.forward()    # compute loss    loss = loss_fn(y_pred, y) # computation graph    if it%50 == 0:        print(it, loss.item())    optimizer.zero_grad()    # Backward pass    loss.backward()    # update model parameters    optimizer.step()</span></span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>0 40010880.050 8527.947265625100 276.97821044921875150 18.40827751159668200 1.5830364227294922250 0.15364140272140503300 0.016014395281672478350 0.0019916763994842768400 0.0004044498491566628450 0.0001368314551655203</code></pre>
<h2 id="pytorch-自定义-nn-modules">3.5 PyTorch: 自定义 nn Modules</h2>
<p>我们可以定义一个模型，这个模型继承自 nn.Module 类。如果需要定义一个比 Sequential 模型更加复杂的模型，就需要定义 nn.Module 模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nnN, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span><span class="comment"># 随机创建一些训练数据x = torch.randn(N, D_in)y = torch.randn(N, D_out)class TwoLayerNet(torch.nn.Module):    def __init__(self, D_in, H, D_out):        super(TwoLayerNet, self).__init__()        # define the model architecture        self.linear1 = torch.nn.Linear(D_in, H, bias=False)        self.linear2 = torch.nn.Linear(H, D_out, bias=False)    def forward(self, x):        y_pred = self.linear2(self.linear1(x).clamp(min=0))        return y_predmodel = TwoLayerNet(D_in, H, D_out)loss_fn = nn.MSELoss(reduction=&#x27;sum&#x27;)learning_rate = 1e-4optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)for it in range(500):    # Forward pass    y_pred = model(x) # model.forward()    # compute loss    loss = loss_fn(y_pred, y) # computation graph    if it%100 == 0:        print(it, loss.item())    optimizer.zero_grad()    # Backward pass    loss.backward()    # update model parameters    optimizer.step()</span></span><br></pre></td></tr></table></figure>
<p>Results：</p>
<pre><code>  0 692.8556518554688  100 50.59251403808594  200 0.6749072074890137  300 0.01346816960722208  400 0.0009340611286461353</code></pre>
<h1 id="fuzzbuzz">4. Fuzzbuzz</h1>
<p><code>FizzBuzz</code> 是一个简单的小游戏。游戏规则如下：从 1 开始往上数数，当遇到 3 的倍数的时候，说 fizz，当遇到 5 的倍数，说 buzz，当遇到 15 的倍数，就说 fizzbuzz，其他情况下则正常数数。</p>
<p>我们可以写一个简单的小程序来决定要返回正常数值还是 fizz, buzz 或者 fizzbuzz。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># One-hot encode the desired outputs: [number, &quot;fizz&quot;, &quot;buzz&quot;, &quot;fizzbuzz&quot;]def fizz_buzz_encode(i):    if   i % 15 == 0: return 3    elif i % 5  == 0: return 2    elif i % 3  == 0: return 1    else:             return 0def fizz_buzz_decode(i, prediction):    return [str(i), &quot;fizz&quot;, &quot;buzz&quot;, &quot;fizzbuzz&quot;][prediction]print(fizz_buzz_decode(1, fizz_buzz_encode(1)))print(fizz_buzz_decode(2, fizz_buzz_encode(2)))print(fizz_buzz_decode(5, fizz_buzz_encode(5)))print(fizz_buzz_decode(12, fizz_buzz_encode(12)))print(fizz_buzz_decode(15, fizz_buzz_encode(15)))</span></span><br></pre></td></tr></table></figure>
<p>Resutls:</p>
<pre><code>12buzzfizzfizzbuzz</code></pre>
<p>我们首先定义模型的输入与输出(训练数据)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> npimport torchNUM_DIGITS = <span class="number">10</span><span class="comment"># Represent each input by an array of its binary digits.def binary_encode(i, num_digits):    return np.array([i &gt;&gt; d &amp; 1 for d in range(num_digits)])trX = torch.Tensor([binary_encode(i, NUM_DIGITS) for i in range(101, 2 ** NUM_DIGITS)])trY = torch.LongTensor([fizz_buzz_encode(i) for i in range(101, 2 ** NUM_DIGITS)])</span></span><br></pre></td></tr></table></figure>
<p>然后我们用PyTorch定义模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Define the model</span></span><br><span class="line">NUM_HIDDEN = <span class="number">100</span></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(NUM_DIGITS, NUM_HIDDEN),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(NUM_HIDDEN, <span class="number">4</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">model = model.to(device)</span><br></pre></td></tr></table></figure>
<ul>
<li>为了让我们的模型学会 <code>FizzBuzz</code> 这个游戏，我们需要定义一个损失函数，和一个优化算法。</li>
<li>这个优化算法会不断优化（降低）损失函数，使得模型的在该任务上取得尽可能低的损失值。</li>
<li>损失值低往往表示我们的模型表现好，损失值高表示我们的模型表现差。</li>
<li>由于 <code>FizzBuzz</code> 游戏本质上是一个分类问题，我们选用 Cross Entropyy Loss 函数。</li>
<li>优化函数我们选用 Stochastic Gradient Descent。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss_fn = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr = <span class="number">0.05</span>)</span><br></pre></td></tr></table></figure>
<p>以下是模型的训练代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Start training it</span></span><br><span class="line">BATCH_SIZE = <span class="number">128</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line">    <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(trX), BATCH_SIZE):</span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        batchX = trX[start:end].to(device)</span><br><span class="line">        batchY = trY[start:end].to(device)</span><br><span class="line"></span><br><span class="line">        y_pred = model(batchX)</span><br><span class="line">        loss = loss_fn(y_pred, batchY)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Find loss on training data</span></span><br><span class="line">    loss = loss_fn(model(trX.to(device)), trY.to(device)).cpu().item()</span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">&#x27;Epoch:&#x27;</span>, epoch, <span class="string">&#x27;Loss:&#x27;</span>, loss)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>Epoch: 0 Loss: 1.1463667154312134
Epoch: 1000 Loss: 0.4962996244430542
Epoch: 2000 Loss: 0.15307655930519104
Epoch: 3000 Loss: 0.07736020535230637
Epoch: 4000 Loss: 0.044787853956222534
Epoch: 5000 Loss: 0.029076775535941124
Epoch: 6000 Loss: 0.020609091967344284
Epoch: 7000 Loss: 0.01560244057327509
Epoch: 8000 Loss: 0.012386537156999111
Epoch: 9000 Loss: 0.010154682211577892</code></pre>
<p>最后我们用训练好的模型尝试在 1 到 100 这些数字上玩 <code>FizzBuzz</code> 游戏</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Output now</span></span><br><span class="line">testX = torch.Tensor([binary_encode(i, NUM_DIGITS) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">101</span>)])</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    testY = model(testX.to(device))</span><br><span class="line">predictions = <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">101</span>), <span class="built_in">list</span>(testY.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>].data.tolist()))</span><br><span class="line"></span><br><span class="line">print([fizz_buzz_decode(i, x) <span class="keyword">for</span> (i, x) <span class="keyword">in</span> predictions])</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>[&#39;1&#39;, &#39;2&#39;, &#39;fizz&#39;, &#39;4&#39;, &#39;buzz&#39;, &#39;fizz&#39;, &#39;7&#39;, &#39;8&#39;, &#39;fizz&#39;, &#39;10&#39;, &#39;11&#39;,
  &#39;fizz&#39;, &#39;13&#39;, &#39;14&#39;, &#39;fizzbuzz&#39;, &#39;16&#39;, &#39;17&#39;, &#39;fizz&#39;, &#39;19&#39;, &#39;buzz&#39;,
  &#39;fizz&#39;, &#39;22&#39;, &#39;23&#39;, &#39;fizz&#39;, &#39;buzz&#39;, &#39;26&#39;, &#39;fizz&#39;, &#39;28&#39;, &#39;29&#39;,
  &#39;fizzbuzz&#39;, &#39;31&#39;, &#39;32&#39;, &#39;fizz&#39;, &#39;34&#39;, &#39;buzz&#39;, &#39;fizz&#39;, &#39;37&#39;, &#39;38&#39;,
  &#39;fizz&#39;, &#39;buzz&#39;, &#39;41&#39;, &#39;42&#39;, &#39;43&#39;, &#39;44&#39;, &#39;fizzbuzz&#39;, &#39;46&#39;, &#39;47&#39;,
  &#39;fizz&#39;, &#39;49&#39;, &#39;buzz&#39;, &#39;fizz&#39;, &#39;52&#39;, &#39;53&#39;, &#39;fizz&#39;, &#39;buzz&#39;, &#39;56&#39;,
  &#39;fizz&#39;, &#39;58&#39;, &#39;59&#39;, &#39;fizzbuzz&#39;, &#39;61&#39;, &#39;62&#39;, &#39;fizz&#39;, &#39;64&#39;, &#39;buzz&#39;,
  &#39;fizz&#39;, &#39;67&#39;, &#39;68&#39;, &#39;69&#39;, &#39;buzz&#39;, &#39;71&#39;, &#39;fizz&#39;, &#39;73&#39;, &#39;74&#39;, &#39;fizzbuzz&#39;,
  &#39;76&#39;, &#39;77&#39;, &#39;fizz&#39;, &#39;79&#39;, &#39;buzz&#39;, &#39;fizz&#39;, &#39;82&#39;, &#39;83&#39;, &#39;84&#39;, &#39;buzz&#39;,
  &#39;86&#39;, &#39;fizz&#39;, &#39;88&#39;, &#39;89&#39;, &#39;fizzbuzz&#39;, &#39;91&#39;, &#39;92&#39;, &#39;93&#39;, &#39;94&#39;,
  &#39;buzz&#39;, &#39;fizz&#39;, &#39;97&#39;, &#39;98&#39;, &#39;fizz&#39;, &#39;buzz&#39;]</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(np.<span class="built_in">sum</span>(testY.cpu().<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>].numpy() == np.array([fizz_buzz_encode(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">101</span>)])))testY.cpu().<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>].numpy() == np.array([fizz_buzz_encode(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">101</span>)])</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>95
array([ True,  True,  True,  True,  True,  True,  True,  True,  True,       
        False,  True,  True,  True,  True,  True,  True,  True,  True,        
        True,  True,  True,  True,  True,  True,  True,  True,  True,        
        True,  True,  True,  True,  True,  True,  True,  True,  True,        
        True,  True,  True,  True,  True, False,  True,  True,  True,        
        True,  True,  True,  True,  True,  True,  True,  True,  True,        
        True,  True,  True,  True,  True,  True,  True,  True,  True,        
        True,  True,  True,  True,  True, False,  True,  True,  True,        
        True,  True,  True,  True,  True,  True,  True,  True,  True,        
        True,  True, False,  True,  True,  True,  True,  True,  True,        
        True,  True, False,  True,  True,  True,  True,  True,  True,        
        True])</code></pre>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Python module</category>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Deep learning</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch-4-LanguageModel</title>
    <url>/2021/08/06/Pytorch-4-LanguageModel/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Pytorch-3-Word2vec</title>
    <url>/2021/08/05/Pytorch-3-Word2vec/</url>
    <content><![CDATA[<h1 id="study-goals">1. Study goals</h1>
<ul>
<li>学习词向量的概念</li>
<li>用 Skip-thought 模型训练词向量</li>
<li>学习使用 PyTorch dataset和 dataloader</li>
<li>学习定义 PyTorch 模型</li>
<li>学习 torch.nn 中常见的 Module
<ul>
<li>Embedding</li>
</ul></li>
<li>学习常见的 PyTorch operations
<ul>
<li>bmm</li>
<li>logsigmoid</li>
</ul></li>
<li>保存和读取 PyTorch 模型</li>
</ul>
<a id="more"></a>
<h1 id="word-vector">2. Word vector</h1>
<p>在计算机中如何表示一个词：</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZCUoR.png" style="zoom:80%;" /></p>
<p>可以使用一些上位词或同义词来形容某个词。但这样表示存在如下问题：</p>
<ul>
<li>不能分辨细节的差别</li>
<li>需要大量人为劳动</li>
<li>主观</li>
<li>无法发现新词</li>
<li>难以精确计算词之间的相似度</li>
</ul>
<h2 id="discrete-representation">2.1 Discrete representation</h2>
<h3 id="one-hot">2.1.1 One-hot</h3>
<p>使用 <code>One-hot</code> 来离散表示词向量。</p>
<ul>
<li><p>语料库 (Corpus)：</p>
<p>John likes to watch movies. Mary likes too.<br />
John also likes to watch football games.</p></li>
<li><p>词典 (Dictionary)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&quot;John&quot;</span>: <span class="number">1</span>, <span class="string">&quot;likes&quot;</span>: <span class="number">2</span>, <span class="string">&quot;to&quot;</span>: <span class="number">3</span>, <span class="string">&quot;watch&quot;</span>: <span class="number">4</span>, <span class="string">&quot;movies&quot;</span>: <span class="number">5</span>, <span class="string">&quot;also&quot;</span>: <span class="number">6</span>, <span class="string">&quot;football&quot;</span>: <span class="number">7</span>, <span class="string">&quot;games&quot;</span>: <span class="number">8</span>, <span class="string">&quot;Mary&quot;</span>: <span class="number">9</span>, <span class="string">&quot;too&quot;</span>: <span class="number">10</span>&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>One-hot representation</p>
<p>John: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] likes: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] too: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</p></li>
</ul>
<p><code>One-hot</code> 表示的特点：</p>
<ol type="1">
<li>词典包含 10 个单词，每个单词有唯一索引</li>
<li>在词典中的顺序和在句子中的顺序没有关联</li>
</ol>
<h3 id="bag-of-words">2.2.2 Bag of Words</h3>
<ul>
<li><p>文档的向量表示可以直接将各词的词向量表示加和。如：</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZPM0H.png" /></p></li>
</ul>
<p>词权重表示（词在文档中的顺序没有被考虑）：</p>
<ol type="1">
<li><code>TF-IDF</code>(Term Frequency - Inverse Document Frequency)</li>
</ol>
<p>Specifically, <code>TF-IDF</code> is defines as: <span class="math display">\[ {\rm{tf}\text{-}\rm{idf}}(t, d, D) = f _{t,d} \cdot \log \frac{N}{n_t} \]</span></p>
<p>where <span class="math inline">\(f_{t, d}\)</span> is the raw frequency of term <span class="math inline">\(t\)</span> in document <span class="math inline">\(d\)</span>, <span class="math inline">\(N\)</span> is the total number of documents in the corpus, and <span class="math inline">\(n_t\)</span> is the total number of documents containing at least one occurrence of term <span class="math inline">\(t\)</span>.</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZCNw9.png" /></p>
<ol start="2" type="1">
<li>Binary weighting</li>
</ol>
<p><img src="https://z3.ax1x.com/2021/08/05/fZPbjO.png" /></p>
<h3 id="bi-gram-and-n-gram">2.2.3 Bi-gram and N-gram</h3>
<p>为 <code>2-gram</code> 建立索引：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;John likes&quot;</span>:       <span class="number">1</span>,</span><br><span class="line"><span class="string">&quot;likes to&quot;</span>:         <span class="number">2</span>,</span><br><span class="line"><span class="string">&quot;to watch&quot;</span>:         <span class="number">3</span>,</span><br><span class="line"><span class="string">&quot;watch movies&quot;</span>:     <span class="number">4</span>,</span><br><span class="line"><span class="string">&quot;Mary likes&quot;</span>:       <span class="number">5</span>,</span><br><span class="line"><span class="string">&quot;likes too&quot;</span>:        <span class="number">6</span>,</span><br><span class="line"><span class="string">&quot;John also&quot;</span>:        <span class="number">7</span>,</span><br><span class="line"><span class="string">&quot;also likes&quot;</span>:       <span class="number">8</span>,</span><br><span class="line"><span class="string">&quot;watch football&quot;</span>:   <span class="number">9</span>,</span><br><span class="line"><span class="string">&quot;football games&quot;</span>:  <span class="number">10</span>,</span><br></pre></td></tr></table></figure>
<p>所以可以得到如下表示：</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZCJL4.png" style="zoom:80%;" /></p>
<p>而 <code>N-gram</code> 模型参数与 <code>N</code> 之间的关系：</p>
<center>
<img src="https://z3.ax1x.com/2021/08/05/fZipCt.png" style="zoom:50%;" />
</center>
<p><code>N-gram</code> 的优缺点：</p>
<ul>
<li>优点：考虑了词的顺序</li>
<li>缺点：词表的膨胀</li>
</ul>
<h2 id="distributed-representation">2.3 Distributed representation</h2>
<h3 id="preface">2.3.1 Preface</h3>
<p>从上一小节可以发现离散表示存在如下问题：</p>
<ol type="1">
<li><p>无法衡量词向量之间的关系</p>
<p>太稀疏，难以捕捉文本的含义。各种度量（与或非、距离）都不合适.</p></li>
</ol>
<center>
<img src="https://z3.ax1x.com/2021/08/05/fZCGyF.png" style="zoom:50%;" />
</center>
<ol start="2" type="1">
<li>词表维度随着语料库增长膨胀</li>
<li><code>N-gram</code> 词序列随着语料库膨胀更快</li>
<li>数据稀疏性问题</li>
</ol>
<p>为了弥补这些不足，对词编码表示提出如下要求：</p>
<ol type="1">
<li><p>词编码需要保证词的相似性。</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZC0W6.md.png" /></p></li>
<li><p>向量空间分布的相似性</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZCwJx.png" /></p></li>
<li><p>向量空间子结构</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZCsyD.md.png" /></p>
<p><span class="math display">\[
\begin{align}
V_{King} - V_{Queen} + V_{Women} &amp;= V_{Man} \\
V_{Paris} - V_{France} + V_{German} &amp;= V_{Berlin}
\end{align}
\]</span></p></li>
</ol>
<p><strong>最终目标</strong>：词向量表示作为机器学习、特别是深度学习的输入和表示空间。</p>
<p>因此，有学者考虑使用分布式表示来生成词向量。分布式表示即用一个词附近的其他词来表示该词。这也是现代统计自然语言处理中最有创意的想法之一。</p>
<p>如， <code>banking</code> 附近的词将会代表 <code>banking</code> 的含义。</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZCXYq.png" /></p>
<h3 id="word2vec-skip-gram-model">2.3.2 Word2Vec: Skip-Gram model</h3>
<p>该模型具有以下特点：</p>
<ol type="1">
<li>无隐层</li>
<li>投影层也可省略</li>
<li>每个词向量作为log-linear模型的输入</li>
</ol>
<center>
<img src = "https://z3.ax1x.com/2021/08/05/fZCDSK.png" style = "zoom:60%" />
</center>
<ul>
<li><p>目标函数 (Objective function)：</p>
<p><span class="math display">\[ \frac{1}{T} \sum^{T}_{t=1} \sum_{-c \leq j \leq c,\ j \neq 0}  \log (p(w_{t+j} | w_t ))\]</span></p></li>
<li><p>概率密度 (Probability density)</p>
<p>概率密度由 <code>Softmax</code> 给出：</p>
<p><span class="math display">\[ p(o|c) = \frac{\exp \left(u^T_o v_c \right)}{\sum^W_{w=1} \exp \left(u^T_w v_c \right)} \]</span></p>
<p><span class="math inline">\(o\)</span> 表示 <code>output</code>, <span class="math inline">\(c\)</span> 表示 <code>center word</code> 即输入。该训练模型存在一个问题：分母有一个 <code>summation</code> 操作，表示需要用中心词对语料库中所有词做一个点积，这会导致需要非常大的内容，训练过程会很慢。</p></li>
<li><p>损失函数 (Loss function)</p>
<p><span class="math display">\[
\begin{aligned}
  \min J &amp;= -\log P\left(w_{c-m}, \ldots, w_{c-1}, w_{c+1}, \ldots, w_{c+m} \mid w_{c}\right) \\
  &amp;=-\log \prod_{j=0, j \neq m}^{2 m} P\left(w_{c-m+j} \mid w_{c}\right) \\
  &amp;=-\log \prod_{j=0, j \neq m}^{2 m} P\left(u_{c-m+j} \mid v_{c}\right) \\
  &amp;=-\log \prod_{j=0, j \neq m}^{2 m} \frac{\exp \left(u_{c-m+j}^{T} v_{c}\right)}{\sum_{k=1}^{|V|} \exp \left(u_{k}^{T} v_{c}\right)} \\
  &amp;=-\sum_{j=0, j \neq m}^{2 m} u_{c-m+j}^{T} v_{c}+2 m \log \sum_{k=1}^{|V|} \exp \left(u_{k}^{T} v_{c}\right)
\end{aligned}
\]</span></p></li>
<li><p>负采样 (Negative sampling)</p>
<p><span class="math inline">\(P(w|\text{context}(w))\)</span>：一个正样本，<span class="math inline">\(V-1\)</span> 个负样本，对负样本做采样。</p>
<p><span class="math display">\[
\begin{align}
P(D=1 \mid w, c, \theta) &amp;= \frac{1}{1+e^{\left(-v_{c}^{T} v_{w}\right)}} \\
\log \sigma\left(u_{c-m+j}^{T} \cdot v_{c}\right) &amp;+ \sum_{k=1}^{K} \log \sigma\left(-\tilde{u}_{k}^{T} \cdot v_{c}\right)
\end{align}
\]</span></p>
<p>where, <span class="math inline">\(\{ \tilde{u}_k | k = 1 \dots K \}\)</span> is obtained by negative sampling.</p></li>
</ul>
<h3 id="word-embendding-visualization">2.3.3 Word embendding visualization</h3>
<ul>
<li><p>词向：公司 —— CEO</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZCrQO.md.png" /></p>
<p><span class="math display">\[
\begin{align*}
  \text{Fig. 公司} \leftrightarrow \rm{CEO}
\end{align*}
\]</span></p></li>
<li><p>词向：比较级和最高级</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZCOkn.png" /></p>
<center>
<p>Fig. 比较级和最高级</p>
</center></li>
<li><p>评估效果：词类比任务</p>
<p><img src="https://z3.ax1x.com/2021/08/05/fZCyOe.md.png" /></p>
<center>
<p>Fig. Accuracy on the analogy task for 300-D vectors trained on different corpora</p>
</center>
<p>19544个类比问题:</p>
<ul>
<li>Athens is to Greece as Berlin is to __?</li>
<li>Bigger is to Big as Greater is to __?</li>
</ul></li>
<li><p>效果评估：词相似度任务</p>
<center>
<p><img src = "https://z3.ax1x.com/2021/08/05/fZCceH.png" style = "zoom:60%" /></p>
</center>
<p>其中，<code>SVD</code> 模型只保留出现次数最大的 1 万个词，记为 <span class="math inline">\(X_{trunc}\)</span>，<code>SVD-S</code> 为 <span class="math inline">\(\sqrt{X_{trunc}}\)</span>，<code>SVD-L</code> 为 <span class="math inline">\(\log (1+X_{trunc})\)</span>。</p></li>
<li><p>效果评估：作为特征用于 <code>CRF</code> 实体识别</p>
<p><code>NER</code> 任务包含 437, 905 个离散特征，额外的 50 维连续特征。</p>
<center>
<p><img src = "https://z3.ax1x.com/2021/08/05/fZC2TA.png" style = "zoom:60%" /></p>
</center></li>
</ul>
<h1 id="implement-word2vec-with-pytorch">3. Implement Word2Vec with pytorch</h1>
<h2 id="简介">3.1 简介</h2>
<p>该文档中使用的训练数据可从如下方式下载：<a href="https://www.aliyundrive.com/s/SVoAJqKvsME">Click Here</a>。</p>
<p>在本节的代码中，尽可能尝试复现论文 <a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Distributed Representations of Words and Phrases and their Compositionality</a> 中训练词向量的方法. 我们会实现 <code>Skip-gram</code> 模型，并且使用论文中 <code>noice contrastive sampling</code> 的目标函数。</p>
<p>这篇论文有很多模型实现的细节，这些细节对于词向量的好坏至关重要。虽然无法完全复现论文中的实验结果，主要是由于计算资源等各种细节原因，但是我们还是可以大致展示如何训练词向量。</p>
<p>以下是没有实现的细节:</p>
<ul>
<li>subsampling：参考论文section 2.3</li>
</ul>
<p>本章节的代码主要借助 <a href="https://colab.research.google.com/notebooks/intro.ipynb">Google colab</a> 平台进行实现。</p>
<h2 id="implementation">3.2 Implementation</h2>
<h3 id="platform-and-enviroment-setting">3.2.1 Platform and enviroment setting</h3>
<ul>
<li><p>Mount google driver</p>
<p>借助 <code>Google driver</code> 可以上传个人文件以及保存 <code>notebook</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">&#x27;/content/drive&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&quot;/content/drive&quot;, force_remount=True).</code></pre></li>
<li><p>GPU Setting and information</p>
<p>由于训练量较大，使用 <code>GPU</code> 进行训练词嵌入模型，<code>Colab</code> 可以免费使用 <code>GPU</code> 和 <code>TPU</code>。操作方式：<span class="math inline">\(\rm{Edit \rightarrow Notebook settings \rightarrow Hardware accelerator \rightarrow GPU \rightarrow Save}\)</span>。</p>
<p>查看装在的 <code>GPU</code> 信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!nvidia-smi</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>Wed Aug  4 09:29:20 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+</code></pre></li>
</ul>
<h3 id="load-modules-and-procession">3.2.2 Load modules and procession</h3>
<ul>
<li><p>Load modules</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> tud</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line"></span><br><span class="line">USE_CUDA = torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">random.seed(<span class="number">1</span>)</span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">torch.manual_seed(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">if</span> USE_CUDA:</span><br><span class="line">  torch.cuda.manual_seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Seting hyper parameters</span></span><br><span class="line">K = <span class="number">100</span> <span class="comment"># number of negative samples</span></span><br><span class="line">C = <span class="number">3</span> <span class="comment"># context window</span></span><br><span class="line">NUM_EPOCHS = <span class="number">2</span> <span class="comment"># The number of epochs of training</span></span><br><span class="line">MAX_VOCAB_SIZE = <span class="number">30000</span> <span class="comment"># the vocabulary size</span></span><br><span class="line">BATCH_SIZE = <span class="number">128</span> <span class="comment"># the batch size</span></span><br><span class="line">LEARNING_RATE = <span class="number">0.2</span> <span class="comment"># the initial learning rate</span></span><br><span class="line">EMBEDDING_SIZE = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">LOG_FILE = <span class="string">&quot;word-embedding.log&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_tokenize</span>(<span class="params">text</span>):</span></span><br><span class="line">  <span class="keyword">return</span> text.split()</span><br></pre></td></tr></table></figure></li>
<li><p>Load data and count data</p>
<ul>
<li>从文本文件中读取所有的文字，通过这些文本创建一个 <code>vocabulary</code></li>
<li>由于单词数量可能太大，我们只选取最常见的 <code>MAX_VOCAB_SIZE</code> 个单词</li>
<li>我们添加一个 <code>UNK</code> 单词表示所有不常见的单词</li>
<li>我们需要记录单词到 <code>index</code> 的 <code>mapping</code>，以及 <code>index</code> 到单词的 <code>mapping</code>，单词的 <code>count</code>，单词的 <code>(normalized) frequency</code>，以及单词总数。</li>
</ul>
<p>加载数据和计算词频：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;/content/drive/MyDrive/Word_embedding/text8.train.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> fin:</span><br><span class="line">  text = fin.read()</span><br><span class="line"></span><br><span class="line">text = text.split()</span><br><span class="line">vocab = <span class="built_in">dict</span>(Counter(text).most_common(MAX_VOCAB_SIZE - <span class="number">1</span>))</span><br><span class="line">vocab[<span class="string">&#x27;&lt;unk&gt;&#x27;</span>] = <span class="built_in">len</span>(text) - np.<span class="built_in">sum</span>(<span class="built_in">list</span>(vocab.values()))</span><br><span class="line"></span><br><span class="line">idx_to_word = [word <span class="keyword">for</span> word <span class="keyword">in</span> vocab.keys()]</span><br><span class="line">word_to_idx = &#123;word:i <span class="keyword">for</span> i, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(idx_to_word)&#125;</span><br><span class="line"></span><br><span class="line">word_counts = np.array([count <span class="keyword">for</span> count <span class="keyword">in</span> vocab.values()], dtype = np.float32)</span><br><span class="line">word_freqs = word_counts / np.<span class="built_in">sum</span>(word_counts)</span><br><span class="line">word_freqs = word_freqs ** (<span class="number">3.</span>/<span class="number">4.</span>)</span><br><span class="line">word_freqs = word_counts / np.<span class="built_in">sum</span>(word_counts)  <span class="comment"># 用来做 negative sampling</span></span><br><span class="line">VOCAB_SIZE = <span class="built_in">len</span>(idx_to_word)</span><br></pre></td></tr></table></figure>
<p><strong>Notes:</strong> 本人将项目文件存储在谷歌云盘的 <code>/content/drive/MyDrive/Word_embedding/</code> 目录下，如想复现改代码，应将该项目文件夹改为个人文件夹目录，下同。</p></li>
<li><p>Create Dateset and Dataloader</p>
<p>一个 <code>dataloader</code> 需要以下内容：</p>
<ul>
<li>把所有text编码成数字，然后用 <code>subsampling</code> 预处理这些文字。</li>
<li>保存 vocabulary，单词 count，normalized word frequency</li>
<li>每个 iteration sample 一个中心词</li>
<li>根据当前的中心词返回 <code>context</code> 单词</li>
<li>根据中心词 sample 一些 negative 单词</li>
<li>返回单词的 counts</li>
</ul>
<p>有了 dataloader 之后，我们可以轻松随机打乱整个数据集，拿到一个 batch 的数据等等。这里有一个好的 tutorial 介绍如何使用 <a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html">PyTorch dataloader</a>. 为了使用 dataloader，我们需要定义以下两个 function:</p>
<ul>
<li><code>__len__</code> <span class="math inline">\(\rm Function\)</span> 需要返回整个数据集中有多少个 <code>item</code></li>
<li><code>__get__</code> 根据给定的 <code>index</code> 返回一个 <code>item</code></li>
</ul>
<p>先创建 <code>Dataset</code> 类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordEmbeddingDataset</span>(<span class="params">tud.Dataset</span>):</span>    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, text, word_to_idx, idx_to_word, word_freqs, word_counts</span>):</span>        <span class="string">&#x27;&#x27;&#x27; text: a list of words, all text from the training dataset            word_to_idx: the dictionary from word to idx            idx_to_word: idx to word mapping            word_freq: the frequency of each word            word_counts: the word counts        &#x27;&#x27;&#x27;</span>        <span class="built_in">super</span>(WordEmbeddingDataset, self).__init__()        self.text_encoded = [word_to_idx.get(t, VOCAB_SIZE-<span class="number">1</span>) <span class="keyword">for</span> t <span class="keyword">in</span> text]        self.text_encoded = torch.Tensor(self.text_encoded).long()        self.word_to_idx = word_to_idx        self.idx_to_word = idx_to_word        self.word_freqs = torch.Tensor(word_freqs)        self.word_counts = torch.Tensor(word_counts)    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span>        <span class="string">&#x27;&#x27;&#x27; 返回整个数据集（所有单词）的长度        &#x27;&#x27;&#x27;</span>        <span class="keyword">return</span> <span class="built_in">len</span>(self.text_encoded)    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span>        <span class="string">&#x27;&#x27;&#x27; 这个function返回以下数据用于训练            - 中心词            - 这个单词附近的(positive)单词            - 随机采样的K个单词作为negative sample        &#x27;&#x27;&#x27;</span>        center_word = self.text_encoded[idx]        pos_indices = <span class="built_in">list</span>(<span class="built_in">range</span>(idx-C, idx)) + <span class="built_in">list</span>(<span class="built_in">range</span>(idx+<span class="number">1</span>, idx+C+<span class="number">1</span>)) <span class="comment"># window 内单词的 index        pos_indices = [i%len(self.text_encoded) for i in pos_indices] # 取余，防止超出 text 长度，将文本闭环 -1%10 = 9        pos_words = self.text_encoded[pos_indices]  # 周围单词        neg_words = torch.multinomial(self.word_freqs, K * pos_words.shape[0], True) # 负采样单词        return center_word, pos_words, neg_words</span></span><br></pre></td></tr></table></figure>
<p>创建 <code>Dataset</code> 和 <code>Dataloader</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset = WordEmbeddingDataset(text, word_to_idx, idx_to_word, word_freqs, word_counts)dataloader = tud.DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = <span class="literal">True</span>, num_workers = <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>为了更好理解 <code>Dataloader</code> 中返回的内容，查看其信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):  <span class="keyword">for</span> i, (input_labels, pos_labels, neg_labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):    print(input_labels, pos_labels, neg_labels)    <span class="keyword">if</span> i &gt; <span class="number">0</span>:      <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>tensor([ 1769,    62,    11, 21115,  6716, 29999,  1045,   138,   460, 29999,
        29999, 29999,     1,    18,  9235,     2,  8312,     9, 13824, 29999,
        29999,  1714,    22,  1562,     0,    30,     0,     0,    22,   990,
          445,    33,  4390,  7219,     0,   255,  1217,     5,     1,     4,
           29,    20,     0,  2487,  1534,   991,     3,    18,    28,   141,
          193,  2800,     1,     9,   337,   127,   157,   149,   107,   236,
            6,    84,    43, 29828,    52,   403,   186,    83,  1265,   552,
            2,   595,  2798,    33,    12,  8462,    10,   127,  8872,  1514,
         6620,   217,     1,  3680,  5804,     5, 29999,   956, 19058, 21389,
          495,    39,    30,   349,   416,    11,     5,     1,     1,     6,
            1,   122,   211,  2719,   873,     0,    22, 24620,    22,    93,
            0,   535,    99,  1734,     3,  1269,  5909,     3,    15,  5069,
         1706, 17024, 29999,    28,   169,   129,  5025, 10759]) tensor([[27921,     1,   107,  3219,    40,     5],
        [ 3832,   634,  1536,   116,  2567,   938],
        [  661,   296,   620,   227,   774,  4676],
        [   98,  8425,    29,    34,  1069,    60],
        [   22,   253,    66, 16886,    38,    49],
        [29999,   604, 29999,  4965,     3,     8],
        [ 2274,  1081,    10,     4,     0,  2128],
        [   11,    30,   616, 29999,    17,    52],
        [   15,     7,    22, 10132,     6, 14444],
        [   51, 29999,     2,    32,   194,    10],
        [13251,     0,   540,    17,    37, 29392],
        [   86,    11, 26305,     4,     0,    42],
        [ 6604,     0,   553,     0,  6818,   387],
        [  496,   246,   331,   482,   312,     0],
        [28413,   451,   400,  1494,  1861,     1],
        [  245,   143, 29999, 29999,     7,  4501],
        [ 6623,    26,    68,    75,  3511,    76],
        [    9,    15,     3,     7,     7,    15],
        [ 1812,     1,  3571,  9824,     0,   258],
        [ 1535,   811,   877,  1535,   811,   877],
        [    3,    20,     9, 26166,   537,    16],
        [ 1326,   168,   639, 29999,   325, 11916],
        [    3,     8,    15,    26,    17,   108],
        [10360,     2,   940,    60,     5,   182],
        [    2,  2319,    24,  4398,     1,   458],
        [    0,  3476,    38,   139,  1114,  3434],
        [    5, 26413,   143,  1797,    17,    45],
        [  617,    46,   736, 14267,    55,  3435],
        [    3,     8,     3, 29999, 12448,  7130],
        [   22,    15, 29999,    17,     0,    45],
        [  142,     0,  9504,    10,   205,  1181],
        [    2,  1305, 28342,  1968,     5,   979],
        [  420,   711,  2959,     1, 29999,     4],
        [    3,    16,    12,    47,   527,     0],
        [   11,   470,     1, 29999,     2,   780],
        [   31,  4261,    23,    96,   108,     1],
        [  199,   238,   100, 13330,     1,  1259],
        [  232,     6,    31,   851,  1244,  1210],
        [    1,  2191,  2570,   112,     1,  2191],
        [    2,   731,  5379,     3,     8,     3],
        [    0,   125,  6752,   686,    18,  5659],
        [    9,     7,     7,     0, 17323,    40],
        [    1,   158,     1,   674,  2110,   302],
        [ 1625,  2125,     2,   374, 28455,     4],
        [   19,     0,    66,  5072,  3224,  5683],
        [11916,   991, 29999,  6102,   634,   524],
        [13946,   277,   118,     8,     8,    12],
        [    0,   246,   365, 18480, 13442,     4],
        [  619,   598,  8108,   227,  8108,    26],
        [ 1978,    18,   183,  2042,  3594,   511],
        [   90,  1265,  1901,     1,    50,    63],
        [ 8943, 12354,     0,  1355,     2,    89],
        [   17,     5,   928,  8299,     1,  3773],
        [    3,    12,     3,  3180, 12330, 29999],
        [  389,     0,   246,     2,  1090,     4],
        [   29,  3445,    27,  3698,   185,    29],
        [11829,    28, 10866,  2075,     3,    20],
        [ 7794,     1,     0, 12126,     1,     0],
        [   18,  4313,    19,   767,    72,    70],
        [  932,  1981,     4,   788,  4574,  3862],
        [   37,    31, 16090,    11,     0, 29999],
        [    2,   114,     0,    80,   773,  1456],
        [  804, 12614,     2,  2046,     4,   187],
        [ 1705,  1218,    18,    35,    17,  1369],
        [  838,   609,     0,  7808,  4002, 10387],
        [ 2060,    47, 13230,     0, 29999,     2],
        [   27, 23856,    25,  3948,    23,     0],
        [ 6476,     6,    52,    26,    10,   696],
        [ 7862,    13,     0,   435,    41,    26],
        [   53,    56,  9364,   582,     0,  1797],
        [ 2546,    23,    65,    42, 29999,  4262],
        [  465,    82,     4,     2,  3584,     1],
        [ 2549,  1472,     2,  2005,    19,    33],
        [   16,     7,    14,  1167,    34, 14015],
        [  398,   274,     7,    20,     9,    16],
        [   55,   288,     0,     1,     0,   376],
        [  215,     6,  5502,   696,     6, 24355],
        [ 4479,     4,     0,    81,     1,     0],
        [ 5458,  6299,    23,    49, 14646, 29424],
        [ 1192,     6,    31, 17208,  4060,  1592],
        [    1,  7227,    67,     2,  3004,  3581],
        [  941,  1300,    23,  1918,  6600,  4329],
        [    0,   413,   113,  6058,    26,    40],
        [    0,  2736,   524,     5,   874,    23],
        [   14,   159,  6298,  1967,    38,   265],
        [16474,   188, 14056,   122,  4866,   109],
        [    1,     0, 29999, 29999,     5,   170],
        [ 1702,     2,     0,  3249,    10,  6748],
        [   45,  2249, 15372,  2155,   987,    24],
        [  738,    24,     0,   421,     3,     9],
        [    2, 22746,  1041,    13,    21,    81],
        [    0,  8999,  3115,   108,    64,  8659],
        [  347,    18, 11663,  2067,   223,  3300],
        [14809, 18381,  2367,    23, 29999, 29999],
        [  355,     5,  1485,     4,    44,  1213],
        [ 1699,    11,   110,    42, 17711,   105],
        [    0,  4378,    34,  1818,     1,     0],
        [  148,   300,   121,   325,   570,   225],
        [    5,   171,   137,     5, 29999,  2936],
        [   28,   603, 10573,    31,    59,     4],
        [    0,   979, 28719,  1363,     4,   387],
        [ 3548,  5920,    13, 14810,  8828,    27],
        [ 2763,    26, 29999,    12,    20,     7],
        [  143,     1,     0,  5336,  1628,   962],
        [ 7466,    50,     1,    39,  1705,   948],
        [    0,   172,    10,   120,     1,     5],
        [    4,    29,     3,    12,    15,  2973],
        [    7,     7,     8,     9,     7,     7],
        [  128,     9,     3,   128,    21,   128],
        [  114,    32,  2546,    19,     0, 19029],
        [   20,     2,     4,   937,     3,     8],
        [   13,    44, 29999,     2,    40,    37],
        [ 3267,     6, 29999,    26,  1284,   235],
        [    0, 26803,  2946,    32,   860,     4],
        [ 1278,   731,     2,   161,  3112,   211],
        [    0,  1598,     2,    32,   298,  1991],
        [    1,    16,  3998,    19,    25,  2796],
        [   12,     9,    16,    12,     8,    20],
        [   22,     3,     8,     3,   506,     3],
        [ 3402,    34,  4350,     6,   181,    97],
        [    1,   468,   845,     1, 14700,     2],
        [    1,   593,  2870, 12722,    10,   148],
        [  742,  1811,    74,     2, 19377,     0],
        [  256,    97,  3249,  6112,  7338,   213],
        [ 4258, 11709,  2797,   156,  3120, 29999],
        [    8,     3,    20,    12,     8,     3],
        [  261,     4,  1856,   321,     6,     5],
        [   82,  5767,     2, 20954,    79,     5]]) tensor([[    1,    12,    15,  ...,    65,     7, 11553],
        [10142,     0,    81,  ..., 28522,   147,    31],
        [    5,     0, 29999,  ...,  5896,     6, 29999],
        ...,
        [ 3780,   818,    58,  ...,     0,    24,   178],
        [ 1756,   416,    23,  ...,   398,  1444,     2],
        [    1,   203,  8880,  ...,     0, 16466,     3]])
tensor([  114, 24821,  3643,     0,  1354,   198,   808,  1074,   268,   231,
          223,  1095,     3,  2658,   484,     1, 10670,   208,   753,     4,
         6583,     2,    29,   345,   802,     0,  7046,    23,    85,   101,
           32,    49,   100,     8,     6,     5,     6,  6905,    12,  1525,
          166, 28670,   953,   796,   147,     7,   200,    74,  3542,    21,
            7,     2,   105,    22,    18,     3,    21,   880,    16,    18,
         2510,     0,    32,    32,     6,   592,    27,  2351,    34,    30,
            0,    74,   248,  7749,     3,     3,    90,     4,    12, 16497,
          374, 29999,    96,    49,     6,     1,     6, 18399,    15, 26517,
            0,     7,    92,    13,     7,   543,   349,   214,   318,  2925,
           15,  3925,   255,   889,    57, 10978, 29999,     3,   445,     6,
         1355,    14,  1061,   325,     6, 29999,   113,     3,   343,    16,
           56,  1841, 29379, 16743,     5,  1302,    15,     4]) tensor([[    5, 26934,  8395, 15733,    18,  6126],
        [18869,   348,    11,  3206,  4183,   673],
        [10297,     1,    32,    10,     0, 13983],
        [ 5245,    82,    23,   122,    76,     2],
        [   11,   547,     6,     0,  4723,    11],
        [   23,     0,  3048,     2,     0, 12032],
        [24168,    23, 29999,  3273,     6,  5672],
        [ 1399, 20662,  1048,    62,    26,   133],
        [   29,   164,  1606, 29931,  2455,     4],
        [ 5865,   251,     0,  4031,     1,  2551],
        [   22,   129,   947, 29999, 29999,     9],
        [  131,    18,     0,   271,    13,  1700],
        [  145,  1093,  2921,     8,    22,    16],
        [    6,  1327,   599,  3433,    19,  4501],
        [29999,  8372,    34,   168, 12123,   204],
        [    5,   379,   419,  9281,     6, 22491],
        [29999, 13761, 29999, 26259,     2, 29999],
        [ 1649,    41,     3,    93,  4492,     0],
        [17917,    40,    53,    26,    40,   297],
        [29999, 16765, 29999,     3,     8,     8],
        [   19,     0,   258,   275,    31,  3670],
        [29999,   153,  1263,   438,  4615,    73],
        [    3, 13732,  8965,  1661, 11719,    34],
        [  705,     6,    30, 12289,     9,   398],
        [ 1687,     1,     5,   562,  2086,     5],
        [    0,  2337,    60,  1566,     1,    20],
        [ 6824, 20608,     2,  3965,  6967,     0],
        [  100,    76,    11,     0,   986,     1],
        [ 2884,     0,    63,    35,     0,   295],
        [ 3259,     0, 21208,     1, 29999,  4596],
        [   19,    87,    93,    17,   124,    33],
        [  762,     6,    75,    69,     3,  6051],
        [  466, 29999,    14,  1217, 29252,     1],
        [23471, 20947,     3,    15,    15,     4],
        [   42,   418,   215,  1887,   106,     0],
        [   25,  8017, 14104,  6962,     1,  2039],
        [    2,     0,  4998,     0,  2337,    27],
        [29999,    33,    17,  4797,   154,  9199],
        [    3,     8,    20,   360,     4,   549],
        [   63,     0,   956,    17,   738,   237],
        [18393,    17,     5,   187,  1812,     2],
        [   15, 24879,  5332,     0,  5332,  2873],
        [ 3855,  1879,  9754,   303,     6,     0],
        [    0,   717,    19,  6867,   143,    10],
        [  796,    46,    38,   611,  4040,    69],
        [   15,     7,     7,     6,    12,     7],
        [    0,   574,  2500,  1681,  6476,     5],
        [24664,  6351,   336,    36,  1011,    30],
        [  109,   146,     0,  9640,     4,   100],
        [   18,   102, 27813,  2648,     8,  5062],
        [    7,     7,     7,     7,   548,   151],
        [  702,   124,    15,     3,  1710,     6],
        [  161,    31,  3692,    56,  3371,   487],
        [    9,    22,    22,    15,     8,     9],
        [    5, 15146,  6872, 29999,     0,  6617],
        [   32,  1952,    11,   267,    36,   988],
        [    7,     3,     8,    16, 10123,  1052],
        [  115,    34, 19711,     0, 19711,  1696],
        [ 4763,    72,     3,     9,    12,     3],
        [   74,    31,   195,     0,   131,     9],
        [ 4317,  3652,    10,  2683,  1950,    87],
        [  135,    48,     1,   296,   559,   488],
        [   13,   770,     4,  1271,  2752,    14],
        [    7,     7,     4,  3032,    21,    16],
        [   26,   909,  2175,  2157,  7098,  3073],
        [29999,    84,    80,  9183,  4937,    84],
        [12515,  2446,   334,     0,   228,   469],
        [    0,   252,    19,    30,   395,  1377],
        [27175,  2793,  2686, 29999,    39,  3184],
        [ 5926,     2, 29999,  1543,   113,    39],
        [  196,   103,   256,   219,  2892,     5],
        [  415, 20568,    19,  7434,  4395,    19],
        [  643,    33,    47,   131,    83,  3041],
        [  139,    11,    46,  3378,    43,   546],
        [    3,     8,    22,     3,     8,    22],
        [  168, 29999,     4,     9,     3,     9],
        [    0,     9,    20,     1,   522,  6825],
        [29999, 29999, 29999,     3,     8,     8],
        [    7,     3,     8,     7,    62,    33],
        [  879,   289,    18,  1881,     5,    45],
        [ 3138, 18947,    37,  2749,    34,   869],
        [  273,    18,   466,     2,     0, 21473],
        [  231,  2467,    55,  1557,   115,   103],
        [ 5183,  1341,   772,    28,   297,   423],
        [ 1989,     0,  4091,   179, 29999,   209],
        [ 2645,    11,   158,   832,     2,   556],
        [   17,   601,  1174,    31,  7189,    26],
        [  303,  5280,  1511,    25,     0,  3176],
        [  743,     3,    12,    22,     3,     8],
        [   63,     5,   932,  5046,  1782,    17],
        [ 2505,     1, 16297,  2090,   530,   785],
        [  904,     3,    22,     7,   324,     3],
        [    0,   194,  6603,    48,  1143,    32],
        [   49, 26787,   120,    26,    69,     0],
        [  117,     3,     8,    20,    16,    22],
        [   12,    12,    42,     1,     0,   120],
        [    1,  3640,    46,    23,    52,  9218],
        [  330,   194,  8839, 11850,  3811,     2],
        [   16,    12,    30,     1, 29999,     0],
        [  915,     2,     6,   148,   606,  8534],
        [   22,     3,    20,    20,    16,     3],
        [   43,   425,     4, 18482,    58,    25],
        [  111,    23,  2067,  1290,     4,   544],
        [  405,    85,     0,     1,    50,    16],
        [17000,   483,     5,    10,   420,    13],
        [    1,     0,    52,    78, 11046,     4],
        [29999,   607,   639,     4,   458,     9],
        [ 1625, 23748,  1948, 22018,    23, 29999],
        [    1,     0,  5176,  2223,   520,  5585],
        [    3,    20,    17,  2677,   115,    13],
        [  316,    13,  2508,     4,   544,   909],
        [ 3694,  5493,   486,   145,  3109,   759],
        [  178,     0,  3728,     1, 11821,   295],
        [    8,     3,    15,  9757, 17544,  4319],
        [    6,  5581,     2,  4700,  3564,    64],
        [ 5766, 10352,   370,   692,     9,     7],
        [   27,    30,  1383,     1,  4736,     0],
        [  492,     4,    68,     8,    12,     7],
        [  509,     3,     7,     6,  1654,    16],
        [    3,     8,    16,     2,     3,     8],
        [    0,   691,     1, 29999,    26,   160],
        [10949, 29999,     0,     1,     0,  3207],
        [   71,    82,    70,   646,    75,   125],
        [    4,  3299,   107,     2,  3490,     1],
        [  828, 14648,     4,   330,   277,     1],
        [ 3312,    62,   632,    44,  4414,    18],
        [   15,     3,    22,     9,    16,  8018],
        [   70,  2347,  1678,   321,  4501,    70]]) tensor([[   49,   600,   192,  ...,     8,  2511,   346],
        [  419,    28,  1657,  ...,     8, 29999, 29999],
        [  395,  4000,   707,  ...,   715,   501,     4],
        ...,
        [    1,     6,     0,  ...,    94,    16,  2011],
        [    1,   651,  2439,  ...,  2007,  2533, 29999],
        [   19,   149,     0,  ...,   322,  1110, 29999]])
tensor([    0,     2,     4,   639,    16,    46,     0,   586, 29999,     8,
          768,    16,  1193,  5799,  2742,    21,     0,     9,   592,     1,
            0,  1227,     5, 19147,  4886,     5,     2,   423,     1, 29999,
         1402,  1351,     8,   682,    27,    14,   279,     3,     0, 12738,
          291,    42,     0, 15221,     6,    13,    28,   288, 29999,   490,
           49, 15922,   122,     1, 29999,   247,     4,   416, 11035, 22725,
            7,     0,   371,     2,  1447,  3366, 29999,     1,  3731,  3974,
            1,    68,   598,   782,   619,     4,  3465,  1266,  2507, 29999,
          645,  3280,  1739,     4,    37,  7130,    38,    15,  1029,  1314,
           30,     4,   219, 17848,  9703,     0,    10,     0,   821,   654,
            2,     0,   163,  1818,  3401,    31, 29999,  6968,    14,     0,
            5,     6,    36,     1,   178,     1,     2,  8386,  1810, 25037,
            2,    25,   255,    18,     1, 29999,  3989,  7394]) tensor([[ 7312,   584,    98,    40,  1898,    30],
        [29999,  1178,  3594,   799,  4615,     1],
        [  885,    39,   432,     0,   231,  2085],
        [    2,  9176,     4, 28349,   315,     2],
        [    3,     8,     8,  2895,     5,    94],
        [  701, 29999,    28,    51,    31,  2399],
        [ 1850,    82,   747,   784,     1,     0],
        [   10,    36,     5,     2,  3095,    38],
        [    5,   457,     1, 12358,  7160,    18],
        [   12,     8,     8,  1981,   467,   860],
        [ 3798,     1,   147,   185,     0,   333],
        [ 4613,     2,     3,    42,   642,    80],
        [ 1787,   478,   652,  1714,     2,   239],
        [    0,   400,   351,     4, 21707,  2544],
        [   19,  1668,     4,  5599,  1940,  2846],
        [   20,  1632,  3205,     3,    22,     9],
        [    0,  1114,     1,  1563,     2,  1730],
        [29999, 29999, 29999,     7,     7,     7],
        [24326,  9658,   122,     3,     8,    16],
        [   10,     5,   143,  1283,    19,    10],
        [    4,     0,    71,   290,  3719,     3],
        [   23,     5, 29999,  4185,    91,    89],
        [   40,  2920,    11,   234,  4062,   444],
        [ 3155,     1,     5,   109,   146,     0],
        [29999,     1,     0,  9693,  2882,   529],
        [29999,  2139,  8300,    10,    37,    86],
        [29999,   539,  1821,  2458,    73,     3],
        [  293,  3278,     6,  7628,    41,  4317],
        [    1,     0,  8731,     0,  1821,  1259],
        [29999,   610,    14,  2231,  2798,  3175],
        [29999,   155,  1756,     4,    65,   591],
        [    1,    65,    25,   217,  1649,     2],
        [   85,     3,     8,    21,    76,     0],
        [  179,     1,   164,    24,     9,     7],
        [  768,     2,  2018,     0,  9733,     4],
        [ 1507,     1, 29999,  1507, 29999,   327],
        [ 3349,  1529, 17952,     9,   341,  1403],
        [  206,     3,  1188,     8,     3,     3],
        [   19,  1862,    18,   202,     5,   238],
        [  604,  1722, 28764,   810,  3046,  2817],
        [   24,   269,     1,    28,   728, 20483],
        [  483,     6,     0,    24,     0,     3],
        [29999,     2,   195,   101,     1, 23172],
        [   39,   417,   353, 23525,  5843,    28],
        [   10,    36,  1462,    46,    47,     5],
        [    6,    29,  6286,   211,     9,  2011],
        [    1,   671,    10,   275,    31,   121],
        [  339, 13848,    19,     4,   545,     9],
        [  199,    92,     1, 13518,     6,     5],
        [ 1190,   193,     2,   178, 29999,    35],
        [ 1158,     3,    28,  2772,  2160,    23],
        [   37,  1791,   212,   478, 15922,   559],
        [29999, 19796,   105,   187,    28,  4410],
        [  495,     0, 27209,    30,  1372,  1163],
        [  192,    46,    25,     2, 24540,     2],
        [  109,   146,   447, 16395, 10670, 29468],
        [  147,  3482,     2,   549,  1808,   157],
        [  173, 29999,    43,   213,    36,    76],
        [    5,     9,  5561,  3643,   781,  3643],
        [24853,    44, 12066,    37,  1173, 29999],
        [28163,   484,     9,     7,     9,   497],
        [    2,  1380,    18,  1230,   310,     0],
        [   30,  1029,    68,    48,    63,    11],
        [  167,   603,   147,    31,   603,  6968],
        [   23,     5,   494, 29999,    19,   335],
        [21385,   587,     0,  1119,    10,    30],
        [ 9226,     4,   116,     4,     0,   291],
        [   80,     4,   459,    44,  5568,    11],
        [    1, 26924,   142,    17,   186,   356],
        [   45,    17,     5,     1,   284,  1951],
        [   79,     3,   343,    57,  1428,     6],
        [ 1180,    98,    46,    66,    31,  3119],
        [ 1051,  1027,  6398,  2959,    14, 29999],
        [ 9620,    46, 12880,    93,  2007,    23],
        [  205,   167,    36,  1423,    58,    25],
        [    2,   634,  1824,     9,     7,     7],
        [11057,   817, 10302,   211,     0,  1203],
        [    0, 12412,   234,     1,  4465,   311],
        [   21,     7,     7,    22,    12,     7],
        [   33,  1895,    23, 29999,     2,   133],
        [  195,    24,     0,    11,     0,  5476],
        [ 1278,  1209,     6,   111,    27,     0],
        [ 6371,    19,     5,    47,   908,  3265],
        [  235,   405,  3466,  5567, 13254,    19],
        [13561,    41,    10, 10922,     0, 10922],
        [   22, 29999, 12448,   479, 28965,    73],
        [  107,     1,    35,    43,   201,  2090],
        [    0,   178,   109,     7,   845,     0],
        [  173,  1008,  9741,   660,  1436,   182],
        [   23,     0,  6179,     1,  4128,   842],
        [  550,   316,    60,  1487,  3936,  7674],
        [   25,   160,   513,     0,  1849,  4887],
        [ 6624,     4,     0,   276,     4,    52],
        [ 2194, 17379,     1,  1614,     4,     5],
        [29999,   238,     4,     3,     8,    16],
        [  108,  3690,    24,   920,   375, 15170],
        [15347, 15371,  2966,    30,   241,  1711],
        [ 5593, 29999, 24206,   947,  3006,     4],
        [ 1811,     4,    61,  1380,    18,   473],
        [    1,   187,    10, 22244,    18,   347],
        [    1,   361,  3312,   330, 29999,  3610],
        [ 4273,     2,  1181,    57, 11847,     1],
        [    0,  2950,   250,  1057,    84,  5706],
        [  444,    30, 29999,   259,    19,  3334],
        [    3,   226,  7404,  2139,    72,     3],
        [ 2936,  2747,   161,  2411,    64,     5],
        [  867, 16747,     2,     4,   549,    81],
        [  837,    10,    76,     2,    56,    72],
        [  989,   598,   811, 22407,    92,    10],
        [   19,   909,   845,  3167,     1,     0],
        [  618, 15522,    11,   348,    13,    83],
        [   55,   673,    24,     5,   855,   538],
        [    2,  3480,    17,  4124,  1429,     6],
        [   11,     5,  3806, 29999,     2, 29999],
        [    7,    14,   490, 18904,     0,   375],
        [   28,    79,   319,     0,  1839, 18476],
        [ 3316,  8058,  6485,  4175,   836,    40],
        [    8,    21,     0,   690,   301,   971],
        [ 1668,     4, 13742,     1,   946,  2552],
        [   15,    16,  6084, 23092, 10213,  1862],
        [   29,    16,  6412, 29999, 14780,  6112],
        [   20,  2207,   277, 29999,    77,     9],
        [  357,     1,     5,   524,  1175,     5],
        [  523,     1,  9470,  6530,   478,     1],
        [    5,   634,   863,  4150,  1583,    14],
        [  137,     1,     5,     4,     5,  4044],
        [ 2518,    73,  8433, 29999,     2, 15104],
        [    0,  8595,     1,    40,    53,  6398]]) tensor([[  145,    14,  5093,  ...,    32,  5613,     4],
        [   27,    28, 29999,  ...,   843,     1,    22],
        [   71,    18, 17354,  ...,  2574,     1,    50],
        ...,
        [ 2736,   338,  1649,  ..., 19324,   309,     6],
        [    6,     0,  1218,  ...,  3399,   594,    77],
        [  377,  1768,    11,  ...,     3,     2,    13]])
tensor([  469,    41,    88,     5,   889,  3089,   106,     0,   365,     9,
        29999,   981,   980,    13,     2,  6325,     0,     0,    99,   363,
            2,  3557,   308,  1270,  4474, 29999,  4082,  3310,  1827, 19417,
         1268,   204,     0,    22,    38,  4544,    11,     0,     1,     6,
          309,  8363,   903, 13397,     9,  5517,     0,  2786,    73,   267,
        10354,    19,   465,     2,    28, 18180,    12,  1531,    14,     4,
         7517,   139,   931,     2,  9675,     1,    24,   150,   184,  5197,
           37,   123,     3,     3,    26,  2065,  1373,    13,  2465,  4329,
          132,    22,    13,  3228,     0,  8287,   615,  2478,   130,     1,
        29999,    21,    15,    16,     0,  6788,  9517, 18483,     0,     7,
        29999,  1119,  4904,  1514,     3,  8084,   459,     0,  3162,     3,
           95,     1,    10,   107,  1607,     8,  1199,   105,     1, 29999,
         3014,    82,     2,    14,   132,     1,   833,  4458]) tensor([[ 1632,    24,    20,     3,    12,    12],
        [    6,    89,   111,   667,     4,     3],
        [ 5220,     0,    45, 12841,   341,  4117],
        [    6,    26,    11,   143,     1, 12144],
        [  434,   597,   657,    24,     0,  2190],
        [  355, 10888,  1030,     0, 29999,    17],
        [   33,    47,  3168,  3793,    19,   134],
        [    4,   410,     2,     9,     1,   111],
        [ 3259,    18,    61,   105,   149,  2311],
        [    7,     7,     7,     7,     7,     7],
        [   54,    11,  1236,   104,   251,  6075],
        [   14,  2623,  2199,     0,   472,  1581],
        [    1,  4360,    67,     3,     8,     8],
        [    0,   359,   488,  6312,  6566,  1275],
        [29999,   367,  3543,  3566,    23,  3223],
        [   22,     9,  3863,  2603,     1,    73],
        [   14,  2168,     1, 29999,     1,     0],
        [ 2333,  3067,  2354,  2434,  5456,     0],
        [  117,     7,   128,   128,    10,     0],
        [    1,  2389,  5642,    28, 10038,    48],
        [  117,   128,     3,   117,   128,     9],
        [    0, 29999,    46,    32,    10,   564],
        [    6,     0,  4380,  2320,    24,     0],
        [ 1668,     4,     5,  2494,     2,    30],
        [   42,    13,   137,    40,    49,  5288],
        [    2,   450,   848,    10,   181,     4],
        [    2, 12733,   471,     0, 29999,    47],
        [12149, 29999,     0,   911,     3,     8],
        [   41,   432,     0,     2,   783,     1],
        [  937, 19117, 29999,     0,   438,     1],
        [  109,   158,   317,     6,     0, 19400],
        [   54,    11, 15041,  2906,   360,  2939],
        [  491,   611,    69, 29999,    16,    10],
        [    7,     3,     9,    20,     6,     3],
        [  236,  3149,   478,  2920,   118,     0],
        [ 8833,     6,   441,    14,     5, 22586],
        [    0, 10293,  1345, 12819,   684,    60],
        [   42,  7937,    24,  1721,     2,     0],
        [  351,  4836,   681,  4709, 29999,     0],
        [   38,   489,   156,  7383,     3,  1575],
        [   86,    13,     0,   726,    27, 29999],
        [ 1946,   948,     4,   478, 11417,     5],
        [  164,  2847,   791, 14218,   593,  2460],
        [ 7685,  3830,     6,     0,  3502,    55],
        [    7,     7,  1666,    15,     7,     7],
        [    2,  1552,  1717,    97,    24,     0],
        [ 4602,    28,    19,   519,  5832,    74],
        [ 2786,     0,  1624,  1624,  1592,     5],
        [  128,     9,  6724,    16,   128,   159],
        [    0, 21206,   794, 21206,    40,    75],
        [ 7579, 24652, 29999,     2,  8494, 12774],
        [    5,   379,  2565,     0,   675,   726],
        [  219,     0,    61,    82,     3,     8],
        [  669,   336,   295,   284,   472,  5339],
        [   25,   958,  3997, 18536,     6,    18],
        [  411,  1440, 29999,    55,    10,     0],
        [  968,     9,    20,  7664,   667,    23],
        [ 5867,     1,     0,     1,    30,  4151],
        [ 1414,    14, 29999,   191,     4,     0],
        [ 3798,    10,  3211,     0,   272,    24],
        [    7,    21,  3815,   231,   301,  2467],
        [   29,  4117,  4973,   216,    33,  3421],
        [    0,  1477,    19,    17,  1521,   383],
        [29999, 29999, 29999, 29999, 29999,    60],
        [  355,    43,   201,    35,     4,    48],
        [  219,     0,  2197,     0,  1497,     4],
        [ 7299, 15056,   541,   919,    16,    22],
        [ 2279,     4,     0,    14,     2,   446],
        [  184,  6142,    62,  1554,    70,  2074],
        [    4,  6812,    32,    34,  1723,  1080],
        [ 1129,   168, 21868,   355,     5,  1481],
        [14526,    19,  1118,     0,  4019,     6],
        [ 4539, 29999,   209,     8,    21,     8],
        [    3,     8,    22,    33,    17,   432],
        [  177,     1,   505,    10,     0,  3372],
        [   35,    17,   186,    63,    32,  1473],
        [  553,     1,     0, 12193,    51,    31],
        [    5,   449,   183,  3159,   154,  3204],
        [  538,   160,     5,    49,  6445, 22543],
        [ 8112, 29999,    28,     0,    92,  8112],
        [ 1301,    25,     0,   326,     4,   263],
        [    3,    22,     8,   163,     4,  2899],
        [ 7274,  3580,  2692, 29999,    91,  3688],
        [   90,   119,   133,    24,  8457,   975],
        [   53,  2278,    27,  3819,   200,    34],
        [   27,    29,     9,    66,     5,  1130],
        [   16,   146,  6008,   622,  1182,  6539],
        [  444,    13,     0,  1213,  2140,   125],
        [  152,    26,    17,     6,    31,  9426],
        [ 3022,     0,    95,     0,   438,     4],
        [    9,    12,  4854,   100,  6755,    72],
        [  153,   741,    16,    16,    22,     3],
        [15768,  1424,   155,    15, 29999,     9],
        [    9,     7,     7,     0, 10050,  4656],
        [ 1177,     6,   705,   342,   385,     5],
        [   12, 29999,   289,  4361,    75,     3],
        [    1,     0,   679,     1,     0,     3],
        [   19,  2395,    96,    18,     5,  2792],
        [    7,  7846,  3948,   609,    52,     1],
        [  223,    34,   128,    41,    26,    40],
        [    8,     9,    16,    64,     5,   178],
        [   24,     0,   542,     1,     0,    45],
        [ 8650,     2, 16933,  3539,     0,  7187],
        [ 2309,     6,   761, 14652,     1,   675],
        [    1,     0,    72,    22,    39,  9232],
        [  113,   196,    51,    58,    10,   521],
        [   18,   407,   739,    13,  4476,   214],
        [   21,     3,     9,   500,   436,     2],
        [    5,  1632,   400,   927,   191,    34],
        [ 1184,    15,    22,  3769,    25, 11584],
        [  265,     5,  3254,     2,    39, 18622],
        [ 1549,    86,  6795,     0,    57,  1683],
        [   99,     0, 13281,    78,    16,     7],
        [12402,  1016,    18,  6434,     2,   227],
        [   17,     6,   371,    81,     4,     3],
        [    3,     8,     7,  1431,    56,   100],
        [   62,  2052,    45, 28316,     4,  2052],
        [   21,     7,    16,    19,  1283,     0],
        [   11,     0,    89,     0, 29999,    33],
        [    0,   911, 29999,     2,   484,   109],
        [  669,  3507,    18,  7612,   249,    11],
        [  197,     1,     0,     3,    22,     8],
        [  577,     6,  3128, 21252,    18,     0],
        [    0,   193,  2696,   607,  1976,  4675],
        [ 6192,    13,     0,  1602,    51,   293],
        [  102,    13,  2237,  3264,   111,     4],
        [   75,   792,   161,  4067,  3318,     1],
        [    2,  5582,     6, 20373,     2,  3928]]) tensor([[   32,    37,   276,  ..., 29999,    30,    17],
        [   14,     2,    25,  ...,    23,  9077,   159],
        [   21,  1714,    12,  ...,    10,   680,     9],
        ...,
        [ 2525,    13,    37,  ...,    33,  1831,    11],
        [    5,  7315,    34,  ...,   108,    23,   147],
        [    0,     0, 15665,  ...,  6368,  1104, 19705]])</code></pre></li>
</ul>
<h3 id="define-embedding-model">3.2.3 Define Embedding model</h3>
<ul>
<li><p>创建 <code>Embedding</code> 类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EmbeddingModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embed_size</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 初始化输出和输出embedding</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(EmbeddingModel, self).__init__()</span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.embed_size = embed_size</span><br><span class="line"></span><br><span class="line">        initrange = <span class="number">0.5</span> / self.embed_size</span><br><span class="line">        self.out_embed = nn.Embedding(self.vocab_size, self.embed_size, sparse=<span class="literal">False</span>)</span><br><span class="line">        self.out_embed.weight.data.uniform_(-initrange, initrange)</span><br><span class="line"></span><br><span class="line">        self.in_embed = nn.Embedding(self.vocab_size, self.embed_size, sparse=<span class="literal">False</span>)</span><br><span class="line">        self.in_embed.weight.data.uniform_(-initrange, initrange)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input_labels, pos_labels, neg_labels</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        input_labels: 中心词, [batch_size]</span></span><br><span class="line"><span class="string">        pos_labels: 中心词周围 context window 出现过的单词 [batch_size * (window_size * 2)]</span></span><br><span class="line"><span class="string">        neg_labelss: 中心词周围没有出现过的单词，从 negative sampling 得到 [batch_size, (window_size * 2 * K)]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        return: loss, [batch_size]</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        batch_size = input_labels.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        input_embedding = self.in_embed(input_labels) <span class="comment"># B * embed_size, [batch_size, embed_size]</span></span><br><span class="line">        pos_embedding = self.out_embed(pos_labels) <span class="comment"># B * (2*C) * embed_size, [batch_size, embed_size]</span></span><br><span class="line">        neg_embedding = self.out_embed(neg_labels) <span class="comment"># B * (2*C * K) * embed_size, [batch_size, (window_size * 2 * k), embed_size]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># input_embedding = input_embedding.unsqueeze(2) # [batch_size, embed_size, 1]</span></span><br><span class="line">        log_pos = torch.bmm(pos_embedding, input_embedding.unsqueeze(<span class="number">2</span>)).squeeze() <span class="comment"># B * (2*C), [batch_size, (window_size * 2)]</span></span><br><span class="line">        log_neg = torch.bmm(neg_embedding, -input_embedding.unsqueeze(<span class="number">2</span>)).squeeze() <span class="comment"># B * (2*C*K), [batch_size, (window_size * 2 * k)]</span></span><br><span class="line"></span><br><span class="line">        log_pos = F.logsigmoid(log_pos).<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line">        log_neg = F.logsigmoid(log_neg).<span class="built_in">sum</span>(<span class="number">1</span>) <span class="comment"># batch_size</span></span><br><span class="line"></span><br><span class="line">        loss = log_pos + log_neg</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> -loss</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">input_embeddings</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.in_embed.weight.data.cpu().numpy()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>实例化模型并移动到 <code>GPU</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = EmbeddingModel(VOCAB_SIZE, EMBEDDING_SIZE)</span><br><span class="line"><span class="keyword">if</span> USE_CUDA:  </span><br><span class="line">  model.cuda()</span><br></pre></td></tr></table></figure></li>
<li><p>模型训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">  <span class="keyword">for</span> i, (input_labels, pos_labels, neg_labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">    input_labels = input_labels.long()</span><br><span class="line">    pos_labels = pos_labels.long()</span><br><span class="line">    neg_labels = neg_labels.long()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> USE_CUDA:</span><br><span class="line">      input_labels = input_labels.cuda()</span><br><span class="line">      pos_labels = pos_labels.cuda()</span><br><span class="line">      neg_labels = neg_labels.cuda()</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss = model(input_labels, pos_labels, neg_labels).mean()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i%<span class="number">10000</span> == <span class="number">0</span>:</span><br><span class="line">      print(<span class="string">&#x27;epoch&#x27;</span>, e, <span class="string">&#x27;iteration&#x27;</span>, i, loss.cpu().item())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>epoch 0 iteration 0 420.04754638671875
epoch 0 iteration 10000 37.9792366027832
epoch 0 iteration 20000 33.68553924560547
epoch 0 iteration 30000 33.009620666503906
epoch 0 iteration 40000 33.17190170288086
epoch 0 iteration 50000 32.391265869140625
epoch 0 iteration 60000 32.888916015625
epoch 0 iteration 70000 32.370094299316406
epoch 0 iteration 80000 32.19983673095703
epoch 0 iteration 90000 31.926647186279297
epoch 0 iteration 100000 32.60920715332031
epoch 0 iteration 110000 32.57024383544922
epoch 1 iteration 0 31.93549346923828
epoch 1 iteration 10000 32.00389862060547
epoch 1 iteration 20000 32.29582214355469
epoch 1 iteration 30000 32.100887298583984
epoch 1 iteration 40000 32.123470306396484
epoch 1 iteration 50000 31.802623748779297
epoch 1 iteration 60000 32.11222839355469
epoch 1 iteration 70000 32.37131881713867
epoch 1 iteration 80000 31.90352439880371
epoch 1 iteration 90000 31.634069442749023
epoch 1 iteration 100000 31.78694725036621
epoch 1 iteration 110000 32.359596252441406</code></pre></li>
<li><p>保存参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">embedding_weights = model.input_embeddings()np.save(<span class="string">&quot;/content/drive/MyDrive/Word_embedding/embedding-&#123;&#125;&quot;</span>.<span class="built_in">format</span>(EMBEDDING_SIZE), embedding_weights)torch.save(model.state_dict(), <span class="string">&quot;/content/drive/MyDrive/Word_embedding/embedding-&#123;&#125;.th&quot;</span>.<span class="built_in">format</span>(EMBEDDING_SIZE))</span><br></pre></td></tr></table></figure></li>
<li><p>加载保存的模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.load_state_dict(torch.load(<span class="string">&quot;/content/drive/MyDrive/Word_embedding/embedding-&#123;&#125;.th&quot;</span>.<span class="built_in">format</span>(EMBEDDING_SIZE)))</span><br></pre></td></tr></table></figure></li>
<li><p>模型评估</p>
<p>下面是评估模型的代码，以及训练模型的代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">filename, embedding_weights</span>):</span>  <span class="keyword">if</span> filename.endswith(<span class="string">&quot;.csv&quot;</span>):      data = pd.read_csv(filename, sep=<span class="string">&quot;,&quot;</span>)  <span class="keyword">else</span>:      data = pd.read_csv(filename, sep=<span class="string">&quot;\t&quot;</span>)  human_similarity = []  model_similarity = []  <span class="keyword">for</span> i <span class="keyword">in</span> data.iloc[:, <span class="number">0</span>:<span class="number">2</span>].index:      word1, word2 = data.iloc[i, <span class="number">0</span>], data.iloc[i, <span class="number">1</span>]      <span class="keyword">if</span> word1 <span class="keyword">not</span> <span class="keyword">in</span> word_to_idx <span class="keyword">or</span> word2 <span class="keyword">not</span> <span class="keyword">in</span> word_to_idx:          <span class="keyword">continue</span>      <span class="keyword">else</span>:          word1_idx, word2_idx = word_to_idx[word1], word_to_idx[word2]          word1_embed, word2_embed = embedding_weights[[word1_idx]], embedding_weights[[word2_idx]]          model_similarity.append(<span class="built_in">float</span>(sklearn.metrics.pairwise.cosine_similarity(word1_embed, word2_embed)))          human_similarity.append(<span class="built_in">float</span>(data.iloc[i, <span class="number">2</span>]))  <span class="keyword">return</span> scipy.stats.spearmanr(human_similarity, model_similarity)<span class="comment"># , model_similaritydef find_nearest(word):    index = word_to_idx[word]    embedding = embedding_weights[index]    cos_dis = np.array([scipy.spatial.distance.cosine(e, embedding) for e in embedding_weights])    return [idx_to_word[i] for i in cos_dis.argsort()[:10]]</span></span><br></pre></td></tr></table></figure></li>
<li><p>训练模型步骤：</p>
<ul>
<li>模型一般需要训练若干个 <code>epoch</code></li>
<li>每个 <code>epoch</code> 我们都把所有的数据分成若干个 <code>batch</code></li>
<li>把每个 <code>batch</code> 的输入和输出都包装成 cuda tensor</li>
<li>forward pass，通过输入的句子预测每个单词的下一个单词</li>
<li>用模型的预测和正确的下一个单词计算 cross entropy loss</li>
<li>清空模型当前 <code>gradient</code></li>
<li>backward pass</li>
<li>更新模型参数</li>
<li>每隔一定的 <code>iteration</code> 输出模型在当前 <code>iteration</code> 的 <code>loss，以及在验证数据集上做模型的评估</code></li>
</ul></li>
</ul>
<h3 id="在测试集上进行模型评估">3.2.4 在测试集上进行模型评估</h3>
<p>本例中，使用 MEN 和 Simplex-999 数据集进行样本外评估</p>
<ul>
<li><p>加载数据和评估</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">embedding_weights = model.input_embeddings()</span><br><span class="line">print(<span class="string">&quot;simlex-999&quot;</span>, evaluate(<span class="string">&quot;/content/drive/MyDrive/Word_embedding/simlex-999.txt&quot;</span>, embedding_weights))</span><br><span class="line">print(<span class="string">&quot;men&quot;</span>, evaluate(<span class="string">&quot;/content/drive/MyDrive/Word_embedding/men.txt&quot;</span>, embedding_weights))</span><br><span class="line">print(<span class="string">&quot;wordsim353&quot;</span>, evaluate(<span class="string">&quot;/content/drive/MyDrive/Word_embedding/wordsim353.csv&quot;</span>, embedding_weights))</span><br></pre></td></tr></table></figure>
<p>Results:</p>
<pre><code>simlex-999 SpearmanrResult(correlation=0.16835319824603753, pvalue=1.6908393994875427e-07)men SpearmanrResult(correlation=0.18093374889038655, pvalue=1.9329614120922215e-20)wordsim353 SpearmanrResult(correlation=0.28416412711604, pvalue=2.440437723067791e-07)</code></pre></li>
</ul>
<h3 id="look-for-nearest-neighbors">3.2.5 Look for nearest neighbors</h3>
<ul>
<li><p>相似度分析</p>
<p>查找与给定单词最相关的词：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> [<span class="string">&quot;good&quot;</span>, <span class="string">&quot;fresh&quot;</span>, <span class="string">&quot;monster&quot;</span>, <span class="string">&quot;green&quot;</span>, <span class="string">&quot;like&quot;</span>, <span class="string">&quot;america&quot;</span>, <span class="string">&quot;chicago&quot;</span>, <span class="string">&quot;work&quot;</span>, <span class="string">&quot;computer&quot;</span>, <span class="string">&quot;language&quot;</span>]:</span><br><span class="line">  print(word, find_nearest(word))</span><br></pre></td></tr></table></figure>
<pre><code>good [&#39;good&#39;, &#39;bad&#39;, &#39;experience&#39;, &#39;future&#39;, &#39;hard&#39;, &#39;perfect&#39;, &#39;truth&#39;, &#39;money&#39;, &#39;love&#39;, &#39;personal&#39;]
fresh [&#39;fresh&#39;, &#39;grain&#39;, &#39;dense&#39;, &#39;lighter&#39;, &#39;sized&#39;, &#39;waste&#39;, &#39;noise&#39;, &#39;drinking&#39;, &#39;colour&#39;, &#39;concrete&#39;]
monster [&#39;monster&#39;, &#39;golem&#39;, &#39;giant&#39;, &#39;vampire&#39;, &#39;melody&#39;, &#39;cube&#39;, &#39;jaguar&#39;, &#39;finger&#39;, &#39;rod&#39;, &#39;horn&#39;]
green [&#39;green&#39;, &#39;blue&#39;, &#39;yellow&#39;, &#39;white&#39;, &#39;cross&#39;, &#39;red&#39;, &#39;black&#39;, &#39;orange&#39;, &#39;gold&#39;, &#39;mountain&#39;]
like [&#39;like&#39;, &#39;etc&#39;, &#39;rich&#39;, &#39;soft&#39;, &#39;unlike&#39;, &#39;similarly&#39;, &#39;bear&#39;, &#39;animals&#39;, &#39;sounds&#39;, &#39;fish&#39;]
america [&#39;america&#39;, &#39;africa&#39;, &#39;korea&#39;, &#39;india&#39;, &#39;australia&#39;, &#39;indian&#39;, &#39;europe&#39;, &#39;turkey&#39;, &#39;asia&#39;, &#39;pakistan&#39;]
chicago [&#39;chicago&#39;, &#39;boston&#39;, &#39;texas&#39;, &#39;london&#39;, &#39;illinois&#39;, &#39;berkeley&#39;, &#39;florida&#39;, &#39;massachusetts&#39;, &#39;indiana&#39;, &#39;austin&#39;]
work [&#39;work&#39;, &#39;writing&#39;, &#39;job&#39;, &#39;marx&#39;, &#39;recording&#39;, &#39;writings&#39;, &#39;speech&#39;, &#39;vision&#39;, &#39;label&#39;, &#39;ideas&#39;]
computer [&#39;computer&#39;, &#39;digital&#39;, &#39;software&#39;, &#39;audio&#39;, &#39;electronic&#39;, &#39;video&#39;, &#39;hardware&#39;, &#39;computers&#39;, &#39;graphics&#39;, &#39;programs&#39;]
language [&#39;language&#39;, &#39;languages&#39;, &#39;alphabet&#39;, &#39;arabic&#39;, &#39;spoken&#39;, &#39;programming&#39;, &#39;grammar&#39;, &#39;pronunciation&#39;, &#39;dialects&#39;, &#39;dialect&#39;]</code></pre></li>
</ul>
<h3 id="单词之间的关系">3.2.6 单词之间的关系</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">man_idx = word_to_idx[<span class="string">&quot;man&quot;</span>]</span><br><span class="line">king_idx = word_to_idx[<span class="string">&quot;king&quot;</span>]</span><br><span class="line">woman_idx = word_to_idx[<span class="string">&quot;woman&quot;</span>]</span><br><span class="line">embedding = embedding_weights[woman_idx] - embedding_weights[man_idx] + embedding_weights[king_idx]</span><br><span class="line">cos_dis = np.array([scipy.spatial.distance.cosine(e, embedding) <span class="keyword">for</span> e <span class="keyword">in</span> embedding_weights])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> cos_dis.argsort()[:<span class="number">20</span>]:</span><br><span class="line">    print(idx_to_word[i])</span><br></pre></td></tr></table></figure>
<pre><code>king
henry
charles
queen
pope
iii
edward
elizabeth
prince
alexander
constantine
james
son
louis
iv
mary
william
francis
albert
joseph</code></pre>
<p>理想的效果的是得到的结果是 <code>queen</code> 的词向量，可以发现出现在第四位，勉强能捕捉到这一信息，但精度还有待提高，这跟训练的次数和语料库大小有关。</p>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Python module</category>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Deep learning</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Scikit-learn</title>
    <url>/2020/11/22/Scikit-learn/</url>
    <content><![CDATA[<h1 id="installing-scikit-learn">1 Installing scikit-learn</h1>
<ul>
<li><p>Windows</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install -U scikit-learn</span><br></pre></td></tr></table></figure></li>
<li><p>macOS</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install -U scikit-learn</span><br></pre></td></tr></table></figure></li>
<li><p>Linux</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip3 install -U scikit-learn</span><br></pre></td></tr></table></figure></li>
</ul>
<p>Check installation:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip show scikit-learn</span><br></pre></td></tr></table></figure>
<p>See more about scikit-learn via clicking <a href="https://scikit-learn.org/stable/index.html#">here</a>.</p>
<a id="more"></a>
<h1 id="general-study-mode">2 General study mode</h1>
<p>Steps:</p>
<ol type="1">
<li>Load datas</li>
<li>Split datas into two part: train and test part</li>
<li>Training model</li>
<li>Testing and evaluating model</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># instance for iris</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris_x = iris.data <span class="comment"># features</span></span><br><span class="line">iris_y = iris.target <span class="comment"># types</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(iris_X[:2, :])</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris_x, iris_y, test_size = <span class="number">0.3</span>) <span class="comment"># split original data into train and test part</span></span><br><span class="line"><span class="comment"># the percentage of test sets is 30%</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(y_train) # 会打乱原始数据</span></span><br><span class="line">knn = KNeighborsClassifier() <span class="comment"># Classifier</span></span><br><span class="line">knn.fit(x_train, y_train) <span class="comment"># Train</span></span><br><span class="line">print(knn.predict(x_test)) <span class="comment"># Use trained model to predict</span></span><br><span class="line">print(y_test)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<h1 id="sklearn.datasets">3 Sklearn.datasets</h1>
<h2 id="generate-regressiong-datas">3.1 Generate regressiong datas</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># instance for making datasets</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">X, y = datasets.make_regression(n_samples = <span class="number">100</span>, </span><br><span class="line">                n_features = <span class="number">1</span>, n_targets = <span class="number">1</span>, noise = <span class="number">2</span>)</span><br><span class="line"><span class="comment"># X, y = datasets.make_regression(n_samples = 100, </span></span><br><span class="line"><span class="comment">#                 n_features = 1, n_targets = 1, noise = 10)</span></span><br><span class="line"></span><br><span class="line">plt.scatter(X, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Result:<img src="https://s3.ax1x.com/2020/11/25/DUaqr4.png" /></p>
<center>
fig. 3-1 Synthetic data
</center>
<h2 id="load-datasets-of-linear-regression">3.2 Load datasets of Linear Regression</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># instance for loading boston datasets</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># LinearRegression example</span></span><br><span class="line">loaded_data = datasets.load_boston()</span><br><span class="line"><span class="comment"># X, y = datasets_loadboston(retern_X_y = true)</span></span><br><span class="line">data_X, data_y = loaded_data.data, loaded_data.target</span><br><span class="line"></span><br><span class="line">model = LinearRegression()</span><br><span class="line">model.fit(data_X, data_y)</span><br><span class="line"></span><br><span class="line">print(data_y[:<span class="number">4</span>])</span><br><span class="line">print(model.predict(data_X[:<span class="number">4</span>, :]))</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">24.</span>  <span class="number">21.6</span> <span class="number">34.7</span> <span class="number">33.4</span>]</span><br><span class="line">[<span class="number">30.00384338</span> <span class="number">25.02556238</span> <span class="number">30.56759672</span> <span class="number">28.60703649</span>]</span><br></pre></td></tr></table></figure>
<h2 id="normalization">3.3 Normalization</h2>
<ul>
<li><p>Demo</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># cross_validation 更新为 model_selection</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"> a = np.array([[<span class="number">10</span>, <span class="number">2.7</span>, <span class="number">3.6</span>],</span><br><span class="line">               [-<span class="number">100</span>, <span class="number">5</span>, <span class="number">2</span>],</span><br><span class="line">               [<span class="number">120</span>, <span class="number">20</span>, <span class="number">40</span>]], dtype = np.float64)</span><br><span class="line"></span><br><span class="line">print(a)</span><br><span class="line">print(preprocessing.scale(a)) <span class="comment"># normalization</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[[  <span class="number">10.</span>     <span class="number">2.7</span>    <span class="number">3.6</span>]</span><br><span class="line"> [-<span class="number">100.</span>     <span class="number">5.</span>     <span class="number">2.</span> ]</span><br><span class="line"> [ <span class="number">120.</span>    <span class="number">20.</span>    <span class="number">40.</span> ]]</span><br><span class="line">[[ <span class="number">0.</span>         -<span class="number">0.85170713</span> -<span class="number">0.66102858</span>]</span><br><span class="line"> [-<span class="number">1.22474487</span> -<span class="number">0.55187146</span> -<span class="number">0.75220493</span>]</span><br><span class="line"> [ <span class="number">1.22474487</span>  <span class="number">1.40357859</span>  <span class="number">1.41323351</span>]]</span><br></pre></td></tr></table></figure></li>
<li><p>Comparison of accuracy before and after normalization</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># cross_validation 更新为 model_selection</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">X, y = make_classification(n_samples = <span class="number">300</span>, n_features = <span class="number">2</span>, n_redundant = <span class="number">0</span>,n_informative = <span class="number">2</span>, random_state = <span class="number">22</span>, n_clusters_per_class = <span class="number">1</span>, scale = <span class="number">100</span>)</span><br><span class="line"><span class="comment"># random_state: 固定随机数</span></span><br><span class="line"></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c = y)</span><br><span class="line">plt.title(<span class="string">&#x27;Classification samples&#x27;</span>)</span><br><span class="line">plt.show() <span class="comment"># </span></span><br></pre></td></tr></table></figure>
<p>Plot the generated samples:<img src="https://s3.ax1x.com/2020/11/25/DUajaR.png" /></p>
<center>
<p>fig. 3-2 Samples</p>
</center>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size = <span class="number">.3</span>)</span><br><span class="line">clf = SVC()</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">print(clf.score(X_test, y_test))</span><br><span class="line"></span><br><span class="line">X = preprocessing.scale(X) <span class="comment"># normalization</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size = <span class="number">.3</span>)</span><br><span class="line">clf = SVC()</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">print(clf.score(X_test, y_test))</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">0.9111111111111111</span></span><br><span class="line"><span class="number">0.9555555555555556</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="model-features-and-attributes">4 Model features and attributes</h1>
<h2 id="basic-parameters">4.1 Basic parameters</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># LinearRegression example</span></span><br><span class="line">loaded_data = datasets.load_boston()</span><br><span class="line"><span class="comment"># X, y = datasets_loadboston(retern_X_y = true)</span></span><br><span class="line">data_X, data_y = loaded_data.data, loaded_data.target</span><br><span class="line"></span><br><span class="line">model = LinearRegression()</span><br><span class="line">model.fit(data_X, data_y)</span><br><span class="line"></span><br><span class="line">print(data_y[:<span class="number">4</span>])</span><br><span class="line">print(model.predict(data_X[:<span class="number">4</span>, :]))</span><br><span class="line"></span><br><span class="line">print(model.coef_) <span class="comment"># 系数</span></span><br><span class="line">print(model.intercept_) <span class="comment"># 截距</span></span><br><span class="line">print(model.get_params) <span class="comment"># 参数</span></span><br><span class="line">print(model.score(data_X, data_y)) <span class="comment"># default is R^2 coefficietn of determination</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[24.  21.6 34.7 33.4]</span><br><span class="line">[30.00384338 25.02556238 30.56759672 28.60703649]</span><br><span class="line">[-1.08011358e-01  4.64204584e-02  2.05586264e-02  2.68673382e+00</span><br><span class="line"> -1.77666112e+01  3.80986521e+00  6.92224640e-04 -1.47556685e+00</span><br><span class="line">  3.06049479e-01 -1.23345939e-02 -9.52747232e-01  9.31168327e-03</span><br><span class="line"> -5.24758378e-01]</span><br><span class="line">36.459488385089855</span><br><span class="line">&lt;bound method BaseEstimator.get_params of LinearRegression()&gt;</span><br><span class="line">0.7406426641094095</span><br></pre></td></tr></table></figure>
<h2 id="cross-validation">4.2 Cross validation</h2>
<ul>
<li><p>Evaluate the NN</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors = <span class="number">5</span>)</span><br><span class="line"><span class="comment"># knn.fit(X_train, y_train)</span></span><br><span class="line"><span class="comment"># print(knn.score(X_test, y_test))</span></span><br><span class="line">scores = cross_val_score(knn, X, y, cv = <span class="number">5</span>, scoring = <span class="string">&#x27;accuracy&#x27;</span>) <span class="comment"># 将test进行5次划分</span></span><br><span class="line">print(scores.mean()) <span class="comment"># 取平均值</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">0.9733333333333334</span></span><br></pre></td></tr></table></figure></li>
<li><p>Cross validation</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span>  learning_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">digits = load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line">train_sizes, train_loss, test_loss= learning_curve( SVC(gamma=<span class="number">0.01</span>), X, y, cv=<span class="number">10</span>, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>, train_sizes=[<span class="number">0.1</span>, <span class="number">0.25</span>, <span class="number">0.5</span>, <span class="number">0.75</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># &#x27;neg_mean_squared_error&#x27; 非 &#x27;mean_squared_error&#x27;</span></span><br><span class="line"></span><br><span class="line">train_loss_mean = -np.mean(train_loss, axis=<span class="number">1</span>)</span><br><span class="line">test_loss_mean = -np.mean(test_loss, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(train_sizes, train_loss_mean, <span class="string">&#x27;o-&#x27;</span>, color=<span class="string">&quot;r&quot;</span>,</span><br><span class="line">             label=<span class="string">&quot;Training&quot;</span>)</span><br><span class="line">plt.plot(train_sizes, test_loss_mean, <span class="string">&#x27;o-&#x27;</span>, color=<span class="string">&quot;g&quot;</span>,</span><br><span class="line">             label=<span class="string">&quot;Cross-validation&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&quot;Training examples&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/11/25/DUabMF.md.png" /></p>
<center>
<p>fig 4-1 Vross-validation</p>
</center></li>
<li><p>Adjustment parameter-1</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># test train split #</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">4</span>)</span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">5</span>)</span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line">y_pred = knn.predict(X_test)</span><br><span class="line">print(knn.score(X_test, y_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># this is how to use cross_val_score to choose model and configs #</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">k_range = <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">31</span>)</span><br><span class="line">k_scores = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_range:</span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors=k)</span><br><span class="line"><span class="comment">##    loss = -cross_val_score(knn, X, y, cv=10, scoring=&#x27;mean_squared_error&#x27;) # for regression</span></span><br><span class="line">    scores = cross_val_score(knn, X, y, cv=<span class="number">10</span>, scoring=<span class="string">&#x27;accuracy&#x27;</span>) <span class="comment"># for classification</span></span><br><span class="line">    k_scores.append(scores.mean())</span><br><span class="line"></span><br><span class="line">plt.plot(k_range, k_scores)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Value of K for KNN&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Cross-Validated Accuracy&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/11/25/DUaXZ9.png" /></p>
<center>
<p>fig. 4-2 Adjustment parameters</p>
</center></li>
<li><p>Adjustment parameter-2</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> validation_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">digits = load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line">param_range = np.logspace(-<span class="number">6</span>, -<span class="number">2.3</span>, <span class="number">5</span>)</span><br><span class="line">train_loss, test_loss = validation_curve(</span><br><span class="line">        SVC(), X, y, param_name=<span class="string">&#x27;gamma&#x27;</span>, param_range=param_range, cv=<span class="number">10</span>,</span><br><span class="line">        scoring= <span class="string">&#x27;neg_mean_squared_error&#x27;</span>)</span><br><span class="line">train_loss_mean = -np.mean(train_loss, axis=<span class="number">1</span>)</span><br><span class="line">test_loss_mean = -np.mean(test_loss, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(param_range, train_loss_mean, <span class="string">&#x27;o-&#x27;</span>, color=<span class="string">&quot;r&quot;</span>,</span><br><span class="line">             label=<span class="string">&quot;Training&quot;</span>)</span><br><span class="line">plt.plot(param_range, test_loss_mean, <span class="string">&#x27;o-&#x27;</span>, color=<span class="string">&quot;g&quot;</span>,</span><br><span class="line">             label=<span class="string">&quot;Cross-validation&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&quot;gamma&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Overfitting problem&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/11/25/DUaLqJ.png" /></p>
<center>
<p>fig 4-3 Adjustment parameters</p>
</center></li>
</ul>
<h2 id="transform-target-in-regression-model">4.3 Transform target in regression model</h2>
<p>将原始数据转化为分类模式，可以有效地提高预测的精度，效果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(__doc__)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_regression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeCV</span><br><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> TransformedTargetRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> median_absolute_error, r2_score</span><br><span class="line"><span class="keyword">from</span> sklearn.utils.fixes <span class="keyword">import</span> parse_version</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> parse_version(matplotlib.__version__) &gt;= parse_version(<span class="string">&#x27;2.1&#x27;</span>):</span><br><span class="line">    desity_param = &#123;<span class="string">&#x27;density&#x27;</span>: <span class="literal">True</span>&#125;</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    density_param = &#123;<span class="string">&#x27;normed&#x27;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">    </span><br><span class="line">X, y = make_regression(n_samples = <span class="number">10000</span>, noise = <span class="number">100</span>, random_state = <span class="number">0</span>)</span><br><span class="line">y = np.exp((y + <span class="built_in">abs</span>(y.<span class="built_in">min</span>()))/<span class="number">200</span>)</span><br><span class="line">y_trans = np.log1p(y)</span><br><span class="line"></span><br><span class="line">f, (ax0, ax1) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># density: normalization</span></span><br><span class="line">ax0.hist(y, bins = <span class="number">100</span>, density = <span class="literal">True</span>)</span><br><span class="line">ax0.set_xlim([<span class="number">0</span>, <span class="number">2000</span>])</span><br><span class="line">ax0.set_ylabel(<span class="string">&#x27;Probability&#x27;</span>)</span><br><span class="line">ax0.set_xlabel(<span class="string">&#x27;Target&#x27;</span>)</span><br><span class="line">ax0.set_title(<span class="string">&#x27;Target distribution&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax1.hist(y_trans, bins = <span class="number">100</span>, density = <span class="literal">True</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;Probability&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;Target&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Transformed target distribution&#x27;</span>)</span><br><span class="line"></span><br><span class="line">f.suptitle(<span class="string">&#x27;Synthetic data&#x27;</span>, y = <span class="number">0.035</span>)</span><br><span class="line">f.tight_layout(rect = [<span class="number">0.05</span>, <span class="number">0.05</span>, <span class="number">0.95</span>, <span class="number">0.95</span>])</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/11/25/DUavI1.png" /></p>
<center>
fig.4-4 Comparison of Transformation
</center>
<p>然后，再来测试其对预测精度的影响：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">f, (ax0, ax1) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">regr = RidgeCV()</span><br><span class="line">regr.fit(X_train, y_train)</span><br><span class="line">y_pred = regr.predict(X_test)</span><br><span class="line"></span><br><span class="line">ax0.scatter(y_test, y_pred)</span><br><span class="line">ax0.plot([<span class="number">0</span>, <span class="number">2000</span>], [<span class="number">0</span>, <span class="number">2000</span>], <span class="string">&#x27;--k&#x27;</span>)</span><br><span class="line">ax0.set_ylabel(<span class="string">&#x27;Target predicted&#x27;</span>)</span><br><span class="line">ax0.set_xlabel(<span class="string">&#x27;True Target&#x27;</span>)</span><br><span class="line">ax0.set_title(<span class="string">&#x27;Ridge regression \n without target transformation&#x27;</span>)</span><br><span class="line">ax0.text(<span class="number">100</span>, <span class="number">1750</span>, <span class="string">r&#x27;$R^2$=%.2f, MAE=%.2f&#x27;</span> % (</span><br><span class="line">    r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)))</span><br><span class="line">ax0.set_xlim([<span class="number">0</span>, <span class="number">2000</span>])</span><br><span class="line">ax0.set_ylim([<span class="number">0</span>, <span class="number">2000</span>])</span><br><span class="line"></span><br><span class="line">regr_trans = TransformedTargetRegressor(regressor=RidgeCV(), func=np.log1p,inverse_func=np.expm1)</span><br><span class="line"></span><br><span class="line">regr_trans.fit(X_train, y_train)</span><br><span class="line">y_pred = regr_trans.predict(X_test)</span><br><span class="line"></span><br><span class="line">ax1.scatter(y_test, y_pred)</span><br><span class="line">ax1.plot([<span class="number">0</span>, <span class="number">2000</span>], [<span class="number">0</span>, <span class="number">2000</span>], <span class="string">&#x27;--k&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;Target predicted&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;True Target&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Ridge regression \n with target transformation&#x27;</span>)</span><br><span class="line">ax1.text(<span class="number">100</span>, <span class="number">1750</span>, <span class="string">r&#x27;$R^2$=%.2f, MAE=%.2f&#x27;</span> % (</span><br><span class="line">    r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)))</span><br><span class="line">ax1.set_xlim([<span class="number">0</span>, <span class="number">2000</span>])</span><br><span class="line">ax1.set_ylim([<span class="number">0</span>, <span class="number">2000</span>])</span><br><span class="line"></span><br><span class="line">f.suptitle(<span class="string">&quot;Synthetic data&quot;</span>, y=<span class="number">0.035</span>)</span><br><span class="line">f.tight_layout(rect=[<span class="number">0.05</span>, <span class="number">0.05</span>, <span class="number">0.95</span>, <span class="number">0.95</span>])</span><br></pre></td></tr></table></figure>
<p><img src="https://s3.ax1x.com/2020/11/25/DUazPx.png" /></p>
<center>
fig. 4-5 Comparison before and after transforming
</center>
<p>从结果可以看出，经过预处理转化后的数据集能有效地提高预测的精度，降低 <code>MAE</code> 的值。</p>
<h1 id="save-model">5 Save model</h1>
<p>Train model</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">clf = svm.SVC()</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line">clf.fit(X, y)</span><br></pre></td></tr></table></figure>
<p>Then, we can use two methods to save our trained models:</p>
<ol type="1">
<li><p>pickle</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="comment"># Save</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;save/clf.pickle&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(clf, f)</span><br><span class="line"><span class="comment"># Restore</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;save/clf.pickle&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	clf2 = pickle.load(f)</span><br><span class="line">print(clf2.predict(X[<span class="number">0</span>:<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></li>
<li><p>joblib</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="comment"># Save</span></span><br><span class="line">joblib.dump(clf, <span class="string">&#x27;./save/clf.pkl&#x27;</span>)</span><br><span class="line"><span class="comment"># restore</span></span><br><span class="line">clf3 = joblib.load(<span class="string">&#x27;save/clf.pkl&#x27;</span>)</span><br><span class="line">print(clf3.predict(X[<span class="number">0</span>:<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Python module</category>
        <category>Sklearn</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch</title>
    <url>/2021/04/08/Pytorch/</url>
    <content><![CDATA[<h1 id="pytorch-brief">1 Pytorch brief</h1>
<h2 id="create-tensor">1.1 Create Tensor</h2>
<ul>
<li><p><code>empty</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x1 = torch.empty(<span class="number">5</span>, <span class="number">3</span>) <span class="comment"># 构造未初始化的矩阵</span></span><br></pre></td></tr></table></figure></li>
<li><p><code>rand</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x2 = torch.rand(<span class="number">5</span>, <span class="number">3</span>) <span class="comment"># 构造随机初始化的正态分布矩阵</span></span><br></pre></td></tr></table></figure></li>
</ul>
<a id="more"></a>
<ul>
<li><p><code>randn</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.randn(<span class="number">3</span>, <span class="number">3</span>)  <span class="comment"># [0,1]之间标准正态分布</span></span><br></pre></td></tr></table></figure></li>
<li><p><code>arange</code></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>) <span class="comment"># 0-10, steps is 2</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><code>linspace</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.linspace(<span class="number">0</span>, <span class="number">10</span>, steps=<span class="number">5</span>)  <span class="comment"># 0到10，分5份</span></span><br></pre></td></tr></table></figure></li>
<li><p><code>zeros</code> &amp; <code>ones</code> &amp; <code>eye</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x3 = torch.zeros(<span class="number">5</span>, <span class="number">3</span>) <span class="comment"># 类型为 float32</span></span><br><span class="line">x4 = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)</span><br><span class="line"></span><br><span class="line">a = torch.ones(<span class="number">3</span>, <span class="number">3</span>)  <span class="comment"># 3*3,全1矩阵</span></span><br><span class="line"></span><br><span class="line">a = torch.eye(<span class="number">3</span>, <span class="number">3</span>)  <span class="comment"># 3*3,对角矩阵</span></span><br></pre></td></tr></table></figure></li>
<li><p><code>full</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.full([<span class="number">2</span>, <span class="number">3</span>], <span class="number">7</span>)  <span class="comment"># 2行3列，全是7</span></span><br></pre></td></tr></table></figure></li>
<li><p>From datum <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x5 = torch.tensor([<span class="number">5.4</span>, <span class="number">3</span>]) <span class="comment"># 从数据创建</span></span><br><span class="line">x6 = x5.new_ones(<span class="number">5</span>, <span class="number">3</span>) <span class="comment"># 同x5一样的数据类型</span></span><br><span class="line">x7 = torch.randn_like(x6, dtype = torch.<span class="built_in">float</span>) <span class="comment"># 创建同x6一样大小的正态 Tensor</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>From NumPy</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">2</span>, <span class="number">5.5</span>])</span><br><span class="line">print(a)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="operations">1.2 Operations</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<h3 id="attributions">1.2.1 Attributions</h3>
<ul>
<li><p>Type <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 x 的类型</span></span><br><span class="line">xType1 = x.<span class="built_in">type</span>()</span><br><span class="line">xType2 = x.dtype</span><br><span class="line">print(<span class="string">&#x27;first:&#123;&#125;, second: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(xType1, xType2))</span><br></pre></td></tr></table></figure></p></li>
<li><p>Shape <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 Tensor 的形状</span></span><br><span class="line">print(x.size())</span><br><span class="line">print(x.shape)</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h3 id="numerical-operations">1.2.2 Numerical operations</h3>
<ul>
<li><p>Add <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加法</span></span><br><span class="line">x + y</span><br><span class="line">x/y <span class="comment"># 除法</span></span><br><span class="line">torch.add(x, y, [out = result])</span><br><span class="line">y.add_(x)</span><br></pre></td></tr></table></figure> <code>in-place</code> 的运算都会以 <code>_</code> 结尾。 举例来说：<code>x.copy_(y)</code>, <code>x.t_()</code>, 该操作会改变 <code>x</code>。</p></li>
<li><p>Metric multiple</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.ones(<span class="number">2</span>, <span class="number">2</span>) * <span class="number">2</span></span><br><span class="line">b = torch.ones(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">print(torch.mm(a, b))  <span class="comment"># 只适用于2维数组</span></span><br><span class="line">print(a@b)</span><br><span class="line">a = torch.rand(<span class="number">4</span>, <span class="number">32</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">b = torch.rand(<span class="number">4</span>, <span class="number">32</span>, <span class="number">28</span>, <span class="number">16</span>)</span><br><span class="line">print(torch.matmul(a, b).shape)  <span class="comment"># 可以适用于多维数组，只将最后两个维度相乘</span></span><br></pre></td></tr></table></figure>
<p><code>mm</code> 只适用于<code>2</code> 维数组的矩阵相乘，<code>matmul</code> 可以适用于多维数组，只将最后两个维度相乘。Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor([[<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>]])</span><br><span class="line">tensor([[<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>]])</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">32</span>, <span class="number">28</span>, <span class="number">16</span>])</span><br></pre></td></tr></table></figure></p></li>
<li><p><code>pow</code> &amp; <code>sqrt</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.ones(<span class="number">2</span>, <span class="number">2</span>) * <span class="number">2</span></span><br><span class="line"><span class="comment"># Pow</span></span><br><span class="line">a.<span class="built_in">pow</span>(<span class="number">2</span>)</span><br><span class="line">a**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># sqrt</span></span><br><span class="line">a.sqrt()</span><br><span class="line">a**<span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor([[<span class="number">4.</span>, <span class="number">4.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">4.</span>]])</span><br><span class="line">tensor([[<span class="number">4.</span>, <span class="number">4.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">4.</span>]])</span><br><span class="line">tensor([[<span class="number">1.4142</span>, <span class="number">1.4142</span>],</span><br><span class="line">        [<span class="number">1.4142</span>, <span class="number">1.4142</span>]])</span><br><span class="line">tensor([[<span class="number">1.4142</span>, <span class="number">1.4142</span>],</span><br><span class="line">        [<span class="number">1.4142</span>, <span class="number">1.4142</span>]])</span><br></pre></td></tr></table></figure></li>
<li><p><code>exp</code> &amp; <code>log</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Exp</span></span><br><span class="line">a = torch.exp(torch.ones(<span class="number">2</span>, <span class="number">2</span>))  <span class="comment"># e运算</span></span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Log</span></span><br><span class="line">print(torch.log(a))  <span class="comment"># 取对数，默认以e为底</span></span><br></pre></td></tr></table></figure></li>
<li><p>Round</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.tensor(<span class="number">3.14</span>)</span><br><span class="line">print(a.floor())  <span class="comment"># 向下取整</span></span><br><span class="line">print(a.ceil())  <span class="comment"># 向上取整</span></span><br><span class="line">print(a.trunc())  <span class="comment"># 取整数部分</span></span><br><span class="line">print(a.frac())  <span class="comment"># 取小数部分</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>floor</code>：向下取整;</li>
<li><code>ceil</code>：向上取整;</li>
<li><code>traunc</code>：取整数部分：</li>
<li><code>frac</code>，取小数部分。</li>
</ul></li>
<li><p><code>clamp</code></p>
<p><code>clamp</code> 可以用来限定数组的范围。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>, <span class="number">3</span>) * <span class="number">15</span></span><br><span class="line">print(a)</span><br><span class="line">print(a.clamp(<span class="number">2</span>))  <span class="comment"># 限定最小值为2</span></span><br><span class="line">print(a.clamp(<span class="number">2</span>, <span class="number">10</span>))  <span class="comment"># 取值范围在0-10</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor([[ <span class="number">0.7791</span>,  <span class="number">4.7365</span>,  <span class="number">4.2215</span>],</span><br><span class="line">        [<span class="number">12.7793</span>, <span class="number">11.7283</span>, <span class="number">13.1722</span>]])</span><br><span class="line">tensor([[ <span class="number">2.0000</span>,  <span class="number">4.7365</span>,  <span class="number">4.2215</span>],</span><br><span class="line">        [<span class="number">12.7793</span>, <span class="number">11.7283</span>, <span class="number">13.1722</span>]])</span><br><span class="line">tensor([[ <span class="number">2.0000</span>,  <span class="number">4.7365</span>,  <span class="number">4.2215</span>],</span><br><span class="line">        [<span class="number">10.0000</span>, <span class="number">10.0000</span>, <span class="number">10.0000</span>]])</span><br></pre></td></tr></table></figure></li>
<li><p><code>transpose</code> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 转置</span></span><br><span class="line">y = torch.randn(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">z = y.transpose(<span class="number">1</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure></p></li>
<li><p>Switch to numpy <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># numpy 与 tensor 转换</span></span><br><span class="line">a = torch.ones(<span class="number">4</span>)</span><br><span class="line">b = a.numpy() <span class="comment"># tensor 转 numpy</span></span><br><span class="line">c = np.ones(<span class="number">5</span>)</span><br><span class="line">c = torch.from_numpy(c) <span class="comment"># numpy 转 tensor</span></span><br><span class="line">b[<span class="number">2</span>] = <span class="number">3</span> <span class="comment"># 浅拷贝，都会改变</span></span><br><span class="line"><span class="comment"># 所有CPU上的Tensor都支持转成numpy或从numpy转成Tensor</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>Get values <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x.item() <span class="comment"># 将单元素的 tensor 转化为 Python 数值</span></span><br></pre></td></tr></table></figure></p></li>
</ul>
<h3 id="dimensional-operation">1.2.3 Dimensional operation</h3>
<ul>
<li><p>Truncate</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 截取</span></span><br><span class="line">print(x[:, <span class="number">1</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>Concatenation: <code>cat</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">4</span>, <span class="number">32</span>, <span class="number">8</span>)</span><br><span class="line">b = torch.rand(<span class="number">5</span>, <span class="number">32</span>, <span class="number">8</span>)</span><br><span class="line">c = torch.cat([a, b], dim=<span class="number">0</span>)</span><br><span class="line">print(c.shape)</span><br></pre></td></tr></table></figure>
<p>按第 <code>0</code> 维度进行拼接，除拼接之外的维度必须相同。Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.Size([<span class="number">9</span>, <span class="number">32</span>, <span class="number">8</span>])</span><br></pre></td></tr></table></figure></li>
<li><p><code>stack</code></p>
<p>可以利用 <code>stack</code> 拼接，和 <code>cat</code> 命令不同，该命令会产生一个新的维度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">5</span>, <span class="number">32</span>, <span class="number">8</span>)</span><br><span class="line">b = torch.rand(<span class="number">5</span>, <span class="number">32</span>, <span class="number">8</span>)</span><br><span class="line">c = torch.stack([a, b], dim=<span class="number">0</span>)</span><br><span class="line">print(c.shape)</span><br></pre></td></tr></table></figure>
<p>产生一个新的维度，待拼接的向量维度相同。result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.Size([<span class="number">2</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">8</span>])</span><br></pre></td></tr></table></figure></li>
<li><p><code>split</code></p>
<p>按所制定的长度对张量进行拆分。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">6</span>, <span class="number">32</span>, <span class="number">8</span>)</span><br><span class="line">b, c = a.split(<span class="number">3</span>, dim=<span class="number">0</span>)  <span class="comment"># 所给的是拆分后，每个向量的大小，指定拆分维度</span></span><br><span class="line">print(b.shape)</span><br><span class="line">print(c.shape)</span><br></pre></td></tr></table></figure>
<p><code>split</code> 所给的是拆分后，每个向量的大小，指定拆分维度。Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.Size([<span class="number">3</span>, <span class="number">32</span>, <span class="number">8</span>])</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">32</span>, <span class="number">8</span>])</span><br></pre></td></tr></table></figure></li>
<li><p><code>chuck</code></p>
<p>按所给数量进行拆分。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">6</span>, <span class="number">32</span>, <span class="number">8</span>)</span><br><span class="line">b, c, d = a.chuck(<span class="number">3</span>, dim=<span class="number">0</span>)  <span class="comment"># 所给的是拆分的个数，即拆分成多少个小，指定拆分维度</span></span><br><span class="line">print(b.shape)</span><br><span class="line">print(c.shape)</span><br></pre></td></tr></table></figure>
<p>所给的是拆分的个数，即拆分成多少个。Result: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.Size([<span class="number">2</span>, <span class="number">32</span>, <span class="number">8</span>])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">32</span>, <span class="number">8</span>])</span><br></pre></td></tr></table></figure></p></li>
<li><p><code>reshape</code> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>, <span class="number">8</span>)  <span class="comment"># the size -1 is inferred from other dimensions，自动计算</span></span><br><span class="line">print(x.size(), y.size(), z.size())</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="gpu-edition">1.3 GPU edition</h2>
<h3 id="basic-functions">1.3.1 Basic functions</h3>
<ul>
<li><p><code>is_available</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.cuda.is_avaliable() <span class="comment"># 判断 CUDA 是否可用</span></span><br></pre></td></tr></table></figure></li>
<li><p><code>device</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>) <span class="comment"># 将 torch 对象放入 GPU 中</span></span><br></pre></td></tr></table></figure></li>
<li><p>Transfer tensor into CUDA</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = torch.ones_like(x, device=device)</span><br><span class="line">x = x.to(device)  </span><br><span class="line"><span class="comment"># or just use strings ``.to(&quot;cuda&quot;)`</span></span><br><span class="line"></span><br><span class="line">z = x + y</span><br><span class="line">print(z)</span><br><span class="line">print(z.to(<span class="string">&quot;cpu&quot;</span>, torch.double))</span><br><span class="line"><span class="comment"># 先转到 cpu 中才能转numpy，因为 numpy 是在cpu上运行的</span></span><br></pre></td></tr></table></figure>
<p><code>to</code> can also change dtype together, such as <code>z.cuda()</code> or <code>z.to('cuda:0')</code>. Before turn into numpy, the data must be on cpu，becasue numpy run on cpu.</p></li>
<li><p>Full code</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">  <span class="comment"># a CUDA device object</span></span><br><span class="line">    x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">    y = torch.ones_like(x, device=device)  </span><br><span class="line">  <span class="comment"># directly create a tensor on GPU</span></span><br><span class="line">    x = x.to(device)                       </span><br><span class="line">  <span class="comment"># or just use strings ``.to(&quot;cuda&quot;)``</span></span><br><span class="line">    z = x + y</span><br><span class="line">    print(z)</span><br><span class="line">    print(z.to(<span class="string">&quot;cpu&quot;</span>, torch.double))       </span><br><span class="line">  <span class="comment"># ``.to`` can also change dtype together! such as z.cuda() or z.to(&#x27;cuda:0&#x27;)</span></span><br><span class="line"></span><br><span class="line">y.to(<span class="string">&#x27;cpu&#x27;</span>).data.numpy()</span><br><span class="line">y.cpu().data.numpy() <span class="comment"># 先转到 cpu 中才能转numpy，因为 numpy 是在cpu上运行的</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="gradient">1.4 Gradient</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.tensor(<span class="number">1.</span>, requires_grad = <span class="literal">True</span>)</span><br><span class="line">w = torch.tensor(<span class="number">2.</span>, requires_grad = <span class="literal">True</span>)</span><br><span class="line">b = torch.tensor(<span class="number">3.</span>, requires_grad = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = w*x + b</span><br><span class="line"></span><br><span class="line">y.backword(x.grad, w.grad, b.grad)</span><br></pre></td></tr></table></figure>
<ul>
<li>eg: Nural network</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">dtype = torch.<span class="built_in">float</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># device = torch.device(&quot;cuda:0&quot;) # Uncomment this to run on GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line"><span class="comment"># 创建随机的Tensor来保存输入和输出</span></span><br><span class="line"><span class="comment"># 设定requires_grad=False表示在反向传播的时候我们不需要计算gradient</span></span><br><span class="line">x = torch.randn(N, D_in, device=device, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, device=device, dtype=dtype)</span><br><span class="line"><span class="comment"># print (x)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line"><span class="comment"># 创建随机的Tensor和权重。</span></span><br><span class="line"><span class="comment"># 设置requires_grad=True表示我们希望反向传播的时候计算Tensor的gradient</span></span><br><span class="line">w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad = <span class="literal">True</span>)</span><br><span class="line">w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    <span class="comment"># 前向传播:通过Tensor预测y；这个和普通的神经网络的前向传播没有任何不同，</span></span><br><span class="line">    <span class="comment"># 但是我们不需要保存网络的中间运算结果，因为我们不需要手动计算反向传播。</span></span><br><span class="line">	pred = x.mm(w1).clamp(<span class="built_in">min</span> = <span class="number">0</span>).mm(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute loss</span></span><br><span class="line">    <span class="comment"># 通过前向传播计算loss</span></span><br><span class="line">    <span class="comment"># loss是一个形状为(1，)的Tensor</span></span><br><span class="line">    <span class="comment"># loss.item()可以给我们返回一个loss的scalar</span></span><br><span class="line">    loss = (y_pred - y).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line">    print(it, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># PyTorch给我们提供了autograd的方法做反向传播。如果一个Tensor的requires_grad=True，</span></span><br><span class="line">    <span class="comment"># backward会自动计算loss相对于每个Tensor的gradient。在backward之后，</span></span><br><span class="line">    <span class="comment"># w1.grad和w2.grad会包含两个loss相对于两个Tensor的gradient信息。</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># not remember gradient data</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># Update weights of w1 and w2</span></span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Manually zero the gradients after updating weights</span></span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure>
<h2 id="pytorch-methods">1.5 Pytorch methods</h2>
<h3 id="pytorch-nn">1.5.1 Pytorch: NN</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H), <span class="comment"># y = w_1 * x + b_1</span></span><br><span class="line">    torch.nn.ReLU(), <span class="comment"># a = max(0, h)</span></span><br><span class="line">    torch.nn.Linear(H, D_out), <span class="comment"># y_hat = w_2 * a + b_2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = model.cuda()</span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss(reduction = <span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    y_pred = model(x.cuda())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred.cuda(), y.cuda())</span><br><span class="line">    print(it, loss.cpu().item())</span><br><span class="line"></span><br><span class="line">    model.zero_grad()</span><br><span class="line"></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">            param -= learning_rate * param.grad</span><br></pre></td></tr></table></figure>
<h3 id="pytorch-optim">1.5.2 Pytorch: optim</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H), <span class="comment"># y = w_1 * x + b_1</span></span><br><span class="line">    torch.nn.ReLU(), <span class="comment"># a = max(0, h)</span></span><br><span class="line">    torch.nn.Linear(H, D_out), <span class="comment"># y_hat = w_2 * a + b_2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = model.cuda()</span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss(reduction = <span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    y_pred = model(x.cuda())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred.cuda(), y.cuda())</span><br><span class="line">    print(it, loss.cpu().item())</span><br><span class="line"></span><br><span class="line">    model.zero_grad()   </span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<h2 id="variable">1.6 Variable</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line">tensor = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">variable = Variable(tensor, requires_grad = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">t_out = torch.mean(tensor * tensor)</span><br><span class="line">v_out = torch.mean(variable * variable)</span><br><span class="line"></span><br><span class="line">v_out.backward()</span><br><span class="line"></span><br><span class="line">print(t_out, v_out, variable.grad, sep=<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">variable_value = variable.data <span class="comment">#output tensor</span></span><br><span class="line">variable_numpy = variable.data.numpy()</span><br><span class="line"><span class="comment"># can&#x27;t finish above function with command: variable.numpy(), as variable isn&#x27;t tensor</span></span><br></pre></td></tr></table></figure>
<h1 id="nn">2 NN</h1>
<h2 id="快速实现神经网络">2.1 快速实现神经网络</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># method 1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">torch.nn.module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_feature, n_output</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init()</span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)</span><br><span class="line">        self.predict = torch.nn.Linear(n_hidden, n_output)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.relu(self.hiddec(x))</span><br><span class="line">        x = self.predic(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net1 = Net(<span class="number">1</span>, <span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># method 2</span></span><br><span class="line">net2 = torch.nn.Sequential(</span><br><span class="line">	torch.nn.Linear(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">	torch.nn.ReLU()</span><br><span class="line">	torch.nn.Linear(<span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">print(net1, net2, sep = <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Net (</span><br><span class="line">  (hidden): Linear (1 -&gt; 10)</span><br><span class="line">  (predict): Linear (10 -&gt; 1)</span><br><span class="line">)</span><br><span class="line">Sequential (</span><br><span class="line">  (0): Linear (1 -&gt; 10)</span><br><span class="line">  (<span class="number">1</span>): ReLU ()</span><br><span class="line">  (2): Linear (10 -&gt; 1)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="load-and-save-nn">2.2 load and save nn</h2>
<ul>
<li>Import modules</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">1</span>)    <span class="comment"># reproducible</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Generate fake data</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.unsqueeze(torch.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">100</span>), dim=<span class="number">1</span>)  </span><br><span class="line"><span class="comment"># 纵向挤压，x data (tensor), shape=(100, 1)</span></span><br><span class="line">y = x.<span class="built_in">pow</span>(<span class="number">2</span>) + <span class="number">0.2</span>*torch.rand(x.size())  </span><br><span class="line"><span class="comment"># noisy y data (tensor), shape=(100, 1)</span></span><br><span class="line">x, y = Variable(x, requires_grad=<span class="literal">False</span>), Variable(y, requires_grad=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>Save net</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span>():</span></span><br><span class="line">    <span class="comment"># save net1</span></span><br><span class="line">    net1 = torch.nn.Sequential(</span><br><span class="line">        torch.nn.Linear(<span class="number">1</span>, <span class="number">10</span>),</span><br><span class="line">        torch.nn.ReLU(),</span><br><span class="line">        torch.nn.Linear(<span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">    optimizer = torch.optim.SGD(net1.parameters(), lr=<span class="number">0.5</span>)</span><br><span class="line">    loss_func = torch.nn.MSELoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        prediction = net1(x)</span><br><span class="line">        loss = loss_func(prediction, y)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot result</span></span><br><span class="line">    plt.figure(<span class="number">1</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">    plt.subplot(<span class="number">131</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Net1&#x27;</span>)</span><br><span class="line">    plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">    plt.plot(x.data.numpy(), prediction.data.numpy(), <span class="string">&#x27;r-&#x27;</span>, lw=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2 ways to save the net</span></span><br><span class="line">    torch.save(net1, <span class="string">&#x27;net.pkl&#x27;</span>)  <span class="comment"># save entire net</span></span><br><span class="line">    torch.save(net1.state_dict(), <span class="string">&#x27;net_params.pkl&#x27;</span>)   <span class="comment"># save only the parameters</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Reload net</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">restore_net</span>():</span></span><br><span class="line">    <span class="comment"># restore entire net1 to net2</span></span><br><span class="line">    net2 = torch.load(<span class="string">&#x27;net.pkl&#x27;</span>)</span><br><span class="line">    prediction = net2(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot result</span></span><br><span class="line">    plt.subplot(<span class="number">132</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Net2&#x27;</span>)</span><br><span class="line">    plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">    plt.plot(x.data.numpy(), prediction.data.numpy(), <span class="string">&#x27;r-&#x27;</span>, lw=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>Reload net parameters</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">restore_params</span>():</span></span><br><span class="line">    <span class="comment"># restore only the parameters in net1 to net3</span></span><br><span class="line">    net3 = torch.nn.Sequential(</span><br><span class="line">        torch.nn.Linear(<span class="number">1</span>, <span class="number">10</span>),</span><br><span class="line">        torch.nn.ReLU(),</span><br><span class="line">        torch.nn.Linear(<span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># copy net1&#x27;s parameters into net3</span></span><br><span class="line">    net3.load_state_dict(torch.load(<span class="string">&#x27;net_params.pkl&#x27;</span>))</span><br><span class="line">    prediction = net3(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot result</span></span><br><span class="line">    plt.subplot(<span class="number">133</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Net3&#x27;</span>)</span><br><span class="line">    plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">    plt.plot(x.data.numpy(), prediction.data.numpy(), <span class="string">&#x27;r-&#x27;</span>, lw=<span class="number">5</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<ul>
<li>Test</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># save net1</span></span><br><span class="line">save()</span><br><span class="line"><span class="comment"># restore entire net (may slow)</span></span><br><span class="line">restore_net()</span><br><span class="line"><span class="comment"># restore only the net parameters</span></span><br><span class="line">restore_params()</span><br></pre></td></tr></table></figure>
<p>result<img src="https://z3.ax1x.com/2021/04/08/cJXH4H.md.png" /></p>
<center>
fig 1-1 save net
</center>
<h2 id="批训练">2.3 批训练</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">x = torch.linspace(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)       <span class="comment"># this is x data (torch tensor)</span></span><br><span class="line">y = torch.linspace(<span class="number">10</span>, <span class="number">1</span>, <span class="number">10</span>)       <span class="comment"># this is y data (torch tensor)</span></span><br><span class="line"></span><br><span class="line">torch_dataset = Data.TensorDataset(x, y)</span><br><span class="line">loader = Data.DataLoader(</span><br><span class="line">    dataset=torch_dataset,      <span class="comment"># torch TensorDataset format</span></span><br><span class="line">    batch_size=BATCH_SIZE,      <span class="comment"># mini batch size</span></span><br><span class="line">    shuffle=<span class="literal">True</span>,               <span class="comment"># 打乱数据次序</span></span><br><span class="line">    num_workers=<span class="number">2</span>,              <span class="comment"># subprocesses for loading data</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):   <span class="comment"># train entire dataset 3 times</span></span><br><span class="line">    <span class="keyword">for</span> step, (batch_x, batch_y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):  </span><br><span class="line">        <span class="comment"># train your data...</span></span><br><span class="line">        print(<span class="string">&#x27;Epoch: &#x27;</span>, epoch, <span class="string">&#x27;| Step: &#x27;</span>, step, <span class="string">&#x27;| batch x: &#x27;</span>,batch_x.numpy(), <span class="string">&#x27;| batch y: &#x27;</span>, batch_y.numpy())</span><br></pre></td></tr></table></figure>
<h2 id="optimizer">2.4 Optimizer</h2>
<h3 id="optimization-methods">2.4.1 Optimization methods:</h3>
<ul>
<li>Newton's method（牛顿法）</li>
<li>Least Squares method（最小二乘法）</li>
<li>Gradient Descent（梯度下降法：神经网络）</li>
</ul>
<h3 id="gradient-descent">2.4.2 Gradient Descent:</h3>
<ul>
<li>Cost Function（误差方程）:</li>
</ul>
<p><span class="math display">\[
\begin{align*}
Cost = (predicted - real)^2 &amp;= (Wx - y)^2 \\
&amp;=(W - o)^2
\end{align*}
\]</span></p>
<h3 id="code">2.4.3 Code</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">1</span>)    <span class="comment"># reproducible</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hyper parameters</span></span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">EPOCH = <span class="number">12</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># generate datas</span></span><br><span class="line">x = torch.unsqueeze(torch.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1000</span>), dim=<span class="number">1</span>)</span><br><span class="line">y = x.<span class="built_in">pow</span>(<span class="number">2</span>) + <span class="number">0.1</span>*torch.normal(torch.zeros(*x.size()))</span><br><span class="line"><span class="comment"># unsqueeze: Returns a new tensor with a dimension of size one inserted at the specified position.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># plot dataset</span></span><br><span class="line">plt.scatter(x.numpy(), y.numpy())</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># batch training</span></span><br><span class="line">torch_dataset = Data.TensorDataset(x, y)</span><br><span class="line">loader = Data.DataLoader(</span><br><span class="line">    dataset=torch_dataset,</span><br><span class="line">    batch_size=BATCH_SIZE,</span><br><span class="line">    shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>,)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define neural network</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(<span class="number">1</span>, <span class="number">20</span>)  </span><br><span class="line">        self.predict = torch.nn.Linear(<span class="number">20</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.relu(self.hidden(x)) <span class="comment"># activation function for hidden layer</span></span><br><span class="line">        x = self.predict(x) <span class="comment"># linear output</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># different optimizer</span></span><br><span class="line">net_SGD         = Net()</span><br><span class="line">net_Momentum    = Net()</span><br><span class="line">net_RMSprop     = Net()</span><br><span class="line">net_Adam        = Net()</span><br><span class="line">nets = [net_SGD, net_Momentum, net_RMSprop, net_Adam]</span><br><span class="line"></span><br><span class="line">opt_SGD         = torch.optim.SGD(net_SGD.parameters(), lr=LR)</span><br><span class="line">opt_Momentum    = torch.optim.SGD(net_Momentum.parameters(), lr=LR, momentum=<span class="number">0.8</span>)</span><br><span class="line">opt_RMSprop     = torch.optim.RMSprop(net_RMSprop.parameters(), lr=LR, alpha=<span class="number">0.9</span>)</span><br><span class="line">opt_Adam        = torch.optim.Adam(net_Adam.parameters(), lr=LR, betas=(<span class="number">0.9</span>, <span class="number">0.99</span>))</span><br><span class="line"></span><br><span class="line">optimizers = [opt_SGD, opt_Momentum, opt_RMSprop, opt_Adam]</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss function</span></span><br><span class="line">loss_func = torch.nn.MSELoss()</span><br><span class="line">losses_his = [[], [], [], []]   <span class="comment"># record loss</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># training</span></span><br><span class="line"><span class="comment"># training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH):</span><br><span class="line">    print(<span class="string">&#x27;Epoch: &#x27;</span>, epoch)</span><br><span class="line">    <span class="keyword">for</span> step, (batch_x, batch_y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):          <span class="comment"># for each training step</span></span><br><span class="line">        b_x = Variable(batch_x)</span><br><span class="line">        b_y = Variable(batch_y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> net, opt, l_his <span class="keyword">in</span> <span class="built_in">zip</span>(nets, optimizers, losses_his):</span><br><span class="line">            output = net(b_x)              <span class="comment"># get output for every net</span></span><br><span class="line">            loss = loss_func(output, b_y)  <span class="comment"># compute loss for every net</span></span><br><span class="line">            opt.zero_grad()                <span class="comment"># clear gradients for next train</span></span><br><span class="line">            loss.backward()                <span class="comment"># backpropagation, compute gradients</span></span><br><span class="line">            opt.step()                     <span class="comment"># apply gradients</span></span><br><span class="line">            l_his.append(loss.item())     <span class="comment"># loss recoder</span></span><br><span class="line"></span><br><span class="line">labels = [<span class="string">&#x27;SGD&#x27;</span>, <span class="string">&#x27;Momentum&#x27;</span>, <span class="string">&#x27;RMSprop&#x27;</span>, <span class="string">&#x27;Adam&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i, l_his <span class="keyword">in</span> <span class="built_in">enumerate</span>(losses_his):</span><br><span class="line">    plt.plot(l_his, label=labels[i])</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Steps&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.ylim((<span class="number">0</span>, <span class="number">0.2</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>result:<img src="https://z3.ax1x.com/2021/04/08/cJX7Ue.md.png" /></p>
<center>
fig 1-2 Different optimizer
</center>
<h2 id="activation-function">2.5 Activation Function</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = torch.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">200</span>)</span><br><span class="line">x = Variable(x)</span><br><span class="line">x_np = x.data.numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># four activation function</span></span><br><span class="line">y_relu = F.relu(x).data.numpy()</span><br><span class="line">y_sigmoid = torch.sigmoid(x).data.numpy()</span><br><span class="line">y_tanh = F.tanh(x).data.numpy()</span><br><span class="line">y_softplus = F.softplus(x).data.numpy()</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.plot(x_np, y_relu, c=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">plt.ylim((-<span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.plot(x_np, y_sigmoid, c=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">plt.ylim((-<span class="number">0.2</span>, <span class="number">1.2</span>))</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(x_np, y_tanh, c=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">plt.ylim((-<span class="number">1.2</span>, <span class="number">1.2</span>))</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.plot(x_np, y_softplus, c=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;softplus&#x27;</span>)</span><br><span class="line">plt.ylim((-<span class="number">0.2</span>, <span class="number">6</span>))</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="D:\Demo\Markdown\Pytorch.assets\activation%20function.png" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<center>
fig.4-1 four activation function
</center>
<p><span class="math inline">\(sigmoid\)</span> 激活函数： <span class="math display">\[
\sigma(x) = \frac{1}{1+e^{-x}}
\]</span> <span class="math inline">\(tanh\)</span> 激活函数： <span class="math display">\[
tanh(x) = 2 \sigma(2x) - 1
\]</span> <span class="math inline">\(ReLU\)</span> 激活函数： <span class="math display">\[
ReLU(x) = max(0, x)
\]</span></p>
<p><span class="math inline">\(Softmax\)</span> 激活函数： <span class="math display">\[
z_i \rightarrow \frac{e^{z_i}}{\sum_{j=1}^{k} e^{z_j}}
\]</span></p>
<h1 id="examples-for-nn">3 Examples for NN</h1>
<h2 id="numpy">3.1 Numpy</h2>
<p>一个全连接ReLU神经网络，一个隐藏层，没有bias。用来从x预测y，使用L2 Loss。</p>
<ul>
<li>$ h = W_1 X + b_1$</li>
<li>$ a = max(0, h)$</li>
<li>$ y_{hat} = W_2 a + b_2$</li>
<li>$ loss = (y_{hat} - y) ** 2$</li>
</ul>
<p>Goals: 把 1000 维的向量转化维 10 维的向量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"><span class="comment"># print (x)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.rand(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.dot(w1) <span class="comment"># 64 x 1000 array multiply 1000 x 100, hide layer turn 1000D data into 10D，N * H array</span></span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>) <span class="comment"># activate function，N * H</span></span><br><span class="line">    y_pred = h_relu.dot(w2) <span class="comment"># N * D_out</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute loss</span></span><br><span class="line">    <span class="comment"># loss = (y_pred - y) ** 2</span></span><br><span class="line">    loss = np.square(y_pred - y).<span class="built_in">sum</span>()</span><br><span class="line">    print(it, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 with respect to loss</span></span><br><span class="line">    <span class="comment"># Compute the gradient based on loss</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred) <span class="comment"># h _relu: N * H, grad_y_pred: N * D_out</span></span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights of w1 and w2</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>
<h2 id="torch">3.2 Torch</h2>
<ul>
<li>Modify according to above codes</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"><span class="comment"># print (x)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = torch.randn(D_in, H)</span><br><span class="line">w2 = torch.rand(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.mm(w1) <span class="comment"># 64 x 1000 array multiply 1000 x 100, hide layer turn 1000D data into 10D，N * H array</span></span><br><span class="line">    h_relu = h.clamp(<span class="built_in">min</span> = <span class="number">0</span>) <span class="comment"># activate function，N * H</span></span><br><span class="line">    y_pred = h_relu.mm(w2) <span class="comment"># N * D_out</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute loss</span></span><br><span class="line">    <span class="comment"># loss = (y_pred - y) ** 2</span></span><br><span class="line">    loss = (y_pred - y).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>().item()</span><br><span class="line"><span class="comment"># tensor.item()： turn tensor into value</span></span><br><span class="line">    print(it, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 with respect to loss</span></span><br><span class="line">    <span class="comment"># Compute the gradient based on loss</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.t().mm(grad_y_pred) <span class="comment"># h _relu: N * H, grad_y_pred: N * D_out</span></span><br><span class="line">    grad_h_relu = grad_y_pred.mm(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.clone()</span><br><span class="line">    grad_h[h&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights of w1 and w2</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">dtype = torch.<span class="built_in">float</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># device = torch.device(&quot;cuda:0&quot;) # Uncomment this to run on GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = torch.randn(N, D_in, device=device, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = torch.randn(D_in, H, device=device, dtype=dtype)</span><br><span class="line">w2 = torch.randn(H, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.mm(w1)</span><br><span class="line">    h_relu = h.clamp(<span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">    y_pred = h_relu.mm(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = (y_pred - y).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">    print(t, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 with respect to loss</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.t().mm(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.mm(w2.t())</span><br><span class="line">    grad_h = grad_h_relu.clone()</span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights using gradient descent</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>
<h2 id="fizz_buzz-demo">3.3 fizz_buzz demo</h2>
<p>FizzBuzz是一个简单的小游戏。游戏规则如下：从1开始往上数数，当遇到3的倍数的时候，说fizz，当遇到5的倍数，说buzz，当遇到15的倍数，就说fizzbuzz，其他情况下则正常数数。</p>
<p>可以写一个简单的小程序来决定要返回正常数值还是fizz, buzz 或者 fizzbuzz</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fizz_buzz_encode</span>(<span class="params">i</span>):</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">15</span> == <span class="number">0</span>:        <span class="keyword">return</span> <span class="number">3</span></span><br><span class="line">    <span class="keyword">elif</span> i % <span class="number">5</span> == <span class="number">0</span>:       <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">elif</span> i % <span class="number">3</span>  == <span class="number">0</span>:      <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fizz_buzz_decode</span>(<span class="params">i, prediction</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="built_in">str</span>(i), <span class="string">&#x27;fizz&#x27;</span>, <span class="string">&#x27;buzz&#x27;</span>, <span class="string">&#x27;fizzbuzz&#x27;</span>][prediction]</span><br><span class="line"></span><br><span class="line"><span class="comment"># for i in range(1, 15):</span></span><br><span class="line"><span class="comment">#     print(fizz_buzz_decode(i, fizz_buzz_encode(i)))</span></span><br></pre></td></tr></table></figure>
<p>定义模型的训练数据，并传入 GPU 中</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hyper parameters</span></span><br><span class="line">NUM_DIGITS = <span class="number">10</span></span><br><span class="line">NUM_HIDDEN = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># def binary_encode(i, num_digits):</span></span><br><span class="line"><span class="comment">#     return np.array([i &gt;&gt; d &amp; 1 for d in range(num_digits)])</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_encode</span>(<span class="params">i, num_digits</span>):</span></span><br><span class="line">    binary = <span class="built_in">list</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">bin</span>(i)[<span class="number">2</span>:]:</span><br><span class="line">        binary.append(<span class="built_in">int</span>(i))</span><br><span class="line">    size = <span class="built_in">len</span>(binary)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> [<span class="number">0</span>] * (num_digits - size):</span><br><span class="line">        binary.insert(<span class="number">0</span>, <span class="built_in">int</span>(j))</span><br><span class="line">    <span class="keyword">return</span> np.array(binary)</span><br><span class="line"></span><br><span class="line"><span class="comment"># trX = torch.Tensor([binary_encode(i, NUM_DIGITS)  for i in range(101, 2 ** NUM_DIGITS)])</span></span><br><span class="line"><span class="comment"># trY = torch.LongTensor([fizz_buzz_encode(i) for i in range(101, 2 ** NUM_DIGITS)])</span></span><br><span class="line"></span><br><span class="line">trX = torch.Tensor([binary_encode(i, NUM_DIGITS) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">101</span>, <span class="number">2</span> ** NUM_DIGITS)])</span><br><span class="line">trY = torch.LongTensor([fizz_buzz_encode(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">101</span>, <span class="number">2</span>**NUM_DIGITS)])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">trX.to(device)</span><br><span class="line">trY.to(device)</span><br></pre></td></tr></table></figure>
<p>定义神经网络模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(NUM_DIGITS, NUM_HIDDEN),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(NUM_HIDDEN, <span class="number">4</span>)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<ul>
<li>为了让我们的模型学会FizzBuzz这个游戏，我们需要定义一个损失函数，和一个优化算法。</li>
<li>这个优化算法会不断优化（降低）损失函数，使得模型的在该任务上取得尽可能低的损失值。</li>
<li>损失值低往往表示我们的模型表现好，损失值高表示我们的模型表现差。</li>
<li>由于FizzBuzz游戏本质上是一个分类问题，我们选用Cross Entropyy Loss函数。</li>
<li>优化函数我们选用Stochastic Gradient Descent。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># loss function</span></span><br><span class="line">loss_fn = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr = <span class="number">5e-2</span>)</span><br></pre></td></tr></table></figure>
<p>训练模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">128</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line">    <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(trX), BATCH_SIZE):</span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        batchX = trX[start:end]</span><br><span class="line">        batchY = trY[start:end]</span><br><span class="line"></span><br><span class="line">        y_pred = model(batchX)</span><br><span class="line">        loss = loss_fn(y_pred, batchY)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    loss = loss_fn(model(trX), trY).item()</span><br><span class="line">    print(<span class="string">&#x27;Epoch:&#x27;</span>, epoch, <span class="string">&#x27;Loss:&#x27;</span>, loss, sep = <span class="string">&#x27;\t&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>最后用训练好的模型尝试在 1-100 中玩 FizzBuzz 邮箱</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">testX = torch.Tensor([binary_encode(i, NUM_DIGITS) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">101</span>)])</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    testY = model(testX)</span><br><span class="line">predictions = <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">101</span>), <span class="built_in">list</span>(testY.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>].data.tolist()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ouptut prediction</span></span><br><span class="line">print([fizz_buzz_decode(i, x) <span class="keyword">for</span> (i, x) <span class="keyword">in</span> predictions])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output False when prediction is imprecise</span></span><br><span class="line">print(np.<span class="built_in">sum</span>(testY.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>].numpy() == np.array([fizz_buzz_encode(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">101</span>)])))</span><br></pre></td></tr></table></figure>
<h3 id="full-code">3.3.1 Full code</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fizz_buzz_encode</span>(<span class="params">i</span>):</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">15</span> == <span class="number">0</span>:        <span class="keyword">return</span> <span class="number">3</span></span><br><span class="line">    <span class="keyword">elif</span> i % <span class="number">5</span> == <span class="number">0</span>:       <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">elif</span> i % <span class="number">3</span>  == <span class="number">0</span>:      <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fizz_buzz_decode</span>(<span class="params">i, prediction</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="built_in">str</span>(i), <span class="string">&#x27;fizz&#x27;</span>, <span class="string">&#x27;buzz&#x27;</span>, <span class="string">&#x27;fizzbuzz&#x27;</span>][prediction]</span><br><span class="line"></span><br><span class="line"><span class="comment"># for i in range(1, 15):</span></span><br><span class="line"><span class="comment">#     print(fizz_buzz_decode(i, fizz_buzz_encode(i)))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hyper parameters</span></span><br><span class="line">NUM_DIGITS = <span class="number">10</span></span><br><span class="line">NUM_HIDDEN = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># def binary_encode(i, num_digits):</span></span><br><span class="line"><span class="comment">#     return np.array([i &gt;&gt; d &amp; 1 for d in range(num_digits)])</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_encode</span>(<span class="params">i, num_digits</span>):</span></span><br><span class="line">    binary = <span class="built_in">list</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">bin</span>(i)[<span class="number">2</span>:]:</span><br><span class="line">        binary.append(<span class="built_in">int</span>(i))</span><br><span class="line">    size = <span class="built_in">len</span>(binary)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> [<span class="number">0</span>] * (num_digits - size):</span><br><span class="line">        binary.insert(<span class="number">0</span>, <span class="built_in">int</span>(j))</span><br><span class="line">    <span class="comment"># bin_array = np.array(binary) # array</span></span><br><span class="line">    <span class="keyword">return</span> np.array(binary)</span><br><span class="line"></span><br><span class="line"><span class="comment"># trX = torch.Tensor([binary_encode(i, NUM_DIGITS)  for i in range(101, 2 ** NUM_DIGITS)])</span></span><br><span class="line"><span class="comment"># trY = torch.LongTensor([fizz_buzz_encode(i) for i in range(101, 2 ** NUM_DIGITS)])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">trX = torch.Tensor([binary_encode(i, NUM_DIGITS) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">101</span>, <span class="number">2</span> ** NUM_DIGITS)])</span><br><span class="line">trY = torch.LongTensor([fizz_buzz_encode(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">101</span>, <span class="number">2</span>**NUM_DIGITS)])</span><br><span class="line">trX.to(device)</span><br><span class="line">trY.to(device)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(NUM_DIGITS, NUM_HIDDEN),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(NUM_HIDDEN, <span class="number">4</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss function</span></span><br><span class="line">loss_fn = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr = <span class="number">5e-2</span>)</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">128</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line">    <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(trX), BATCH_SIZE):</span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        batchX = trX[start:end]</span><br><span class="line">        batchY = trY[start:end]</span><br><span class="line"></span><br><span class="line">        y_pred = model(batchX)</span><br><span class="line">        loss = loss_fn(y_pred, batchY)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    loss = loss_fn(model(trX), trY).item()</span><br><span class="line">    print(<span class="string">&#x27;Epoch:&#x27;</span>, epoch, <span class="string">&#x27;Loss:&#x27;</span>, loss, sep = <span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br><span class="line">testX = torch.Tensor([binary_encode(i, NUM_DIGITS) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">101</span>)])</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    testY = model(testX)</span><br><span class="line">predictions = <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">101</span>), <span class="built_in">list</span>(testY.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>].data.tolist()))</span><br><span class="line"></span><br><span class="line">print([fizz_buzz_decode(i, x) <span class="keyword">for</span> (i, x) <span class="keyword">in</span> predictions])</span><br><span class="line">print(np.<span class="built_in">sum</span>(testY.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>].numpy() == np.array([fizz_buzz_encode(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">101</span>)])))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Notes</category>
        <category>Python module</category>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Deep learning</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Stata Introduction</title>
    <url>/2020/12/15/Stata-introduction/</url>
    <content><![CDATA[<h1 id="stata-operation">1 Stata operation</h1>
<h2 id="import-data">1.1 Import data</h2>
<ul>
<li><p>use</p>
<p><code>grilic_small.dta</code> 文件的目录请根据自己的文件目录填写，数据文件可在陈强老师的网站下载，<a href="http://www.econometrics-stata.com/col.jsp?id=101">Click here</a>，选择《计量经济学及Stata应用》中的数据集下载。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">use <span class="string">&quot;D:\Demo\University\XMU\Class_files\Econometrics\Econometrics and Stata application\Data-Finished-bachelor\grilic_small.dta&quot;</span>, clear</span><br></pre></td></tr></table></figure></li>
</ul>
<a id="more"></a>
<ul>
<li><p>clear</p>
<p>关闭一个数据集，以便使用另外一个数据集</p></li>
<li><p><code>d</code>escribe</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看数据集中的变量名称、标签等</span></span><br><span class="line">describe <span class="keyword">or</span> d</span><br></pre></td></tr></table></figure></li>
<li><p>set more off/on</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 连续滚屏显示命令运行结果</span></span><br><span class="line"><span class="built_in">set</span> more off</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分页显示命令运行结果</span></span><br><span class="line"><span class="built_in">set</span> more on</span><br></pre></td></tr></table></figure></li>
<li><p><code>l</code>ist</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看变量 s 和 lnw 的前 5 个数据</span></span><br><span class="line"><span class="built_in">list</span> s lnw <span class="keyword">in</span> <span class="number">1</span>/<span class="number">5</span> <span class="comment"># or</span></span><br><span class="line">l s lnw <span class="keyword">in</span> <span class="number">1</span>/<span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 罗列第 11-15 个观测值</span></span><br><span class="line"><span class="built_in">list</span> ss lnw <span class="keyword">in</span> <span class="number">11</span>/<span class="number">15</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出满足条件 ‘s&gt;=16&#x27; 的数据</span></span><br><span class="line"><span class="built_in">list</span> s lnw <span class="keyword">if</span> s &gt;= <span class="number">16</span></span><br><span class="line"><span class="comment"># &gt;=: 等于  &lt;=：小于等于  ==：等于  ~= or !=：不等于  =：赋值</span></span><br></pre></td></tr></table></figure></li>
<li><p>drop / keep</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除满足 ’s&gt;=16&#x27; 的观测值</span></span><br><span class="line">drop <span class="keyword">if</span> s &gt;= <span class="number">16</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只保留满足 &#x27;s&gt;=16&#x27; 的观测值</span></span><br><span class="line">keep <span class="keyword">if</span> s &gt;= <span class="number">16</span></span><br></pre></td></tr></table></figure>
<p>注：Stata 并不提供 undo 功能，故需慎重删除数据，最好保留备份-</p></li>
<li><p>sort / gsort</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将数据按照变量 s 的升序排列</span></span><br><span class="line">sort s</span><br><span class="line">lsit</span><br><span class="line"></span><br><span class="line"><span class="comment"># 降序排列</span></span><br><span class="line">gsort -s</span><br><span class="line"><span class="built_in">list</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="plot">1.2 Plot</h2>
<h3 id="直方图">1.3.1 直方图</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">histogram s, width(<span class="number">1</span>) frequency</span><br><span class="line">hist s, w(<span class="number">1</span>) freq</span><br><span class="line"><span class="comment"># histogram: 直方图,</span></span><br><span class="line"><span class="comment"># 选择项 &#x27;width(1)&#x27; 表示将组宽设为 1（否则将使用 Stata 根据样本容量计算的默认分组数）</span></span><br><span class="line"><span class="comment"># 选择项 ‘frequency&#x27; 表示将纵坐标定为频数（默认使用密度）</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/12/15/rKz0OK.png" alt="image-20201210163044446" style="zoom:80%;" /></p>
<center>
Fig. 1-1 Histogram figure
</center>
<ul>
<li>查看帮助文档</li>
</ul>
<p>对于任何 <code>Stata</code> 命令，只需要输入 <code>help command_name</code> 即可查看该命令的帮助文档，<strong>初学者应养成经常查看帮助文档的习惯</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">help</span> histogram</span><br><span class="line">h hist</span><br><span class="line"><span class="comment"># 查看 histogram 命令的帮助文档</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">histogram varname [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, [continuous_opts | discrete_opts] options]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[if], [in]: 条件操作</span></span><br><span class="line"><span class="string">[weight]: 权重</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[continuous_opts]: 连续型变量选择项</span></span><br><span class="line"><span class="string">[discrete_opts]: 离散型选择项</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">continuous_opts        Description</span></span><br><span class="line"><span class="string">----------------------------------------</span></span><br><span class="line"><span class="string">Main</span></span><br><span class="line"><span class="string">  bin(#)               set number of bins to #</span></span><br><span class="line"><span class="string">  width(#)             set width of bins to #</span></span><br><span class="line"><span class="string">  start(#)         	   set lower limit of first bin to #</span></span><br><span class="line"><span class="string">-------------------------------------------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">discrete_opts          Description</span></span><br><span class="line"><span class="string">------------------------------------------</span></span><br><span class="line"><span class="string">Main</span></span><br><span class="line"><span class="string">  discrete             specify that data are discrete</span></span><br><span class="line"><span class="string">  width(#)             set width of bins to #</span></span><br><span class="line"><span class="string">  start(#)             set theoretical minimum value to #</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">options                Description</span></span><br><span class="line"><span class="string">-------------------------------------------</span></span><br><span class="line"><span class="string">Main</span></span><br><span class="line"><span class="string">  density               draw as density; the default</span></span><br><span class="line"><span class="string">  fraction              draw as fractions</span></span><br><span class="line"><span class="string">  frequency             draw as frequencies</span></span><br><span class="line"><span class="string">  percent               draw as percentages</span></span><br><span class="line"><span class="string">  bar_options           rendition of bars</span></span><br><span class="line"><span class="string">  binrescale  | recalculate bin sizes when by() is specified</span></span><br><span class="line"><span class="string">  addlabels             add height labels to bars</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Density plots</span></span><br><span class="line"><span class="string">  normal                  add a normal density to the graph</span></span><br><span class="line"><span class="string">  normopts(line_options)  affect rendition of normal density</span></span><br><span class="line"><span class="string">  kdensity     | add a kernel density estimate to the graph</span></span><br><span class="line"><span class="string">  kdenopts(kdensity_options) | affect rendition of kernel density</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Add plots</span></span><br><span class="line"><span class="string">  addplot(plot)           add other plots to the histogram</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="散点图">1.3.2 散点图</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scatter lnw s</span><br><span class="line">sc lnw s</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/12/15/rKzrwD.png" alt="image-20201210163409860" style="zoom:80%;" /></p>
<center>
Fig. 1-2 Scatter between lnw and s
</center>
<ul>
<li>标签</li>
</ul>
<p>如果想在散点图上标注每个点对应于哪个观测值，可先定义变量 <span class="math inline">\(n\)</span>，表示第 <span class="math inline">\(n\)</span> 个观测值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gen n = _n</span><br><span class="line">scatter lnw s, mlabel(n) <span class="comment"># 选择变量 n 作为标签（mark label）</span></span><br></pre></td></tr></table></figure>
<p>其中，<code>_n</code> 表示第 <span class="math inline">\(n\)</span> 个观测值。然后以变量作为每个点的标签来画散点图。结果如下：</p>
<p><img src="https://s3.ax1x.com/2020/12/15/rKzsTe.png" alt="image-20201210164351554" style="zoom:80%;" /></p>
<center>
Fig. 1-3 Scatter with mark label
</center>
<h3 id="核密度估计图">1.3.3 核密度估计图</h3>
<p>直方图必然是不连续的，如果想得到密度函数的连续估计，可输入命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kdensity lnw, normal normop (lpattern (dash))</span><br><span class="line">kdensity lnw, normal normop (lp (dash))</span><br></pre></td></tr></table></figure>
<p>其中</p>
<ul>
<li><code>kdensity</code>：核密度估计（kernel density estimation）；</li>
<li><code>normal</code>：画正态分布的密度函数作为对比；</li>
<li><code>normop (lp (Dash))</code>：将正态密度用虚线来画。
<ul>
<li><code>normop</code>：normal options</li>
<li><code>lpattern</code>： line pattern.</li>
</ul></li>
</ul>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/12/15/rKzRSI.md.png" alt="image-20201210224215508" style="zoom:80%;" /></p>
<center>
Fig. 1-4 Kernel density estimate
</center>
<h2 id="statistical-analysis">1.3 Statistical analysis</h2>
<ul>
<li><p>统计特征</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">summarize s</span><br><span class="line">su s</span><br><span class="line"></span><br><span class="line"><span class="built_in">sum</span> lnw, detail <span class="comment"># 显示更多统计指标，如偏度、峰度</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/12/15/rKzDeO.png" alt="image-20201210164927010" style="zoom:80%;" /></p>
<p><img src="https://s3.ax1x.com/2020/12/15/rKzgfA.png" alt="image-20201210223033995" style="zoom:80%;" /></p>
<center>
<p>Fig. 1-4 Statistical description</p>
</center>
<p>显示了变量 <span class="math inline">\(s\)</span> 的样本容量、平均值、标准差、最小值于最大值。如 <strong>不指明变量</strong>，则显示 <strong>所有变量</strong> 的统计指标。</p></li>
<li><p>经验累计分布函数（Empirical cumulative distribution function）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tabulate s <span class="comment"># 显示 s 的经验累积分布番薯</span></span><br><span class="line">ta s</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/12/15/rKzwy6.png" alt="image-20201210165710687" style="zoom:80%;" /></p>
<center>
<p>Fig. 1-5 Empirical cummlative distribution</p>
</center>
<p>其中，<code>Freq</code> 表示频数，<code>Percent</code> 表示百分比，而 <code>Cum.</code> 表示累积百分比。</p></li>
<li><p>相关系数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pwcorr lnw s expr, sig star(<span class="number">.05</span>)</span><br><span class="line"><span class="comment"># 对工资对数、教育年限于工龄之间的相关系数</span></span><br></pre></td></tr></table></figure>
<p>其中，</p>
<ul>
<li><code>pwcorr</code> ： <code>pairwise correlation</code>，即两两相关；</li>
<li>选择项 <code>sig</code> ：相关系数的显著性水平，即 <code>p-value</code>，列在相关系数的下方 ；</li>
<li>选择项 <code>star (.05)</code> ：所有显著性水平小于或等于 5% 的相关系数打赏星号。</li>
</ul>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2020/12/15/rKz6FH.png" alt="image-20201210170540089" style="zoom:80%;" /></p>
<center>
<p>Fig.1-6 Correlation coefficient</p>
</center>
<p>结果显示，<span class="math inline">\(\rm{ln} w\)</span> 与 <span class="math inline">\(s\)</span> 的相关系数为 0.5368，且在 1% 水平上显著（ <span class="math inline">\(p\)</span> 值为0.0022）；<span class="math inline">\(\rm{ln} w\)</span> 与 <span class="math inline">\(expr\)</span> 的相关系数为 -0.1132，但此相关关系也不显著（<span class="math inline">\(p-value\)</span> 为0.5514）</p></li>
</ul>
<h2 id="generate-new-variable">1.4 Generate new variable</h2>
<h3 id="basic-operation">1.4.1 Basic operation</h3>
<ul>
<li>对数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">generate lns = log(s)</span><br><span class="line">g lns = log(s) <span class="comment"># 对数</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>平方</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gen s2 = s ^<span class="number">2</span> <span class="comment"># 平方项</span></span><br></pre></td></tr></table></figure></li>
<li><p>互动项（乘法）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gen exprs = s * expr <span class="comment"># s 与 expr 的互动项</span></span><br></pre></td></tr></table></figure></li>
<li><p>指数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gen w = exp(lnw) <span class="comment"># 指数</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="虚拟变量">1.4.2 虚拟变量</h3>
<p>假设定义 <span class="math inline">\(s \geq 16\)</span> 为 ”受过高等教育“，并使用 变量 <span class="math inline">\(college\)</span> 来表示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gen colleg = (s &gt;= <span class="number">16</span>)</span><br></pre></td></tr></table></figure>
<p>其中，括弧 <code>()</code> 表示对括弧中的表达式进行逻辑评估：如果此表达式为真，则取值为1；如果为假，则取值为0。</p>
<ul>
<li><p>变量重命名</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rename colleg college</span><br><span class="line">ren colleg college</span><br></pre></td></tr></table></figure></li>
<li><p>变量重定义</p>
<p>将 ”受过高等教育“的定义改为 <span class="math inline">\(s \geq 15\)</span>，但仍用 <span class="math inline">\(college\)</span> 作为变量名：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Method one</span></span><br><span class="line">drop college</span><br><span class="line">gen college = (s &gt;= <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method two</span></span><br><span class="line">replace college = (s &gt;= <span class="number">15</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>变量输入</p>
<p>对于较长的变量，一一输入较为麻烦，，有如下简便方式：</p>
<ul>
<li><p>在变量 窗口双击需要的变量；</p></li>
<li><p><span class="math inline">\(s1 - s5\)</span> 来选择这 5 个变量；</p></li>
<li><p>用 <code>*</code> 来简化变量名的书写。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">drop s* <span class="comment"># 去掉所有以 s 开头的变量</span></span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul>
<h2 id="other">1.5 Other</h2>
<h3 id="calculator">1.5.1 Calculator</h3>
<p><code>Stata</code> 也可作为计算器来使用，命令格式为 <code>display expression</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">display log(<span class="number">2</span>) <span class="comment"># 计算 ln2</span></span><br><span class="line">di log(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">dis <span class="number">2</span>^<span class="number">0.5</span> <span class="comment"># 计算 $\sqrt&#123;2&#125;$</span></span><br></pre></td></tr></table></figure>
<h3 id="invoke-and-terminate-commands">1.5.2 Invoke and terminate commands</h3>
<ul>
<li>调用旧命令
<ul>
<li>使用键盘上的 <code>Pg Up</code> 和 <code>Pg Dn</code> 键；</li>
<li>在历史命令窗口 <strong>单击</strong> 旧命令，将命令调入命令窗口；</li>
<li>在历史命令窗口 <strong>双击</strong> 旧命令，再次执行此命令。</li>
</ul></li>
<li>停止执行当前执行命令
<ul>
<li>点击 <code>Break</code> 图标的快捷键；</li>
<li>同时按住 <code>Ctrl + Break</code>。</li>
</ul></li>
</ul>
<h3 id="log-file">1.5.3 Log file</h3>
<p><code>Stata</code> 日志文件的扩展名为 <code>smcl</code>。可通过快捷键 <code>Log</code> 图标使用，也可通过输入如下命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">log using today <span class="comment"># 在当前路径中生成一个名为 &#x27;today.smcl&#x27; 的日志文件</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"># Result:</span></span><br><span class="line"><span class="string">log using &quot;D:\Demo\University\XMU\Class_files\Econometrics\Econometrics and Stata application\Test\Test-log.smcl&quot;</span></span><br><span class="line"><span class="string">--------------------------------------------</span></span><br><span class="line"><span class="string">name:  &lt;unnamed&gt;</span></span><br><span class="line"><span class="string">log:  D:\Demo\University\XMU\Class_files\Econometrics\Econometrics and Stata application\Test\Test-log.smcl</span></span><br><span class="line"><span class="string">log type:  smcl</span></span><br><span class="line"><span class="string">opened on:  10 Dec 2020, 19:10:30</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>暂时关闭日志</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">log off</span><br></pre></td></tr></table></figure></li>
<li><p>恢复使用日志</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">log on</span><br></pre></td></tr></table></figure></li>
<li><p>彻底退出日志</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">log close</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="updata-stata-lib">1.5.4 Updata stata lib</h3>
<p>更新 <code>Stata</code> 命令库（ <code>Stata "ado"</code>文件及其他可执行文件）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">updata <span class="built_in">all</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>非官方命令</p>
<p>最流行的非官方命令下载平台为 <a href="https://ideas.repec.org/s/boc/bocode.html">统计软件成分</a> (Statistical Software Components, SSC)，从 <code>SCC</code> 下载 <code>Stata</code> 程序的命令为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scc install newcommand</span><br></pre></td></tr></table></figure>
<p>如果非官方命令不是来自 <code>SSC</code>，则需要手工安装。只需要将所有相关文件下载到制定的 <code>Stata</code> 文件夹中即可（通常为 <code>ado\plus\</code>）。如果不清楚应把文件复制到哪个文件夹，可输入以下命令，显示 <code>Stata</code> 的系统路径（System directories）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sysdir</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">. sysdir</span><br><span class="line">   STATA:  D:\Program files\Stata <span class="number">16</span>\</span><br><span class="line">    BASE:  D:\Program files\Stata <span class="number">16</span>\ado\base\</span><br><span class="line">    SITE:  D:\Program files\Stata <span class="number">16</span>\ado\site\</span><br><span class="line">    PLUS:  C:\Users\YangSu\ado\plus\ <span class="comment"># 复制到此文件夹</span></span><br><span class="line">PERSONAL:  C:\Users\YangSu\ado\personal\</span><br><span class="line">OLDPLACE:  c:\ado\</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="search-and-findit">1.5.5 Search and findit</h3>
<ul>
<li><p>Search command</p>
<p>如果想使用某种估计方法，但不知道它是否存在，可输入命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">search keyword</span><br></pre></td></tr></table></figure>
<p>此命令搜索 <code>Stata</code> 帮助文件、<code>Stata</code> 常见问题、<code>Stata</code> 案例、<code>Stata Journal</code>、<code>Stata Technical Bulletin</code>等。</p></li>
<li><p>Findit keyword</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">findit keyword</span><br></pre></td></tr></table></figure>
<p><code>findit</code>搜索范围更广，还包括 <code>Stata</code> 的网络资源。</p></li>
</ul>
]]></content>
      <categories>
        <category>Class Notes</category>
        <category>Econometrics</category>
      </categories>
      <tags>
        <tag>Econometrics</tag>
        <tag>stata</tag>
      </tags>
  </entry>
  <entry>
    <title>Text-mining</title>
    <url>/2021/09/01/Text-mining/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="f8f00114c05a8952d25047b8a1bdb94568eedff527712a7a6f5c56d3d0ee4673">1a94f5aabfd567a9d84f9e063bcf0d9b26aa52ab41ce8c450909b9e6b4aeb0abcb8eee23629b6ef075d778f629885cc57cd59ef23a6c244174a4e6f516a9d50cf073ea1111545ec0f21ea4ab1e6793577db04d65b081eefaceeeeab072fc94326acbc3282237baa577eeaa23a08c6d69f914ee17f1998fe7e662feac6bc6adff3941a0b1a46e3950e89076e67d117381589c757574789b6c43f75225344fcf639a64f84ee12ea7ae5fe57a14cb1a5b04f421f5a4abf0a82914ee3cb44873de92070c170b6c1ff64dd78f311eccb9a52d2e352d608342c53647aadc197fb4542863b6c6c04b079a16ff2b58b663e7989c88463e56ace0bd4c9301a7a134bc72ccc7db3b383c8f41b4b91c00177e7b8adf43849d72dc948e07fb58f35eafbc2504246845a0b67747433c023cb2cdf5254b29f17fee176c2058f9b56feccf5edffc9b353008b50068827a12092c89a07dcc7f643592cd2247000392bdd76b5fcdfaf2567e5565e5112dc1ad85cea7da38cdc5fab4384598485d5a8188b70f9775c5abdb3b501c3351a21d0a0ffddd61a605c7afdd4fa547e8f7a0c6bedf7d85c3fb622d0926741c410ba4851190807df78f29f1287e822a7007ee59dccd912b25b93b2ce9e125d00873fb85a24311936a842baa35294ad7371b7e4e80862eecb4d40411bbeb70e7ced90fe785d79b14e5a3db351dd0dff952c25b153f2bd7968fa7146936b10eccb1f2df98d25c1d69b7a038477a49f52290eaec860c735dd3d075a0e51a8595c357bd6d2f8a3c633ea5db197c86eba4b3a68fd24c25cb43e72de5bf55e9d4640a200f65c22f5702613434b300db97b4dc16fbd4578e8a0ca0a04e6b0b3d47af1621eec08a3f96fcbae4a71186950812544f7ae6ab00e0d424c352cc60d6173addb178bb9914687a91fa2cca401d3bcadf25c13e414854edc7c037c1c527d868e4875f906e478b7472e15df85498df7dcc361bb6d71fb0aa3f598571d7b91d643574fd773ca2f68e63d20eae53b914af73b3aefb0213d14e309315abb4862f7fe5c7186813e60b5e752bcda2412391bb352442c117a9f32bbf56c45e3115d6dadc0d72297c788db2b25e68c60d2dd563008207e2eb9bdd40d3c914f518df28605328e434429050b57c5dd127289ab373794609258f6c114f6ebe6dd812e1ebdcbcad16cf37cd6c70d3b38c3c14f97aef65a72fe67264a41cd780476b6cb69493aec17c4f6c0f837613c6ef8c3230201f73a0573b90ede627d571b67c871bfb12e03c72177a4888ffe6490d362231c30879b0ef2676ed4baf92398975b5babcf3b3e20a150688263a3c4b6e1aa02256e74a251698437f88892efa1d1aeb671788ea238f2b0811144242eb22e7582ebece146fb4795687950e0ad13a78f4feda96d32caa4531c05e63181aa84dbae3114b2b9bc436027bc21fde4b3481dad5ff4f499881ec7ccf7f657bea4e2ca151a9d63c0091af1450c83e613e4f2f1450f62a7c49edd94b3d91b02154afb7462f88abe5bb948a48e45c0d9eaef9ac6185529e04f0dde0796e8844cd78f2b229560f01fd4725f2bf6c9b50f4b6cfed09bd30eb6e8faa1ef5fa05f2546a955cd257c84905d11586af65f7c6e007ee423bc838c85f4ae73ed717098d256cb1593d7d6d46337cc27c62367f876d1e0ed83b991f9007794305189d5daa8128893e8caf95ba3251d88c4186702320733c33c9f4fb0212b355ae6407a439f2465e2465c2a958ba3b06676c46cc8675827346392ebd5579e0b64c0bfb3b8b08b0b373d0b582388497f297e2abe60232f2ec421a3e6e6c2edd973aaa1de1f6801f90271bca4ba2e07ff53bafe78c0a124330e1a6cd21c916218aae09f8cea90a6138d1447de3a7d8f5dbca1a92e7bdeb8f3d495077af0c8bba8cb81e976fe974f6092802ec9d055bdb68c95359e76a03865df3eb982b272afe0930e21caac0ac52a4d372020d7a6dba27d4201ac4d89bd46d1b01ecf17d2cac86aca041bc0cad2bfd07b9eae0b44d8dd564523f11e512c47932e3a1688a32934edc4a8e904309f70e593d0df3ab40c8878191bf9ec40480c9f593bc8aba4626b420b170d326e105c58c04dee9e894c865a6e00946598c766501b3c78517c92e90c1879bda2afeabeb1d24908c6899752879849e18990b3c67a4d0e2ca886eb23532534205492d067427bcb4ddb25e78521fe6ef01f378941f98bc093e631133061fdf02e3ed55f458c9d8ffdd9144fe7797a6d008477cc5fabe580cebecbe638eee6249663fc06bb07afbf10f23318ea5edba2358e07fac8af1b0d9e37422757b38572e35efa72519196c7d58e57cefc8a74b8974f1cbb0e31c63adcd320800c73b12ec58aa0e44d301f5dc49e49998480a58601e3cfff31499f3b9f8179040c15fecd0c37cce5fe73735d869ad6cc260c0de3ca96a333f2bcb1082e7ec3c72fca87a9a7acd44d23babe5328434a50129e8bf1f862d2830ef34d43d396d7504158fb344c7cd7b7447a82d0b77e4fb67d464c04f98d8ac9e2413a4a5cde183eccb6d626262ccd4a48a69d67dd7e70d84e2857c8d4497ae555b1aee5e3e7a3aee969afec4d5aa3f53298a65e1807f8eb92811cd98aba44cd5881dc3f0028fe3bb0376c8bed4f81975e99925eac604b96e8da567f771aa11b3e1dff5ddc50a3b29e26260dbe3fce282483b47d1cfad5c73f3bdf7961b7ef3ef9e38fb2565f21c76ffb4704386bed5e9b94a8b6f0d0ede06fb28723b1bdbd7b636065c1972aa9b731f8772c2b2a6a98fb65405a5fb22d8d864f929ffce9545591ebfd1cfb29bfd2c4bcc0320cf1d49039d3f8177843ab152ec4057977880efe44a190e39f702920e39e52c55e82031e80fa789e60b62e80028db5bcedeff3e5dbc15669ce4d23bd8dbe50254effe6bb441ac6840c4a0ee1ebd37053fc694c022d6484c438e4e1746c64bc77126419a7a632e74bede4ee02289308d4309cfe616a27cc82a8b5f118fa73541e19a60117fdca7b2271dadaf53b78771612f8cd7964430abe9d114e95c96e5591d7093463f2ba1d3c4a310e3e5d69c594e54dca65602d3510689c390fa7aadab4a5a0c6b1d72dcdb1add5705294626e921ed3d759acb63b39e50b3ae7f32330c913733fc5bfd07c98d9ffde8ae8330112c87025b55a68beea17783064b7fd3b08765e396ffd49967a7274070cbecf61b990f949db2453cd082c74f65baa4768c31ca2b65811017b4eb2a16bdb26c210cf9cbfc06b6874d14a8dfcb7828bb4e6c719c00b670412b52f17b17df74d7ac23a37c98c22fab1b081d70e2fc21e77040bd6d4c8a2f34000deec9b11164e07c9f6b8bf07df6a43412f486af8161a52c8800b0bfe9a3259663862b2485f7c9c2c75793a754b1c22f08372d1cf7b3111f8309d136cd8a30809774ece9c0e107c2ce15fa3adf5b25b97ea60f8f2fec9d6e18613bfdd484e30e446188be91ffad2388a007ef2e9df15515ec93a0e9203077d0ba07629eff52ee7e68d1582ba9b9662b8a375b9516933e8b6f7214b086c4fb1b09811bc312d5b0d2c48ff92d1fe31c2cd80d580e970a904963d10b0c10256790e29d3f887f35970a9e64c5468a9e33e81a753d18d66ed3c30c16f85c6b5c400c974513265a6e26ce40aef1b28882ed75d13ec80a4e64e67565dea6324a14ced4f3d358be0bd20aebe238b1ea2144a5fb5f6d8a2f7d1fa14bfc83a438b87238fbb4206dadddfc723f2f73d372cd1253c0c421efe93b8c1fae925ff34c2a1f98d36485457aa9aaea9feec73e83f7b9d35838429a1b5a7ac738d74f260d78b509d9994a581e2e6b42c216ecf358257fd87aea720b3e8dcd58b1265e6392e691ef06bee82d7af05798b6eb25611986d0d665b7eac8731ebc7fed81d12fd00e0fb1fd7e664dabff4eaa00860e21d3b132ac431a5d7cd448a27e0dba827b74b7886adbd6e75f69eb9b9a6f1f629feb83ad3273d2343983450ade1ad4908cd3ce8721b675aef28914ccc5929e109b44ddeaafb3875b290a883369fe343223f5ce0c492c5557870fe87c2c1ba95769e51519714120b0649db27e182975596c945a233521111745dd69132c3c15dd2496300b60a633ed10c9d402c28c8b7c9ba32852a3f5b4676a43359677c930acb86c6fea6d9d0ec24993eab0c724bbaced5634c22459cd48e3918dd25ee015641bd21ec7928469c63ab9ec1521d39d70390608069cdd2a1b0ba07bb0a3e8e6c0190dc5563bad2cf7d65dddaa119ff60193af27324d4e5a845dd743b0d43d6d8b0d3884ebed34f1b220b7284182e284a8015d270413a38cee9ffa5f8181d3ff9fa6ad45d1063d6a325435979a2ccbe970ad530486955e71b534f9fdb47840e6e6f43324a095c400236bf9b1ffe9b2ef8b4da0c2cdc92ea80ee4d558314889805bab1273b43d5d24ecc35c2fe3718b2af8df171ee115b9b626d5437aa27cf882282307961732166dbe4fe1d7fa08d29933bf42d83fda33fd264816f0c75255919f6eefba647fee7f907344a17212341a18bce0829e45f7277e012d561385d914b7293bff07e60a5489216ee773833bae48219bbcc50504a786e924c89e69e54624b5bd20d1656188f53c44a0055fadcea45ae1e5782e74995e8dbaa9a4576db3a362ef9301b2950e44855d096bc13f983e90e1831abddfbfa8d2a42ac766e89fb4bad5c90b2fcb5a9ae5bbfa35b6fef6b4f323a22d3893054cb8a9b2828a1642e9d0e6d56e40406d78229b24450a0c3bdb129392629edb50e9f10b28c757e7ce41bf9563ccff5ab5f3072d9d6e4dd4eacf9e556378cab919a111aba6ed6847581017c8dd5fb82aa1ceb7a9dddd1dc69bf0b0a2d5d8d0260440aa50dd968d14021ccb7ad76e22611a8172acaf8280d7025d9c39f9782b55bbc08f31400941bc30d506300128c66cae690176ec72d1982ec2eb902f9172a63c8d2e6e92323cf70f00a9f26173cd7d66f9dd7dcb8927e419f0f75f8846b4325b065417d6688226819e3f08342d27f27364ff2efae9a052a3304625a6112f9011f48224fe56610772b3dcc0102d99a440b55c8b8d3111c477d3458cb281ccbb8845ad398afd0358f844ef615b95db679a8d67e242597f4df77357ae8958e2c81c0892fa4f52fed1dfbf68ae13d9ee41f879dce7676f5e4b8e48db93504de0c722f781ddf9ee92c2b6487414fb7da614af62713f95fa64a208ef20d729f6241ca6540cd469814d58a210c0ed31d4c8ce1f0d9e83d6b4b81fb1cd624b8e1ebd2ca953f2b2465cc4609e42215e144b1b4a71c5293331da1e74fb7a35903863af5d3938ce87a914a0c474cc18620d38890a977e01a33b60ba2e826a4d4f1c60060ab3e0bbcc3b967f7bd19055dad406ab3d544b348b7f1c355ba232b00595c84e4bf99e34547a32c32d4ccb194ffa5e15e90dedee6f4823d5441c56edd8b7b96d10759f274ba2a1e5494081edc8b72acab8758834ed094c5bf0cd23264188cb1afd567c6dfe8644900b974df8437538200f078f769fe75311e07631f7ec6034d6268b82da2ee51af29f486d4062a836ae9975ebc070fd5fff0c21ce018da39554aaaead7c4f640a1f869beff0f141652123873e0781cefcbf172eb65055c6bb70a0569d8f7625cd1d3ae3bb1fac8e62b740e146df1131f51bd4ee409ec87dd4cd9b71de0b11f76fa94af737d16bb81ecd2fb754354e2b6a860eb24186cfc72abad8c98e835fbcd74cc81123708b60476ba7526f89ecb3f663c1d5c473a610e27ccb247ccbb0b2848581560a74d3da48f65d3f020e24e86dc22ab8144cc69f7b9afb129c8b53acc0b867428c701a05e6eb314390cebe6db42529c0ace35440d03a98fddece9064ce20dc46c345c5fb8826a35e8079ffded5e85a4e9430dfc135500c628b217e2fd50d45ca211d6d6d9afa950815bca00af418b820c62d4a44d98bd060335caf1ac4f674e8320d9af8c2524f3a19376ccb195d864d2a49ad8352da926f53f52d9ef142f813866d9b72a49a1fa295d4917eb0851293d126d11804f3534200ffec74bc5143895a2ecde06391be5e7d074670f947f09ffeb3f6de1d7244e7299898868f67b702c5c0d20243414659b77536582b54aed16f3c4be4ca376727b424f1a6b94e07f82bf19254d568a57f2234b312759ae8739a09fe1a5a33caf24f560609b7c36d5bd176fd4c344e47bbfc048e75b9c3cca7a7a84bb804bc7201c8d8d5cc98592aa6b4b3b0394e3b337e1900449c2dfcb9b807bf614395f7a81a49fda159dc1ecc7784f696ff759f0f1cfed78a2c2d340fa716126f12191914c2d6f2b6c3836aec486ad2c93aa814778c9fa808572fbc052c4ec1bcef7c04ccbab1249650ae3a661574f53531cc2ae6b4d983512b1adbcdfc73c7d2cec433966fa0d3622ef3c9c3f6d4a2129eb67b3e4855eb0e67e70ebca5a7b239be2757f3ba26901d293f63ca3da6191ead18260a07a31b232cd37f58ca9af3df138714b3480e23cd012a0b5a5e23f94f2142d9e63050926a91d13bf21ff5f66063945e061b59a709b8b084631740c889b4e27ac6cc52d5f968a5ceb023749e8313512d9a9b6c6f34bc4f92aa86f688bf37ad2f678dd59ed9cd2a1b5ed9836709d325faada11507f3017a413070348a27f2c575c04fa2c5923d54026aeb011903afe5c12ec22722f30cb4325b7ac253330fe343769769c97dc09fc8f137e577d3cb75019147611e657e5e6245a0560316aa67f5623e11c7dd62a691cf610b573babf3ee5b3a401d45e62f04bf91a051414a9b76e75cd06b14a5c124bd4b3e157b2f7c1987c5dd505cbe4741bf73f18c1e384ff7027d4852c04217e5636772ca74999e077011aba9a67171feb9f7f5a15109ef026bf7c19d28a8793a8401f2956816acc8fc24e1364e1e30a59a4570435015ffda22a4585bdf592536641d48d10ed19f6b1b023430cf88ce503ee0d92f302a36dc9ad17596c84aec7da950849189ca8ab60b1f3d4ffbed73ea72c5a8ef8ca2950babec67b058101a39f4a0c37c065fb6f7e84ff00db6348008100494b9107ca18c771231d8bf2fa8d9e938730b1a9041f8aa4889d893b5c4a0898967dc81f1eb685298fb43666b6e7609a85c021e6591604a990bf09e08ce072198233f98c972970e1abf4ab65a9d6c684ba4dc814695a4de8eb1c33f3de803e321edd0882588c2c530b3de16555e05304541d915fc8b19f4bfe0b2d9da7fec66627aaa709f2aa27378cf9ef75ec4b71dab247834c4201bffb03f78bdb9d4d03ec359dded5fc2af097edc109574a23f3345b58e168c2654b9027b9fab75b876b688caff05074b063fa6aa5bf9412c34c503f0c15dc4a80d9749b628f4df2636337cd739eb15b437e464b2891f507a39dc8afc37e4c33a248d9826c7692f238526af455b651b68857cd013f743c371f9a4e97cd7743cfeb451ac4a6d8cdeb33c55a6f5ddcc159d2693d622015e52549eec6dd9fdfd2e461729f1564addc29c00937535c2cfcf28ffb0bf0d1fdad9457a84674e57b6c800a4cbea8005f359b77c2db23fd71150a564fa39b5b32544a81f8df90afd37e62f75a02ba686c3b2824d382244a6659355ab21713f7ada1ab53d27ceabd6af54d0a0987bc1054525cd29bc75d46fdcc10d7de671844e500cfa3aca0680fc7fa3fc57c754475343cd374b3fe1d80bbc7aba71b0f66b566ceed621a15edc629e2d4dd4ad33740a7e22ace0c0bc6a7b32cb246a7adfa9acf1e09931e37e01b233b5101b5eb11e1718c94562f1bcdbaf00734b6011c5b81e405b8306ab7cc5b132dad70fa9be281b434dec7e328f4b1d89bd32c302ab422888704ba29778b2fa3facfe6dd67720c732703a266a0d3349205e28091e2dca3c3c1b16132eb79285a7e4ae4d8d1fe188507a2c8ccaa75d3a5f41343c75e5beae765de738c759d64668fb18319f0b6e0fcb3680e969f036be785488207038c65a24b0c2cb52d625a77d74ac0d6d8f9ce897b186888e70724d9add34bb4b2a8255cd261f47cde5246eb796930bd9f8b8543c9f11ddd228aae0fa13778acd7849755200bc449a7d757d89073f91d6f36564f51fc845466e15575b8860cd1d24f44dc1a3d91bef51f24622ecf566d99b16861c7568450fa07178f4d3dd268a9eb3526ccfa720ee0f9991bcd5c175bf25cff89e4ae83a59731e123f65b7f725d09e3b3fd7091715f954558b091578b0d24954d1e081cc9382739424b3a081caaa616b23d25161bd857a7b011e8fbf9183eb8ce551f175b6f676666815aec5ce69f585251612e5f7fc6eb368d33158d68876940cdc10cb24b9e650aaa0aff734dbe3039ba6cb706e1f44ece3bee9b320606ed5d5d86c0f3c4b164fefdf0245960569c9c337ca4a0cd6300fd42c20d0f0404501b627eb9af74c43179aae2afd9401340190769b4a42e64d3abb34aeeb4e1c8b3a6c6898ce30f2babcc4a98c4e9ccf92deaadd83f9f8d7a7d782ba2f4206174d302312b2c47d0f49f4dfa0d9a137db237d2a1e66c0e76579e2fe59913ed4353334e4e113b9e864dcacd9436d0d71b75aee6079582bb49acf04ffa26c18216d111208cbd06276f87e11f633d07ed11288498edae59f9dcee62e6d497ceb2b5835cff71524a9365757e5b257fd23c8a44aa22bf832cf70b1d7c095d1e0369ba95e483a055b9742c51773064a943b2b7e8cd7058cee84d5217690e1a091d4f939b2eb09709dbe1a124a82b83f38fa06c252b2f9d0a7b5e548f3f32bc19665923fc76ff0c67db8d8ab1495a3e91b5a950406c29face29087c464cb9fc42fad6b6b75a835e8ac758e6e9cbfb00d6e8fe792e845dbfab8c8200a497878126f1c13832f68fc1d2e7b62374c558458c749c5959d4886b877b86d7a2b419d0879fd71ce4e830e2f1cc0e1432e74633b44f55952504b5c08564dc4bf85510a38e2234d24dd9cc02d9b464305f4a104f1332f31b7a3b31d6ba175808162df922a4b64c070651ec53c3187497e47f5a57d9aff54cca31b20bc67934c2207a4f65dd0c9f59e7326e6ffda685bb702a37da68dac7fef1114a1994368657d2627910522988492742de804f6207a9dc63516250f3054c0d265b7c9ad6ec775737bb54bbaf41a2b08662c6111251e6c46c66d08f4a90201d44c15f892bb7c85b6608f13a4b3b48976dc4810e6eb6741304d7a5303efd97e053d9e293a9f5aa2e85e378a67be0a7060f626d548d0dc35b0effa9b88c7789a59b8496fc7852687fddb4a46b322a4e2332a2d98abd7ddb7b211edda9d3524cccc59e650800503ec9ed775cccb0c13f11c6acec9901d9869b214f5908c3cc506d6ae0f228c603531efa85cacf3a8ce955e61222c6c36c19b333df235d972a902cc62e98bdf0f5a50838f6ed178f17aa52a01a6b66ef6866b24d6010ff56717d1665728bc34dd78e398cb45ccd54f9059ba8304e0e3fd69d82bc27f670c541b89b4e865671a188ebfe049f0edca5efe79740006e86d0937fe0b7ce69fb949b92b0595e37ddccec3abc7a0deddda0e2300dc57321dd7ef6b2f153ec2446bff1020bbd36e16511c7637e3b0f2310671dcc262c61dfc87f796a605ff8f24d8ca7fd8d1e89000cf8fc45e1decc2f2e232d32b0c19ce4145cdb031c37ea9434ee0acb129b63bca40287decca51370bf0d5cd37f4b9729a21bab12b02dfa2d975f263b72ff81206f56fef6e42f99553bdecc4a19cb8fcd85d31e08ac47213d580e3d62db4dff79ad2c3749c02a62d70b2ca457b3b75f160c87075310e99213f68e05112da6d4ded98aed6d05b9b015946c0fe82202df3c1506ddab8c53496cd37a9de0e9789eaaa8eb091c9089346b229a7cd7b69b6d9f10f2153231f705c9365c535df2a7ec065e2062376f84d1cd1762e3a50d004f571e94105922c11ec0b6f589c5214367d17a7a27ab78786d83195ef40ac4c1cf8c1db764d4f4a0fa1e86be10328066741bc2d9acd3f6ee03d0806a92185c7c06759b442b78dfed9170615bc4096065f53035514e5bc06a762e8c78b631524d2e1b3ec1073de736960cdcc739732000bdceaefa55a08318b22d52d357efedaa75556abca5cd3a76d7e6f105ca2d89a1d1e2d078a56a0022988458e21df86b6da9dc81eeec0854f6acab9ddeda1b604a183332193611bf4861770ce66b86078275cc4191ed96d3d65ff10b53596fcb07e7b398a6734c0235fc9ba817a2ccbeea138aac4b89d6f06fb5e0c5972a82e80846780419a43d6f1b6d0abe59c82d7176341a222e6322ab09b61f97b16366b1fea08edf47412b8246dc5e94e5c30c126113f7a9cb61de0cd5a5976e2b042f23d48bd44edc363837f69006d7fcf4c64b8dc7e05fb4884f9db3e832121369e411b653cd7caeeeed1b006cd8084fc9808a67f7d6ac5ed8134acea653bfc2dadd30b0d871fa2c7b1a182d93fff42e2a2d011b1972d237e170f3e3519dd159b403a22e2ae294402c03b07657039d78cfa479e6d7afd8f3c3e3ffff054d4ca90e6d24a971a4fc0dd4e9c57501003182884199f71f52d3ee628c5bd7fe9bcd45118ab71f8b0b335214a74140cb2ea37828e9d7a5676ce1abb0e84e70ef359c1e02be329e59135e2832e85fb7980daca6819ec58d9c282ccee36ba120987b027630531d37aadcebde9cbb4b00ff2c312c117c7bcbcdc9ddb99eb946d356402a4748d4464f918cb650b27bff4491bafa9d19bbad08430ff6fb9f2b31191447c28beee9e1b92e1988c14d4b357cbe71f9e4c42ea124cee91e3ff1f04e4c66e75b77181644126c34ab228fe29e7c248da4ccb90c63ac4cd320202570320449c86d1dbbf5b3365fcfc73f9778f219e4de469119b4afce8e4edf636e6da7a179b2f5663e2920d3e9c1bc7567ff67b104bad0e21d91a0a2f18d1e4474c8c5c7c95468516840f9192639134ac3e5648e276cca91cd8a5d58492ef765691280e62f9491f641b30287cbafc4b34c872e625714d3797fb911fb35de00b5b5d17ee9cd3a62a4469072bd559f54bffb867a1598aa2b50cb8c93ce3bc6c6915e532a3abb29147bdb1f958dd084f44c69599017cd0a879f0421021c095f332c90ea29bf863c0f414f172f3d386b1a9e8a10aa12d96bf0bd87690896a63725c5c45689c1470ff2b3e551190cd9dbdf4eee6c80a8ca1e764ce59d4b3d76d7765bd9e672b755d38f462f3f5d272cf50aed41ce40cabfdefe8a7a4c21921eb535e0678c8fc7912f89a0216497166d4f8a4f433476f5055d611afe3017f8830f2943dd3541975cbc8fc275bff4d7672504e956317f45040237739cb32849aa7328f9d3b0c41f2b0c50b11c474a976681324f099196b5890e218591243322d082345d945b18cc63e5df2bd4ee0628b746903bdb5564d7fde0b69bab8d4eae786e3f6e6062384d4d46870ed04f558c47d93266bc0b38e3fe0dc08b029eae15e98848d7228c3d1fee4402912185274d35555c1cf613bb8f4f171b0b78f06518982de4338dc29c4c596edf1662cc25cd2c560c12609ee8c52eae5301fef8aa9f9bee443568f40aa5b97aea254251ce2adcd97187b7c43dbdd30583e2caf00a76ac1ea3edbf154bce7afff2cef2c17a16a3234eb77cd556ba6dae849a4d54fb94fb3633be105032386338c3e39a0c291e5f58e56e933324244e2f65235f388276b113beedae24677183c80ca74158796a6e39073562bf02d0358f30894ad2de8f8616583d94cdc3fe4f1a01e68e5a3c0e22e75ad4bf90d758eb9c9223c864bc6125f4d8039d66b8b6d72982c5167196bbee8a2ccab41c7f60daa7738d7fe9edc347d5a25e6a7b7104c82c0a18699f15ccffe943dd1ed3f64c21aaf230f326ce7435eb52ce6abe8a9a5a6bed86f90b980496df6449c4b27bdce354e13bfd995cf514db5b983bf527f92ff5bfe84bec4c97f0b4cead1f005c6fe63c909e4fbddef323358aefd7a41933e01e71d7b620485eb97a9c4f59d67d9de03ef6dbad471110023eea3b3a4952cba159f49b6dcf38834f51f4bc026d4fe4fe1b8e5fd946f40131c532f91350f9b7bce4e79d9f5432679216e19ef5beb8fab05b55d1d4d2df1a3cb3f44d306c4046c9f291179bb04332fd5f52613ffe7089f3cad956efb9308423dc303f5a7ab5e7f119f1e2905a645a05d3fb23584174a1b16a58499f0b1c76d150dc88f74efdb407a086325069f0a028f705cc47ddc0db5a0ce3a4f8bc68a464b32b1bcbf21c34d42339b7c74eba8597327eae56920bd97da3127de22104bcc2e2794a44a92a42cd3bae8fd9e18e27a955ee514dce01927a20db2e67797262ac66d73a360dd99c8048ea2d2bb642f9a01ab3c2ad4e61c81f3889d39143757166b9e1f16d3b0bba8495ac2bb87ac3b423d44c5eaabf8351de327eaba00cfe853b1b8d623a5fa8a940be3c86203c154c0670f6cb07b159a6efbff9ba97b8a941bf358801225d4bc7d9d757aebad2f934cf630da57ae85af0eafa57e4b32b1b5fa8dbac78ba7bdb0852eac07284542c5bbee0b4ca6601389e15dd1a8c8caf2dd650160933cdefce891ad0331ee33861f95aa9a6b171e54d2dba3b77ba1683b581753218203699a5b37d996cf72af737a1d1334203e2b392be6ce58eb7e69ce6f8bf90faebdc03a9f095e87af28a4b1c29c8ec676bdd735f2b0da37ad83f303352a72a5eab14bf4a94ce0399b79403034db5b6a91ae6d50df59ba35949e27e28454cea47db18b3ac3d2418535cffdccc1c710e1fe249e9896c504ca53b1346c6b1929dd5499efe15a852051f42774a5eb510539b706910a389946858fcd76c9be768aa9b1cbbf58c8bc1e08b2741309cff59c9f374a1f7b5c95f641236e1e9b11d295bff519b47dfaa165a00f3fa42c64f39f339b56ba44f8d9cc36feb078dd87f0ff80ff8db7635a2b10750b53a92df43852533cc7b9418ac30275bca8d0fcb40b349d666292c09516322513db939f8861a188d009fbe027e02a1ba56df8883461ae59425d8c75f432166b8b6d0bc5783fa4a18c7e934b9dbc4bc53eadd3562cfa768342a63f5efc85b8acd8e07acf78123cb4cc9d564a943def7f987fa85c11051d7bba95506803c8bdb0004398e241ae0ebc0a5375751c9dbf30a84b64189a1295d7e9b0830afc4d1429d70dab0723faef05d818732d0fa5294e21a731f2b9161d906a950d8cad0eb47645bb190e0ce025bc268a71d2486abaa831fcc5fec07a772a9faa15d463ffd2db99bee821f7d2af10c8547494e19e7aa2c678017c8c36ceebff865d8662058af3e4997029191f158da06b7716815715b183e49305d234da4762b98305e9a998847a2e976b464ca675bb3c54f1f3e0584b2ebbf8f6e2104508961e8c11fbea3ed6a98e7f7b3771771e17fd2984d7c84c36f50f394d0dac7d81937697d9cfd102d41868e00c6a697cf417c59031f3bccf367e11db572f8c35f5983ea69c04039d277635ba3b550e5433838015f3d8d5301d37068f9e6fd252c012c5d14d5f3ef5bdb2fe966b3d805bb732044cb3ff1090fa61bead0d5a7460a394f0c7f7d38d5ab0ca19867f03ce2a84171752daf74328f2a1c2fa0bef850773c6dc669d70418ccff9531428624fece4e329ff440c74d4eaef35a73297cecfe98cae0ef46cab95b73c0a5cff35abf9e2d7f6984693095af97129b287aea1f9236fc311208c1b03da2c6f600c4484089a29180ac9409c5e0f2f090df3f3999da0a6f6d8ccccf5edd19da1d5f657cf5e49bb6d886bd45ea97ff58a02ca4463f49c06c6c4856146ac329c7b1e1b92469db69950525826dadeed02e524b2c8498808d70142e8f846948a5a49ef7a5ec3c18d170257e2e3e17e002e72cc0c35d2d9ec132cb7e31a79bf7affba3d5b8d1c8e14d4162718d7e7f5a0158d884f58b49880bf16baa47bb9b8a4a0b691db0c43938871cdfa3808471e7336e07b83981a601b3658f81cedb6ae749dbe0581a938ac30dacb1c37986db4c750d25412eed001870fb809a3043a0c51a903f11da6f81f004b7f05594eef93578c4f57e10cedb0c7bccc6d1f683350d628001bf998009a3fd5da24447b8e3be735e1316ac7621f8f5e1743d07b52b67fa4ebf45fd1a062bbe92e7ab9ab1aa0e434f61fd33f5fedc81ea328b0f78e169857714dd2e21d72efca276c28acc9cebacac2df641475093242c8bc8e27ee9091533188933a485470eee5dc5de0e84b385974ae12528237293fad2718984b5914165cf4bc4b35bfa14e03dcf183b5e25ed580b31f632c83cb0824a4a675d533c52d1071086a63809fcafa5a1637a030c42df689e0244398b077f13a6eedc5ee4e8aa054066e3c293e3d53bbca7099e251135a9c11058f58875ac3de29cc6163d542a46ce4cdfb0cfb78632ca4a67a094f0dcd867bcfe35f33cbad106c12abadf668ddcfd60f760acbcab7b263bf183c2ce3fa410825548de911862755d21948d9606ac7ed46bb97645179ddfd182c71e040f9803b0b3cc1e32199f830135d036f497c33d05281f17b8b9d47b54d4ff5f014ef2cf98ff2b2f3b428678b6fa07a52dc0a426c80194ec2f64ae440947f651425c941a0871607fcefc7be2fddecc6108106eddc9eb7914ef832788a6b5ce7f716dac0e3c55b658f08adaaa32e329c05b644dab79d7059f7a894c78c224eca2bc3a6ee3a24d5726d9d5917f157e4b6db72dee0ae31a6da1c1739ee1e56a15b775874cb416ae4632a1c23a962ed55f4bda6ae50338e1562596f3121d6d8dcfc07c536223e282d85a51633b70e27ef5e0e3943380b7056d1451bdbe35864e30cca0bdea15b53659749f1c8f6c4a60841dd5e63bc58825f9507a9c512eff5f60c85a63206546b5a8741c9128c7e6f1c2488881f15d973126e546799736174829ae20afb1bbc3c7476cbf82315f636c408ce3148a019bae61775e653129ba683bbe34e314a28b12a1c5af294cd435e716f5f7e5b2211a078dd738c3ac480615a30d27a90044e78cdc1d194519077a87734e3ab0f0a85c637dcfc2ce1aa84eb79bc523708ba4a2fd1d7be9cbe6044b8d53a0ba80387bac5ce0d9a6e7c80ed4e1965f224e398f56bc5b995db3822fe70b185bb1f66e0da5d3fa85fb1cc75dd1625b027e62511fa57dd4ecae23a0d587aafb73e41cabebf331965e0e6dd5171930313ec7e75de85528a8d90c809c9223ca8ba1bef67b5be082b437b95af5b52608ac3ee6212313637f6e75dcf82ce936afa55dacb8938235c01bd7ff55db3c6a7c753e98d3322ef60f3d77af3e2ca1574eb320f7855953fb6ecf8d45fd3248682dd37547bd36e22be3f99249ea2006fa1aeb4c7a04c6156eec268811c0a2f1e6617d55244bc99d47cdec9f79f7e24b653b9962a54fe6baa414850ae6e282ad7c19d42a80bda406e4233bcaaceae4d1e83a630aab174af99cfa483fa1422f58dafc170d652356a216b5c5dac3122f15bb64ef97b1ab05d04a8acecb98184bd98538f64fa6520dc991da547fc72f9442e0a0c1aeff7f4e9bfa613b1ab748ac6546af67c8ac5fbfa9ed1f29c559502ce23b92f022db658b785e267401eee19053c6eca644a838022a90c346d2eac510f1d3cc857039a45856289beea3c5dae368b1b646a1e6e88d046b4c2333feaca03090aef4d5683e33fed3876e07b1aeb1be8e095d0a6722a4c2509200023c62824b74a809dd1c13ec6c18b5247f8af195a268ee82cb5cd9e01be5cc51bc1d0b3f484edd5e9abf6d9789e3d23e0ba3266e5de2e66729956bf51cc47b4fa51eeb2fb03963661ad5c828bedcc2d2ecb458812b85189f60a21dd5e2b5f934ea94a0d14674979536567bde4697c4a1259cdb28116988da726aa1b02f81ae41bc062ab6315d81d40a421838c2f2b1b142f3bc042c70c48359b4857625c0727837e18d0aeba9ee2f59a7c7f7533c659b5bef567772ee0fd112ebeed00a9957f03dcd3d158aa4cedf190ba63daf6b4c8877ca03e8f9ffbccc35cf1fe200252778efeb9d690a80232491cba51fcfcdb8fd842b45212c3854b8304ae840eb8ac5ecd2bcab5fa7ef718fd6706d3a739cbc8799ede7295ff5609b84bdc1753446ad7ebdbae019b6305d791eaa35f846d1fb4294d7912af7eafc7aef19a474852008d9d9b84e0bd494fa97ed288665e44b0dcbcc6b5619cd091f2689e76866b55a9ea0fd0dc982a8d2aaf87c450ef0331d2cf836df469e2689aeb3182dc3ddb00aaab3b8f1323b35185ac648e63fcaa9f0eff5bf40559d7a096f5fa9d97d5b8580df248984735818e21e5bb3e037ab19ecfc1a2c66d0eb4f4ef5d936c4b3cce0bce81f251fcb8dafd9586d5f7fb26b92a99f0e45e4da18ade0477fa23addaca72ec3641fd0d688064aa15f94597d04e670854db2233ef5e505a935a211762b41dbff04549fd89b7bd243639ed1be0ac6f40ef895bb2484eb87a2b913becdcfcbe2cc62c5f5b28d73998b8ce394edc71d3b5faea1df8637253b888af0968249167f520d5b6f16e52033752e13e3fccb8a11354251b17e50599ab507d9a802d805a07e758cc26046583454935d0d69118dbaad0bfe4bc1322d3ed3d127268ca13ed75c6f7952100e4280370e6d3f6a7501a6877aae235ac0b660329aaa96ba83afa83d8e5b1d9ea74d69b8ee3e4b8beb332ef5f52d6bbb12ba330899d2ddabe89dd4d9955f48f5000aed5146da4263afc84f597c871e35da9ace9f24c87e37d564913fa2e9073421063c88dc19117d54ae39b16ab4815c923115e65a57287dae38153d02d7439c55d000fe4f457b669e8cf66b30d8d8c1c06f707e3cc456cd2078fbea7f1fd26572768feef2345edfcab3f4b68208574359a60a3ba64f636ede195ae843115b3ff7a07aec737edeff778e210e0983cd4d7a5a1681ce866456c5c608a71b82ae8ac7c01f58da1d03a86757a47f94af9a2222a8c24d4119d9bfa66ee1bcd8baa19ef3fee3387affece67a70850882860880844246121e775f9b887629d63b9bb0aa99e553effcef31635811aa19bf57104834e1568fe0753089cbb09f73cd609ec7d1fe07488481db797b53ea107c6dad75907f87ebb5e808d493eccb243acc72199213830d78849939d6cc5e230e7a659df7b611487ded0becf0f8081bc106cee3d1ed19f27646fbb71f206db8343bbf544a14053afe92b85526be508953c666fd741532e55b8cd5c37cd65e1b1680628456cebfc70a63bda2d60a6ce456aecf15374f3c58f1b399d7697b8409a94d690807f48f60cb30091ef028ed8c9b7168dd3aa99675ad63526a468d7ef280d7a5de0fab4665d990637b56ea6b10c02458a7f798572a82a192a5de42b04d3af94ef088526b24e8be0ed57019dc7742ba6f3a37b36b98a0cc39c476364a2d76266b92550b476bec87e9219677585cdc300a97b40c86c6ec0442374d4d1be8d9f633d6288bdb9a2f663564c9f28c15d8efde2d979345b44f4515778efcb0f5328c89a8d314e22ea7c714530b5e268123e08583c51ec954813c15912770e3e9301502f75174ec67a5c60caa8ebf1c1050cdcf731ce6d1b9ed1929ca857936945613ad18fc8fd672bff688bfdf3aa8c83108f5223c1e0f36b96086ba8ab95b7ecd5b2ffc63c508008fda6b4f6c0545dc334e98aea34d59fe8f60943e16ac47ee9d82d0e156a890ba06af1b1f59b8da5b8d3c6af6a9f8fb3682cd0eb04b6bcd9c9ec5c7428a91e964acd69cc1d50fdb6d1058f09d3d6499b6b4f4be3a286d823e29bf7354a0edddf987ace169e6a18cc909fab482349c069c125ed1b0371d8d5e074527b240b62f678d1e0557465747b46cac41ceda076a581ce02ce87a6d7c329b898e8ae153431438cdefd4ea9b5d97a30406ca45951cfbb18dec93efd61aca093679fd11badf8076236e016854f1a9cfae8a7c72ace61360ecc64598461d045c24ad4b14eff529630371f20fd8933e49fcebf71d99f0b2660f460fd4b312a7b2656dbea7cb9d51c13d8c5a71d3a1bfdc677f60026b762596b41a1e05b598ba69d3eb4004682e3851597189af7626b5cfb06d79ca03cd92e9eebd5b7447437c8eab265de2854ba21e82dfa85e7b91394fd1c76534069d922cdfeefa80b35890d4a41a46cd772f55a1c15aaab437dedfd9b5353492d12fd33468b082f9182ea512e57cec49f9ed677a11cb31a9f167156676fe8b88a741b9179ebd10cded1bf9484f0f16a944c793ad28cc2889ff8fb7da4462ca2c8d7922b5f30b4bef746bd5432e6afe5899765bf19f33573b00e3d5db05e74aa69cf2b590c1ec27a7ea982135631397a6bf937aa0b30108d08232580188294cfd21cc5be0bf3d5ecf3c53023f2fec417d30268b27ba9bc2515af59e898618ce339eb27efbe8d47c9ef76702d50fbac135feb2006081ac7493a5b9a515c921fc3a1648cf21eac3296a4e535227995772d5b001107cf01c75683f3ae0be028a3c68b011ce492e2eac5564dcfd06664df6738804aefac277023f3d2cb6ee5c52c4ba46ddc9c9e7ad1e66633cbaeed45f7d2e76b4719477f411c0d4df9e465d313ff37b16875a4a3bedda7cb7c4aa45d3a281ba89deda1ed0d9cb94eeddb14025d10446ef6b2c4e58ad91c1f514131564c822953c04aa3b95ad25282c050540a5f605237be9fe9137b8531110f2c46e8c4c5b1875310cfb05cf026104ca15e7259e85afcf07d19370415bcd33e1b5171f26a782193921e873a5696bf35c51b660a86f94c4d21d0110e28eb147f4724ce8bd08514421823f47c4463b8198b07c37e4611400ebb99b0f1b7c129be6178ef0d70828e23c5ebaf3a70a6676463f997b4afccc56d22537bc164a10dcfd120e9bc67b55f72848600c407437fa747112419459c568ce6c749da36ffde741841e8d3476dfb03908fdfb2b4ca95329d7d1bda8235dee17491641a7646d21262394ded859573487cbf5820a06c2905e6e4597847248c28b31196dd4f8e5abff10f1f2b31dd6c005056f106e28671016ae0ad6c22173919f781848b2d0da1527c57a215edb217f84d3ed2353e5c928379711f4d00bec4e77f8c0825aa52e5441475f1e0b3c3ca9962fee61023664dfacce9b700fe7f064c2b16c6422aa4f3533a1e099195613b3d8aa9711aedc4a4a3922f792941867b0da2e6737daf380f8a50f8e69e1dbb20ef890c8271f87f5168e0b0302e11d09fff2371be62bc80f9e5abec224e7f9047de96066918ff4659f5d1d17ed0fa7419fde7d6451a15ae96c5973eb5f5cb117824e4cccf8a5e341aadbc2365cc6eec45bd3bdd37911ae27381c2eaee68ee347ede0e9090ebd4582d8e484e51b301919eb3cb50f49606f7f46255bda739e7a4bcf07aabf185c9949d875f3a1ec13882a8c7b951c06bb09bcab105d16cfc409a13b05784d9f03faf4e9fee4ae8f647e12d0595ed46869494640c342ac9e4d37b632455e6379e882feb63924b1da0660b9f0af47696ae94ebda7699b696541c3b7fc130d7702eee0b913d7d8c409f93240780bcfbd864be72d0e25cd6e5cf49dbd9b9b8a7687bb9cba3199b2293071c7827543803c68c61433ef92a56446d12a89dce34f0dcf4a88b6052b5e6ccd8e6f3720ff2f0b2895d08bfea3a4391cf33d2e692eff7180d3918e599df5a1e4b028fa0c487e1128ee2cdb9ab969567c452cd088398048df50d2565e6b494d94f2295dc6f69d9889b1104f10dca95b775c9d012eb95beb2ae9738f6b860a6e01b6fcdbabaefa3b1209cd3276a1b2d221dac38217c185fcca20a5b1f1803475d075ff461ebaf83c1d58f49e02f674d080693f9fb6dc7508042c2c137cdca44b5e394d4616362a497be5c675e0f8aae998602963a1de445e6ae27447b4ff8d9b753ce73ab1bedce14e8fa4f425ee02e90c7bf48e9ffca3580e81d082402bd708a6035e22d77cacaa477a8cf4ffa3a2175eaf6466d899ee3b5e87fe06b4d178b103a4180b4bb901db314fe3d6630a6c5af52a0b69ec84f33c4f63be4e7cfc2477a18d88529cae0eece11235b58f0c3c22b62cbf73b2e95ddc714fab961514975a8761bfb19c7b5327dbe400db4f6be4ae0fb2eb44157ec05113a6b92b1ab8e800bdba5e872c245b270a3c6d96094cd8b08351037b49d0c454dbdcb748e7d0071c4a4e838925574e4774e1939a428710aff61119074ad01c6f1f96f76fd05d7158786dc7f9c63b73b45f43353f8d62df2d441bbb1f1e3493762018410aab621dd196f7fcb77ea841018f0c40e4d76a40832422bfe8c3711d397c0442e68aa98b65e154686055ae2f483fd2bd12b2c8b85eb10839556d25d06ffea3c7bee09b6e2faac5ff2513694b1d33dd764b01701a564334f26992241920047c1a7ee15b83df2f123e224cf2245093bff83a0725759d172799bdd0ba9e58d4be1da17ae6960c6d4fc2aabe5f360bb7b173022bbc0b93b72e6c546370f348f50e34dc09de30c8ac68fdef629761c3609d9f7faa1a729777a5eb0046c5a01b36d5fddd8bdb6c74768028421ca7101cc2cd2079380878654a97f97f559096c828eb84cdaacd0e67ea43e308d354d0390336bb3b3556cacca7722d1ec0285e475b8e8cb7497fd5004b900727389b5b81ab47033791f6e11decf02d1048655ad5139feafe8c1d5353ba0803c27729ed9b2af00190fb3980184cbc85f9eb743594e6c0e308bc31868b7438ee8f4f9990bc83b0f714ef5c1c9f7a8a743803dbf8ce17cd0c97e044f23317cf25f90c75cf08ef333d0c77db3018b635db456165b648959cb27c005dad0f75925ebe800ce62deba9f017e2194b73cc2a4918b2a51215f76fdcdc607cf2b23ece18370319c1371bd578e7be9d04944785cc46e8d551f4c40dc23ccce0880053407eca21f23780c10f573e2698a77a2bcf8e267b0f51c7d753a2821bac25e065e4d723c3a4eaba65854ba8cc7003cdbecd8e2f3f47201d76624b98e452ba292b9efc7f56a6136b30d07ab15dcefc792986432e7d9536ac089b7943bc92449c84fdf58f6d4261de95aff31d71743cc132938a23ad3c01612876159e08c6c03aef16de87f3b44614719a42d07f82f7e8904c66093a21a29f701e480d77c9384e45db70a6c3eac6b20d96610231761ad9d77600f81bc3a2e080710ac85255c41f2087332fbc16d12c92796eb3f77e57ac46332c4881a07e10b191c0628badd1e812936d5da5fa714ad9c4b9db4d87a9d886b04dfb3f730ba72a3cef0cbddfd9b355cfea83feefe517c65e391140e4eef06ece766c5c7b2f78e285c1c5ed8848f775793f49e56d65ba2e43e6fb4e037dd60d385ee3d264c1958b47cd6066486aa1689efc34f62fe3d9bc34d127253fe2405977c5399a3af8b91f227f71cc7c84d57cb8cc75af0ffca06e979f36255e664df9ace99770c7e8689c816991d4dd01bf60c02094e227e17d865aaeca670b1c0eb70cc95ea514eacc20bf9c1a0666f04364cc011eb4d6c205e78e536135d642fb337512d83025e0923e6823d99cc28cc39ca3c2a6e3b6a842be4590e1264a65148fd452fab0de961e8b4d8e9cb48e010fd5cf691975ef17c1f6321c15bc494015e2a0eb5757dc80ed3ab544dd647ff11273cb25a10670d1099c526ddef5fc07f4ddb6a16acbb9c13f670342726965a84fc295a34be9b0d0092ff8f8cdd1066f3725b0f640b135633f6996c2432a33d706d147342d3b6280e16bf8d554134b16c55d23e28ac59b0e33eee6421c86db6d166fab2e81212a9ed8c27cd7b9abc27344898d20d21fb3a85b71ec6f863ffaef3dcfeda9aa6a7506f229cd952c49f0ea81ef0ccd5d0cdda12f13d3d5ca6e3516eb5f616f794a5cdf12922a8d8601cde6db6372818ae3970dd2fd0003f88c31504dba4c7582f4e06e2de856b1ee03d3d45235ecc0503a2b4bd4e562597ad43e564337e1f435936ede62a98f0b030c779a5a8c3a4ac209752e7f660fd79543d01551f2beff01aa233af04b3c83188951851a67935ba8c4402a6ea93ebf0e477109f3fab29b38f758e5a7466fe774dc716c719ac49b29ca7cbe1f40c9292bb1d9800ed1f03458434379fad6273759e00e95374a57be467351dd133497b64a1382957e5416d507170c02b2ed114551e4f01e7d6f49f88cab18132009e467afb63646025752e0a427e299034eb49329fbf1f4c35fb58da07be6901a43ac067296056606bf70ea9018a8761a361cbd51166a9989eb1c282791629f67ce2359c9f642babf8f9e4a9e2c41f7435ee1c25eff39372e9c43930674b527e58b80c4761f1aa80eac84c0f46c50e13f3644a5e6cf2d1b07c2565d7b19941d691534873b850194f3d9d2dc0a646046c55138878cf1129798deae426a58b920aa08875d6d9c3497476f5d0ba7d80df8404b7a4c564b177f677244399264d49c2e8828bac666073f4596ed3cd00f9b5382c0f647b4e61215cd04683a8cd10002ab89c50fa15f64dbafedb2f99bf9ce49ede3b1d3563e5ccb841751af855bb9cbc23d5b540a15fb3ff08f2c1d68e9b40480e573544319b1f74bcee7eb08ff9ae259eabe9dfe6bcfab82b08a67936ee462a6d4ecc612086d60f20e513664f1034b962155fa6f56c37e91559d3be5f2d45f1045a830d41db9c1d86ccf859bc439ce2ffdbd0abbd4343d937f082abb0cec31f3f8a697eaab9e91a09952c73b8545d428636647e751a1ead71f6dd4419392e18ed3a1695e639c816b6526d90acab7dd8cbedeaddc348708f51ba5449a3fd7afe61e10ef49bab3c48464db5abdcdd6ecedbcc6e4b9f077c865f324619857ef5292b6450c761908cce012153cb36fad0d6388d1a103e2b9a487e95eccc604234386bc49cc6caa6209540f35591b9bc2e3f12cfed95f5957376815e8de1184c42ed8e57ce9765de50118d1a0f963af84c6779c2f1ada7be5fff1f29f833084cdab684ded6286f8b6f139713cc98fbcabff3dbead59489e8b640a9e328842e4cbdfc344fab6068f4d084235b277e7926c83d289e3590d08d6264e05b7bcc08322f0ac8fe165495ccfd48cfa8cecde3888692347ccb23c4ee8c829e01a203edf527c9d57f991c7cf0507b35d289427cd37739b384798df8a3a73cddb7296e30a5aba73fe9b1aa23207882deebe56fd8ac92368217631f05f3efc7bd32d2d0c54f3a03127b45dd1e5d6a50f28702a1e4391db05f4badbf58ebb724750350b3f3d597aa5e3eb4a27c1bc0edee6b161bb1a72431d9d7eb69f9f064ad3d5e59ea12cd69328d07562825302d91206c5ee8bc1a90885f1229f7011a86c63f5acf08686239415eeec2093e169b9806ef737a9d55f5ec353fa97e30e8c9b65f5bf0d5eb692c5b36c39e7f2e1dd660353262367099e7590f9b6b1ea4e1da61797e1f310f036aa7f3f74948adfe9d368431b071e16d7594a23c8c68b604836a26ea06facdc3d1af35e512272b80c55a0640ff55ad0f57366c0c178f70561f0aee07ff08fd4ddb695b06857b836229f1ed0498cd443e495ba034afb9fddd65da7170b1dd55d5f5c611bcf9a096242514ad0a678d1845937b24eebce5448ef935681c53a79e0099aa3a48adfc8bdff788542e6b855a5857899252324953950dd0368663644fae76e00f4601ca054a102f07b82a3934229ad30604eb06b4d98000e015166dff91d87f95e78e34b345b8f0ca07d4953eb01d8789472ec265932ea1451b9c36bba873bd727a5fba4bd822436caece3341257a704469c5aadd6400e2b15b7d9c2f6bafcb4b6ef62531dc5b841c999f86a72c73b9945ea6d0533c3884d50c87bc0358f2f1e6ecc3590304ccce53ea520f3aebb8af3063940739fc28e92d92943308489c497af5842e10dee1613c61a3512f65683962d4d5738dbe6e6ca74c1380f7915c46e5dcb40b0e964165fbc11de174d10a7daeef303e208b395979253ec2fd30d7f1430d7ffb84e8e7c9aa2326d450da0526eff1320ebcc4ce0d3961b32a999cba894449c07fc17eab5a57bc9f3f7284e11f02a333e4b155abcce6add5ddbeb92f25ef83653d81b3d7b3eefb4885b86ec583b85555384feccd2b9b501d49c2c7414fb50ffa4b7b4799d7e6a83c6eba9a1b83aeb5c1765dc1cb243a9570b3c17614597303b1102e3b36efebd80ff619a0ce97ae98f323cf11a2db471f256c898a5f49e3ecad3b78c387254e4974eae1fb8cb53af2473eb99275d1a630bab9c2cc4bb711f5e2104834b3d4d7b1c9fa2340b131af7b2663ac4ba35512429f3bc4b7a72de66b9d5b94f1ab85be512617257ae71148f899b0eda7efd30f7213ca584f71659cc492dbf4052a533a759299e38f9099ab34c525da6b7fde87acd7d892aaa7a0dcb136f6deafd222484008a45334328fd4ad7d1522f9cfe4bb60af5355f095ab4a1a776ec7bdac8bbb778fc8451479e3a317550e4f9b1ea445f2e8613fb58ce38d211107b5b34a4568c2e1cc9d461068ebd240fb6d967c093862ef59f56e450e47864aec821ba839d708f561f6811f763155d15bc51675cc00dc7a229f0f87031e1659292115ed90a01b7aeaae098f59ce3d3ca1786259ee3773341204d51811f7260e6005b401313a2de6b6729c44d11230aa41eb450d9b7e49a42b7ffb930ecf786e4e667abafcf2c6e5419f804826767f90946d6abed262b3594cb0c0516de59ffa38e9cc9ea5c24814fa2efd65abc0451de61e62af44d3d1f3bf55a8d5e97a27cadb6d018a46d2a4e61cb3f949c27c8f7e89a4cceb4061fe84f4c7b9714dfb36eb169df5d52cb4eb3c0da1508a24f9222d68db855af57526055962b940bbedbd5e408a97b53629c2ed18a3c8d4399a3f6302ea8d3a27878ff64e04cf776d95d3481b539e3db0d346f41c77bd072599202f0ac0111824bb2a77cfbc263ad2c29213c74ebb0ab484dd24eabd35da8545deec26df581eafe3f319b83147419640d84337b7eb52dfd80f4ba7ee14b7ec9d2855c33b9762fef47d8485bf4c80cfcc957ea43a88d4d82eac45ec296e864844edf4bea399ac34e15b47f36e13e37d98171f15806555b0058bf5139bf531e60e1fc090ba66897e738476e2e4de3756856d751a0e51c43e431ab793618f397113cb196e890d972fd50ad3236fb580fcf3f9652581b7a3f29ef516f8d5c6de76545833caf76ace958c1e4cbd6a269e129872ec983e9436ac51b411e48aea077c082910cad95ec4bafa5f296a3a677be341d6d6f760e4a549356ac55516e071c2f59094f6d9acb24fd85cd92405c518ff9e1f6fb067c2bef153300bfddaee01e59467494b47b8cd4869828a9fe439a4d93990158045b670d39d9df99474f86c891ab5743223cde22e11013d9a3dba3b12286b7b6e664dd0e0bc48d6e03b5371cddc61c00b1173501781586d09434144913ac9f355750ff5efab1b061085f16bc528cc55b62b1bc029cfe3d47beffd900affe01369df01a0273c8d05a316fb33e1038e3ac9c977ae768c1029815165a30f210cea2b2f318ac8f2d5494e49fba41e2fd4bd13406dc728a5998eb84198f83c728a93d614bae2a0448ffea8e11692bc83aeb93acf59ab63976038a945ce8f422c0e9b8d1292dc3c739088ea5c42dc20682477482a82b008fe7c18a58c375b52ddf8f29f4b2f2286287bb04dd95e81be08814c310619636d0cfb5516cd303a1f9d52e69b71ad0943760056dc2a218ddcac70ace1ece3b3824bd34b088080fee6063b5ffd16a1ad1e30afe98d329788d3de70bfca1d0373966280bc7675ee961e814a7552c0939b64e3862e5779016f8995c6dee09ccff02d0a358d91da51757d70970d59f55b463952e0eb7c1db601d4fde2f95d2b64365222924eaaa56fea3d115ebcb30e88894bb167cb1ab355cbc5c8cdaaa75eb41593e3cce4e8af575ab2b70da6606340a3cff432f4bb09eed4194e4291b70b1bf6e2bcfd992ad47da9da8af0c8b40dedc11b6fd54ce7fcaff7bf85d6c70f7d8f5d49ee9e834abc9fed61f2b72298c7733d4f9a5b07c5cbae05199b02a9ecdc5ad1dfc2edabc9da8400e4499d4e2fb4b1badf8ffa72cbcb173669c9e7dd86d1907f811cf2cd97423241213c860e070c8160629c5610750aa2d49ae2041606cf57c6a2bce35d7d4f2555e7828f313e5c9c978d71fd7d49fcb141edc2b23e0bba375c8303fdc0bdc97e8d6a85a8f540da3919d1973f2c01a1da6d8653feb14d3054cdf58522d4eae0282e23fe20125025ca47f5595c83a272c8c48232b6bc6d7410fe535658bd7a3e17732d4cf111566cd35bb96e70d76dad23e2f576c675188f30c35a3a59d13bd962c44809fbf9a6e0bec12e5b8477d4d22c455b7ac7f667b684d50342e22b5c90fe320aee7fadc325083f3a7bd3680e7d2344968bafbb9511ee6c97417f20de48853054ead96fb45aa9b438d6ed4866470fdf7b946382fb6310184b44c1b404b8239b5142d9edb4b5c443b6e45afa96ef9dc7f557fc853f5813c05b885175aae821d8aaca6a640975c311b833fe71b693c8aa3e9fca197311606f8299400d98e036b54da65beb5f9285f9cd0a31514dc897629659495c83ed1dfe05da1814da6b30ca32f491ed1ac40a3ef7ef82bba3d891a1267eef67e68d4ff13207420babd420f6c7e6ac1366ff672f41e4ce6e095fdef760cfc628e3de517a4a7c84cdddb692d97e44434e278d8fad919e6778c617ed3fb07d282f1d213debc174b0de5edb71d4ba6164a79edbf8dc35e886b8480d3a891205df39b169117c7a0b24586695cd4e80427fc64483da25688aafb6501270c3d9f0ceeddc269e1ef45feda307242599db50aa290ddd5869e663752cf266172aee38d0610bac200dbd155d74c2dc8bdd6817207d7daf113f03f9ba9f48536be081b576e90802d7f13889ea95b6f27cd9255cc6e00e255b73f30e05478233ee1551bd18d77792e3676c8b6e298f60093aa38814b3f3058616e6c8c353d2ee4e148162cb56617a327f4f10c3c18b1159490f0615b18fb2217779c6c399fbef9355d172d1c41aab2479ba864bf400289e453481a985caa82b9f0bb309e70857504e2b0f12a68ef8599d929aad4e16e39cecd2ffb114f2386d962a116b7cc1a6befab260d2a9851aa059727ee3027501320e77dc6a38ce0ea04e944b5534f8412d6fd2c0ad17029aba7abc9f9de7bded28d8fdf6b41ffc9b3e1c8f76b9d0506a1cb40a4d4ce6b3c833bcdf499685cf3ced416b9036210218ed98bcd10da055d18c4a4b727ec656478151d57a131983e1cfa589994f7de9545a23a3b66abd0467b811aef915a7b60dd108295ee5c73a368438b06dd62841bb2bd6c3bfb8b298185d54fd337ecaf1ce29993a9d20f57a7a1b23d602c62c41c7dbf7a6a72147871e6ef092c49c2a40a458af24d3c8300f6fdb56dc7489ad26c0457cd3248f00ac0893d7129bbc6c36d99c1cc172e250fc14e94b56de5ab6d8b5f9b1cd0e191bc4d1a4713cb1b7ca1cc23dce84543a8d5531301a8c433e2be38d3eef02fa230d27d105a4fb11c424f59f2ad15b98c2a88255b51d8a0674913c5edb61c3e3dabc1414736dc6f506028d798d92783e2cf2fe80e28080062cbe6135590f73002ea4c281f4a6fea1ce0709c5e3137a8df28601526b5baedfc47cab6a64af611db53b6afe8be0550a9b27ee68d1d63852b80ea771419d89ca8a45ec643bb46c1fa11be890b57b825324f20ad451e3fb1cbc6ce3826b9891bf3511739214ffb029f4d75e21dd668941b92494db96de98e550a1b40d6758102ee652f15314bb40b18e5e97442eb50751dbf666c6c99e2f3110b4f8616470cc2013499339f4af34a825031d9a9c0f3c38e59e821756e619ea05badd8bf479a545b9031b2be398d34f26184918c61ba03f61cdbd6341c6b0969d8f7d6e21de03ec5b134a2ed4faa6ca490244819dd7ad4e32947fa1dcb0c7d773516e8da7d36aee46274ee841fc09ca353a3e5e2dd8ceb956f530af49ec2547ddebc9d419ad10515a63cf359c3cec420b69c9ea74e2e50ca8e9de4649a8626070b391382292a983bfaf29d69049b6b2bf5213342c66ee360f86c3cf75d8d9d1e39f8165edcfcb3ce439f4c5701f705f07efe706ae5e43cae9134015f117ae09466e458d6f007d43639ec5afc8a201e68283def8dedfb260122df391ee44c436617fc0f79d0a134695751c793907c8ce8b3e3362d315afb8bf753a1afdc22464e4696b8dc0106f35e128415f3b5101a110f16aa9e74afb22dfa9595c87306733cb6ae853ba2ae30af9e35bb5722e7bfae1b66afcb9e3161b515df089d8e65beb0b7ae47e736787773bd35d600bab8fbe1ede4ade88c5d3cc938e3cc39b11406c66a8b8d94d03b97c5fe73fa531838dab02b853cb91bbaeec50cdaf2fd59e3790b4ea4d02526aeaeabaef9177001b5022baf9b924f153f24e2c2c782312941fca2a2459705206ee93f8ce402f498282458dca3310fb175a472c00a883942a2d17c7a354939d82c655906c2f74682e817a287f1a479f3b98d567227c134c6c05fd3dfd457254ca7dc16aaa059df45c6dcf21dc877432d32e26363663ca2d9cc8e468e52663b9b9e04d9d80bc43dd23b99324ad5ff2b47ffdf47c19695675738218356dfd6aa7be6644ac4e5e7a19f1389a90c7d6eb8d3ebea6175a3adda93b24ba1b6d1c6971aa25a158e08ccb0682a6c75e0a498957e85dd1a2b98739993cf922441771d42451064e5144574ecf62e695913f71f216bc7ed09dfa4909356808602f733f9bac79f9374e1ba03cdfad68c99e2426b62982092e8cd2eabc57e50596ab6041d69eaa22a803edb963a82b2f7bf20f12c74a2074c7293126060810a16a3db9e40c9a8898810a04d14e4d551cd752d30fd153a8cb907b302fce2bc4cd3706c2764cd33a4d9f04d02175087f1a1d894541b9d2e862253e6504a8d112f85860173b5146478966e316e60b58224f7f623bded17113ef8507fd92fa74067e3587babc046be72a8431f5966cff23eda4de08fedf157925f877f3a708832e7f4452a2f0ae4d1bf82953e7793797eb419abb823f58e5b8cfea60f4d336fd3bf38a0725118faac41d809e2238c459a1a3289232e317628c1db9a3984a1046895940b6c0db992f06d8f902cfbd36386856fcb33a91f3248d52e352fecf4413d0998d158823f363240a9782fc695d7d7e53914cdfa03e9192270e9cf57cfb31f47804859923545a803e07cf3fc6c04f60da9cad761c29dfb4dd705b8070b2bd36afb68e84f7ed6bbac981098b4a493c3530655abce5518df51dc0b6651ff87e2de26120b1c413be63cf08868caaa09d413835e75e5945d28b19263cc51dc91e0759a772dec9d58665da90f6b0a66193b65d9a62c5c7631f914a6c83d5645420892d9b5a7e5a40beae33243a36861a13b1d774e8f651d76749357206886dc29a0fe9003e7ceb767f030bb70520452e526b34e83271d7b79031f423c30d273d2311bd3fe7050f5ec26d0c38f40c793c7c39c80dd035d104a55a15c1b76bbd78daa0d3e758f9a5908e2f9c4b86739577cf7a6c36531c22aafd2870e5490094b731aa2ba0b6b07412703e3e8294a56373f174a33abaf38ad2c67821a7e2c4ed5b4064919281b836ef8bce47f95403d3a338bc3dbb792a41c8d47eef54e94d342a314b6915fae9ef5f1cae5377eda07ee51810b6e32c2babcaaa533b33179fd2e4ea23ec175d569988d125e3cafa3074ba287455eb0ebe6e1da96d5740e3f3f2c2b2573f00462dddbd761c6eb48a3c931a00e3666e9235da3e32b6bc03996802efdeaa793bc3bd6aedaa94136a95073868ef0fb003fa33896d87383c50dd79eddfdee1dc105c7d571139e7bf94eb139b04234dfa4fdf05da1acd6f555ba947caaab6217e13753775140e654318e7e7a0cccc6380cb47698e1c24c03d7fb13644dd9e4e6689a3c24f11a37f5962c9451badfc9b0513728e0e4fe14533c221352f353ff1c3f39e733abb73764a34f105c18762d6c7a24cece5a4fc4adedb9834df8c10438b9ab790d119eb8d23f479d99076381a04bc1dc6eeedab4ce1879b12428ac4a0ef161431a5a2afc053d824972edb34735ced127f5d34d53384cdaf116136cf9bd73db0e1901dc6239f7ffbb7ea14aa22d9fff2424e27932b828ce7af79ba78231c938fa4a4e85b6ddad82921418f7f05c7fbbb84de1df36c138c05d15b608a35f64e2165c696e4a77a3f396706a15ed20af9130dc3171194f7da976b78eb38946e865b3a37f1cd6adab7e76c8e37113c2a15a57401c8dcb099fc2fac78f586440462b082fef9f74f760c151ce29447f9874d999f7919d581f34660e5a890e090cd254940775fed1066e7db449fceb77cc9ad5ed439646e0dec66a5f7e6dfcd1eb5bb1b8ab999cd1dcdbc6f168032b65ffebbf44b0acc8b5a4e6d1766dbebd32a7b69a72f92e64aabef29e1f6e6b76862c7c3f18623f7ca897914b1f9a85ed292e69a29b76c12cebfcaedabdc9e11f834c1caf6e576ec79d4a91ac37923283779a02c664aae1782f45c40fd55902f8945b9436db04335d27f1e7b0b63721fda23a9d31701cd2031cbe59ac47704411cd7f6e2ac297a653fdbf829e341312f2ce6f244d650de2ddb182ab9f4a66c38b9ba1dbb364adf9ce7fefa2c899f26a8a342d12b8a37b1dd62b68102df6c3b7a8f8547036210f45b629f78e9f6f3ddd2db524ba0e4084fed85c712eba74da7357482f8ac0805291065751ed4d595032a60e5fbe32d69b23ee28a4071e99f508fd4adebece0b02c407b3f6a9813e500605db555760e37985ca67bbe8428d31103473d42676bcc624586c841753493c220eb55e5e58f42311943964ac00decddfb6ff616cf7da17277a794cde9b00d72b7f713ab952c426302a7b6e6037a4a440b3b2c702d159b1428dd138eb660a6dc2aa689b276c5bb98a040bb5b82e17a77d58dc9dea9ddc65623c42465d1bbb590609ff14a5554f1e491f6ee0109ab87492a1dac14f178f3c9545915daf9f45fa40e321afd0a2580ac78852bad98d4d16b837cd9d029a053fee63b39f9ab506497e6f196696b056b9ea9b64dc3ee5788d14ea61e1d9ddf5934eccb00c3610815b39c6e60591bbb5a1ee9038f4cc5a37c7d16acb44b27739ec0451948638e2f022fa59aa4f50a7f17329e5a17ec18c480307df37bd6ac340c58f4a21589050b64d2b9f23c642363b0f976bd1ec35c0ecb412f7567794bb4c6a6204d4df58e8bd07b93404700c661536349c484abd5093ced2347b08a3c738d6ae900ecb23f049ace085b79d9552765eb84e3bda7d97289c72d3e006322b6e7a34f717b5f985d66fbfcc0288e5b2805a62b0ba5a33c059522e2c4e9be9059662fd63699ae84f7997bf40d401654fa54f6a705794f104a712e9e1de05bf41f0b11aa2cfc5eca8bca07c472b7d929ccbf270cd9a34d950626ed3eb5e1c3717a75546840af8483466eacebe789e5aa4c7bdba04792fe3344c34eb0fc25ff3bd523c70c24338b4ab78f14d48f26d23b53b6448a778161facd8b3d3620e6e7df10c258e08744fa17d7861897cb236246f22d511e40aa580932d6abd8b64e5b770661c55b5c30a56a7bd1b252f979779239646e448b7910cd2a7e7e4365c5497d4df9ead953cfafd1afc43bc80042b56b12bfea03aa3db9bcb8d8e29b2cde33749696eb411040dd90e5cf63432bd2d4d1d59581bcbd1316dfaf2842e186528eb7f9facc1303c5ec123d4456c73077d215724bddf230f4e14752dcb5b18060c2c3be8d4c733b7a166e85d6923022d50c89a986c5a851fd4a5a67b354ad778b2be1148d9c32218650db208914694b0115cb71dc001077772bb6210d6a44aceaa5f262114b55c82d9bf8bd9282579b1aa335f2ed91fc3985d0ff4b8395967145c29f3ef63bb2ee8bf93ba45982f9950b9e483d46a00f3a1cf06e26144f03e30612dc4563b4ce969f07999ec2a8bff414e9d101729dc2bd39a89a5289c6419537e034ab270b4f77a2c89f59b93adb8a80ccdeb0de875de03f7abc35585a54277f2943878f0e161a65492d7adda128af2ae1a34c8ea61af88aace87a07353e7921d528247b9f9015cf85cd946577f9d0505fcbc9cacd9bfb1a78c2de301a37200ee10aa8a2b03e65bcca2b0dedf681bed57865414785e8030abb8bf406099ece543585ec80cf30e65ad9ae295767c531785c620b8c8e287da232a01b1c5dd013f6ecd639fa5c072d08012ac8ad0b77abc5fc601e43a835e061d5d23fefc86279d86f99fe0bcc7e635b7ae056b30805ab367036827ceee8427e783016d7d6b1dd08bf94804cb3ff6df5317056e541db1c82a62508d66df3a077229a5c2f7f1013dc8031d7e9ff4a1dc45ede33b039eba9c113b968f0049f1c11958ec6f9f68ff32f6bf8f5fd8f99593061a112b0aa4bc5d661a9fdff84b42b862813a2b6889de0ad285b96f15ff0da10b8af3e4359abd360c339f4d1a70a6ba459dbaf8265ba1493d73f40007d7b32e0ed6b76407e9cd350c769cdee7d071ac8a6eff2a49761a9f3b926aec5a17ec5c29598f1cf473fffb23f68c7bef9cfbd1a278ce250f8074aa8b9c494a5b7e8dc1dca78e86c8edd18e9c964d1394067d748748390eccea472c29ea4f9d925193001fa6ba9a2df0cd4d7bbc860740de1573e5e03db2c316e67b7521b6edaa7412cfff3b0d5574aa358308c4263fe6b450c4e98bf0b58e5b89f8190cc947454272a0cfc212f826bc22ae13b2077a2b2239421c99646840bd440cdc186fcb4970adf8b604cc7589e8330583b0c7d0ac4ed99f4583de89bb653504ecef0888a7880c3a461bf637bbb225a4a1a90e8630b8b3ca88ef424b361950b41ccfc7097cf4d149e6682a2324e16d46bcfa32eafcca650da83334552cc7ea7aa4b1ad471e71a64229bb8e0b47bde357e2948807d0020965e266abc2a8f17934a4eb0eb2e9d2365681d910f9a25fc1d3ed13aee4e897356dc427659a52889ca692d1edb1fd75ee63aa574854d5c05360b5d30eaff9c1944d7b402116feaf5129ee711abf6a4ad02054795adef74d952ddb22a2cc46ee22b9becd3a1f2e17e9e02bf04eb2c87a5df06ba054cdc8fa357590d6313e3d61e66c204add0f287ac82d40f647282cc13e300ab02b06b6d7d915b09a4712b0db284bec23753031bd18be5e05fddb60be6b7047214017fce22b023abf8f2f7a64dec1d9f3c9a55f65fa8f03b2535dc1f7088d8db296fef897b2cbd752161c04416dec6957dc84f377e00403550b92b2f52a9e4b35c0c8fa9c70860f0d8df75242ea8c87f0feaafb6a91cf826b2c9463b59d7a1a867817e97c66f7c416437687a8387a9284b65c283c4775724d945d9716a88347cc96dec611c5deaae8937c9868cacb8f53c7206a564dce6bad39cfaad6bd2b305bd8e9974c55c6a6beeb6cabd35f7cf946d8ec82c905eb9a3d78dee26c8738876a2e5c7629de43e3801072fef95086d7524eea16b9b385489681be3748d8720d424e06bf4853a28a646c867354cd27bc5ea0c482e1db3965e5413e1dde2b21cdd2364f3ca882ad99f2c8ac32722ca0a9902bf49eddacdcf028b115d9fdd5e1d067f948c4c53a4b2ee1f2b2f2cbd8877664ba70bb5bd2c626d71cd3fc83ae5e45c0c93f2b7ca5c20ccf443c30cefd94090d25e0f871bf0cb039a0c6729bc29029d60a42815e516681e9be73c6e8ab2e21ba8d74bb90e25a656321dd056448be553d5901c5b1f4c3ebea4cdb079013332ffa9aa778af0c3b3dc9a2bdaa673537fbe403e8e1577268c013a53fbf9b29ff95c921b9e93494413371e3577f424f59a479b19d24074420aee068ed06265720d440f4f7d5bc7b32ec7702fea01c084361d51dd257a3aeccff64e24dd5508fe6d2c2742500d8c457c2345a9997458c4851411ef0130d6cc08880b484682ab39f8abcba91f6df83550e8496f74558305df31aa356328d3c9f3bf7fc624d083a138fd2e9bd8f24e637111836172835d774df560a7d3f4a0d0133210d088c90f29448759fa44d3dda1c78358afc2298bad547051080cbdebb5d457155aef743afeb3a4743ae919ee2ffc8c05f6d06a883863e69f6e19afc6b1df5bbe365a01a7c6f47e8b9c90747baf24c0438072b2de4c84e1c1b7c7a347cf01459c1a88dc0093fa26fc3b108c59ed770249b195d7a6ba485cb0389b58885ff7b8b9bb3d5a5f50561d44b1c768eae4c7529196a47f7fefffe1e391cf6fee3f81b791a634f64503ef3f7cd462655c3de1b403927a7baaa98051c7e80598d3a98bbd103408cdd1a3a9c4ec5d28a107255aa6289ae34a84a19072bdcf24796366fdf9a976efe540f2543fdf5f131fd65fe84c3ad9eae361b5d01a30d1a79a9ba0b4077478d90fbfbdebe48e0bbeb068921c05ee78843600adfc4efc3de99d0e0e7061a4bc3c2326b1ef852ae402d14764a2dfece7bf020b7a2b04d4af17badb7bd0b3da79cd0dd56994126479e0b7ac4db7546b982cff3c5099173c7e3e676b438bb4507970f5f114e256f931bfa84297952d6cd51d0d3984e25589e8a39092995a9454094f748708f37b1786e104281b9ceac6b94a869d3c70311b616853729aa8b90217203a28f49e3c936472e5002720b8f936cc4e6abd16b9d051a5a2436d513ffdd80b41e48d6821a280af87aa6f231d3d305e5fb53b3f071fc0e724426f439befb1e999c6dce277d10fdf488de468607f4ebd4a516c3815be50857c524805623dad29831db153fb57289aae3ec5da1d4cd87a26ded7fe002bf2b0755b3619fc7a546fe6768cd433556639dd77b8f1b246fb0051bd35c4d3c4a9a3a64d47f210d2a694f9d604da42964647c6e4cf615438816880ef18de53bcd1868fb1e1271dac931b04fafdd4fba237e3ec1096481ea08381f5221a7f3b614cc208e9de5a2cab8e13175693fa2905d61b740d6bfba0d71d7e20d46c16d81a730db4f2b1bc5bc03bfb5375353deeace7096e31d1311461d69d56193fe8deeef866223d79aeb520062780d6bbea0aa7dbb86908ccda7795ffe3d289ef9225ee9ecf5d4535eb1edbc98125931fb88b42c6632453171fd9acd5fe7ca31f84524002a282acc3c33418f79bd58206e92cfe175a1741b662cdb8032fd7f0d4d57679fe9f54d628f2e0a447af75bee82577944148d2b484ad7383582395148b29fc2503b8e0aefd71aa5059b0bd40425e27a6cb0427c2b5d9e7bb31dcc1bf28bb9d4fa8b4a19d920935a69b74d21081f717df7b48db6414596ca5bb5b53d4a3f7f5b62c52ac1ad980a22c7ee10bb4825ec4941a72393875ef8c96e941c53ac1a0ffa0097b4bb6322efa9d7e90e437a85b5bcb7b31f0b2e850ccf47ac1b079950db9f19e2bfb062fcf6f2de2ddbd164e59721a3bcf3c8ea0e7f9671263f22c53ab487befb3f49a07e063397a3254d6493ac8d08a82fbb91f72922bd08aa153fa49480d3f765fd6caaf83918461da276a3abab9f415a86750bf33bdad81e9b6c8fa8faaccd7c883e745fdf0fcb3e40f49afc1b5a91eec820a47b9da1b3d3d2fa0ee2d9ed140180da553f0f643b2859a3bc4e0edbe7bed67cef4fa4259c7321867c876237fbfe26e355f59a97fd85844a89a70cecd0a5b0ac3580038c635f9fb411442cc696269ad524b20d80290209f13317f4a21b1f2c99d47531bc025c83ad3b3dfe4fe9909818507e2c77dcd642ea9ff6e01809c61030c3cbf5acee373bc3c4702c1f6685f52474c4b2133871284447b687cf328558c3dc0f576918d1a409169cfb5ccd0cfda3f69e3c2b39d8785e7ac08848c51c0cbe500f02f5160a407b4cdbd3231a86ebe56cab87764b85ac0d52b6206d698fe9815cd07bc6eb6a59d1da320f56eeb2af2c20b566b734d659ea1e8466201a0ea167e0cea1aebb4f50be64a59c2d54b8695c356aaefc9a254ea9e3e20a92bbe5359ea69b7824f861bd1597e6092bb62a36e5304284b1a187a9cac802d3d58130802e5e195cb19fd954a25bb20abc3da41cf252db1db95556282645d24ca6668a00251b49229058e5485fd59f25fc297ceddccc39cfef5354970f58f2db6bfe13e7d69fc04c01ff69f2389c4e12cde9648ae4968a1e53bc2a802c354fc998209f7d9b7946daacb8e3df49938809c0cb2b18799a038b2226a6c11815cf84013e90cf8e2b2a7d86bebaff1859459e86ee368bc72b9edba32c9116e95fd93142227cfdec63de5912f9d2be0d51f44b4b8012c2956dd5da22103cfa6dcdd186576069ef924d11648df53c1d63d077991698d9eba9c8564d289e02d1fd45f57ec387317714cc991e06a59286fa32c15aa1da690390b72bf0f095e7cfac59863a7a528c50f55e335a0906ba1c43515852ed13f3d451f7009bd869a16adca91ed813631eef19959bbbe1adc010236ee5f3cb197153683076a620540442d2bec86534702d81b225b7874ffe5809041e0afd6559f4416d1ea634ff71909c5536d3fff957f0475579f9aed85f23df23f8fdac5fc6a19b77ed968a9c02058d0fedb411301aea8b3de0a9c00d19d0d9f1b9814dae2be5a2ec414e52f06b381367d6d4f07989e3250daba3afbbb62e55c064d22c935a52edb298a75b18ea97c202c9e3d9011f41f465a690ae1cda9d3664e400873c11cece6cd4804f2eaea703c17b13de8452cac8cc2bd6fbaf87271acdafb44e0dc4f2e4d35e1ca6252e7e051031c9ef274f56676844c6810f1cee6541e3cfacc90f894e0f2d35e72daf7dae3aef296059ccc91dc623b5dae4ca2fc18a60d5664dabf036b5484f9e6b001f0559d6ac4a453ab32cf45ed8c8fc42c8d7495ead69cfeaccc1242c3e333b5103d6f49b02a345bf621014918cf1638e2b2559c37124057beade3d58471e7de63aecae5cc432e9262f757af8d0192448f971ea463ed9a740c4016ad2e5a9546fd375f2eff9b4b4f36238d28fe974168d14c530d678032658d203fc81d5343952e230b3ec6e9afa9d58a8b0eeff3be94b50adb57b9642ed8b2ad0cf3e31f288ec2f1113cadca87b5e4fce6e7be1fcccac230fac173adb69d415d4ab4e201c492673d0c9431598b8ad769b3cc1eb3b3313c1e8d350ae7544bf2eed996f62046e2bb2b8b77ec133f588fd90c13abbf41af38d8539b81c89418b825a1e7c9c7388426ee92fa3af090b77efc6807f30460f750c77a43e020b3a52cd9e41866eb31cf2caf06bf15b23c0577af894638ff95e273a56040a1808d6329212ae699aecd86eb8d1e4022da9fefd0b709a8a2e3841cfbd96343c92138bd2c631363d2d11cee26592b459d0b07ecc766516279ecf69b7d71728a91ce93404796210d70ee98dc8530e86c89af8eac44636d752d0db6a1d6c67d4a0c20de91b5bcf0134834849eeea6cbca5137f8c669533556b14e21826ebcde24965f43e8cb64d880afb13eb8ea3f125292f22033211c795994cc68c25f1dd02196abb52ed586508bb2ad900291e56aaf725bf94959c1eda8dc8565a604d7f16a4835e6ce6a4797da9a22ecf0aa7a573bbefc4207a84702779ff8652adda8d9dfd87ed8502c88a7db1595ac24db86dadf27d04dfd084edd826fdc42b5b6d075db07b06d9e299ce71598b4c46b7b80aae42abdc5b13473ed640a6ab81166fb87593427ef0d2f3dd2dca4193b3cf2fe9db68c561078e26d1e10d6ad87b8e7fd5264a332890bf0076abcebc8f5e60256717fe802a5c5cd89a0d0bdf678db3d5f11d81c873fb89dd4544923ef715b3a9bbeb89da978ca305ffe691bde6d85ecf1a00c974da11c00023562587fa8b4e009b03cfece5310d268ec840430793f70ef3ab8397a14f5748ae55a2a7b84eda66ca2c43f575696cd945017a2bd4d6bf3a619002dc62c9e933504eaa1ce88dee06e55a83eeecfccaa65e20716a84a3a59f274a49e0e0e10f71bee494f8895766ee7ba01ac599a88114869023fab9fa7942b99969bcb2d789e93ed82fc719fcd8a95364e0cb539832465e38b5acf4325477d4d204cebac54155c843f7bac5eccdfec26b38d6069d28af9560947ca853947c729d7ad07c577bf97083f2ca5f6c0ef9727eac98f07b81c402f41ac94d890cea0bb702cc2bce52988d69f51bd0120fc11929add80f3d46db1756e3eefcc941ce761c7eab0a6b166e1b71966b1c5f66baae3d8efd02655e327a71e160c725b4acf7c1606e94104652462aaa8677ad89aaf9386597f57396353f0537782eeb52f546dbac6a69a0222ee1f98ed80a0c54925f978358a568c2caff0b42a98a5ba5fed81127e731b1ea3743e5428cba07ff3caefee981962fa3c57bd16815e092e83094f021a62029736f58c2807cd786e338bf4b7aa5fcd2bc5dd25e8efcb2e7aaf13afdc169fad1c8db274114085cdc6aa46933228703ddf2e967cd7264fc4bd3789a960171ef988c8bf8e51f6236b10ebaab78f880d6c97b8c38160a8865cae7f3f9d397a644d9ee4793e9d99730b4b831ed2bce307d14b23392cb4e59d3b110ed0bc415c53e4134cdb0dd34a807fc067bf214f0261a08ea8b2c4502b4dba1b0a645e57c680ce5ff657032808c97e22801ae80d4cc53a23a7938294349b03be8e51ef5f055be1d4a066ba530b83e6100f5698329797d78df946afb6b362c3fad86ef5691b8c300182926b7dfd207a51825749757255926738f5c1cc8377c5d625b0b2ed3fad263d0d12c7fb6541d6a7b12f593da5b82fba611f47d3d8c4013dec419daf81aded4e0908cfab5b9b8ca143bbac7ad5eecce6633fe5f0ed932a6522dbb08551c53153efa14f62287cc365df2e7d2aad225fe251626567f02239944595277b92f37121ef7250a6b55f3ce34b44b504e04d6bece00da4497cabc8ddf9d4aba0c23baa1db3df1038bea1f113970d39e250b9e2b7ee2d1da66785fee96a6e270aacafa1eeaff4d4df42e02119798f78ab9acf69620598a45def66e25a2e813c86520a71365d052951fa3a6f497ad85486c0a6163de02320310c6c7a5cfc33bffea650bac806b6cf4ce1dfc7581103fd36eca9ab427b7888131d9f4d30dc7fd9fe47c273a7c2a2198081ed7ae63d01b1591d6d099346222b858a2b7c06b01ffebe8677348b45d1dc9efa4c0729ffb272e600f4605ffdc19bb0444bc3ec0348ffe0faa1cb3970aa0b144cc47dec73b7b6faa4cacd51c4022abf9c47d5efa955d3ccd8a8cf2d4a8798f52814e2f84f7af723fb3dd662a401edead0d812729955461b2615228a7d7982e5f014ca756d87a283abdb3d0a1617b50d96c7fff65d6ee3e4cc31faa77c676eed1d39b110bbb570e8b6c270832b1d4d460e7c3896fa44e1e672b8ae66515d7dae027e95f3a056936935d2369033aaf73f5a59ffff685dd71595bb43f2ad49fed8284140c159c7e2361523fee60d9ff4994d7d1d6102c28c22b908c4c2837968551b705510141d1e65c0f952c891e23255cf894435341e7804462d0aa53276e44f11c7224238f771a225f7a199ec3c228f3bd35a7bbc108831c50c4290887c3f6be8f3de9013d51b6686e782d8ef5cb8138e780393afef0780766f52f0f16f69955d100b4a525235aa72da37a5f3502d171b9146794ee81428166f5bd459e18b8625db5fc7b28892ece63f038ac816308cffe4ecc63db3773975b09b0829ddec38bc3cf8c996ab6015cb4e1d7416c3bd643d4e293be2b44dfa138267506338f08468e09a6d2c3e1dea9755b0db3fc2b59999247e1fe06cc576b15f57dcd267b20d077a4250b9d2917d5131f4742206b20d0ef87578c638d03df11ddc8078acd89a46d3dec65b87e38a9d20c4534fe3732576a48e34245054758ee9701e4faa1a916d5cb057216ee16c4127a4f1a74ecee05f608519a8121025789ff76e8a3f3f60619119aac47abf81e2d8a7cc802c1e687513b2f551b1d9397c3aaff5669eca0641fae489df6ae732bd228fe7d4e85d66dd3cdc8bfe0c914651968cdaae53093c874fe27397365f48f425623854eecd47fa683491854f36911c0c1e019d3eb4ade0b0d9c5400e4edc7d3d6a20e827110ccf7591b425b05efba2c7c7c26194bdf4956622b50da8f7afdb2bb56eb166aeee7f74ed27b1b4f94b2bc1c7caa1333153845972324cca098cf3ffee6e3e1a5db9bbfe95dcbe4d4465d0bf25f4ebfffa4199220048f779dc09a524f3683ff92ad7c2cb1bd51fb149e42393628c2f0263e07c0abe35aa51e626aa87908de7bb745ed7b614ea71535d44b5f573f887110460dcd547b9b685ac47840c11e94542d9c2ba9cbd14044f98bb30dd17d5b9733eceec038a13f5bb6544369b4383d175320df9f69321609f62d90fd82193d9b8860aef8676ba2f3642e31221d8b94c3e3e655f19accb810b4eb04c664b08d58064c97f5c2bfcaf47518bac7f6110da5cad9e6b5174a7611b6020bacf9e873e2290f9aa0f79bb6fd6162d12b72e1bfd7cfd21221cef17eed1baf82fd9e2edea1b15313ca58df16df31dbf8496fc6dc958c1ac2429cf64f8e7bc5cc9c8114b0f7cfc4ff0db3ff790349cd869bd2561f3e5f43f7f85cfcb469cc460a1b14d30c7e73cb939d92da7cd48047219ff00f7d9fcd984a2ddc5ccf7b482490e20338bb0413d1b7df86cc1e933968bea03e15d963202daa6f0e3c05df3c0683c74c931d561bf6f1d0e5c07c27db4c9da0d2da30a6f5c576c9be6b6198b7b58583cf15f728b3986da7a4cebbb6f7e3a592d47c26d4922486d82a798186a92170edec5eda7988fcfcfaa4d39ca91c011ebe717bd9f43e693948c3b6af43c5b639ebb3b3bddd6e3082363c084cdf7d2f615b799ec3dddc5052f3e2efa128a032bf53cbfb1dd40793ee2c27386daf3e6070020cb6aad0fef98377ca9432c4c4245bd278aea9f4b1bd764ca095cce22a61d52f71542fe00be1312af5841c0ba4c6ed59dbf07d17a75091716b15a348828625915268ddcd304d0112b6600a1f6d8931a4d5c0d908f73e83b0869c49860b3e608ea19e16d52c5bf3bbda162d998e23a76294c0026c94265749269218ec5a5ba63b2b56896c84e1485cb753000e43d0c5d71d43f78f2aa23246c59c3ae362387fa37e13e48a7238780f83fdfc48b72b9c0cdebce15e31fc2d08ced705e8a8aedf9b8b63d2ec23318a246587c25ecf0c76467ce15e5d73926af9c54b071bdc20ef45d8a2138640ac98aacbb5aba2d3107bf1b89fd0639f3996eacea82eed18024a056604c7eec249b9d68d55e6b56e77d4ae0de995016aaa7437a2111b32238846134629e0206408c6cc9534444eb36ee76efedfeb6dc0d2a015ce86931b3e89353a92cd8374a3eeffbcaa7022a443924c3366a7140a61e6028f20e523a2c5b266fd49dd006c7bf6687281d16cb6abc7ed60a74ab6347022e96a2f0a8e33747a36be223816f1e81b42937a86579df1cc624e3c6bcc72df7f4e22e407f2770330fbf2f064faf49dc020fbf8e9e7b4d024fc3d5ba95911ae953ebaa288458a3736223aa67908b86233fb079bdabb2d8fc99e270cc1ef8cb93ba9472dc5df30f6bc54b67a0eff53dbc38b13fd5726de26a204764d38f11a10b35cfc46aa15aaab6f5e084af0b960e48ae4b07f33fc9a36a892d82d61aa3da6d774398b42532970ced545adb84d311f5380b5772c67ebbc2b104dd1d402745ea1085c687cca0265262d205bf940653c911857cc864c4c9056d514eb5272811309dd4a4b3f1b8544d73805f0b8485697823c25f0475368da847a15ea4de916e0e3f475626ac1bdaa370a655d4a249d0ac6ee6b12d1a0483e52a768c3523e55a265c564eb206aa13ffe3a5db62ca9ddfebcfccf8debe9343de4f0a47dc9449ce2cac25c8ad1b747282b74ad9b0b5c4ec98ae5ee5df75db4d97302fb547b4146eb7cbcf7f6c1ce075c5afffcb6df594990bd25316b0f3498bc2c3e67f521efd8b14a9f5a3fbad7091fab59f35d7dd5026abd20cd35aa3119c8e3ed604f68699dc8884f539628b0d8cb6e2570accb2e299cb7ca0086a58dcee81eaeaaf271a01adeeaa05eb5f531229859f588d7534ba9748d554769dbd1aee73294608ed23549f2cc842062a0b4a7998475733d3764936a85bc63f09d244ba0b0fc525aeabc12f5df8d3197efcd5ff26603780399c9ccfdb71d36d327b48852ad4a86e54f16a9034d32de60c9a943a4266f121fd769d28a4669ed83c9da6e7712dad4f28383a65f5b935c7596eab7c4ce1a56af40bc8d2ee65c29d3c005d256f7783fa4b5dc2aa7783cc01f1ea0e524a6973229f686aa3769689260daf49e1de44be49e5d1630e41b87a17a7392cc1cf4414d0f660280db13b5ef6ca44c592f67bb65bf0eebc50b6aec71183f24a8d0e34d832ab7ebbe707ab51c40bae69545830d0b88a2cbd938e41df2af144516f97acde952331a3ea825fc96ff9dad401aa9441ad15b9005e0d44cbd3290891816557ab118b2da84b615c8913e0542081576ceaf29ae274404e23d0be105e6a0cfbda87ead08c8e4ecb4f2bc490c058d8b1280d5977416eb158738c8f93ea68144d910c65997a34eca4e5d016bc0ddab59ff48107ec19a6f4f8bda4ca38752ea4765a17fc5f4994f0b1f11b829a02de8d70368201bd04566d1175ece19e839f3ea0c764c238338d551d62134c29d658fc5a832b5a98f0f06db557b70aad40a3f26522ce9cc1ef6c8b101b8f1ea375a54be95fca970e45fc6388682ed8d583075098b09f8d59f980670f88e87ccfdc205274c8fd8d9ab50fea70eaa98826cc19f1a37afc4125f44bcf5aa7f4ffc7dbd1bccd83337043dc9644e55394e3f315f8164a841b5b73f96c7b09c58b16b7731faed27dcd0ea372820d7db8732a77df710eb3b54b17b8cbc8d5225fd33b9cc59596df3196e221c35781a7bf746a76ea996129fb4673449dacca0426a04be3d4817872f5080660619385e58a003661cc58a15294a8d47dfe69441ec84dc6fe470597c01a292d3d94f1debb4c26f88fa5ace8a694dda34abfb12e0b761d79839076a7089c0b80961e8a755b2a939cd8de7e16b9e8d74d45a84ab165dbfa3a1a2605b0576d2f4626fae2e80184fc3b142230b86371ee4269613b8b4c68c7f55bd023d265c529db7fd1900ada407f48d4953ca3f55f4dc0cbabc4488e94b6da2baebd40b0f5d86ad849a3968119ac34bf734ce88c467cc51ad20116cc049a948a3084eb99f4e9253e38d166077631f0e28d30ad243e329d01b2bc7cb8f7a5f99495238a931ad39b5c0a4b8f9c85709bdf608c180afdbaa909a1d49f0124e8fd18ecafc1f6da944a6f6a8190c8a4a1398c134c443bb37ea837a42b94aa5f764da85640835a633b306e1dccbc469faa30678e0b3f8acdc0c1a8aa5351ed63db2a49822805a4d00f0c5d94ad1df860a39af1af106cadd140b8667753fa461f1cb897227ee9b38d13c35f11bfd7a3cd8252a80d14b80530fa0341e6c04f27c6d57c291fb64227399033a8c533bd7a1f1fa520ce0ca4ef20f0602dd3f2c0dbe8128d286acf37df0341f7830704921bacfcd329e9a834e5d04d6ef91ca3538197003264518835269a028e5cd115cfa6e4afc635db7bd34c181807e4fe971dbe90e931e2b87505b0d99e686e54b1b057513deb519b9998c0f2d5b631d1ba06d906d2043bf2b513055233e397dfd280ac9fd8ab3f6cda9105337ca5ea134ba4e3a48446393434f6fba2f6378a77f0e19b23793686041925b934e40de18d4662b5c2a23a011332f6b5e14c95e0efcafd83f96287abe9ecfbc3e2c10c1cc9fe4aeaeeaf6cbc77821c6fdf962643a24ff56d4e77a1d67b22e9196f0d615610b01f566bc748050c429a0917593e7b2cc3aae92633ed95174b98761c76d60e95b1238c5c2f371b9a28f8d011f26414b1ac23c1efaa30e132fc2402920acd60275d510ad7c7c93f825320ab4f5ebdb20bc7a78ba7fa0172c5e325e6c3b3739d94c35ddbcfd2c460dd56b7fb975f7e0a6528a177455d29c0a60920dc099102d6fba7802f0853ccc17887ea425c0f8e73e8dfe227c0874f416d5542a897bba21c3f45218033cab30b81c94b6f778d745c741c0db75e0f1688a8964538c9f6c044c9866c87b4d7610f40c6ca9dfbf0e8ca142671674474d557cb7ae724dc1c3372c56574e24e1c83ce49621db0cccb86a5331ddf82de7813f92842caa3058f7f63abed015a66df21980d650d016c830df74898565847fbb3d6a6d96fcbf502cc386d49b8cebb676af0c70953429ee77bda8081bcc324bbfac211062b61c509ff2f93792007a5faf2104a762a0cb5ca7f267b413edf63dfef2bdb39035c12986f01a75884b64a892dfcf006216b93f9571e93f2388efbb397722c537d14b0c22df4c3db2d623d405b368709828d9d2774ab42255627a94b84bb956265ae7ebff61291141f79bb9df257788bd6b4edb40315cb49f37d14bb80f97193f4442bd50a1a287e40e9b836e13fe973d29d29152c506ddad9a57f316811a8980f6f84b3f5757e494bacf52d3bdbfe38d665d2657a7fb3029307f9e5c4a403392fa1250de011ce5a1012a654db785646ea33f2c3a60287e8fe53da50a98c06cee6094927b3262fcde1fa5e2298c44bfad0e3fb97afadedce1c1539570100b2f0eb047890c80dcd85ab667b1072d7c29455453c9ad135a253d05ddc440d7cb3d2d2afaf642148eeddc0d0b1f6e6a6504d8533e93d7785efd265de1086afbbd367e00b5d06dd85ce602d36abf3f8f9b33edad97aeca35610e952ec9c8dcc669082171f6c1cdafe86082840cf8a46f88c9323ec6873978c8503c266efd4ff2d6024dc0bde84c25a2f84db83c401f7a3268fabe2833c5c4559fac972e0dee781d66d125c68b83c76954a4e1fbe237b4f7b58c3d49b51aebef84010b4adfda69306892e8702465f9da446fba053843d40dee8157558e88c620bab2e6a9dbb8dc5479d35b1c1a82472e3726adaa6973727665bf11fbe14f5af31ef1a70f2846ab02097146a0ef7a5ba4ac4b5a96b2c280af18a5fe727444fdbd59dc791d999279cfd829720c94ee63c042fff5001eee633254503c97da933f6128d9d05c241b587de94e383020fd6a6223a0c0999dc8f84b41a9b4e1ce37a4ffc4fac85158dd2461bc8d36d3e2afd93919130a1a5df04d20330946bbf1c5fa179233239383d754d044f544571ccef154dd95badad63536809c901978f7dd6b95b5f03d1504fb93d0d99a728d614d58d52fa66ca5cdffad3e7c0a8080bd6b3538144e6296434274d9bbd7a921d6131a2c3b677b1cb7e8920b1a2251fdc37f0b726e166311a034c353a655ea4ba951e42ce89ce476ec6436f1d725508b1c26b33ccbb73020265935b582cfe717dec227e02d7455f7fac2ad671f8e2c95cb195a7508d691be81fb3737f5f166230101892e2f9fa3642b7bc70960e4a30daf7f88f30bcbb78d0b8112c85f66865a38d507d5a036f50921127b75f114cc87d8124ed7fb1cdcf0f90c39975cba3bd17b55c4e786072c0aaab1c54584cd6dfbc314b5269b6af27b8acc818c5c6e8195920f917192a4bf0288d23116a37a60cad26e12d392eb3b116479472ac802228c9370046c01a2e4016eb7208bc1147548603e88b6aa12c39d8758e248a2adb2b8e34d682a51bdccc8b5d6e310883c222e7ad17c8d97e5f85f9ea4f610ef02dfa89ee468af8acf4656ee46f57bf3cbe486a137ea1279bf192d2948304f5e4227fb1654299f701089062ff2575805ae213c80c5ec811b70799c80bf71e39007d1b838c8da8bf4f3950c8dd7f45a9fa5f6f7e935f54ae7b80ffe380db6a33ae9d6ff27ddf473ef814010f14eeec2bbf14aa206523922c417fe670fa5604b874c8b3a4985122d3dbde69880c3c5fc1954767327ad0f72220f49e7540a63084b7812f3d9b4fde39f217a277e5447bff8dfc6b6f909f883ce8c08cbcd85fa92fd9a2630938237b8258eede7a8eb240fa2a8cce38760b16d2b6a8681809df73c2594fc408f360c97213da7a2169f6600d2c6360c819208fe111a7b8bbafc3d7453b02dba563e68e462beac949d40aea10ef8e883693b60d0c41ea1bfeeece859f208459e23f8c79b7b72b8036e9764eda8c5d4171502074ae3a887bedf5cfb9585b2a602ea7f820309da366fe025b941ecbe385638cf9525347981a0e50e156870972b7feb37e37946650a4fa898a751b5555d2792b895645096037874c59077d655a0fa228ff6b3b04ed90bdb974379562cea63177fe6e165cc2c46b9a1b8b4b738934c7cceef750e85237374b9fa64d3898a42040b0765c5ddf4f2364adb7561f18ebe0ce21516d86516f4695bdee8d243032b7c37192025ce8c380b2d364b90f1ea391d2e53aa574a69b43da7dfe7901feabec3185f14bb080e3a4df32c03d4de985ebcb281900257bd9fcaaad50d330071740baa5def7392ce8bfa5a0454b70606d20d835ec22056e733c4b00db4972817cc72f68b4e83c5960fbdd2a785726fc6479c9196dcc3615f47dc8e64848f439aeb8a88d37586142b5204e4f02f72a87e29341a1eba218b0bc9daf01665acddacae2aa347d47f835b122412e3832be9bcee8187c7e913a360e90188f68a5e4c5b5fa7438923ea071e6aff59a983c553a4e13232812ce463d4d29f5b964b4ee78884b230165a07051cf4c4bf4fa4a0c5249de33ac8e8bd2b45949f215c37dd5de2985b9ea6cd1f43a5939f72b9822f9b10c365886a7391721262057b40e19ab7bb1595e880438160375b182513f88ac6e2ab7421f2a13358c4b63d19ccc44b7d7b9322dfb4227944d530d5b7074e1aa3dc34c8f7ac4b8bd6eef5da5f5fc973b2b42880dcb2e2083c5a87e57d2c9bf9b26d96b6593d7a4d8d68ab75658ce9a39f4c2d60bf2ced6656860404a3d51a9cd6e84253c23a4261df760446a22babff1b55ae9e434e0f657f8fa863e081369ed187b97500c2e70945450c90d2f5d884c6b2c850f08ed51966b2170a046943deb7d25886cd97edffa0d84e3f8f2831754606188bca764bc888526c532feb8aefa0d3499a1081deb8e25b8004759c17d5fb43b33650175c2aff53ca7c55f5dd2c0432e8b96b4a127acacb978b3c0bf4bc296fb263fa70e5ebfbf831dd226c9dd488ac4337a7d179d4f6557c258cbba7436bf038d7ab2c58efeca88e53a50623f394f478f46a93c19df41089d2006b8145bd7f1c8e3735371a35e552f6db8561dddfbe4011d147575e5b2ad3601b101982ce60dc9030109db8281de6b9c7ede07fc92c8693a457e961f50c2d6ba9d58f83ebf6f757f998504e88b78dc1faef71de6b6de8229698435f6fe6bfa8d8fb4a385ade1e16d9054cd1983ede2747e5abd5d1e7c48966934b06ac93c617aa22898f15c1a0474c3376002043a8eed2e36720019257a33ef0530eb75c04e7e8335d27fa23ddfeeb500b50d2849a06ed5ee5442e0f6670108b4ef4b0d1d8411dc02ed1bf17ffdae4c5e9a6384586c3440cb108861f295fbd744ddfc63216bec2aa91ad97103e1d8618e2225dfda520fc8c07f04f968f1607a001065d248d57da370346586d84e01fd272fa3531a0fd2a4ca66f9b8bd8ef70ca4a5647c364e47b74bff203e5baebc6bf65e38e73b95628193d7bfbd55a0a5e2ae7758f2472bd83d8ba0977d34c7451f31646a52cbc7b131f391589cb08d3f5749204998566612c0d0394efbdcec46f31c1eb6c9469c6785eb586972b8d3fffae27c909577654054f5bd4547f43d43d1f29705a7ce2382620aefcde148911407d7c574bd936fc94e288e816998efe4983fce2e600c1437a9ae0a7dd73db9896803ec3f143ce27c77edd54eac661aec889f9a7e33504e4aba52c979128fdaba6c921fc9889a9dcf1fe5cc92bf188ed40c1ffa05406b0751f34360774464d78874c88f4142e29c89ac39eed8e5866f53a8ce4cd77f914724c1ada22534e08735bf99c2fea2b0ca435e0fe3ca97a74569d282f3bc8f968f1bbe2c5b8f4425a6c09b3d1786fcfb2fbacb602c74ce3d865a9737a154f7505bd218f3fdea7bdab4cd68c3c2dc06285d51da6aba2190cd078f4e9628a7b6d3c9d8bcb3a0b34dbda5513d58357ab2169052c568e8aa4ca01e6dadad2b7d0194e3d22cc27615d22ea8bf51875371148317f03fd22dbfb1ad828e715aa1d2e74ff37844f0c6f34ec7aaec9846540d2ca395e5c9ff0ba860caa10727228ccd1586bf309441324c76af5483e83031955e9fada6fe3bc0a886c5420a4153a5096baf7469236c16d741a187e316ea1993bd0c497148ce899271e94b30575c196a2ec1f2b5d36f72faae9cda5399e240070e8314edba696d659963fd5a7a5681f4624c4c43e1ce9d825460a02892ed06b7b85d777c8cc70749bd9891394b0440e3cd9382b28626ddb5e18f23ece723dc6490ece3a078ad0053a72397e4b01c8ebca9b1502981124c3691b6bb0dddd75d0047433cb2ac90579060c5204b8b0b48fb2fbb27a38b2cff9102eaabf463926d3dc4d7fd0d61c8d284fa89b4afd27bc6a3c0e2be5c0e42396604c1c8e632cef8364bb164835d1f96b5d8a7a931f37c11371b372613deb18513d7737c0074d679694d3aea49641f192db75aecf1dee55dd755678a8f781c2de2612ba3d8e9c372de546e0ce57b776abbc02ff3d61e941dfd60ec0f87cdbf34daf56bcc88eb703c7505aac66b268987d3f547cdc7c3305804b83785f71bba608d297fc424f3b6963153e80f387229c7d107b19593d303f2d46d7d7196940f6d3c79291a876dd48ed9598d14479fa2fe75ae3dd2e34416a78dbd5686257071d7f2d1c17915a9b15785a5e2860ab4797c15b6d02fc891f4a5313a583f2c56eed9354b167c2b24e1109d6eb3f00d2bccd689de35289196b30a030af6e659e2f1377950fc13e0122405c50bb18670d30595bd006802f9545333e4548c08d8e1606bd2ac198e8b4d276b46121939fca6d8dfbc26318d980c023914e3f9ceae1c970c8d18b6d36529ba032755353c353f8b5f3fd7461b874de868a281a93cec63836c8fefdbb15bb1dfa33e24e30b8cf135193354539f48948c4e0d63ff6450d5f694d4a5ac8127a76a230ea9c6b6fe84e16055fc18bcfcb4256f4775503f7968a69e21515c477cb854c3c506e13ecf9bdd03bbea601c2fb600a0da6336c82b9fab43ffe802140fc9ee3fcd5c3b80f37baabc79d6ec304130a68660babd5b689c2813746af6685f503df299d8cae774c6122e6990ddb9df77b003ee5ebb17cb93f57dd8a656e620e5e48fe9697868ce5eb443ddee80beb4a77909cc4fb0691f60451e7052294ac7502036585c7d72741538a81f929409d90b686a97cd1e9d15d8b9f8c979bdc0e9987402fae8be54debcaafa2341769eb94dc698b23075e896b3a118f2dcc0ec8ebb6de12e34819188869dd9fab2ef1549c2770837df1d5ee2768184d691a8ddd3e1455383fd0c29e3d7ed3ff6cb61f308c47561e50fa6d7918559738d4a2974b4192cc3f576090df53563d71570013046fd8359fdc797f89ffb2155a5f51c163d091444afdadf8be501e19ed251402febf20242922d327444290e02b918cc68bff432772737b7a33d72a459027cf8df70c7953189134569dc6b664475193774402afbab2ffa50d8187072b6ab160af6d617ea19d68f3e1b4575631238bf4d45c805027ca12745a31144aaca390f0e4d96a3e37ce66d90b273d565b304455a94ad7a8a016249b9cc86b813b07940e065d2f0c0719d2bbf8d919372503cd3525b5c558753bcbfc11141a3f48535bf79362af632527e81c0852a887f737a6582d1387892fb4294856368cdb0f1d558df85fb06d96d936f467801c52eefc8a538e4b61e3530b543be38166122a8209007b27a0f90c402e45e41d4ef1a40633c8b3a6c48799b37f9d190f39129d235a0cfa5ea2b94ac2a75f2a30a596fcb4ca6c86a5dc7f385e0b1f618e3cc3c6afb3b98688b371efc683da18690fc2905c94774acee32d20151c1fe3e8794f2824655556830823cc40cd140df87a28399968c511e5e46c632a9e336fdca5b4105abf51e2f75d1d0bbcfe17923231e2e0b36f248222002726659ed96b728f23711fe127bb9a9afcfe9c75658d9c3ca44ceb4369c536adfea8a48fecd9d29a2910fb24a842578d55c6d0bbf15ad7882edd840548ceacc936e7b88746be0d9874c6c1a8432691638690568ccd60314b04b15b6a034f00302f8d1b8649782f1c23c5aaffd1b3970da9260d9d315f34ca60943d5890e0d3ab4d365b10e5e026c8c321f0f6d8b7dd097082c44ae950d611b6cf26014d820dca3f7ec1c51c138f7f1305448f95098b580b75916885024b8aa86fe9c7a5eb5eb3e0b250eeb491b0320b7c9dbe265becda5e057ad81deb261f5988d2251e3f1186ac757170cb0ba11e4db221f03eeb24f6280567a1399ef74561c83f2b1a6ad349e9b399794d94bc72e0c044b555855b6c1f895c147691b5ab9cdd8cc50c2b13c1e529ad10641fa799e4397d42b134ffe36db8a1102572099ee4df71139504d201582c9babbfd4b5437850f8ca081730acac54d19c5b240866c6a1be6c20ebfee5404d5170b127350a8f0cd15c7849721221a3f4db3906217180137eeca58e005d50c129c0f4a754ce2e13f180dbe4ac66b71320a376279ef92375855cc994ee180253914614f5924ae6da3997588675c91016fe84e58eb80292afc71c27ae5066db4af8cfda96c5778d7dc67b989ea5969a04cd8b4c5feac584a54f8059dd7c21666f35647261e8b4ff201d2b9d1761b7afa6d0aeebfb5cc2adf1c822b8aa67b1f7d1d46beaccd2cf0d7f33235765cdb4382df5cc9540e4e8f2f690c43525e45528e983be67669ceabcbb03d4b0fdfefabe4b0087883264d013ca063fe9a8e723508f09385df75b2b36a8cbaafebe9700e5c251a381bfafeeca4138b6f140b29b5cbfd2d0489f8ba6fd55ab17a97a4858b5446127de44ff2822aa93cbe60f673d6a75d2d2e9c3b95b84d52c1cabed5359c4940db538cc4531bac8841bbe30077a2b418fa5d7ead9d1e1d617df87f8e2578326f6ba6ae4ddf794de142ee3ba297907278c0ba4b0a4b980487cc8e99dbc49cb65a457b7f1929078a6c9786d81467b996bdc1c85dbe3c9914c8513fad4830dd3f2a026eba0a8bc815d0774361480f74615eeaa0c56dbefe622467fdc4b4c52ddabe107b2f7497198365c14d3828920f8fe8dde95595d1b4d64267f7649e0eb2520c8f367f843cf814bdc93f9f030f2d8af95e4e44a9a0fba0b3f9b31f19f0a1fb246befe5c3b3d825a86e33e1d88ef69ab965d3dc22d8665a98b4e7be000e8db0dff04ba477d59a725a636a906ab2f3355b9279cfacc5ccc6d3272437d17dea0659bc4bf7dc1b25e7edc8cf799da8884d57b29d2d680b26e29c649ee6ba63a422b18a0655f11d54c2bf6faa357a083b321b4921e13b01727b34aadbcd44cd895384a5ac993a21d9faa31ef1923b3f233fc6d080904f3510b8d681c91cc9406d7b6a5ff701559d5510e09ad60c82138c1a02d7cf393d83d4a8ff1ee209a5f982e6cd2fd20298ba875f6319cb357b288be1e98d1edd096eafcfe1697b477b6be8d5dff8b944c74440302711eee7d26545c1fc8008b78c19f55a4aca3f3d08d98b450160a3e4009a0858510317b89e9ef52c28e3a5268a585340be1b08373adb2173fa85f06373e72120494e2d9751495c10858f65297f2becfe3efb23ad6e38da66458875960f49e9f38b6ec8c81275d431021563589f126cce4645d5fb5148673c968148290b202ab4ea5992f98cb39ebe209bd2f1168ec48f7f267690dbb20cdd17987dbacc254a8e8b425d949ced74947975915fc974cc6319a7cefb1d79b8adc0dcb0a7fe17c2d8d01778339b5ae87b5c29a81f399be83d6909bd1d68968d5418f25a1c2846ba058e10daa0f9354641c0a69c5dd6d6d6e9a66e19a559b172fb24255f2189575b5df589e3119b4a59e58294b90bd39a4ae919b50a21ee8289cc519d96fed8e5fbc9c7f23734c8abc885c68923ba8dd65c8a09738aecff7894a4db7a69d742f6e648ff0ecb678341acd8182d0b5572f44faad1564f1a30b67eb87af8a98967e04bea051d9233c7d07bdb842a4ae76ec493863e11160d201c77616781c7a543300d206f9d593fcfb4e748ff72ea824a66327d9e22552f8e65b9ba648000673f533a9c3df63a63fd604cc19a6943e8b056c93597ea24dfecf3a0732b0c05e71e936a552ba9294911c1ad55a376602bdb371cfd6b6160d3e5656737e5badcacb58b44858eb4be035d50818d8b58affde7bf924644edea976036be8b80a90f3bd9388228b46ed6e03395da9e4a0520517a24ecc56ace9e787b9a55f40a03eb0e5da08d77112e8c6f64a688e0ec418c95b04ba840fad4fe163253872f58e2a840b0f19aa8100432e8798543c96d2f4a782a3f29f81b8d52cca94e31d2aa98020122290a8389ebbf55c151274dfee584426dfee67ddc95c4e93b3f70ec8f6d7ebce390a9d03b1c69e514327c4486761d16a3774a03e12b0750bd9ca6a60bb8f9486e5bd3d962a0a9fbe63b16e4100ccf708c9f298dce048a50ee9905915377b2576b497f8340c13e736b30722a087b49c5637227064b89685108910e827f080a628285785b2563a066d6b718103ae52a1d0d1647b01507383d62e7b9ce91f2eb49e3a8b23f0bf2756620bb01c3e10a5a4908a97e7f6d76d6428987f4841358af02a4fa8ee5fc4117f7423f128ecdd1455e49659d1ca11a4cf6f4b7cff0bfcdef8dd5b5ca85e6c18b08fc59f792a1a2a0d95b22a9ed9b52dd6e7f91de29206c7995130195ad9998e4615d364f356ffd93d3c931f3ba84cfe592c89178761b97da0347e7dbd6952e3e934655104ef05007daeaaae715bb2a6f66648af5e0bf5190f2ea66b48f3f18737c2829b50612049180076b3e25ac4a4edee8bc317c31f2338579c1e9ac8ab4816ba1f59b96b99bb0e4a70c6cf3d2dd93cd4f8e3af0c41fbf92a647a97be66a4f2ddcf26779ff6f0df9b17590d747987d7722d90aff9f18a22a797a1bfd2e5d95c6816ccc2a6c5071a63b322f964858183b3bc3ff4d9b5f4cf73226c640f0918a0cdc949a0f59d6be352486d5fb2d13308c12dbe27934343a38a4459730e7d7d86e32a233535e93e4eb7bcd6780813be16daa03444c305a1f291090bfd00399136f8c59afc4c1d820a3648163ab548e46460356afaf60a32eb65e3cb13c926d104749d27e2209687edc89eab0a82ca8019fbf6e65a69982f1202a9047ca03ee0df5bcaef688c08e672e01046a8f111b2036454f12ca3cc6f02398f8ac700c499045d27c79da44959b90ed92d85efe06801b52bcce4041486f1923194822baf69b53b9192356c19f93ef371d8e00780c416f16731454273eab97a24f3ea305c7dc27af048f681747be8a73c080b3559f4017d869fc50ddc176d3b33d12309aa552c145ef4e1195ccef0f219d886df0aba41e77b10576c2b80279cc6e8713aab68d8e8be86908ba0fb44a665b61c348d611e53ef522d0756d08543c10d697d05a2bb1edcb83f64593126c7a4c402543e466ea952c15f2d1806c68ec532a55f201b9374509cdd4e5fd078c8022e04d834074900541a291af770384642a3aa9e52cf96f79d7f34a1fdc8296da94c1cae605493f0ee543624012e0f976ddcda7c21edaf8e68fc5c9b8812ffcfde30d11086e87fc19f5a49f7acb9583e1ef9e7c775cb63beecff0a108340ef0ffb5528860e4bc5a0e59ea56cdd034f8592b5fa15acf357b40dbe5b9821aa21924bf939eb1463cf31e6997479806c27364f0ecfecf290be899fbe6a30dc94fbe096aafca12ee3fbfa9fd949270d3b2bfb9c9f48c2594d637c760b6f3a21fa4957ea76250475e518860e42a68b47d1c2a07c911fa19e3fa29f830b72f49fe75f56e2913de3b6388b2cc865589c89331a5eb3d19201dd2e43223442b7926cd0b852df090b79e98e96821ba65e04f9f2e5c7ae6c076e0150f312952af45a6c732bf0d18608c61b224f9a9e770cbd0b260ae92d2a85d475043c15c5756ec294a76a5cf7ad92785044c237f232028783769b3a9909adcdfca35fceaa94e1b1b41c194b5989fe01edf5d3a77fcf310cc954b47e2c484704ef796276208c692c151cb1b5998ef18ed531ec450c0c74ae7a6a23a8478388451861368d18000fdf0f01850bb2cebe9cfd4370fc8cf998c587fc96593565a22defa8637ba3a52afaa4bd01fb67e6bf98d0364507757e4bfcf11ca24a7f80118caf6981f97dd4f6c57056a0449bfac8f76878bf094e1be3d5c733d11f862ff13f49790ae8e122474fa06268866135272925588e660b58ab528a6f93131b297449c988d17a979e076a1cc221a80ca387ecd71144f4ce4f142d9c831142350c980411ae74168c4d23304cac6cea548a53a5dac7653743a44251dac28021c3bc52c7499ed80bc1c7d64f16d9563b4fdd24fc0245ed53ccc01c48443d2fb371f6d5102a29c19d0671a0a2a571d761d6bc2aa17278952e7145ce64a636324f53cd9cfd454b1f7bdffd978e9632363ed32fcbfc7f6251ad7c6e494db3fa984b1df2cd510c902dae71487647d37a92a2df16270510e66389299b325341b9eef4734da85d26f5f56eefd1189aea60ed6e6dc3a132fb8bbfd8206994a35582d7cc12f9084ef73427b90f0b7c38712570959d0fd1c4722597f718e2ae68a6c46e6f8f85da72709ab6d7cd7c73a6fb3a7f7b9ffb8c7cf11c1be7a6b6514c47b711cfaef8afcd72efc892816c3828c2cd55345dde0653e22c9fc988b8c219cc41f42e2fc0214cd4c2e82b522662ed7d24ad8e37d8763e42d750e93a5d2e3ac1e3ffceea9de30fb562c394518a1797d84a3b2db76a9bc9b69176e02000b5e3d7efc3268c0667f6cbd53b22663128e4efc07040cd1167b6f76f5c4d4edaffdec2ee8b7b16615c4efc40fc21ef48c20989c619eaa7f22d7fb8fdd8a53e04bb4356a4fe1516030fbd336c9260b069126c0d1601a652bbcb1567b9776540a0c1097b502bbd7af88e47f9903e40193e521f0618a8a70a6fe44e2439e946c64115a3bd97734db773cfe9a2426be9e0ca997f5ccf726b8b71bbed335cf24f37c22eae83fc8132cb0bce630f50aada6ffdcf83eed451efba2593d6262c692626f01d40f9216189b9224cd87c22aa1f794f289fc86a77788ad79d013b018f092d628c00675ddefb2c14db16d19d6e4df09533c060ea5f7eb397eb4471b3bb4acb03c814a26a32212d7e35fbad538b3d268ffe4c58a5a272b36348100512855b880cd10b8b4567b53c730dc7e31c5601809969dd709eacfb961faf034eeddc4cea4694e75fe8bae0dce8e874a96fd2fbd99c98a073b3e30f034882a2061fdc336e51c794b8b12852a6126755f9049eae9ad3cf31b382ad3e11185acbd088b71efa9b0218f1cb2c8266dd0cfd0a09cec74d16a396a1973318f954a2acf362a4d58b58575df572f4206a2723fe5758141fc7e1ec02615aae985d9c84aca9f84a2ded4f2861e82f8ce612975a526c02511bffee190336ff8a8e34f67d5d34470696b1d0de8da8d2244e14d242bd8c33a8b7578635247021f7e44746d7d5d2ec817cb49d35e3df5743c083d2cb9a51db1536ba83d005c04ecb84fd10e955338508fe6a61847534a0bc8f7fca7a1cff551b0254adb7bbb53693284baf01ed2da95a2325015e98be40e3e115e8860aafad298d3167a000ead780b5473621e9d565a2d41b106ccda73a74dc9292a71b720ee7d77740c85a4ce733d0049b8e8d05b0261bad11dce4ea4c87cf296a1f35d6bbab2e1dc90af5fc84e5f9c92a979ebd9e8790f19cd3b9b18e467b489eca3c99637c5e6829a15c0c4eee32da5aa9b81089548cdcf46fb0d93a32b79090b15dcd3b2e584ce2aa6b3e4caa3d3afb7525e6ebb7698b62100f98f901098547f6558514e8eae791966692632d2eefc40052270d8c03b974fe681b9bcf55ff91f7317c43e29e19eb06be6bf14ad92bbd884b354c52aef1350c504a6b7e1d6ae2ce9b0173719a138b21db5e9220df055c67e1e2f068aaac06ee8c89b75c2d6a51445645d934b24c130252f95c2ebf8755f132024ab5093b2bbadc921fb59b69caeceba47730fa73add8347d32753ee0df7cb020fbe614369511d1309939ad0efafa4b6f13578e77b4049ee2da20fc50dcca96fa80fababa8aac1e092d6bb7149e9bb1bb088b131d4a8d2c95ff7e03280ae3f7e490dd7b8f185758b491f5b537d07ebc69d601099f740877d6e2ab2b0a98a9b4c6759e239955cbc2659252b3bffc9b912c555c46c4c8898fba8cc9187f6c550ef980a2114490ca197bd902747820af2b732a4e4260a15d84038327627a2c0601c4011a40e432a98f6dc45aff00909b5cfb81ae28425b38e1d2a3f6276774a3d747fde2b8d1ee9098294bdb74384cc040424e4005ee8cc4ddb7f237b20317a8fac134cef2bd766d353dd3dc56a877e5c93923de1be8a207bf7c2751e70a9cf6065d3fca85ec73f121b7b1e95f2c6e35793d7d48be25f4229c2af26e82915c31c116065667dfc5e3ff41cf2fd0f4362cb685ebdda4f500a391a2dc44f36e35d8cb00901f698337f54f65c3a71e1503add188eecd1c0be5384d8b8d76fbf02fd8de7cdba554d36d78a9d594970bb5c4484f7f5007124f8d1c7ccfc6a9318d8816ceab4cbc78ee50b111418e7d6d79d216dfd4f4605c517ce1dd2c42853383626ce11b6643eadd5af9e9a24c88fc27772411b3954edd339eca8741ef3f48209dff06102e9fba0742e7fb1991b4be28912dece492836eb3835ab45cffdfc75644617a9ac83cb36cb0f7885a90a8efd516fa40dc67ce605cd7b1f2c2c0cff769edeba0451807c0c34bfe95858ffd264201318c08150b1d0d644ebcd7948e8f144410068cc35a5b7a4c48be1d0d2468273acea252f4bff29abf83ee681a568ab458073501e4da023cf64f4571dd51a0f55c3faa31483d7130b58e9801ea569dfd837e69490eea6c5a67a65ce82ca27036d505e11a251579437627b5d61d53cac09bc6dcb2170270c9e807247a9ea3fe629313924fbd5e26aad8bf85a988d0fe56816cf09e2242776d10beaf2aad403933606b03a54560175bf7c0057f6c032f77c08d8b52a063608388ffffa2e12b906199e8db974266ffc0127307dbe3d6ca92abc17b1dde90cafd877fd3e60621bceb8a82ae6bdeedc44beaa2dab514f4c3ce73a2016f3a9d490d32f3c80d0a04929ba4385cbb9765626b8f70b188ac9af4cb1c6fe9400572a2c58f898f3fe8e7f16d21760109f0fb29086ecf38ed8a894b492aab994353c12afd31a759281ad9afcd210ea6c3f8e27eadda5689eb82e470283fd1cd1e774938f89b81c9c9559b657740d257b1b57a0e9a5cb31d5cf5ed0e287e280d069d70648cc6e1ef8fd4cf92681733d4cc69bc5dad296c61b67e28a118580ae777bb2bd4e693bd4af9fd5ee1896357512470b9af27d55558129be7edf1f1cbfd39e4e50c2d53e23c7d2b6974fcaa414fccea108baec8472d7c18f74b469e9776032d97336353d8cc6e6d3fa2709e81cd0d51aa9df64291e084f81df406fd47107382905ac9a44a6c472111a4fe29c1c722f2a0fef2a051455504df8c3a9bd2d33e3e9db5f500d456b41a00a8e5b81ae2c3032bbfd7128457e82d17fbb7da1a0a3db1ba30890129b6908c8feff4597a08936f3ad886675ec3ced991b11eb3b259673d5489a402d6b0c2f13f08fee18b7e1dd8016e57f9e21e71abedc33dac5dabacecdc72ad00b52dbcab609bfc39ea41dc32ba72fd035f43d96a9c6e0df228fa4b907a1627d2837a5de1accf2428c557d0da08b6cfb0e77529cf7a0275105a8e8eb55536edac5711a6519b1aae03f00a7b5d3d88220bb34ced975fdb03a5994df19f75e466247e04e22294da5cd366ed627f0e12f7c04523cdac04775e579914d13821e5fe85422bd8e259c312adb951cdc10ba4856b44c6175aa2857efc60a97e39ddb2266a0f1e0f979d31c588d7be0c647b7414d52d62baae02c6a38cd3232c24d5591c19eeaa504ddad946b4f8bcff4e06e7e5fe96a666ba5fe27e9f2e00ede7a21582f0fb0ba0bf5f15d81554683297a26e07a9d6c46afcc3797f4ff5b1d0e9f7cb242301be3f2ec2b96b0cfff105d27812637459f285b300d826637f9e4ef55f9f8387e6006885f3aee7c83a654d20434640e1b4d207701da6fd508fe921532e2fcc27ff45e27481d755d846fbe5f3c239bfd6ed58faf078191fe8260c8a3e800d0742e87b225bc5b24363f3a04399bfa64a44d6ef2a7c265961a3990ef9e89cdefa9fd3984a826e89de297aafa350bcb7b6af712ed1197eac6209e5b4c3c77954efbaed3be638789f3588d438d48376d5269a0bb2a66ab001a99177f61333c67c5bae9837e3d2a6c1f24e01bda5e62aa9a4875cf4a29c9723923fecd444491d17c2b8113fb9a38c583e8f5d1f4bfb2b4ac1cfd2e1432e924a7c5fc689353ea3251e61f6e5cc05fab82b0cd70ac227d128bd8eba30fdb353b1e45f22b330b983fc6c425b61819bbb4a949b488ebfb837a6c6087293a30b177c9230606a637e35c10983b358e8490e7081c4bd05d3daf3e34a814cb489118ec17362f4783ed6bc38ca4384269367a71d332378bf553f2fa4c9ab2f8035e8b754c2b9e630eedaf29906a684035597e3110a51d3ae10af7ce37f26773458726fdda5162f78dcbe68424ed0bb81b10c41e7cb2e27cba55e25bf1a74e6b49c65bea5eabf0bebbb72fffefe1f86d37aca6e58a371f08123fe119bbd885c240efe79cd343556b70591b25d5d78b0a7cbac9673304ae112f7198d9cb40523db4cc1f2a0994631f2414e439403d6a8a57e80bb025cba57e379ac5a3fb26183637a388135122a461014d3c9114d44f2e6c9dfb485acf4302b0b8f3aaf66a5fbc88f822885a8a893fa530b8aa985d7b2f5054b5a726e8dac80c449aff3bf636cd0fa683afe27b9ea688c8779bbcbcd58430d933abdf627876d20d31c574016f9b08ecd1f1d5135b7741606c3712b3ec783334f10badd9eb2e36a29ab40d7c7a1cd2f62f306101f79004aef085a6d66d77e48519b53e9c0b81f8e8fd0fa3b2500900509eff6755eb9fd179fa00e74431eb560b301d86a785195cf47681de046c729f56f5a0ae1255c71586c948f56d86db1d2632bcd020ac6fda9eda8aafdaf8ad908ec7492d4cff6ac527550fe7b4890defd5a59ac9ee4419f6de07aa6928486ea754bdf1c59ec4b9f9556e33471e9e2a66087f35c0759d65fbeb0a146c3d8b4b0ad8af345248f1c11984dcef87c76088caee0fe33ba93be6885b5402189745a2c4ffe7b4d4cc661751f0792fe8b181d88c4335caa86ae0b62adf02605db21c0455c26a8f6514a30d9569f49ed2a340ddef3d3aec87512440a01cea5f0568b259d892b014679a68112cc9a79de7434950ea5a8eaf1027e8d692173d062d57b0c4f4524e8c85363fb59ad3c029b2ecfd5fd22647ee6e7e61fb24d735b717613c45f7d2f6a075f71bf375aec384d08203c653a42c396ccb9ea112ef6d7b101f6d57ea219987da4ff97177f5a8157098384d02f9d59de0a50741fc293bf0e5ca2fc8166899c55b1ce173639052753d8a7f0f949660762d4ee2bd70ece8d2d8ebfb9621ddd03cba89b8491b4ca9cf52883236bddb75fdd147fcff951ab23c89787a49f90c4c32ff53aa420039f7dee712936f37b65f110ebe62028ee3679cc58321b4d7ab60daaf83e970da98a1c6f54fcd13da8bc6f3921036268d6028811113e594ce9951d424dd5a246d85dcf71780b2b4f9f05739addad73d3e63d13f12e25c78f6e966e98629ed13ce62f21f690d09c38bf62dab40c54eeafc54b7d2b1d4d37a3754eabb50fac5e37826a5ed0640d92e657e36230d280d372f7e2e8dc2aed5b79bd1cffdf93cb386af1ceb4161a374090ad4b59a7b0025fe13075b9ae1c4e15115a9762b97d15f78d8913c6b153271df5f422e9b493b4ca7e4b963e57758e5649fd9370f32be4a0c40fbea5cd55f6af59724dc184115aa110ef998ab4e334073c0cf84803988a37758722edf9416712d675167edd628c1ab5e8c43f2d614589535f11da04d73bf269a9d0277149440afb9873e45e9d1cf8c457f75ad1fbe1e1ea95b4db39b87c6ec0a324e0168b396677d9c385a70f9a18b7ec0ada262419c567e03ae968b252fd3fba0dc9e57b6b5a7d58eb5ca3fae68d319c0849577d14f0dd035fd22f122a88f41423290cfde38e0cc63983e9466bb84fe8956e3d69c037446c52e38694a4007cf860d42601b62205547da86c5338a059f1cb483af297e82d9a57835edb85e6f3d4da43f609263b80ef75ff7091a61d86594768db2fad85411686b39da24cf99b9eb600f4b7a0295eed0cf917f32e30f6eaa921ae9081c11a98e0b4690e49b8528bd38dc26dcda12f60d1f6bc025edad323f736aa1e9c1134ab1a4db7da12235e579d72bf85ac2f5cd7cb23551aa62fd615512811dc680bdb0da258dcc3159e4966fbf873e7dda31d7c835c11ff2533d42d0eae0f590d71bfb90de9dc27b577293e0d88b1fe0aad001a84cd3ac4af1990b5ddecd238fcdb71fc18ef5dd03f397fd0a242b346bd87175d9460d629c682df2b8edf5c4a12a956547a456f367b7486f8a446d3d81f9f07f0def20e2d77afe854077631258dbbbe95b73f920e6ff2c6e120df3b547e6fd1c6bd86b5fb2a5329735aee32f999726282db7105881cf0027e01f27d9627b02dc8855c1672c69886abd055832db1dc917e1d5990e0767958e43a6e4b2fed2846f4134b12c0715c4a113ab5cba16f2c0f5d8393d2d85696917cfe26f70faaa0988b8a8a8347b25e3c935291777410983ea5638bde2d0b91910f0349366b02857e7fd08b4ed8b1d6fa89fe7d666bc63af846fe9b1ee040a6df29bfa4031ed9a1ee4989cb2ac2fe0c3d289873fd88366af66ebe0fec32a84442a7ba5125c9dcd23d72a88e3e22b606d1f29014f46edd81e75ca277e556e9a713617e66faa634d8491369bfe624637b01c5cc77b208fb0a30340f9367c9a6440223368551f58ee04fd8eb5a13e0e1461582649b4d19fdc6b73f485021090865ab7e36fc5e9ab0984f0bf5acbd0384a6a4587a0b11e5bd168d074c4c063cf376fa28ccfa9a8b2db18588049283f3de859b0ccd0e801aafdbe87fa95174de7c44554bba69e294cde1050e049058ff9659a57a1d33a1cb162b9eb2d00722947e7670795619c583b67b7409d98d1f2ce05e52860ceb430e228d48d6b451a6cd54e47d6d80eb054e62eb715152398189de489982d1a0d118023848deb3deec578b69bff8a7bf6f323e42121df265b126a768b40234e5c6f3053df94f1eb2506aa47518ca59e2cc52a97db335b7fee19e16a0e1e40fe226fec94ac0ce49a9acd3817758d6cb450ce13bab5688954852ca3179de480d6e828c20e77693a15944b17400cc5c03dbc41ab74ceb9506cea7d0ac66a65ecf6950df00bf1080305c9f65b57a22aae2c819f7e8e588e7423ecfd801ad38c68eb07641bccded7f0516db9cfbcdbf0a86dc9147ef501c224fc75279fa19553b1e6b31a3ee6c346548dbe828dbdbfbe2f074d4312f07be8e1d986782ee9ad4a9ba3c78e6ccf29989aca25f4918fb18ae9e5c4fbf2d4c4f89f33890f2ce9f3d144d92a01d84f5e6e6b5985c9309dda43820a492482e2ea391323c61ac4c59bcb79a6b68467ade2b580a36d6ba00be3b40f04e73dbb03af58c57bbddee11323c2fcbc9edad59bea341996acdab99e7b244b57068c13c86c1d10c483dc46fb9c80cad7640bfe68c1d44231e61cf2523271e6472523534133e75ebca473c65c3c1140cb6350e07ca6287d5804722014731000528fe0344ee53e99674895a389583150dadd84b6f83a61719f286084197cf0d0de1423002d4dcea10cb73a6ce61d4e97f908355a4e7a0bbdbaf4cf65a9c5e7eb83a16163250d63b3718e4674a35bbf55ea83c336659c6e9ffc75d5bf001db4d41777e08500476bc1441d1fa1dd1a85fe6c341a6765293da48d92064a808fb4a2bf1291bbfe3c979f05a5fa7449e42ca512d1b1ab9dab5aa185bc0fae70ceb420161662e4675b03fe381d72a38fd6d6ced48efa51994c08ce728503cca4158cb517c829b8a0fd180a3c8d75fac776a83049fb38389ed6641e3b938aa4351030ee099fa75df8aa97723667b50a6c881c7d7a24cd46ee5acd42eac2bf8cad40cb1bbd0ceb9d8c77ccb9aedc98e8be5806257350c9b50e2308c027d1c2a213356656079b52efdd278c509aaad40274f93e99169d911c3fa59b0c8b8ded3a407ad34d11da949c56719623d6862aee4988c89e5a12b9c69a83df9a884da876ca0027fb8d38540d391373d4347f37f6729b6403b463cb094680899c3ae7515baefeb3a9f2158996e5bcef73cc94be4df7d731e8536823837ead3519b0cb22c5109dbeb928216e1919b35d11a03c9ab5fb3e8fd116c696029414f7c4aa67a9f36fb6fa40fb785fe826e238f61c3ca690f8e2c18015cc1329a6d114500737d6a739d3447c4671e2bd57e9518592451efdf4fdda7508922711f2d98ece307a3ca4dbb6166c3072d9613dc5b47d6359cc57458fed45a0aabfe985f76c5b05b28e10b443cc4ee054646f44062b103a177ffe00b60371160a81194d1d6b77fba8179cac147b128264a4eda3d2fd9dd45b3d0f62c70c5ebd80304f94fad1a13f086057e4177dc03db7086d1bdefbbc6dec780f51a7bb2e7b54e8757fd2c07c03a060c764a0612a068f799e89c9175531d4eb98f577a475bdfe530c629f7a6124e6617dea0b0c41200c76b2a41680ad36eca8a9312c76cb5e012e70aee423d8f36fb5cac5816c192247120d49afec3e04ebe841e8617f07102c5667da8909c67752dbc1fd4069c3a09f4938ae911f4b3598ae0d043440a9cd0af4725b37302ec92db83a2050375d380d4464bd1f94dc93c5e496bd0244764fedb39d0e7bde6189260429086f286774a2f6572008be8fef1684d04ee00d9700d7942877f11551eff7766d1b9a624ec9362814ca98d785a941c5e3243c2d40da426f88b1d47f68a0a6ea50a48dbdf646426958c918eaad19465506c9ccc56b7bbb9dfa15029b3b5596a597b75e1d55d762023e8b045f117bd8bd085a4f4d81b72b1434d3bbce2e603a4c8df6dd5790ccaf6363bf5fc59b74f9b5132872686d8b419883b3a66457d47aa1242d0f3c80eb33abe6149d08117565dd97c5df916b90982b9b721ff38822cf2ccdd9fb6f67e05f35b7373f9b81c861d9762a735a6714ee7addfc789d760350787d1974903490634cfb9e9c4171b222aaca29d9083d47478ded611b8726cc5ab8b57034c69cc5a369e633fefbd9f2d7ef783b8b2517daad4e2e80f40e5ea7bdc21320ab5147a5af2b0d69bf84e54a1418590a633e2aeef1a96146ac5d28f3bd7b30d55d58e1e222b98861e3475b877a767dfb5da9564fb2dda90dc7aee80cb652f47c99fc3e17501c4c280a953b3a6235d77cbc7914cde75e3d63c48fee47d317437a40d1efd810efc16eec03c9b0ff4d07564a13de224378f051c2c70ad39678da53823021cc7b95f304306ec7a00ec67b3b6f062b83a77e7f14b85ef691361740b47a9ca2e3425c79a71ebb38644db771eed1683100690e7a780292fd51de9bf7e77a909a8ad470ceb9dbe206cb4e2f09ee9adfb0b497d9757f8f6a1d97d09fcf150f3d8ebcb5fadeb73883f1c3efcb5d33187d578bda96d268791ab53e79788f45ab938dab035ff25870d82e556debfad6032ed9d20c5faf5bd57bc02a052ca0f4622e082a000bef455782eb287666609b48b55f1d60a5803a15539719ede0dd2c9b377125a296f16c6ee7bb5228970b126caa2a4bc7d3b07369936e7cacff37758dfbca40a44ff5b492ca0cfdb489cc36fe4a3c4a6838e634dd0a2bbbbac991b811e4eb28b4462b8b1fe122845decc1b359a7039ef0b44611812b8d72be3bd5ecb6604a301a16badc417f5a510f9489c78617bcba2d7c70eeaff18b07689289b9c44c05a609f544be34cdf685a35a8827b7cf583701b40e5e006ef52beffcf7b1955f7bf28cf5a14fdac2ae53b932612a315516ff124defb5ec2284e19a31aa45cd2a566bf7ce1d6c5c330ae7e6eb7edaf51930475283f45ea8d8ee46b86c549bbab5caf4fb21ce0057236c9a49842994e7f63aafbe245eabb1ed55f7056d9e974d13b624fb2cf0e79e58fc2e6b00eef2d995163d4f6af32e68e9af6c37b8901a163b13cdc35bdb906540d1cb86f356756cb247bd929fe938056dfadc23e058a2e18d2d2b0ed3a386c6655f8b630fea53354d59509cf32fa8f28c6cbae4f2226ab1faf56b0cd528998cd2edbe7234d8c46d11fb9984be9e195559a32d6c739f9a28e3bfee898ccd1242d32250064afb4aadd86e161319c36e5d87f58baddc1002416739bd4a454d5246ca504d1de37332dd448f36465ab454aad7afc5557afa5b17fff632773f4d680b5e438ae699e4d68ef65fa14b48dfd728d52f5a31afab990a66dd90d5a36840b59bdf9e92b095efb5296ec0ee4caf4c22eaf684ffc0f80371bf62763315c57cd7928317c164ade6ab678a4c4979ad490fd1489f95049998b2a2e571578af2610627e608151690e500d786c97c59377dece2a5626b8713aedb47b959a1c114448c1636231fbf79990b0fb88525cc15514936c4ef294d9940d984a56dc771618bdb06e736fe649332b3a7a02413466656e7b313a8a5a6f7204cc4fd43aea89fdb68f9e68cdd5af2bffe9be49e31cc81bbd754980b6facc77d9e811fdaf630627cc4db87b902e38b13f450f8098fc31faea3621b57be9c0fd6c61184556937749b6fed77f1d17ff71d95f53285525bab70678160936f10cc5b4fb0c8f40cf2418afc8162c28090f754b4184e231838adebc6787f616aa78f05cc743d5760d3cb9947050d60000d8ca2c07456c8fcaf823010bfb6c53dde5118f05dfa05b5ea164acf987644c1fcc884f39fd44c695d767d4963fa1d5350034d01e7e606af4ceb048b3b5c6faf1bd6d9fcc22cd7add4ccffebc50d59df17d213c88e32e098d5c2b3d463d2e01d1ae12c31f02a9ee479bab5c3a2de78b03015d507708b478a4503c342b487459099a4ab86c4e010737cd35f633523f02da725112b0f53ab5e515db4475ebb6e12a032e73075b0514797163de1de3f09a1aae5e7080ec997a440acad10c1ffd08e592f0ae7b805ddb232e45a4ff12b25ef8045f4af7356d4df1c15600596719ff4a370cb6a4186689312cb68be1da4439710568193a794c1845c313fe4cb590604e904d346f647c8a0b48e45458883760f7f077783e1cf2907cf5f2227429102305479a4dbc9ebafc8d8ccd983fc22f9fefb9bd75637cfb2315219a172dacb40fe8ad37d38c49690e25f814553da8c9178250fbe5db04d570f6e6906a54a84845b7ae851357c6cd9dfffe02ab3956d69acfa6aff35888e161068a37fd18b1ebc1c5de096ce77b1685c4b9400887ece6299c34e19bd813996fb3e7d6795b16ac64e62181f911a61cf63de900e19a07cf3ab11076d33e4d47385f8582970bf892e42da3935a214c5992a984ad88db0018b6583b39516d42b78e0c0c3cc53eac58a6963da726e0fb623a4170de44e9ea9a21f8023aefee48c0d821652c1a9c4a93a74d766173435d9adeb8dd427809a942230547844669f0c3eb312369c1e40209f1659440bf79306fcfbf5c8e5b0ae73faaf161227a40a14998427627d90f6050cfc8f02a3c86169b77c222a31f2ad20425d18ea30a68631199a036bc2a9c9b730863504824e04daf7bd4f1dddec53a78a51d3eb8204f3845793019a66454ba321fc7d8964bdf3cf064da11bd06d41772f1c0f1478211375335ddd4d2375256659e60cdbbe07ec7ea7d684707ee8751324951811ff758dc38a1746322d9d4dc5ab19dcd881574d794d168d60fa8210043e07008211fbc7dc0238be277ed19a6b9d051f139c7c049d7afb60f7d2467b97be051eca2b2eabd42d371aef774e4e94dac2a911bf4137d915ec34802520626dff9b6bc7cbe869a23311edf0342c25b840724a506a782875fddc7d90c352558176fd44d7576fc7962a146291ca2abcdd7dfc8192ba84e87f292a16215ba683f379bffd35aeadaefccf56751ab2189369afbff47ee569c16ffd87f8635655971d04a70cbc5dcc8265c704ab2d93c096f2c8d394a0aab7314a7aada85e20fe34dd42be163875ed1c5a524ed71b9f7e5a274cf14a927e051fba9b48fb373f4b2b298a6a084012381104c0d3878338addf3e0439d87d3a8214355a91a7612384b2f611a87040c22fef608d35f37772ee2f5c80d0a0a4a2078afed9a30f13d2a3b86ccac381d9330cf5ed75bfc0268f8d56c9f1fc04d7e432f0984e7c299700ff7e304c0e8a36d263f43139b7155d23f4fc4c38fd3a04aaeaff8163360bc82972203e8fecc6f50322feef968ff63c68e515e3a26774e7fcb085a4afa509d518f0e6c21983f5b374d495b8233564dfa3fb91611b9f090d3f1556848d8ce8d289c29bafe22d544d22a1e21f3442d74ee786ae8410008424e95b2579d921c4d2bd549e99b9d843736b70abeb6d7b80e2a48e18dff48bfae527e53f0c23e309d8f2288b80781abd50094807ede5c982fa31acc86e9b13a179bcdf969272e9ffd6e028aba6acf0606986b23c19eb829f232554118ecc9fb20f11ba10496aa506b334f7a1ee0fc80de8857001b9886d1eb3f83b33aa01f25886ab5a0591926b28382d86fc2a224eb39f7773e2c03db62579f7df4bbeecb0e02ea7d10d11fcf6d875ed465f2a858a7aedca3395113724555148b876ddadfd18d5a0403a13b1b10b03072b70cc2cd4301190c52bb93ea5fc3dee154e810375cb0c8c1a88137ae4de98f45c60cc702973c126efde222c4a5b377abf8a63b9d48aaf1c71b801cea764435559440c08d1869e300273add0a55093b60720dc419edb667c7e0d03a8667a81a922c818003c461a3c6314a69d99194de5a20508e218fa9180ef33a90b171f9a6dc2896841367e8b9c44fb69e3d5802fe93cb06ed8ec92ed22665de25bcb7e5d5bca87f9c09cebc7a1f6dc58820d89d7dd21f46945239b43a7942069103ac1a8f64bee8d2a547435364d3cd9c588e635403beaac2eb1dcfeac223f266e2808e49c1554a0169d995d5a578cbc254e371383fe475fdb112b07637b2735099a4d65caf746592a58b16b0717b9a62e2f8c9468d2bcc649b7cf4b4a408e02ecf62c7b69bf40fa8bd2204296e3778bb945d99063b03c2cd573244d3b3d486efdbb0700cdac8684f437100328eeee0911c64ad2d9db8e556c56add93e86e934094d52f28d228bdfc45eb5517785ba255d4b4df83835913b2546cfcc19eda4087a196fd7add111fae21748235561981cb69c8f9e6fa2e6e3cbac9a798b9dd6ea7b862eb07d3eb51357d39c37ad892df37395c723fe3b889fed7578c832f08a537a9229d228b9bd51654f807b2e2e2b34525230d217b372c1d865deaba40cf6565e2977e8b72377f550ac9facd3e8f5e05327dbb42fe3d4c53147151690ec1f4b6fd267443a4fcf229db6c0215220353060104942bb6090e59058f17322edbe1c1316e7e4af1417b453bfc55a068d19fdcc5f4c42282f74d12eda1d11ec040a53090f088a2eea0322ef0a6b85f683a436ad4a699fb81db55cff4702a2fb9a5c9ce59b0cae60df91baeef5dd5ac01f17b1410b5cddc18c32650109e11716e0eebacbc1bb8f85776533ce2a55217a6f87442f233253f8fecd4886781855e1af1fb8b6167dc7f5d2f7e2bb1e86241a99b2fd9050d2b7977b88451286f860db72e266e0cbe555fbe926d1c642cc04c4bedc7c324779a340b19777bd0654b44822e1f2292fd6d1916196622d7f817870b6e9d72d19bda5e6563657ac6d45fb88ed4e552ee16f43775268be939ca6cc8dce75bbcd176412d8b9b9f6763c1df4918246f850df21230514096883c97953d989aeea8f0201dd2639b3abfc78348ed56e91bb8a9f4faabef4b2aa56aa9f8596cf742c2fc2b4c549bb00881bc01a6ea82e198b4564f9cfe4f7d836de95fe6d259b2db3c31ab90539b14c51c6adeed538fdeaeac799151592e12f5735311bdf00f0f075be5af61058d3e93a14f9c414affdd5f56ec6db218de371a2bd8f92ba16cf72e1adbd5d2812e057f86b2e17286bbca3c8aeaeae8553913b67a05654964be268d6e47aa39bba6361d5fcc81834077d4e1bfb8efa93e5f2a89f8df52f6ff3ee3bc5f5c93836b6f625b0e871a914377bc7dd455f41fe1c619925abd932bb3dc10190044624e23b54d0550856ea35e3a49ecf967cc26298e22650224a995ce7b1770358e6edb5a63cde6d0e14d54b789a0e9e764413f4465a1faf1801cdc0e87428d9023cfbf4669dfb60e887036229b19d3ee5c08c94d487e180ea4402603941acac60d7283e4a6e3b7978d11ffc9d27ae434973211cdabbe6d0076ca3bb0b4d5b1181e2f183c47762ad0ef6fe68db8d4d690a5d93e47818933441a35f835982e6fc7672c4f8d1c59ea54d65bb2d05ebf7569d4d0ef250f1a1bca0b9c868aa7aa10da0996f8507e78216afc8a8dca34298a480166a02bf0c99a8fbef858442a49d788753d763ccc8a320bce945648e32d5ba5e813edcd420f018e40ad62cdc856587f63ae032a2e9861b5060254ea569358652a2d832a6a93f1cd3a69a9d909dbbb6be6fa5395111631dd7638442b32c158c71a6c42fb3fbad46a861a1bcdd16cd6b4d9af28721a4e4ca89632b5226d26e5f54c2c067f934cf1ba2e11140ff187d4c41bc325f21795b94d076910999ffd7320d9cb691a4eede92ddcac6f5e50976485503f20a2d5592a49b29dfbd65fde65d31a8a63d478e44533f00140ce2866826b004358451a267cc018cdd3003b649ff79dee3aee78c824ca61027be9a225910dfc3f091a8e0be17f4b2f1aaefe6f72e3fe6ecf4151e2cea9c88d12d4609e6e45e399f8ece3d54845bc5c082e182466c9ffecf8cf202be931bdb873c835e9829fe94bb109beb1010525a0cd39f54767171a5c05fd54e515fd40471454474c59fe6ae8b5fd6d6e3351c76a36343a090e9b7df5691fb2d181e626aa9648b7095a391ddcaf51e0c6b2128403958b38ded6316f4fef4152a5074f078544a97c460fb447f603944fde18cf9ea38f36dcd798f3dfeae1e6b9c5c777154fd6092233a0d39f84d5ef0c56156fdef28509b4341d8ad7e9e1eae7b6eb36d473cfefb880e8ee9c4170e2e955c601001975480dc7383095ef7ac9624ac4c008330e6496186f41e10c8f5c825d60f81c977768a3e772c474f263823783ad9882b97ebf4080246d5825b21a98fc97af665f2f0dc9e4356a36f25d941fc86b920d7b2df8f46eb2a260103b3b87e97a7e86b9b00fdd4dedbac99a20b2019cd4e0a3d50f754c967ef329b1447789c3c67cecf1a48e29c4661a106638100a02b713d5085ff3188605d3660f3283537cbe242a0904da7125d511dc58063bbb4be8531a486730f1525e9208f4410615969825bdcfab5b48cbe8517620de69cf7adfc9f1393415da011d04206e6da8bd66b85fed7d4fcc282a841080cadf4da59e578d4b0bbd1dc92fc6bb33868091e029282c9dbe39e432eca597d0a4aa37611eca548d6a8d8e8fc556e511ece9ff747e89b884a1107ce7b4a8bf7df25926fec7528122d1e76e699382b129b1d692e4e50700a6a1755a171a08e8226140e6a0ff8cf3e6d615cc19e54e9faf0f02acd53d55fffe153d53561b1da15c09ef5330d5ec90fe80b11118cbe3113ca48a9a72611a666da4c89772a492b6ceca226679beadff81eeeb7d10425e39f21da60f0898af7aa48bee172e1cb0fbb12ee27757a4f771f6fc84bc4df1534c076a7b83153fe5b86938df362b840bdf1a11b679118f1cd874b69b44a309d371a6dcd9745897aa5b950040751a8faebeb11dac45e56e617564011d6231d50280fc535e5ba7d80c48ae635d61f4e22a2738af394d3611f777c7e042ad8646bb8f3658e2bdd5152e61bbc1ae95cb421c9e0d418cb7935ea2b7a0ecf12a99617dd534c5ff52ba074316128b3d7c3fead1ec6dba49a18296789e8417299f4899d503192fb557c1d05c27ea6379a2225189b7790abdf5eb9c83ac5c4bc931ea12ed3dfe14c32020c925ffa527ab2c7c7cb37c32c52f5953d7f76e15887b95d59bcf646c209bdd83e8d6e2e88dfca312dc4d814269bfd5157d647a54f19dab4b35131f8264ba627bef5b45c4086c7a42b3e8260fada378d2a4417a004fd921dea60d32650f7d45ef6b045a031388b3fd62b346c6edb6384e71a2d71524e228dae80281e464684b0353d1d0e1050c9196bd55c4c4969e0c03f271aac5bb56b2dbc16b1b1f98bb0afb78bb2e215b8291e1cc15e64d43805ac2aa58b06982d4af4f0e9642e397d8512daa776279b0ae98e9b41e4a04e26c13290eb0df88cc3cb7120de5ea9fe53cff3755b77b64573300570e89211f398faf542c497e0a43eb06b666a218ed0cae8939486941e3f8e482bfd67f2dc0bd065770d52cbc7903575bdb0d795067425bdcf90c8c69a8525878d6e4cf64e4fc3545b306f4ccdfcffaa5eb67957850e7ee27f47f91e98ebae00d892d396a4639f0aee7fdbb4f55291ce25fcd45e937220bfa5aad49adc6bd52dca70552d39c0b5665c9f8258b62d0e385f5c1575c3be12f5285579bc0e37f2996ff3f9cf45d4a34fb81bd7f38b801e7f026bfc785b292447ca889de9cefb3bc353414b8d738200e164da9d4716d220bc771ccf6f9f6502d579e57d1a37b8c7124dc100704c3a211a0511011012a2e329fb70576c289b90daeadcd7d92e37d3919c664f46eed87983b48d05833b37a6775ae3cd4713149095db111551230d72bad1c6844d1d6622508766123e8756bc1c392c13bb1ffa2f93f866bac7a25052ce6c7420e04e83c62f65deba0e7d3e8c6c720f18db27543967a3c4eadab4bdda514a8cd8e29586b6b4afcc53cb47d26b8df9b7e7bbff3eabfb54cf9e2d60ad5f434e53d4ba5e3eee8cfde0983c25198e86d4bb57be529f023788305b59185624be443718fd086af516d184fece32d55182a7a11ec115d5fea4c104dacfcbec2e4324de5888cd1d671c2b7e27374fd3d7082bb4c95f5d6ad11595ef424fe9b25fd1dc073f5c192d0085c8b805fc503b1a46a50e7c5398b59328637b75f27b5e73b586c0224ed544b2cb205f2e3b06a73d0a76ee8c69015586bb4499f0e48fea6111405dfe656d42a05c54ce6d584974a102c5aa48229eb651dda055d190618e552f64fa05d9782fb5ac07841947ef2d615139d37d5aa4cee3ecfaff074e76460ecbd8b320ee8dc1099db25fe934fefae688e4519fa626bed100153bb3cee59c37a110e8f1d035dafcb847da3c282d69758d2eb77de7b30f5bc34b8d09348fe44f29e7d7bb7640fb5a35bd10e35e284cf1f5b481766e3ba3d873f4108bbc904b86e0c47e72cbb3e0a6fde898be24cfb6b9db1d7eeccc0f920f82af1da5107dd5927170622f02840dc21bb79821698752362b42e2c1b04f38da18f8cf1cf3bc5eb350a76878dc49605757006be693eb13dcaaa0469a9e7a9a502a4a2e83b9c0cdc646b122930d5b79e50fe855499a3f902b651f09e4c6e4c8b936c64bfd2a77d6d71ed3863b0d1696fe9e81902fb036fe24c034970df777653c241ff16f873fa89865864233fa25c192fb9a6ba2de63cd1654e11e021ab0674974a0ee24c41f7cb2d9805b42446ce6e911f26de958f233cb0719511f6a75c2c8f071bf08f6a5562015df86ecc9d8f1cec1a8582912eff19860feb1c6b6af51492cb21a793e7ecb89a83167ed8e83e86e49ff419f10d4480f1701d2ab967f6cc44850d8e09d949b7ee470563ea6d8b349074c51fe2f040a11b553bf46b803ee6df138bc6fb52294f3043194a32af5ff0aaa62f3224a3f110421c3967920caf74703b14a0efa9264c0b239c8ec82fc9d0c06698d7e6935f3aa599f57483966b821482618e878f94c218ffdee30399691dab31b4d9320934e493c232f533b879b8feed663817a7d6930b61286d2fa32c8b2b0ae925d143ba0622ac08bda70b37255e6f0192cbedd13d95bf43eaa67d18a440086caa3c80ba2ac88b92f1c8784f967551410629731aec39ffdf42f59bcc9e3b7b88553f6f7b777f3a6d39dc000d59c87b58cdea27cf86e0d04cf77f778bfd540e945085bac61f8ef95e3426496ab2887f979da03db104e9a72df0ffc78077d8f161180757adf4dbb08a1927d916177923c93c18d622919cbc198e3b9e28c4ee25c1a597483d956e416be6264a53efcbc10b8c6db2932b4577ce3a52b3a6247b8f045daf82955958c288090070514b08b0d777de6c7e8b4133c6a343558b8271060c8b8703b1137029cec8d0395edce01a06ab9c76fe51eecafc664d2aba937f844f76efb8991c6f407902c9b1dcf1a08889c68340881ae65bc86a34dcf74742acff194fd1e6cbcf78760bcee5f8107ed3c520cb2f40d156eed318e7e5f18b4411fcfbb9c4b1a10c2fe82f1a41a21a201dbd54d1d1b615f4e5d1b379540d8133a74d372d9daf61532e8db63730986e78263f342240b90448798552cddf7d0c0e090a1b270e4ad31e3084eeb35d4bf5e62fb3ea69f5e77c63e87de76af9969442649520124fd43047e51e981122e8d322530eae345f7a200dcdd991573db8b9a306484a56220831ae01640a88e9ab7a4a59ba5e355fa6939461f7119c73a99526d03dc50e90a0cd54d4ee1e236c6dac443af657c474b34032e0cc198a86cbd347fed098aacf3a7da4c0e77eb2c42da8ab95885ee089d275f91d4cb24d05864319cd875dea5099b7b9418b8973a2062a94abcb34668a7a771bb143ce362b0e8a14d29f623d61af3f148203b84e6288d078544ab2e6a33d92003c993e1049078fb3f5432f2ee32ad309c3d407dbe617916d65abba4f52cfb1bc76a2ec032af133827b05fd3948afbb5ff82b7919832e1ff9a041e1cefd3a215fec440766affeec8d513fccf67adb50be33947b8c11bc9c911b699111fe07e137cb98ec33a077b857298731b37b7f1e578ae508465e972b14b2aaa39aa3014a087cac6209c29afdbd138c5a8c2e4baaec1bcfe75a53d35ade3c3b080417a78840828a9b8f75348c88bc92442a4406376d82a8411805c38a11d00aa9545535ed26444b6704c0a6ff397dc78873bb69cdb980b453c3d22ef9ce2eb1c8e8b951a0f762798a5c79b517bc340a4de8c9bcba651f676d590b93ba5e0f9b9442c65e8bb710cf9d6344ff8a803e9755b62f0daade95ebdd73a6db5bf1353933c5a88f20f9fd5edf591a6f2ccdd1f90c036375661cb8867f810922ee3b95471c18a53b1b3fe1df3dcb2c1de4753a4d25b883fe196d3958ad3ac2b9a783518f25557251299c63d6e6d774aacfb91a360d19f7edd71cc8253f7429149fb489d5004c63148552d8674effb9c6a6291aae7bda955f8970631191879757faad42e5fa8d547a30430f1d9a4d43afbbd502414be85b42c823a4417303b6d3d156163bd0daf8c0caca20ea56e1132f8f94467954d6ab220e9d71431961054a0ee328a131dc1b56fc1675ff3a34da12b9aaf55e8a5d9cb1b5afc3e8537e972617a3b7aa831bfd237f923d8a21de9526e421eea663def11cb8b4a169b80d4a2e66d4d0ab54c6c8fa0f71229fb0ae860bdd418d42e9183c68351b1f65b18b092ec45dbbd1c765b5fb103b79ab231e4fe873884bd7ab90e9870fc212d6213e0284953b234de83ad854d9c7329be30291964f0234231c0770d34e41e48106501360348da9858cfd14b3dda84641b4e0e5f783b6b875a38452b0564b8ea5c93a99ed1035338986b7ce4520d151fbaad7f7cf74bcfcbd436f2b7c01428cfdfbf367d0d3ee4f499aa40e86db42e5d46b2c8f938add44c46d978e8df6c8bd075005517d2cd22d3fceb8e55de4397ffe27f747e6797ccea7f627d5e41ab4e3c9d5af14b3180195311e4a9340a06ce5344ee5f7edf271b493b560ff85b44fd5f792df1cf36401930b2fdab08bed2767062e3b0d154baf32d24168e0bc726e5b668a3e9ad6e30bfee67fd09119d833ba8ab0b7c25acf3db8a6ba06fe75395117efc5f5f48f6203c4d9eae6f59ffa6b1a3e194861c5ef57d5dad6fe19558ec7038c2d6bf66962e258820f275f9bd102900f15f863ef252d584298c3ab08bc00615e28aced3ed65334a2d2b78cb688cffb4609fdefd31ea5ef2d81b589b25d814eaace7f94a29355a3171bf0bd2afddb43e87b1ff840d07af655a088da068a9fdf0d13dfcdbd36c3236bc9ca15c326aadf19ebcdc7886edd491fafc7eb41ca04e4a1904b851225fef68517207558f3d7e1eda929560308b54f2d5063b19a810ec13d3f999c734fae71eeaf859b69cab059de2fae725e861451130f8d6dbcede65a10525b237bef2b5af566b737964f40fdf6ac47c2c9a10441a2be4aa40bfed6a52f80ae5bdec8d889f78a9939dcca00a92a7dfde82833e5f03d21f2c16036f4a9d0c05d6b6501a6189033d6f7671f09049800836d541a4f88cdb1c247b10e96323cb65e83b1eb582e7103ba6d8f124e62614d08dcf5407fe764bc2a59d55f641252e2aa0cf77d7811b24a77b280659f64e0723a1af0ec44082d88cad3a36c04fc6e9acb969f5a758c039795dd445b493adf44406d892af090541b443abb1e96117a7093e70a35aecfa2b4010f0edc21215dfc2acea8cf71e44de1ee5bde8e6fa4f370b401454ef1e474c80409bd407f39cd10cfe94a78ce687a8b81b5256f3a233dba26cfe9e0688facd6e9d9fd723d50adb30b001210d4e55e3997ce8497ebade5bc23197767a99f69048bf62928a8a84446623c708dae8e0f0d4bf93e639dc01dccafa87795a700d8e0e3f6ad5c3a09eebc47f35d88c86e0b5a6df896d2a6f0e121e24a68539f22cc50d5bae5f4ce1058cb8ef923ec8813022f291914d6ec98c3f033cffe5f5c37498cd1b715736222364582a4aefffcbebf709218dcb1fcab9d4361c66f4152fd809b82daed4f060e4838e2535a4afb8ea0f1259ab3a5cb13ac4036bcf3eaa7efd6674a19bcb45c7dc838c6b6e5c5a4088cb4b0567bfe2a6e3e98bde1824c88258432b13f0a6866e0252d5bc759a6f418615f5850f8bd04ad98d6c66c081c801ab14f696ec456f0fc757d4b2b5879197e264f93d97c3c0d1daf2acb157935dde66a56d26054afcdbe8dc8aac2d256c9e276f65a9793a0651684e44e9a4b764ec932698ebf86e4c4e8efae64afbf8b326bbfdbd20cacf57adf20d0a498292f63e67d72dc2a1446ad1899635eb052ab0626c3f5d622454a21f598ddf07b8365175eb6c13cb3845a150db40f3d241b4de64593ec1ea6bce1dcd04e9f8fcec76d96a99a74656203f825f663b4c4d44d1e32e8901bfde73eb96733b9127ab6c90348cc5627717e9b6245b8d8ebd1b422453b9cf6ede8d9b8356c36020ff1ea413c256f62ef1e401a21fbe04b717054a9720d3db6f71e78de4293bd2535108461a872411201cdb71f1dac490e37628fb9094b81b0e5c0a97ee9ab6a9f0887172f40b2cd8a730016626903ce0905aa859a85c6da017a37483be11c1698fda97085439753632db1c08f72ba2a9835f55cf535831c5341fd14896391649ee31ffc3b1f81d18f97b232d1c601f826a2c36fc6325c16e350c09eddd171dbf3d10a5492b5451a7ad2d231abfdf9471708b54ec094422e1c1500e8d70a88422389cb79198f76d7bdd4c284cb77cce93b71e148ea05d7ef4e755d696b34b134deb5bdef4df28dae387766515f3880daa642c9385eb20a346d65fdbfe889949c6a2d68b04092ae907ffe47164de3f40e96bdd6bd6401ed39088d33140ff21e691637b9432973d1d8ed2430887b22d2a9e7c4c846cc998a5e8f3f79e3aa019499075460b113eb1ddcac177530de078ecb01596567a9960bbd4e86fd6322e1accb67272e400868dff235aae30446df70797d1f1ce1ea3012b3e9e1a6d7c596dc89797bee387a876927f03f4495debc504dd2a2beba1ed80f2c71b1d61da25d15d506dff655cae18d9a4a0ac8d34d4f2175b3e62c3737cc85a082752bc1df34f1d718960a77cbf4bde3a873e1f23df22d36ec91e5e2f507603997e013dc7473f7693f3997d97120ee27939bb6d8de1e9e5b5b1b2628550207fa2d7acf182eb05e9c19d31397db4b050225a038bae6603f4dcfdf8f60e3ad3a446a8ecbd99da279215f378e03e53662e428f90ff8d36d29f44b861c58637466f834db4017040260db3d10d5edfa10466f730c200157f9f815c73108dd81365a7f35aed4f4313c0234b7ef7174158aa3c88d73b4228f6b95ac358373d6d82c2ffcfa78181585d0c0b8bdc2c339e8c34a6eada6b99d2347bdcba737180cd96708ca032cdb96a340381085cd127e8700f6e470969586c02f3f3111d2e6991ddc814b6c38553c61bbb1552f3ccc7461cfee4f57ca006fb1bdc9f5bcbaf2377ee3a661b087fcaf0b0313d4c3114884fe832c907a3a0a0cb46d499a5a00d8b4c5bef42bd8042cd9ae17b903c46cc9fc5cdb4d4cd809fc5821f58715a99feba05e945a386761674368513177b6f2dd74aa1016003d09be51aa3412a55964290e3d6b8b553f1f45e29f40391d4d99a9befcf9e4ae5cb9eb4934e4337f56dc6be12946dd1205c0d44cc4c64783709c1659101473c7996facee5b8cb8fb1f209e692c195bfabf760d435cecbdd3068d5673349ebab21a683d841318fe70e95fbbf67e7080f396fb940b4952d086830286d3adbe55b861be9895041e3c6dd6c6faecb4bf83b818e7a183fd17ebb3a5f66c5aec876bc8f08c85ff2c6ef6886049f0d10e5cfcd94189ac5b9443ee227226dd07dc4ca43dfa266fb390bab69f725a8bc7012ec338a09625c95fc1d07f7b08cb1def0103eeffa618e2265b1a00a6298d20da44479b8e4dbb68780ca6f58c073653e6a58a0baf576d59402c616af8961fb2f3fc21b49fe3ff758aa7a07d1b39ebe1d0cc41cb1436cf8b5c6af9459e14b86c1e7239f6cbc81ccb135d33e9cd705da80f970c735f88d60d45a369c9a9f711d308499f0f470671227f17bcb38d249fcc5949b8f3ebd5f8d46e962975b6c4228b26cb73c6bb6a7e7ec43854c4f50fb816c56e4b6669e6cb9962951cbe6b98e49ce72a026b6648abaf5d6e036abb55dbfad0cdd11060dee9de200c05387bf8a912a07605e7099fb40ed71bf65c1a5be23f4f4642635a8917a964e77b6938e6c56eff8e59ec624105737a465c840569c89fcd4b51b650e6d1739df7307020bf4b9ba48253ff922af8a01e7a860fe684429aeec8d4047ffb60b93320c8ca106cf658608328cdba37ee70387ce7de8b3683e337fc5486a79b64c659cf0d4c071d61966c8a1bdfa0a62c1d768d99d62bf8191f22b22be1589a25b35c3688db81518990719134ff47b751dae2aaadde612dad0d9f871be5d798af612e56efe724db28bf9616036f3ff95e9d5b4f3b2bebd27b5b77f6ff33494d19b96c644246e7b204061700a5552b91ef663feaae3db1b61c7c0a2de0c022c89886a99b4bac9ef66793b3b56e079cfce149a41883d11fc301f83c8ab562b1fcd00e1255b23873d6cf3e9ceb83d3f65fbe00238b0da7011cc7cdc39566ba4021ebf5a19d73bf7cde2e29a67cf5a5d6955150989286a8d34d9648ad690843d805b120292515909637c5bddc91157a1ff81bf06fd50722573a88f923156c22173cf6db245537a47734cb83e263a1b4cb28fbcdcc0fe173e3bdd7b562d792b1e89917ba5fec3d7e0980edaa998112e5b8c1ecc6c832183c38212f38106f8519185b46cc26a64d02241eb640a36e1a14bb549b7e61fd7a1e65f7cf212306d146b3649f29d3e10bccfa67cc335c5d5f8c64a9fb49955c115a2833338370c27cc45849d0eb3049c2383e947faf50176e4fecffb70536bd343694b810544f93d4337a16d81aa15312efab9d868dd2791e3edbe6f5873836e18341ac54d14d36d861b83fda4dce135efec79bfd3a7113053599e8771960bd1691cbbb8e3baa0541bc04694f062bb69819fc9f876773a0913f3733460f9bd4e6f90ffdab821423b739952011541d47b18ff8469bb0021ab72ea4be4a7fd9fb145f309a2d84eab666a54243dc1e5a472b8446591a57c9bee9ac324a24a4703cad475e08039f58fff950306e4a1b112bf58f57752bb7aa461c70636fbe125b217e17fd9aa9f8b5a39517ebda9e6f0505d66001fd15648ce4e94d1e1a3e0e72c18c1ce8cf160b1e9befdd2efe41e998003a4b295abcacba5eee3483a32d1a965e95b6ed59f27e4bfbb34c25695953d178fe393231902f9601c5c67dd8d7191b9b4bec7127cbb4e5ed5f49f41e6fcb5710f1cf0ec556027fc22551c2068183f6e8e6835c91484f3fe2beb24cdea2f05ea25cfc56c22f673b63b6b9ce327585dc6f18538420f82895fc78e6a61bb49e576d15e81b222643164b54981380f68b67352a73e84281095f86aa75ba907a9927bd3e2c08337717f696e5169f9e70dfda9b020f3889f7b767e66bf874f1d5129a865b3388113e12d62700161748a84183b90ca06272553b9fcb52b9a42cd27e7f010c9776013d9e4715f69fc859bb9fd1b8d13f064754251ddc04902431e50ee39391eccbe9257b8a728f25c850d626d65bb96327b2a123280aa564dfe7a2731b0b044e7263c08d0ac3a32e98bcfbace7432b2075b9a0d42f3ee6dbd6e75db60dda26288eb2d231718f9777d65d3ad285e54df682c8821dc7f0bbe9705cafd0c4341e2dac75b068c13489a547b9e44c03acf68ea07e024882237ec0f926522bd0d4103c4dd0e7fb177ee61d9e212229feab359b3d6a0ef46f79b9223343f241bc98c096b6e2f934ca7d108013b09fb6e6946fab71a0322aaf4745998c439dbbe7b1da4387307443cf33d09444b5b3678bc526eecf2e8f1ffbf2297948ac5ebfc448a3c8493e206f36b98956a106ad26bcbac986ad9aacc8970cc9f76115d6ee258cbe0d1317f1f6e8ca70f29243d0b9830773aa81a0f5b8debaa81e231fcb9939ff3fd8d3da0d6dd95709e72e7c83d16b7d213941f6ff873177d2977f57195e97db19412b4692c369d190d0bc19053c96655386adef489a0beef9897412d15d387d68f0fc7787847c6431a82c665a80d72f00dcd7f88afb59b9c7bec16a1ea38b0bb1f8c74d6b6bd6b4a3ac7a8a1518ba8ee238741099576ade4909b4842e60209393f052f2480dca373477efb7feba32ac53a056d29809482285d69fa1fe262d5f2c32d447c703372f2f613133eb0a9343075bb3ba1bca32fa4e853c7f571e3148fb165d43ed3ce5ecca61066e4d033581cc527dfb65c2383ae326a7c8fa513d018a52b36c31b3420e51041146e9cb427fe46b18b1c8dd6dcb4faccf315020cb5470e7dcbb6799f2949cc0f7fa38d0ae79951bd16082410799112c28f30dc9e510b848ec23cb8f591f5b40e41bc8146757c797f9997c506ff2ad1670ebe80a096234f022bb4df25ab1e228aa82958c3b5302be32f4507913f0e6f99ec93a6375d8b120359c3b63ccdbd0d60f2114924b192e370f0f32bc14d6d3a963232b0272ec62c2e7467bfe4fd57c17875023cf455553139647c041c8cf256c729cc2b34bf1021214e5edd5adf78530a3781d2d9145a39e57c3e04ac10f49a6e4b30a57d2509134c6c17819b443771ff02b49c607a96dee68863896a2e7a0ad4ac14ca348fbc80ca4fd9c759ea27f9ccbfb515f1572e03d62dfe84df4da43e641a96a4d120a9c6c42e6a360134f941680a91ada9dd50bcc3d6183cc4bf63e2b4e8fba4eecddf9957e660122fcbefadf3c139bf51b698b95187da412b2298f2adc0d7eeb5ef65e6989ce2c39321a2c0a0a18f16784dcc7877f1baacbbd5d31c20c00be2f779c058fda273a1406751bde1e06bd6ad7c47f732da2d4e5f9fd4eadf53da786909400bd8e682d11f8421f1b1522f96ee5245be1c2bc23177305d6b4c887bdf5672f7bbf8f6d5161ff9f3cd695b886c65e5e7a658c3946f0a01154fe1ce42e8c654b98d41cab2ad7354ba4f768b00d2c0f1b94131e6fd9a856aff6de0487e75896db2f845d54f1d8158ac1f3217a0b32463790f167f946646e488eb31292ce5e3dfb72766358c4ccced6fa8bbc2b081ed87f7ba314291f1ee4956cb18117c7667d11385560cace872eb4104e6365d23ba9c1dbb49fc54c6cd51b275d53606381b794bec89bf75fa977c6f128224954b68dabfe02a4ed2043c56ec4fdb25b93d39f85ee7cd23f66328fce7d8e10df277319a3ee10a15c42e3002d0bf7e46026613dcfd43c2ff61c23109207aebd529ab15591f800eab0047e8e968adcb465f16f2fbe96483d803fab2b780b93afbf62657a3464c682907100fa61a97b0160c7bef959e5acf2407c5ae423680dc7c0ffc3be1b1e39699643ac6fffc2bae45c5264e818facdd11536759b4b2006372e215bf45e1de5a7dbe43bb864917b1968c06532cc63fb703854becb8c3b17abc25301cc6693ea5c022c3bde85242acce9f2afd6d1cd456077293bd182dfe4bd56be76e34c8f9e44595923b319eead6c6d795fed697d18709ca7509c4fbe78ca3654caeade39e770d0c11e4bcdcfe6cfd6de7eeddf29e9054b0d2dee2b46ac91817ebe53a4ef0291d37e73b14e1c3c0df5e1e1adda94fc6b5dde1eeded5e06a8a5a2aaa31ac962081db463e6be60d7f891c845154e1d75c5ee974dbea4ef6a66fc215dfe7d9849d4ea6f27f7ba5df7ef4d67a3024fd3d64dcc222d773938546a19283c7de1bdc9b37bccf2266569a2c03049dcb63978d401b9d4ee881d457f8226d06b2b1edd58b0e8c65943139c89ce74f550293b2ce6d9a632748d1b303a837c7b109f05fa379ff5dbfc66662f632c0a0a97dd85079098a7e1e821c76cfe81bf958cb8539b36344de5e66cdb890bc524baf74e10132d9c4526cb370f1c9329ac0ea530ce1be144aaf820521c9ed362322f95c1c7e7da710bc2b01c3019b8d333884818804077798df956a1cb254395fc28ba7e9108d28823e8f63a46071ca4f82dce9b3624cc6bd8543d864cb64ef7ef20f4edcf530164231494f77444b7820c3a55a565424facaa9d7c848c0d187610fb529807c04a0a37fdfb93682b3d3863867fc8c4668a8b8e869925ca759c6c759af3e12776b9e339ff4edfd7339f1e9b023e95900713aed458ea4bc4879b1dec5d6a089838958f4a3fc9a5d2d793bd00c888e547c442144860fa3583407072582e06d4628b7898b519d16d382715935731962ef9df2a9b55844c360dbf0be6b64dc7f7c0d1a5760861f13c0d48dd9fc716ecec0e4b32884cbabfc741dd58163007802fbc011393d05aa4d8ac2cfcf1edbeb42543a4d8ce921ec7797094c652b64411f80d9bfcd155ff1300a96dd1cf563121bd8e66eb0be641904fe65c61e25f25a36c086ccca540c06709684f3224e85967d8757918ef65a073008b1370221e3e71df94cfe8a39c41fc4138b1ea25e1bde1a84a99be0b9e90305a30f1e8dca5dcd846fa9fa23a8a0c3bdebbd98386b0905ab868c4b794ddb6b70e9e996029d1fa2997655efd3a5c7e0baaa75ec8bbf2ac0c6b7c5a55829062743390d39497158dd94cfff65ab5a3c0894e0f8177304232206960908bfc9ced3e874a43d790070b25ecbad61ba5de7e54931b5a67ceef775454cc557f052ed08acd60b39c999ba19bbbad71b95087250d3384df5c33f9cd967f684e6f815659444845f7aa866474d691bf55d06466188d022a34a2e2b76bccb67cba9fe01b3d41d3b263daf674af50e9c610fa404988bd772dc66415e200774d955997fa0dc71ebc9f709744dd4d9af29d1c729f12b5dfdebd932a0d6578e307ba6bd8fb8800ce5719ca169f09dd10b1ed5eaa9a0cc04cbc09b65e989b02acb58176b160705d34c7756f991b0e9761ae226df8202a4d87edf4ca5c150e68356b12efc43fe6d3dcb1a71cbae815202e78160e1fa3db9c94f0e6ceba57a04b9819ba54d509d292ef022736410d513fe416be9324ee0e732b7306765175bab734f4b9c6b21ef5528ed389be5d83119dd09fd2cfcba6ea71f1b9cca34c7589d41ea18e2cb99d85c66abef6462d712bce52480dadddf02f9bd9729133c19448f9f2949158e06775b18b3c6cd087d8eef8c10d762aa02c1101e268ddd14316de6ed89dfd358e68e764504b59381c78e16c7f6c62c8ecd1815248718fef3b643c2e35c37b5683ce696ae9e4ca605375ef5c71b84767ac9e316d4686037f0097e603fe940fd8e7c79681dae95ffb6fc142e9870ca89cbf0a6aac3bc8478acbf4fd6deecc26233d1c61777bf789224e0a4ee27effb6bb7851be7bfe6cec3e6e68b07f0311ae5e4278382979a3924138335470b71027c6ce8fce468d099e663333222ec850b1c27c62e477e1c63053a6493b2e6bc3c284fc4f168f7d8a37962de4493fa9c9f0db02bff3602e211c62581e4b734a2d43f98fbe9f9b4ed0acef4d78c6acaec5cc8d97e769de2c3907f9346d473b13ac78e3b20a843c16e755368a74429b551d668c0369db055dc025274a513d68af7b246651647285268cfee251922676c9ebeb517097dda1c467ba0e6033063a362352f55b2a4799ef1809ff2b36e94e718e15abf42b49536bde8c7327b818beeb0658b58a25417a0b6b337078b84b04962391e31d41eec60be575943279a3bffe51845d9eb739724bd7ca0ec7616852996d78019ece51bad284d66fc27d426e7630874d86c1c44024862524c55176d5abfc1ea7bcdd345e0dbe00db33325c8fb2c294a8f47c4567a1ab087c85435f58cb4624a459470a73f7a075222f82a8a76c31cb43e1f62f38a98c7405ac54f262753ebba56fbcfabc649458055d23c4f57bc2581173cb28038fb7b05ecdc2d8b4e229ab37f1f4ee7199575d7cfb36b11567b83759fab16457973b554aae65784f9ee277603c270c5739bc5c82801ab80d9b8dda8467a5a7df5ecafa8a20756a6cabebb8aed79747ab45a5498f7c2a4933673c5c359dcc321b4f47fc396033660076e30b036812766f78e1d50d8f8a3bd51f7c73276626a6811a7d1c867920124d084a74bb92bda45e7875a1afd0831862b6d26331b1e71f623b0ee93b97fd2ac649c76f769ce6cd44955088caa7c70c15bd33e7e206cf3e170aa58691cfafc16cc48fb9ce15b11467676c806b04d3e148a846eceeeb09c54d6fca37ec12f4b754cada464f837188001d2904899f83fa63389d1c37abc19813a9cbaa480c3a54b7c1174694563c2346d63704dd9387965b90da1ceb0bfb812248b5789bdcc31a1938afd95c623d21a93596c59548ebdb3e25129ed61b01361c7209ee52ed6d73df68ad5a0fccf186d6ba94c12821d1d17b30537ff8b028f6b39d691f8164cfa8a7786c7aeeb028734bb39d9456c20c800aafb49cc49e482bd569238dd946350d91a68789dded6645a78684012093ada5f63987ce498234fdd338ee09c4ff1a8e9e4eba938881695fc859f9b138c0b1a068bcf2f898de26b45a5f980e1cb3cacae0969b81f155ff7fd566367452dc6c15c529508fb6700e35e3bffd101302aabd493c7c88e981927bd5c3872ac8637dfa4333c7032ae9d2748d24c579074022f9e88775bec461ab4170906862d2cd710a2a0e25d48a25a38ce19e6976a9f5917a9f3aacef09fd206b6a1458091d3ac0ed530266478dd4727ac9196936e94ec8c21db526356b406fa549e8c592cd72bbbc94a51a6e61ca49781590bb33dcfa5eaf1edd900bf6f62c317bbf939e671767d5da3d4016449d1764e4b2b6812a68ed4d8f4eddb02c389da855f6a1423f2b0efed838513c09e1086caf4e8e7eea1ec99de7a5c0d7fff856b214720cd6a33b0bf2eeae977c1c0401e56590133a8e3dc79e570cd95f6395b0b25c25cb90d89b0ef59f6d1d0e1787982fc84ed8790b70d87f3b4ea00108b12031467e24c67b4df665eb7a7496fff99ecd616aede0d58e784902fcfa207229c1301c9fbed9a7001a25549e88e06899d12a928b9a2112402f28ed69ee9e2297e2b176f6f89b695e46596bf322839c204df0e71575239f0213e9e455a16e875e5f90a26f4f4e207c7e130f4dcd78948c7ce134ebfd5695f47e91344ce6c700ed6190fe0a3f81283ffeacfc278210ff6fbc5481ef3cd6caf575cfee232acbf6615a2c8714ded8a1d2ca6c1c625fd5f5b36f09cfbaccd0dd505871648a15318ca5c708ce076f512e6dbaea909b101e7f9338d83eaa310b901c62ec958b4ec616908a1df37262503f457e837d7cb4e6dca7d283106a0d8bd44fee224ff5c690fdd3fa072981f5f26e9e18cc450d275e458a571ace042a12d5580bf0d39340c429dcfbe7723118d4679c1ce2e289c66370df115c01edc0d11a6592e75a8c29ca9e2bc742159477b8c7aa03bc0d088752cf5e37ab4e552c23fc4f4ba5611d4d42237e03f209bebb159b507636f414bb6c3f2e0d6dc31057455034501140e44380c57f4c1af60af2c9364b6caeb33bf498cb089fad2a03f9bb5401788a01657a32b12568be28f43c47355937884d69798db64a367b7804b46fc8dafb708c954569790f812362bb17a939658edf5ec03f930fcba29ff5ab88f5b2665ade23e078ae1b169d48cb7e7757251de5dc57356569e6774359b062d3558571a8821422f3fc5f60cba806be3e36eb50e71d6ddee647b59de0c2eab681e4569444ee84c8eb4add02e8d2a523af23cf51641d0f04c01885c56835ee23395eb53527ade2b5007ab45c5619ca5c51d4c0539e26544ada02436fc922d3eb8005e7bb8c294d32428bb30db6adc340d10baa4905e9a807a207db33a78395ce3ccaa2326e44be1dec45541e6934be936d6a335b70d327d92de1e54faa503cda0cb794452afd85d888c523c39b867099d4061d68fac92aacff2568a7c088626cbd94145f490307cf47170ee7ebfe90937d5805d1d1fffa10b6ba713707c97081a153aac57a4d5699773e3355739b1a0f892f1aea59a666a486eb6f32811bad3e964123e63bc79ac341f7ad6ae773fbf8f5258c6ef46adea958d876602c862aad81be8a8620b1e2b6b85b4a35e5e1f363236aeee31511867bf6717e7f13fcc5b0de7bff24b890c6dc6fd2a21bbff300b2a0aa9f0c3815ecb045b0067e341e690e7d21a435646247571e850f7051d39330866ac50d7c527b6601b20b8169175c69f3ad158c86e59544bd19d24f54b5b26f823251b1d090ef9ec7e8450e6060385faffd7a41047905ff723a2243e08e78b56d6e3421ab5f4dba769afe75cf85a03d41cde97b0d05ab5e003419e08830568507e459dff6043f2ae77334b9223190d8845b3a14c083f8efb5d9f0be951d1c0b25b11a1a24cc85c152ba4d5203bf01ca723b5bf56392a8a4b128ccabaecdebb8ae378a39988a6075de5100db1c34aec04844f6a7a099d45cbbfe66afbb52575f66d333e7d3dab832fbb870497511f9db5283a85de186a798cc94cb905977d41f1e7c8e7f0c2c923a8c2457ae852593713901e052063aca37dc31ecd00ad098f6d116da42f334ada9316fb6eaa942c448dc1f8a9c7dd0c90464f8cd9390e8abf15dbf2bc1f19e700e47e7e1aa96da8b0dad2cd0cf9a58924eaa568249eeffe6dd2c1f1c8b14e85bdae75091aaab84c221f2430f22847ad596753f6fa2fd88922abcbc440ce0655b64f7dbc824b47f45b1083247e2d8b6a02ad7b6128444df728500a80f7c011f249df3e9c126befaccf8e5cf4b4cc2ddf5ee18e8491fbc59c723057babaaee0891444096bf26b1ebff92ccb19ec624d4cd92eecb9e28356e86109417a76cbbf83c3e8d5e7d1acb4502da65ba016afe77446ae432421458c322c17f018e8dd43d9af11a1e4d26369a5c634c9d1227b62c0935650711d0e2eb5cc3a6d64f4d0bf444695142db1e280224ea57079e235513ebdd29144fde64ff9fe129f50b4651507d87a13f8e3a4fa89f5696c629575238f6bd7a87e7933d8a61175db9c181194a23dd801291061bb70cfaac6d8923766e3a923eabe2cfd15563f75db58922817314ac50f569f1a37e291f4582fbad4a708120182a33a2d649e233347db2c5f6400a590ea6daeedb8129f4150739f6cb3605f7ca7f181138be7ea00da9ff7c0811e82160837c53343e171ac922a04d51220b5828229cc7161e9f50284f50ba6ed1941a2b8f77022cc8a6d8766e27da622d5d0b98f07416d08953742f8a4a1aef657462fec4b76db2696fea7c28d4a1657adef3c0cb35d2781677e782cc3a4a3c804e3223cf436964777e75f8977f1c35c58c59dbc50a5d577cfe0e91755e607f3de38de9377ed4fec4769b30573661ce104e1342acbb5e8efb40045e2f962f658d4c3b8518a8e13b0646af89b3d259c941669b8cb0069eade899bd897f070a4f799094bfa264a142d8542d17955d16e0cc6f735915454d4f38840c89ae8496d7c68f5eead84902c96e33799a72fdb642517614eb4814836540146645aca4f2597eab865cee17741da5e2d17d72439ca21f21278fb069cb4bf90df8deb3a4590a6b0754101abd63666741de03b9dad84022e571f8b456d3505fd8f79ef1543521d4af219d4408cf0fe4dd32e9f3c29cd8c9f7f51d6d9fa71723300c92498e130b224a386bd2375fc62e830b8bae3f67c99042fec62aedffa1796ff43e2970666e2bcee60603a2a305df6d5fa327232af530f519b5ed6f76d5f2349a70604b2d368ee4ccec8b5e7c53f24221569a6ff9358ff4d870dcd60a089751df24face964897bcac58da99a691730891f68d1760423bc12b7df74c915ea9b5e29e3895ba7715faa96ac6aa607b549a92215f5067786a5941d641746b13b8a508a037359f4a22d86c4b9f68e718055b7a7e8b0acda2eb52019b981c3bbc88a13c72b38d84f1eead492a398e0f3f654b41c7c91c79c43e51ae96619662790ea8e943c2e28badf33787c2174c4fecdcb314c1c1e7c6c6b2ee1048323f28241174f248d50a1f42f0498ea4a428e9198c48769684ee0e5d068f86b654a0e4ea08b065a093c92894e6286c89b0474f64fc65e1aac9470e5aa022fd01f5c256f57510926808ee0c390affaf7896682e39c32f1570a3fccfc055113beeafbc10cb04a7a3315dad4422e204ef384c13dc8bd01e91d83992ec50bf71bf0b01eb4d6cb495d4aa58083c6861b20779d9760213686902eaf9a2a81a90f6980d45fcdabbc9ec9576ec1d788f09c2cbbeb7942324727e6d2d3070ba56b9f88001a2d3f007bf67f081416378b96b9f50138296bc1a3be342133b94d77117f2b31ae84319fbbf5c7663e9dbd9b04ef845d289a35ada6a10e0522715f98291025bf364f6277d53802e43c3fea86ee8527e1373820bf868ece60a164ff3ca4359eabfca50d8bb9f56168f8c341ec1310918cd059f436c54133061922355e9a7a2d7257820632fe8b9c476e852e453de0cc129220a64c41f3a6610bbdeab84989a7193227c84860b73e4628c038e9e5ca69aa7fee7490077e1fc33a4282794a9d1ddb0a6c4189560d82d5795d3e81e2ee2153358125103a10421f0b218b03dcd1d0eb70e60149dd6eec1678887b8309c1d3ce32ef6e0c66d87c083f57285795461f8eb165be6bd94967bdd4be45b7683a5b9ee32703cd257db1d3e62b8a89c838fcac7083468648dceeadce70d498392cec47e3b1ade31184104aac7c66da01ecb03039165d9ab68759ae0157b67d962809b89f59018f61ec610d472b4221ecea9c7584d41aecfb74058c2da50c3dc6be995e5cf28b862ef269ad0e41fefd8349db39bf992d70532a27586536a7e45ccc870c03311af19dc587d8c29f72fa0664a8da3be5ca023e0ea17d29f0d8729c3bab0c8fcdebb6dc424fa98c4c00aa72d345cb215c27baef1d9904a72b0b7006242cf43e3b89fd21b3d355389a4d78609e68cd6f8e90cac7e95295d242bbbb8bdc26cb925873679b9c518bf29408804b638cb6d01144020541a3c43599154a93e8ba1d265b5cd8b6ae2c1bf98139a0df08f24cfbc099cfe0a6a655a1e37d81d22f259ade4947966c0c4ea541009b23b191e69c37575acfd0be66ae5ba6a3c49db8df3699fa6886500a9cfd91c9236b71bed4715457ac3f8e82253be9640459919a736e8bd3dea5fc6fbb349ffc0290f18ee731dac72b164622cd6c6e7a46a24245361ed46676e2b4402e2477318d2440244b6222d11f55f8caf75384807852c7e2f0f1efa6d31e49627e08ff5793b11d4ad81651df5f1f2354a082a0625d85c75b3c11ee4724ea22266382dc317e8614a809ade935fd0e05165c8c34cc4d7bdfcd924ed3d84be669d85ab7285ae582418d251ac69933490da9668cc6c8d31341d58d9de7b905512d52ba14eecf0191354b44f4a23d9b9c6dfe96bf7bd456ce887bda1c40a808c79a4e395be492ec39edb9ad6b19f282a3f46dc6b60a0edea24c41c1a49e7007b94f3a589ab31ab6a00384b127e0985c2e5f4cd5a049bb30c315127200a1a271635303b3b65ca01385944f88cd1cb39670df685d8378518cc69865efc98716a191c7814ef5098f14847cf8a34ebf54b37a810e400e299c1df80460ec3dcce411dc8f45cbd2cc609caa0899163b0ad5c16c3c9bacbfdab9bc5d316ff68f005b12ef992393dbdb75b74f583a2df105b48e401db0f1aef9b956db75dc7054691b8b83ea55439b01e5d5ecc3791b9fa2a5f319969795b40c4e47319bcf9d88e2792761b5066b03d86181101dd994d662c4e0e2081263d6655bff9701bde3435673ed1a41171f1848050b3f4d1d028ef6a3f34c3ac480a5b8a04ad3425512b8c260e395b959c369e6d717072f10c677389fdc121c141a45e1892a53d1321b5f201e18fea7ead2815e14a7e66f8b33b64b018f7a5b3b7b2cbab0f2067696e23e98b349612c61ee78bca6c337ad1d8ede84fce0d9e641e1b67e963fc02dabbc5838d8fbfa77aeb28d60afd65b18658c5d92be1ebc93b86e520886a82e513698023ada7d0051bbcc9c0841c6e1bc58709c207a6a1e7fa6418d7b5bb6ea4221e7e889c406d7d5c435c7e81cc2498e3e1d695b8bb4b2369ea1c63a3ec8ad319d9d7210d67d6dcc2b200ddfc7190f7c9df1b397541983b95666284e42d0411a1d4560f39699ed48c2195464fb4d8ca0c56a5af3c6b5ec1bfe5fef247f277655925f8c2df84a40bb6adaa6e1ad5f54a70c8e56e6de9765142f0c12e6c2b3f41f9c79d75ac4e7bf75599c8ee21b531d2620c89a3685edaf96bcb6a7dc8b59d666acdf3c9d1b7ee760973ab048a1ef83efe667b0349c1ff32add77d2a86c1f12434964ab30c179dcd25168a67c3af9a5ec48a63166152168010180eafbfaa7b2111ed65eb0469436834586b2d92aefbaf82f9689b3d901181c137fcce292c4fa6c9dc08e09bd4e06821942eda7f1e34466747fc1e86e23ae1115bf666e598f230851bddca126991658dd2b4fa672aaace38cbfbae1e27c6a79d54ecadc5e1d6e7d9744204dd13886b7e3d4fd360bd6595782d93719e5b8035d969059d5abfd66123a0ae46a7eee6a4cf2cc2042b640b846dcade7bcbf0b9b6f08503cb8fefc03cd686cf3b8161e0f463e46f4dfdee3a183bb8076564da348ecd71493a46ef551653c32337acdf9ff6231dadb1cdf2aac667c74c32c68dc015304fc90080e16e12f1d5bb7d2e57251690a08232ae6fd4fc2cdb1d2b9014ad3715ba2edec0b2ca2e46aa302532478e7e84e3ca5f09169b29e3d8f36ccf82a05d69d35a13d6a14576fab4fc0010da8e82062b6997732516b0d5a16cb162e12fdf5c5a65ed3365d75ca1e0ac788947b24dec5e144b134d5fa89e9f1405fd779d84ab87a023ba1897143c5edc28bf3c92e5bf37412a68fc0f260185140580066b6ee88546ba3d17002b0fb40defcd0050e12d6e72f56b447a7b6aafc898d15f09731c448613890b5b108e98aa1bb0bbb640ec40bddc709bd3066a3c158df11ff4a4d20766276b391ef7a37eb248e422acc350e3c1c6f0b5d65f6fdef9d1f6fc22e983d5947a7ca9ed2779f3ae7e66403fa80a961509376e196dbaa8495ef509b76210f9f6cffeb5a8886ca5d25d03d006dc8390f005f06935ff986c4707e85560bbdef71e156e1cd88106687cfe1c4675d8c8d08a69c76850e71861584777279eee9da3978b2fb9361a1a4e7f76856cf808f262278474fd192928c5f150209a121472b8d955cc707cf9e4ce54aef6c9619322ff9aae82071f6d09ccc5db7341e66b5ba44c113bf79ea21a4af7674e687301f5b2d0176fd99d11839ca42547beeaf3fc1649681649a131d36be259d775312ebcdf5d5f59e10becdbc1beb46db92fe8c5fc9d01ae08e91b8d2c79aab2b1076a6edfc1a074a8cd94e45192ef7337f7886713e24b0dd73a8e3580e691d3e1b2461c6e69f60e0af7b5398abd660a3ccbb4b21203012602c0f2a074552a4cb6b75cb444fd499eaa3b6eb1673d78ccc000366abac0cc2f06568ccd030cf3705603bfeac5c1b4f4920bd59e7f887d2a7ccc751b0ef11ec80cb13388c2107014e2d7b3666e158fafecbbcc66ae234ba0b543a270f991e797c70dfa0dd721d2f6ff83e47eb994bc30763494f4bfb0b24b9fae992d146d084a2f508e25e39df1b2fd047a71beef37cb77eae11ba914fecd78bd928901d182d5c8f486b0a5770a2512dacab9ee70ef36792f700a847c0e744586fc3eb628dbba87e6835ba381ced84ae94f590fc3abc88df50e79c18a185699f58e1f757a8507ef63b789a81ff76202fb8ac242c33b77abaa71dcd346e47afbbe02d930bb299b276a8ad30180637fa1e818da1696e2aa1c651bd5203650b948f3b37224eb0e0789e6eff06270d5be3a76575ff47f1327077ee481ecfb34435d6c35a5ccc2e460bbac84bb2513d04ffa47bd218d1560db59cbba9362a7ab2b84b6b2e684a6e17d13a8c09c8b36e6a329d0b0a1070abab513906982f39c0e002e912f8bacb0a37d8410e9f3be972abe385859ce242989a7baf04ae246238e67d9a22cb5e32ad7825c398a5fb02a12a4a026bf6564cc1019d5708fb433fe475035a4e7bd21eadc82d84047fd9e740f6b02215914428f33684dd8425e1fc777bf93c3e92ade237f65009f0de08fabf2b1707ad55e19bd225b48f5a2b1c2fcbd7c2d9dcbae17cbfdb75792c25670eff082ed1c8596bd47c6ae8fc18b227adfde78b5971bde67f8eaa79b02c8b81381d6946d8a344f3000d1faa97db3ca5bcb6a4cfd2aa7e24b7e1f666e59eb424fcc1bb84ebf597f37c557bb3d0db9063cf4d658bc8faa40649a1ed6487667ea5d48471188cbb839e63241f47e514f363ff4f3c21c6be0c827ba397fd55a6b04069967c24f5cd55c49e0f007a3d63de0d9f90b94ad4c4898da94970b608970e13da6df95141f1e9130ac73b31ed1cf5f712317f1c43120049308bc48f4ff52d05dddf32ea4af6823ebabd4cd55c8c08fb63ae9a2d9db141d6662ec45971f0552b8d97a676697507fc2a6e2035ffbe7d22a431bfedc9c8fdf075ac71ac2aed59049629083d6e11bc6f77d47344dbbf5632f3074a0c56ac999adeb5f02a8759ae906f68445161a291302f2d6fe8d4c4d89b3e8614ed5424a0983101d8458d179b43364e55e71ffca8550cbdc0352b50022a2bebfd7232202509f8685c9fea06501f6081da444cf548ec480848eca33cab933a35f393371b0f628b0dfaa69cfdeeb182b4fda9c5702bdab1f6101060973a78109ecc0f7aacef9b2b32b41fac200ab956b2879b1a2ec2e9bc243cc31d57afc00d9e8a3f50c430ebac36fbd8502557b4ffb7e30ebe09f8e5c1c4b3de74f18c4e6b58959f22a7990852bd8b69e2fcf952f076d1902e81ea70e2cfb692adfef0e0836ef03cbbc26619225aa9660f7f3f066732b8843626788ee9012eb0f93020d5ba8910965de4dac49c382e13ddae0a7ef55e9823e5b96dc5ad03f4b5da041501539095cbb9484c921045c5a0df44c219da802ff35340ec9694fb74c0efa94ce4ec2530b32d7397c7f2ddb7a4213bc0d6388ee26510672582351423d5d5688c039adb973436c07272b749dc7cc4fb0d56594c4b4b721c9e4348e1e076ae7de00aab6f8af0aa8e4525c62835f66072897c68fed68693a6778597a52c9b269a115011852c18e0f4dc173d65158c27499626ba63df93ba3ec82d0e4bd1f7da53263e35eb7e85bc59f24025999a0665f7744e7ef75cd75b2011b9f4e83e1819661552e377649bccb3077d6d4107e6b1428a94558181e9f4c685b0e5a344ab510ec2d19ef522a976c20c07fa05401f5df4b5f7f32f837ce2ee846d9355ccc32a8f7bdad363b55e8b395fae0d710d5af647f1f37c36a3ced96c42f88bd1e10026873f45d674b939c6002ee13c1a0acee3e7cd5cdefad4679a70c97df495a5659ef7129f2e5af4aaea0c893313f1e374d4c9dffcb98925f0064023ed1583befde05b6d78223f7ebb40dcd0786d410c03872da797f56e63d24feb9b83ba7008de62ac9ec9c773d6b540ff4eca60ac278dd4065da98a089baa92cd394a40fdd5736523843dee60279ac415eae3c8526abe5d326e4318c308a027649773231b30fefa3d5a1140539a5d74d4007769520584435ae64b897c171b605844f0cfebd6b9249b28c9a45a4e6f8d5238a30a42e95fcab99290317bb968d0b7869eec68475dfa77c12caf2f7981c10de2f0f413fc053d482aa66166332b4cbde085e35fd58030183d3a240f050acafd203c2810c05fd823a4421e361400a261580e0e12ad3027e982772384d4bf1ce80473ff9850e2c5f5fe728c102aff8551b66b529284172938621817dd420c99082dacf32ddbdbeda9878c19fa8a74b1fee374e46840350d52f537ffef62735c57a45ac531f7823cd04f1f1ce1ba50589360ab2655671edd0a9a7b59b65493592c4bdca10e33970b1c4078cc7b05b5476ef4bf3185482212e40ce5d2feb6537dff2828c855b50d063f2f850ca234dbe851cc48857ee29b9e5c2877ed817737fc7bf51a5479b3a7f02caf11bff0b66c790111f77b1b3eca3b6911e6bfd3350e83420c32ce6c1053312c11a97b7dd5dc64dd2a5c262594b1fe5f695f0a630ecab6c2fa1eea37a85ef34be88aa3dfb33e0dd488e6b6aabccabdd53b9974f6d0f0704683c91833c51b2349a028abe35f015cbc7ba5985148e559713659f71d177bfe551b8fb34e65b42c66fa81ef5537513dcd48ed0a100940efd8ed4f1c76f9d1a4911bd99bdd7f0c7e01f38bf5b5fad1a7b0d2e5020fa839a818b5593a567d8e8daf98a91bd6c21df4eea9b62e7663c966fd9e62ed8e4c0c5fbc39aa769e1d689ae8cbd93fea14060e200051b9ab3e168808b81538ffa71531e95cf71bdeb5abc7b63ca1afba90e536e449d59064282820965634301d3ae925e016941a12c89d7bb266a28a69efe817a0135b025af099498db7a20ec5ca1580ebb03c493a835f2d511a6e31fbf96cc56cb2949a30dd7ee00202f3a3389c2eb0dc2e07a068e551e7dc6ca6478b1827141b91b42b8820c5a4aa51eb42f53ac2f2af494ebaceb6c97e2264488fbc22ca2dcd293c040e8a30b5720ba7f5b7f340557969726b81c3db5e8b01384c3bfa1a5aea0ee7c68feb46be0d0e3a52b2af4ebf09756f2e055822c44dfd652f8dfdb570cda50fcbdab3e1f7618a0d990d45fc6a9423cbf0b5dfb5ca47dc84fb8b75b701db0a51e4cb8c8220c0fe71668f398378cf523f24e4f75ec8e36418c2f25ed4574e405585b366ca5db163242ad70fbb9798fcacbd0b2cf7762a4b5153bb850b7c7d373e8d1a19dcd598edd2bbf41f6264a9f26ecb422f567d63cb22e9a1cc67eb1d781852d0cf2d9102aeeb686d9c7911ae2a0e9b623b524eac44c2b6da2e856eb20ffcc17ab329b1a72fdf23dee718df6b89f5e131748f56d10eb70e4f7f73322ffb13baa2361f3255dab7a92fe471bfd3b8bee52fc73520d9be06440dd538f4ea07feea4ca3176e7544b6ff0cc2affdaa056b95926a3c0c1803de79f848a9b2a255464891d86d727e386aa8f2bac5cd4e45a5d3a7a5c8d9a5ea281832ab9e77289c3e5bea939fcf1d73211dc1e181388ad7f30b76a798ecc098449dd3b07469ad3029f703e8800a23b12d651ec7dfc48ce6c04b90340e3e8de5b48ba6d81253cc7e06349206a5cce42b7949dbd18eb35ce2ed0f69949fe56bc9c5e5fc030bc04f897284874735a000d639cd76b73bf2899ef4b98bf15ce391f8c3e72e58710fdcb930c8ae340d9f275f93c9d8aa65275c15c8ef797e8ae02c5266f76a8dc7038c046bdc9ff7c3a515bd6246241739cb29a19edadb74b1b887c9282cf6bf1595de58ca0b7daecb032e07026c11268b1f1ec71fe8597ea67999c0a32b52c81c33f5437ca3899014141bb38e246323edbd0002652141459564db41fad135dbd3de86f3e383c797bdacd273bc7c816e13b8aba19f9ff1d69e3b21701e028b8795ed7207cec306679138cb637ea75e44eaf0c4bbf83a69c1f2eccd9ca08a714cb75e49df3d91377607fe03d2190b2d8b2fabd014dcdb6dc73c4debbeea48c72ce7b8915ebcdb4411c404258e0172dcd688dd0c0fd5ecb41440b3f3af514da0c47ae609b63d389613c72ab0ae0944919671471ccb7b15974eb51fbea90b73c07312b588626bf17cc96662b73b435c0037f9a5791a76bfe5eab143f529ff5109943e3d1fe37644a46711fa1f41152177e778987312a60775d628acca8bc70c2511772aa2323c6ac83a1f811a2dda87643d633ecfe1a08407f6ca6fe60a282af1f418a0b8fec5eddc7e48bae30e3d93843e18b489a2971858177632f334987662596e2cc33f598c36a77b60d4c59092efc279f752ef3ca04059e40651c2c6300fc57a45acd64e5a19362b7a8d06ae8527534527449087c88b15a68a6af37839e05bc49839330e751058ceb7507726618f8d8f7e8c70c9fcd75dbe1db68687092485aeded29e7c6019999ca01eda9db8f7e2af8677b45e29df3604c69c25d0ca3e81c6d67024128d6980ce2ed461ba3f0289737dc48fcb8c037d872c4e12230fbd43a7450ab49631a8918e7ccb88c2f6de055dd5b50e679c9c0a918d058f0feaf3889a5e890cc1f867b246fc86f1c83dac29723ee80f2ffae24da0da4de836e0afa207959d9d50bf31f176ef44383c32e5d95ae311d9c1e98c4c46c29ad0b11ee0e91be682b4865b9933ed39a68b2053b51f4fcb054f4f24179cf8d5b9bfc1164c3abb504ed7a58379720a27d24f1e01a3b2f89676c5762852ba97aa99c9356422e59fb7b75221ec0666fc52b9b6459be0ae8078e2ec8c502502e942f9f148a0a6b9f0cd1e8a9a48f5a29b9d57d087c648e34a2d4cdd9545842201dd8bff44a4e45557b8d2721a75ceaac5530378c6e84af5c3504c62515d33ff79d0fc2c4d5ed4a3842b02453657322e20df632aa40878ec9ef24e2bdcbe2c35ed26bc0520a434231170f5bf02652601c83fde0f8152bda8d84d18d35eeab9cda1ec8cf9292295d8171b9b194f15e17d26c5781b430d8e5f28832ccb83cdc0743a7095ba3451743cb733f56da1721c41c257e59cc26e4c358b2f0060b9409005b7c59b215191cd96e77387c0521473760dc8d6bcaae82d96e0cb256501493b45305a0e10c2c0e76af0b063baa4bf01b0eb222f01e6d198a4ea79f752d41d05e74c37ae6b5be7c040554aa614f5b5ce1163c1747e3731a405c50781cda23189ce5dddbd7cff272b60f3b3e2ce57cb9cd903c7ac55df49f910b31b9e4f32b7263f10ba13bbafb65a56ae9afb02b2720dd60ad6a381012515d436b0660e38b8e2702a90cfedcb9c3b4d242508f24a8a255cf3d752a086741ee5869a253426a5ab7b26aa888c765abadad5a9f9a1ebc54523641750c4ae772d0538e6d219daf2694c1d0ad6338b2e29cce3d293cc41fd355b1bbbae9bbed3ab37e5b4d967190501dd291e0f12a5c408796ae846bce02e349978b53537b084ad86e32cde7713029fba3f86166bfb95ac46186464c71739f33cb72480f37beb2d39d00361643a99b29ed233827c66f5026c2f57226130e874e94d4b0e3f7ea3aca6e5b31d1c003a30e5ef96512a3eceb35ded5b2700d3540c31539523beddd62f2de734b5fa63427f255c0f083038d735a018f3dab9e95d236d60ef2ad15c65bbdde5ef3be6b5ce7a2083fec1deb16fd3ea4e10beca9f9f1b782aeb7f3436447985fac5b60fcdceda36acbc5ffee35278946d60c77af8ebfae704ae986229ccf192e4e4446a27ab226d5cafe43907eb3a5cf7740c9b7a48573c292fb05dfb83542c6f98e0ca12c7bdee1bef6b7c387cda2d9dcd921f9989a4464629d29f1b0928a69ce35040010356e72ba1f2063dbc4e8b59cb272f6a9f977096e17df73e860ecc8fee5b23a2f2a093d93dd02d087fd8c22dbc59fb09a649f78497fe732c4111504ade9de8ff9305c4038d9db154bcc1841a95dac7df7e5cf40d92546259ef9d629ff875e227ee8af435d773fa6abb2f416dbf163585c959c781d722aff570259f8b9b64fdc4e81590aeaf284135c673b825ecbc9764affe266847d75067ca3aa62e7271a65cbc93ed866b4737af5e30fea9808381e37c85a5117e29632eccbc473f62c9c370da34d133ed9ee7b3434adf9d52ce59970abb025e8af3114041ce6be739fea0879233297e828ef3845a44f44578bda945d64ea53a30ec5c9179132d65359d2a00fc1fe735a60f0d5beef14370be0cbc48ccb13c72e67a45c3e092585511e7a9721233e8627afa1f98635e132c5d032d52bd610a3cd4f33781b0be781a1252c01de4fd6461fb174d95e8c898b5e6d890d6fe09c02e8ff57114580be75ab25135a9353879cfe82feb80bb1ec9b088f086cc9be73b05447ba88d717cad49ba5c5a98302855ba12d69532fa89c5439211c371fb2776be0ed13e9152b8bc80b5ad84fcd04e955dbf3eb9482bd4f4b616ec5631e9e120fba4ffeaf5908eb50c67b3e977da0480a823d79ded1dcd2846454c477d70daee48ae68ea9935a6f075fdb1ac01ffe1ac9b4a8b43abbedc209d3aacd5290f52a90f9019f32170596b9673e879bd243a5acb76d18e4b62e1ef1c747adf4b6a3fe2cc8b345532fb61dd7366962ee3f73f19451349394b95e0a9d57e5770611966d6b8cb31ffec1d0eba54bbfeea2dbdb3b02ea313e18275974dddf5e5aba5f8d37f9059e29dcdb72d3bb4a98f91b534447850af6e9dbb0ea93a63421edf09af988e45427d4b8ca00a5adf822ae02d89b33c430b6e11bfec1830f1a3f3c2726f326a65445469eae18c26283eeea9963ef443377d60f3ebc1202858daf926795d0410fbe182348c59b7a570d8d3e7ed771ea95307459f5d33db030df701e18ca7acd3c724ad34022635b38d4cd52f5cc3ea82a48c6912d6ff850d2c492337c138eba0a30876d804bc2d6fc4190dc4b6c7e8ebd7df950114dde57467163e780bc1487d9b381f01a02ed3fd1a5044d8d93676465d1e3ce295cbc3b4e8f41c60ed2a878f3670dffb2d8713a811dfd3d7f5fcefbbc7546195d678c34ed427eb97f56720228e4931090174f61286024512abb4082816959e106943883b7f473247e66a9912377650df5a54cdee224e06c193190c0cb23348709e3c0847d669b479a70b9adb8a01d6514bc60dc5511873b5068ca61af84ab37db3bc05efef456b3f0e30ccdc40dc34945aa903fc15aa4fb31b3c877db023260138a975a8c51fbfa155cb3f33cc069f8e7bb58964d54f97349f3bdc02aadf0a06fa821c220f039264ab7b5dad23e03623cc20fdcbf0def272084735b957985a30e8250b1c0786bddeab81575eb94b382cc7ba96ff38cee9c28fdf259faec3d327ce1d339d463873b8e278ecb1bc55b2afebacd0e05601bca6c7aff7b9b5115ca37db4dc542bdced93132620f9caa25c87bb38a8203c4f7c73004ad0a0c7dc702a54a9d85d09100371927454951768ca2bc8fda4950c76c8d1c61bd9c93506f5ce69a47b5ccd6debd811ffb236c6b6e0952a2da2033546cba4afaa319d5e5d0b754b60805acf06034f25967ab487a3e52343a98e2ece603cae2eaf1b736e1e51b5ef861cac0b5c68cb9e5ad3cb4d3623044f5fa25005710f8e167d4e1993f856ebd392c9e3ae65013eb526842f04766998f11994c999a2b89b1bad0acbb67ea2203138ef866639cff80305c65fa58c07c7c3978d2bbd19058f0c0f8a636fc6dd8b5e30a77f4e1cdb5a772eb820ff3663a8b3de8e8cee042bf963b7deac834f6c6c7347e3c8fefd068c6045e532c3e353b398fb1776aab98f7d1ed32fae327f9185bc0d254023a88b42661f29e4c3196154774e6bad55ee7a762895a4c33d50043e53</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Welcome to my blog, enter password to read.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Thesis</category>
        <category>Prediction</category>
      </categories>
      <tags>
        <tag>Prediction</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Stata</title>
    <url>/2021/03/18/Stata/</url>
    <content><![CDATA[<h1 id="stata-data-operation">1 Stata data operation</h1>
<h2 id="data-operation">1.1 Data Operation</h2>
<h3 id="browse-data">1.1.1 Browse data</h3>
<ul>
<li><p>browse / edit</p>
<p><code>browse</code> 用于打开或编辑数据浏览器，相当于单击数据浏览器或编辑按钮。命令格式:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">browse</span>/<span class="keyword">edit</span> [<span class="keyword">varlist</span>] [<span class="keyword">if</span>] [<span class="keyword">in</span>]</span><br></pre></td></tr></table></figure></li>
<li><p>rename</p>
<p><code>rename</code> 用于对变量重新命名。格式：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">rename</span> (oldname) (newname)</span><br></pre></td></tr></table></figure></li>
</ul>
<a id="more"></a>
<ul>
<li><p>save</p>
<p><code>save</code> 用于将内存中的数据保存到硬盘上。基本格式：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">save</span> [filename] [, save_options]</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="import-data">1.1.2 Import data</h3>
<p><strong>导入原则</strong>：</p>
<ol type="1">
<li><p>打开新数据集之前，必须用 <code>clear</code> 命令清除存在于内存中的数据集；</p></li>
<li><p>如果某些数据集超出了现有的设定的内存空间，则需要使用 <code>set memory</code> 来设定内存空间大小；</p></li>
<li><p>使用 <code>use</code> 命令读入 Stata 格式数据，使用 <code>edit</code> 命令输入数据；</p></li>
<li><p>使用 excel 文件复制粘贴数据。</p></li>
<li><p>use</p></li>
</ol>
<p>读取 Stata 自身数据的命令，基本语法：</p>
<p><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> filename [, <span class="keyword">clear</span> nolabel]</span><br><span class="line"></span><br><span class="line"><span class="comment">// Clear: 指明目前内存中的数据尚未保存，仍然可以用新的数据来代替它</span></span><br><span class="line"><span class="comment">// Nolabel：在载入数据时不载入相关的标签</span></span><br></pre></td></tr></table></figure></p>
<h3 id="descriptive-commands">1.1.3 Descriptive commands</h3>
<ul>
<li><p><code>describe</code></p>
<p><code>describe</code> 用于产生一个对数据集的简明总结表格。输出的结果中包含每个变量的名称、存储方式（<code>byte</code>、<code>float</code>，<code>double</code> 和 <code>int</code>）、显示格式、变量标签和变量值标签。命令格式：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">describe</span> [<span class="keyword">varlist</span>] [, memory_options]</span><br><span class="line"><span class="keyword">d</span> [<span class="keyword">varlist</span>] [, memory_options]</span><br></pre></td></tr></table></figure>
<p>memory_options:</p>
<ul>
<li>simple(si): display only variable names;</li>
<li>short(s): display only general information;</li>
<li>fullnames(f): do not abbreviate variable names;</li>
<li>numbers(n): display variable number along with name;</li>
</ul></li>
<li><p><code>list</code></p>
<p><code>list</code> 用于显示变量的数值，其后可以跟需要显示的变量名称。如果没有设定变量，则默认显示所有的变量数值。命令格式：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">list</span> [<span class="keyword">varlist</span>]] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, options]</span><br><span class="line"><span class="keyword">l</span> [<span class="keyword">varlist</span>]] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, options]</span><br></pre></td></tr></table></figure></li>
<li><p><code>codebook</code></p>
<p><code>codebook</code> 用于详尽地描述变量的内容，包括变量名称、变量标签和变量的赋值。基本格式：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">codebook</span> [<span class="keyword">varlist</span>] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, options]</span><br></pre></td></tr></table></figure></li>
<li><p><code>summarize</code></p>
<p><code>summarize</code> 命令计算并显示各种单变量摘要统计信息。如果未指定 <code>varlist</code>，则计算数据集中所有变量的摘要统计信息。对于任何的数据分析，使用 <code>summarize</code> 命令进行数据的核对都是很有必要的，尤其对于缺失值、无效值、奇异值的探测都很有帮助。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">summarize</span> [<span class="keyword">varlist</span>] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br></pre></td></tr></table></figure>
<p>其中，<code>varlist</code>表示需要统计的变量，<code>if</code>为样本条件，<code>in</code>为样本范围，<code>weight</code>为样本权重。</p></li>
<li><p><code>tabstat</code></p>
<p><code>tabstat</code> 命令主要用于统计量组合，与 <code>summarize</code> 类似。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">tabstat</span> <span class="keyword">varlist</span>  [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">`options`选项中的 `stat` ：示设定所需要的统计量，`col` ：将结果报表转置。</span></span><br><span class="line"><span class="comment">统计量主要有平均数、观测值数目，求和，平均标准误差等。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> wage</span><br><span class="line"><span class="keyword">generate</span> lwage = <span class="built_in">log</span>(wage)</span><br><span class="line"><span class="keyword">tabstat</span> wage lwage, stat(<span class="keyword">count</span> <span class="keyword">mean</span> p50 p75 skewness <span class="keyword">median</span>)</span><br><span class="line"><span class="keyword">tabstat</span> wage lwage, stat(<span class="keyword">count</span> <span class="keyword">mean</span> p50 p75 skewness <span class="keyword">median</span>) col(stat)</span><br><span class="line"><span class="keyword">tabstat</span> wage lwage, <span class="keyword">by</span>(married) stat(<span class="keyword">count</span> <span class="keyword">mean</span> p50 p75 skewness <span class="keyword">median</span>) col(stat)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62AzJe.png" /></p></li>
</ul>
<h3 id="merge-data">1.1.4 Merge data</h3>
<ul>
<li><p>Horizontal merge</p>
<p>横向合并是指将两个数据文件的变量加总在一起。合并后数据的样本不变，但变量的数目增加了，使得数据文件变宽。横向合并的两个数据的样本是一样的，只是被存储在不同的数据文件里。横向合并主要通过命令 <code>merge</code> 完成。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">merge</span> [<span class="keyword">varlist</span>] using filename [filename...][, option]</span><br><span class="line"></span><br><span class="line"><span class="keyword">merge</span> 1: 1 make using autocost <span class="comment">// 对make变量进行1比1合并autocost文件</span></span><br></pre></td></tr></table></figure></li>
<li><p>Vertical Merge</p>
<p>纵向合并指的是把两个数据的样本加总在一起，合并后的数据变量数目不变，但样本数增加了，使得数据变长了。</p>
<p>最常见的纵向合并情况是使用同样的问卷在不同地方或不同时间调查得来的数据。合并步骤主要包括：</p>
<ul>
<li>两个数据文件里相同变量的变量名要一致</li>
<li>两个数据文件里相同变量的变量数目一致</li>
<li>两个数据文件里个案序号不能重复</li>
<li>每个数据要生成一个新的变量来辨别合并后该数据的样本</li>
</ul>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">append</span> using filename [filename...][, option]</span><br><span class="line"></span><br><span class="line"><span class="keyword">merge</span> 1: 1 make using autocost <span class="comment">// 对make变量进行1比1合并autocost文件</span></span><br></pre></td></tr></table></figure></li>
<li><p>Cross Merge</p>
<p>交叉合并指的是把一个数据的个案和另外一个数据的个案交叉搭配生成新的数据。从数据的结构和用途上讲，交叉合并要比纵向和横向合并更加复杂。交叉合并有两类：</p>
<ul>
<li><p>组内交叉：<code>joinby</code> 命令；</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">joinby</span> [<span class="keyword">varlist</span>] using filename [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> child</span><br><span class="line"><span class="keyword">webuse</span> parent</span><br><span class="line">descirbe</span><br><span class="line"><span class="keyword">list</span>, sep(0)</span><br><span class="line"><span class="keyword">sort</span> family_id</span><br><span class="line"><span class="keyword">joinby</span> family_id using https:<span class="comment">//www.stata-press.com/data/r16/child</span></span><br><span class="line"><span class="comment">// 组内合并，将 child 文件中的多余数据交叉合并到 parent中，重复的变量以parent为准</span></span><br></pre></td></tr></table></figure></li>
<li><p>一一交叉：<code>cross</code> 命令。</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">cross</span> using filename</span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> str6 sex <span class="comment">// create sex dataset</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">sex variable:</span></span><br><span class="line"><span class="comment">        sex</span></span><br><span class="line"><span class="comment">1\. male</span></span><br><span class="line"><span class="comment">2\. female</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">then, save sex dataset and drop it from memory</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> agecat <span class="comment">// create agecat dataset</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">      agecat</span></span><br><span class="line"><span class="comment">1\. 20</span></span><br><span class="line"><span class="comment">2\. 30</span></span><br><span class="line"><span class="comment">3\. 40</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">cross</span> using sex <span class="comment">//</span></span><br><span class="line"><span class="keyword">list</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62AoRJ.png" /></p></li>
</ul></li>
</ul>
<h3 id="data-extraction">1.1.5 Data extraction</h3>
<p>对于一些大型的数据，如人口普查数据和计算机记录的市场交易数据，因为其样本量太大，不适宜直接进行分析。最常用的方法是从数据中随机抽取一个样本，然后对样本进行分析，通常使用 <code>sample</code> 命令完成。语法格式：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">sample</span> # [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, <span class="keyword">count</span> <span class="keyword">by</span> (groupvars)]~~~~</span><br><span class="line"><span class="comment">// 随机从内存里的数据中抽取样本，# 是样本容量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> nlswork</span><br><span class="line"><span class="keyword">describe</span>, short</span><br><span class="line"><span class="keyword">sample</span> 10</span><br><span class="line"><span class="keyword">describe</span>, short</span><br></pre></td></tr></table></figure>
<h3 id="数据处理">1.1.6 数据处理</h3>
<ul>
<li><p>z 得分</p>
<p><code>Z</code> 得分，也叫标准分数（<code>standard score</code>），是一个数与平均数的差再除以标准差的过程。在统计学中，标准分数是一个观测或数据点的值高于被观测值或测量值的平均值的标准差的符号数。等于一个观测值是否异常最方便的方法就是计算 <code>Z</code> 得分。</p>
<p>根据切比雪夫法则，不论数据的分布是什么形状，都至少有 <code>3/4</code> 的测量值落在平均值的两个标准差的范围内，至少有 <code>8/9</code>的测量值落在均值的三个标准差范围内。</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">webuse</span> wage</span><br><span class="line"><span class="keyword">quietly</span> <span class="keyword">summarize</span> wage</span><br><span class="line"><span class="keyword">generate</span> z = (wage - <span class="built_in">r</span>(<span class="keyword">mean</span>))</span><br><span class="line"><span class="keyword">list</span> wage z <span class="keyword">if</span> z &gt; 3</span><br></pre></td></tr></table></figure></li>
<li><p>箱线图</p>
<p>箱线图在数据探索中有巨大的作用。箱线图一般指箱型图。箱型图 (<code>Box-plot</code>) 又称为盒须图、盒式图或箱线图，是一种用作显示一组数据分散情况资料的统计图。因形状如箱子而得名。在各种领域也经常被使用，常见于品质管理。它主要用于反应原始数据分散的特征。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">graph</span> box yvars [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"><span class="keyword">graph</span> hbox yvars [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> wage</span><br><span class="line"><span class="keyword">graph</span> box wage</span><br><span class="line"><span class="keyword">graph</span> hbox wage, over(married)</span><br><span class="line"><span class="keyword">graph</span> hbox wage, over(married, <span class="keyword">sort</span>(<span class="keyword">l</span>))</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62ESRH.md.png" /></p>
<center>
<p>Fig 箱型图</p>
</center></li>
<li><p>分位正态图</p>
<p>利用分位正态图可以判断一个变量的分布是否近似于正态。基本语法： <figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">qnorm</span> varname [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> wage</span><br><span class="line"><span class="keyword">qnorm</span> wage, grid</span><br></pre></td></tr></table></figure> Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62Epzd.md.png" /></p>
<center>
<p>Fig 分位正态图</p>
</center>
<p>命令独有的选项是 <code>grid</code>。加入 <code>grid</code> 选项可以在图中依次标注 0.05、0.10、0.25、0.50、0.75、0.90、0.95 百分位数的坐标刻度。分位正态图将观测变量分布的分位数 (<code>y</code> 轴) 与一个具有相同平均数和标准查的理论正态分布的分位数进行比较 (<code>x</code> 轴)，这样可以就变量分布的每个部分对正态性的偏离进行直观的审查。</p></li>
<li><p>偏度-峰度正态性统计检验</p>
<p>偏度衡量随机变量概率分布的不对称性，是相对于平均值不对称程度的度量，通过对偏度系数的测量，我们能够判定数据分布的不对称程度以及方向。</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62EPsI.md.png" /></p>
<center>
<p>Fig 偏度</p>
</center>
<p>峰度，是研究数据分布陡峭或平滑的统计量，通过对峰度系数，可以判定数据相对于正态分布而言是更陡峭还是平缓。</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62ECQA.png" /></p>
<center>
<p>Fig 峰度</p>
</center>
<p>基本语法： <figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">sktest</span> <span class="keyword">varlist</span> [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, noadjust]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> wage</span><br><span class="line"><span class="keyword">sktest</span> tenure</span><br></pre></td></tr></table></figure></p>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62EiLt.md.png" /></p>
<center>
<p>Fig. 偏度-峰度检验</p>
</center>
<p>其中，<code>kurtosis</code> 的 <code>P</code> 值检验为 0，落入拒绝域，说明不满足正态分布（<code>P</code> 值检验口诀：大同小异。小于 0.0000，说明落入拒绝域）。</p></li>
<li><p><code>Shapiro-Wilk</code> <code>W</code> 统计检验</p>
<p>夏皮罗-威尔克检验 (<code>shapiro-wilk test</code>) 是一种在频率上统计检验中检验正态性的方法。它在 1965 年由夏皮罗和威尔克发表。<code>W</code> 检验基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">swilk</span> <span class="keyword">varlist</span> [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, options]</span><br></pre></td></tr></table></figure></li>
<li><p><code>Pearson</code> 相关系数</p>
<p><code>Pearson</code> 相关系数又叫相关系数或自相关系数，一般用字母 <code>r</code> 表示，由两个变量的样本取值得到。是关于描述性相关强度的量，取值于 <code>-1</code> 和 <code>1</code> 之间。当两个变量有很强的线性相关时，相关系数接近于 <code>1</code> (正相关) 或 <code>-1</code> (负相关)。</p>
<p><code>correlate</code> 命令计算变量之间的 <code>Pearson</code> 相关系数或者协方差矩阵，如果不指定变量，则默认对数据集中的所有变量计算响应的矩阵。<code>pwcorr</code> 命令的好处是尽可能使用两两变量中所有没有缺失的数据，而不像 <code>correlate</code> 只采用没有任何缺失数据的完整的观测值。基本命令：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">correlate</span> [<span class="keyword">varlist</span>] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, correlate_options]</span><br><span class="line"><span class="keyword">pwcorr</span> [<span class="keyword">varlist</span>] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, pwcorr_options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> wage</span><br><span class="line"><span class="keyword">correlate</span> wage hours tenure <span class="comment">// 相关系数</span></span><br><span class="line"><span class="keyword">correlate</span> wage hours tenure, covariance <span class="comment">// 协方差</span></span><br><span class="line"><span class="keyword">pwcorr</span> wage hours tenure, sig star(.05) <span class="keyword">print</span>(.05)</span><br></pre></td></tr></table></figure></li>
<li><p><code>Spearman</code> 相关系数</p>
<p><code>Spearman</code> 相关系数是衡量两个变量的依赖性的非参数指标。它利用单调方程评价两个统计变量的相关性。不管变量之间的关系是不是线性的，只要变量之间具有严格的单调增加的函数关系，变量之间的斯皮尔曼相关系数就是 <code>1</code>。如果数据中没有重复值，并且当两个变量完全单调相关时，斯皮尔曼相关系数则为 <code>+1</code> 或 <code>-1</code>。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">spearman</span> [<span class="keyword">varlist</span>] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, spearman_options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">spearman</span> mpg rep78</span><br></pre></td></tr></table></figure></li>
<li><p>偏相关系数</p>
<p>偏相关系数类似于多元线性回归。当研究某一种因素对另一种因素的影响或相关程度，把其他因素的影响排除在外，而单独研究这两种因素之间的相关系数时，就要使用偏相关分析方法。</p>
<p>偏相关程度用片相关系数来衡量。即当有多个变量存在时，为了研究任意两个变量之间的关系，而使与这两个变量有联系的其他变量都保持不变，即控制其他变量，计算这两个变量之间的相关性。使用 <code>pcorr</code> 可以计算偏相关系数，基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pcorr</span> varname1 <span class="keyword">varlist</span> [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> wage</span><br><span class="line"><span class="keyword">pcorr</span> wage tenure hour age</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="数据分布">1.1.7 数据分布</h3>
<p>如果一个变量不符合正态分布可以考虑对数据进行非线性变换，常用的转换包括平方、三次方、自然对数等。<code>Stata</code> 提供了一个非常强大的工具 “幂阶梯” (<code>ladder of powers</code>) 可以尝试转换，然后依次进行偏度-峰度检验。主要的转换包括立方、平方、原始、平方根、对数等。基本命令：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ladder</span> varname [<span class="keyword">if</span>] [<span class="keyword">in</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> wage  </span><br><span class="line"><span class="keyword">ladder</span> wage</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62EAdf.png" />
<center>
Fig. ladder 数据分布
</center>
<p>此外，还可以通过 <code>qladder</code> 和 <code>gladder</code> 分别制作直方图和分位正态图。</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">webuse</span> wage</span><br><span class="line"><span class="keyword">qladder</span> wage</span><br><span class="line"><span class="keyword">gladder</span> wage</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62Enzj.md.png" />
<center>
Fig. qladder 分位正态图 (左) 和 gladder 直方图 (右)
</center>
<h2 id="operations">1.2 Operations</h2>
<h3 id="relational-symbols">1.2.1 Relational symbols</h3>
<ul>
<li><code>==</code>: Equal;</li>
<li><code>!=</code>: Not equal;</li>
</ul>
<h3 id="mathematical-operation">1.2.2 Mathematical operation</h3>
<p>数学运算，命令格式：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">display</span> expression</span><br><span class="line"><span class="keyword">di</span> expression</span><br></pre></td></tr></table></figure>
<h3 id="logical-operation">1.2.3 Logical operation</h3>
<ul>
<li><code>!</code>: not</li>
<li><code>&amp;</code>: and</li>
<li><code>|</code>: or</li>
</ul>
<p>Example:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">sysuse</span> auto, <span class="keyword">Clear</span></span><br><span class="line"><span class="keyword">list</span> price foreign <span class="keyword">if</span> price &gt; 1000</span><br><span class="line"><span class="keyword">list</span> price foreign <span class="keyword">if</span> ((price &gt; 1000) &amp; (price &lt; 4000))</span><br></pre></td></tr></table></figure>
<h2 id="function">1.3 Function</h2>
<h3 id="in-函数">1.3.1 in 函数</h3>
<ul>
<li><p><code>in</code> 函数简介</p>
<p><code>in</code> 用于指定观测值，可以是某一个观测值，也可以是某个区间的观测值。比如从第 10 个到 20 个观测值，基本语法如下：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">command <span class="keyword">in</span> <span class="keyword">range</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto, <span class="keyword">clear</span></span><br><span class="line"><span class="keyword">list</span> price <span class="keyword">in</span> 300/500</span><br><span class="line"><span class="keyword">list</span> price <span class="keyword">in</span> 10/<span class="keyword">l</span> <span class="comment">//last</span></span><br></pre></td></tr></table></figure>
<p>其中，<code>command</code> 是命令，<code>range</code> 是从某个数到另外一个数</p></li>
</ul>
<h3 id="if-函数">1.3.2 if 函数</h3>
<p><code>if</code> 函数用于一个命令后，用来满足表达式的数据集，基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">command <span class="keyword">if</span> expression</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto, <span class="keyword">clear</span></span><br><span class="line"><span class="keyword">list</span> make <span class="keyword">if</span> price  &gt; 10000</span><br></pre></td></tr></table></figure>
<p>其中，<code>command</code> 代表某个 stata 命令，<code>exp</code> 是需要满足的表达式，表达式可以利用不同的运算符连接起来变量。</p>
<h3 id="by-语句">1.3.3 by 语句</h3>
<p>Stata 语句大部分都允许使用 <code>by</code> 前置语句，用来对某些变量具有相同赋值的样本子集重复执行命令，<code>by</code> 语句的语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">by</span> <span class="keyword">varlist</span>: stata_cmd</span><br><span class="line"><span class="keyword">bysort</span> <span class="keyword">varlist</span>: stata_cmd</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">by</span> foreign: <span class="keyword">summarize</span> rep78 <span class="comment">// 按 rep78  变量来进行汇总</span></span><br><span class="line"><span class="keyword">bysort</span> rep78: <span class="keyword">tabulate</span> foreign <span class="comment">// 以表格的形式呈现并排序</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">by</span> group, <span class="keyword">sort</span>: <span class="keyword">regress</span> Y x1 x2</span><br></pre></td></tr></table></figure>
<p>Result：</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62A5iF.md.png" /></p>
<center>
Fig. 1-1 by 语句
</center>
<p><img src="https://s3.ax1x.com/2021/03/18/62AIG4.md.png" /></p>
<center>
Fig. 1-2 bysort 语句
</center>
<p>其中，<code>stata_cmd</code> 表示要执行的命令，<code>by</code> 和 <code>bysort</code> 的命令区别是是否对变量进行排序。</p>
<h3 id="generate-variables">1.3.4 generate variables</h3>
<p><code>generate</code> 用于创建一个新变量，命令格式：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">generate</span> [<span class="keyword">type</span>] newva = exp [<span class="keyword">if</span>] [<span class="keyword">in</span>]</span><br><span class="line"><span class="comment">//type 默认是浮点型</span></span><br></pre></td></tr></table></figure>
<h3 id="real-函数简介">1.3.5 real 函数简介</h3>
<p><code>real</code> 函数用于从合适的字符串表达式中得到数值，所以这个函数的定义域是各种字符串，而值域是数字和缺失值。命令格式：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="built_in">real</span>(expression) = result</span><br><span class="line"></span><br><span class="line"><span class="built_in">real</span>(<span class="string">&quot;5.2&quot;</span>) + 1 = 6.2 <span class="comment">// 从字符串中得到真实数字，若无数字则返回缺失值</span></span><br><span class="line"><span class="built_in">real</span>(<span class="string">&quot;hello&quot;</span>) = . <span class="comment">// &quot;.&quot; 表示缺失值</span></span><br></pre></td></tr></table></figure>
<h2 id="variables">1.4 Variables</h2>
<h3 id="dummy-variable">1.4.2 Dummy variable</h3>
<p>虚拟变量是最常见的指示指标，通常通过一个连续的变量进行转换可得。最简单的类别变量是取值为 0 和 1 的虚拟变量。生成虚拟变量的方法有两种。</p>
<ol type="1">
<li>利用 <code>generate</code> 和 <code>replace</code> 命令组合生成虚拟变量，基本语法：</li>
</ol>
<p><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">gen</span> college = 0 <span class="comment">// 生成一个常数变量，赋值为 0</span></span><br><span class="line"><span class="keyword">replace</span> college = 1 <span class="keyword">if</span> educ &gt;= 12</span><br></pre></td></tr></table></figure></p>
<ol start="2" type="1">
<li>使用 <code>generate newvar</code> 命令生成虚拟变量。基本语法：</li>
</ol>
<p><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">generate</span> college = (educ &gt;= 12) <span class="comment">// 等同于上两个语句</span></span><br></pre></td></tr></table></figure></p>
<h3 id="classified-variables">1.4.3 Classified variables</h3>
<p>生成分类变量可以使用很多方法，常用的命令有 <code>generate</code> 和 <code>replace</code> 命令组合，<code>tabulate</code> 命令以及 <code>recode</code> 命令，还可以使用 <code>autocode(), recode(), group()</code> 3 个函数。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">recoded <span class="keyword">varlist</span> (rule) [(rule)...] [, <span class="keyword">generate</span>(newvar)]</span><br><span class="line"><span class="comment">// varlist 表示需要进行转换赋值的变量名，rule 是事先确定的转换规则。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">recode</span> x(1=2), <span class="keyword">gen</span>(nx) <span class="comment">// 将x值由1变为2，并将新变量保存为nx变量</span></span><br><span class="line"><span class="keyword">recode</span> x(1=2)(2=1), <span class="keyword">gen</span>(nx1) <span class="comment">//将1变为2，2变为1</span></span><br><span class="line"><span class="keyword">recode</span> x2(1 2 = 1)(3=2)(4/7=3), <span class="keyword">gen</span>(nx2) <span class="comment">// 将1-2变为1，4-7的值变为3</span></span><br></pre></td></tr></table></figure>
<h1 id="drawing-operation">2 Drawing operation</h1>
<h2 id="绘图简介">2.1 绘图简介</h2>
<p>Stata 的制图引擎提供了一整套制图工具与选项。不同目的、不同水平的用户都可以自由地选择自己需要的制图工具。如绘制二维散点图:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">graph</span> <span class="keyword">twoway</span> <span class="keyword">scatter</span> var1 var2</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> autotech</span><br><span class="line"><span class="keyword">graph</span> <span class="keyword">twoway</span> <span class="keyword">scatter</span> weight length <span class="comment">// 创建二维散点图</span></span><br></pre></td></tr></table></figure>
<p>图形的组成可以分为四部分：</p>
<ul>
<li>由横轴和纵轴围成的图行的核心部分；</li>
<li>核心部分中诸如轴线间隔、连线、数值显示等附件部分；</li>
<li>用户在核心部分周围添加的诸如图形名称、轴线说明、图例名称、数据来源等文字；</li>
<li>在复杂图形中，用户添加在黑犀牛部分上的其他图行的叠加部分。</li>
</ul>
<h2 id="scatter-plot">2.2 scatter plot</h2>
<h3 id="散点图简介">2.2.1 散点图简介</h3>
<p>当用户面对的是两个连续变量时，散点图可以直观将数据呈现。散点图在探索变量的关系，为进一步的统计分级做准备工作中得到较为广泛的运用。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">[<span class="keyword">twoway</span>] <span class="keyword">scatter</span> <span class="keyword">varlist</span> [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">scatter</span> yvar xvar <span class="comment">// 以yvar为y变量，xvar为x变量</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">connect: 连线属性，默认none(i)</span></span><br><span class="line"><span class="comment">msymbol：点形状</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">graph</span> export <span class="keyword">test</span>.png <span class="comment">// 导出图片</span></span><br></pre></td></tr></table></figure>
<p>如果命令后紧跟两个变量名，Stata 会默认第一个变量为 <code>y</code> 轴变量， 第二个为 <code>x</code> 轴变量。如果命令后跟着两个以上的变量，Stata 会将除最后一个以外的变量作为 <code>y</code> 轴变量，最后一个作为 <code>x</code> 轴变量。</p>
<center>
Tab. 2-1 散点图的参数
</center>
<table>
<thead>
<tr class="header">
<th>options</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>marker_options</td>
<td>change markers' look (color, size, etc.)</td>
</tr>
<tr class="even">
<td>marker_label_options</td>
<td>add marker labels; change look, position</td>
</tr>
<tr class="odd">
<td>connect_options</td>
<td>change look of lines or connecting method</td>
</tr>
<tr class="even">
<td>composite_style_option</td>
<td>overall style of the plot</td>
</tr>
<tr class="odd">
<td>jitter_options</td>
<td>jitter marker positions using random noise</td>
</tr>
<tr class="even">
<td>axis_choice_options</td>
<td>associate plost with alternate axis</td>
</tr>
<tr class="odd">
<td>twoway_options</td>
<td>titles, legends, axes, aspect ratio, etc.</td>
</tr>
</tbody>
</table>
<h3 id="散点设定-marker_options">2.2.2 散点设定 <code>marker_options</code></h3>
<p>散点显示选项的设定主要包括三点的形状、颜色、大小等。散点的形状 <code>msymbol(symbolstylelist)</code>、散点的颜色 <code>mcolor(colorstylelist)</code> 和三点的大小 <code>msize(markersizestylelist)</code> 等。</p>
<p>具体设定包含如下5个方面：</p>
<ul>
<li>散点的形状 <code>symbol</code>；</li>
<li>散点的大小 <code>markersize</code>;</li>
<li>整体颜色；</li>
<li>内部的填充颜色</li>
<li>外保险的形状、厚度和颜色。</li>
</ul>
<center>
Tab. 2-2 marker_options
</center>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">marker_options</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">msymbol (<code>m</code>)</td>
<td style="text-align: left;">shape of marker</td>
</tr>
<tr class="even">
<td style="text-align: center;">mcolor (<code>mc</code>)</td>
<td style="text-align: left;">color and opacity of marker, inside and out</td>
</tr>
<tr class="odd">
<td style="text-align: center;">msize (<code>msiz</code>)</td>
<td style="text-align: left;">size of marker</td>
</tr>
<tr class="even">
<td style="text-align: center;">msangle (<code>msa</code>)</td>
<td style="text-align: left;">angle of marker symbol</td>
</tr>
<tr class="odd">
<td style="text-align: center;">mfcolor (<code>mfc</code>)</td>
<td style="text-align: left;">inside or "fill" color and opacity</td>
</tr>
<tr class="even">
<td style="text-align: center;">mlcolor (<code>mlc</code>)</td>
<td style="text-align: left;">color and opacity of outline</td>
</tr>
<tr class="odd">
<td style="text-align: center;">mlwidth (<code>mlw</code>)</td>
<td style="text-align: left;">thickness of outline</td>
</tr>
<tr class="even">
<td style="text-align: center;">mlalign (<code>mla</code>)</td>
<td style="text-align: left;">outline alignment (inside, outside, center)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">mlstyle (<code>mls</code>)</td>
<td style="text-align: left;">overall style of outline</td>
</tr>
<tr class="even">
<td style="text-align: center;">mstyle (<code>msty</code>)</td>
<td style="text-align: left;">overall style of marker</td>
</tr>
</tbody>
</table>
<h3 id="标签设定-marker_label_options">2.2.3 标签设定 <code>marker_label_options</code></h3>
<p>散点标签选项 <code>marker_label_options</code> 用于设定散点图标签（位于每个散点旁的用于说明散点所代表个体的文字），常见的选项由：</p>
<ul>
<li><code>mlabel(varname)</code>：用于设定标签变量；</li>
<li><code>mlabstyle(markerlabelstyle)</code>：用于设定标签的整体样式，包括：标签的位置、大小、方向等，取值在 <code>p1-p15</code> 之间。</li>
<li><code>mlabposition(clockposstyle)</code>、<code>mlabvposition(varname)</code>：用于设定标签的位置，它们之间是可以相互替代的，前者设定一个常数应用到所有的点，后者设定一个变量指示每个变量的标签的方向，这个变量的取值在 0~12 之间。</li>
</ul>
<center>
Tab. 2-3 marker_label_options
</center>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">marker_label_options</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">mlabel</td>
<td>specify marker variables</td>
</tr>
<tr class="even">
<td style="text-align: center;">mlabposition (<code>mlabp</code>)</td>
<td>where to locate label</td>
</tr>
<tr class="odd">
<td style="text-align: center;">mlabvposition (<code>mlabv</code>)</td>
<td>where to locate label 2</td>
</tr>
<tr class="even">
<td style="text-align: center;">mlabgap (<code>mlabg</code>)</td>
<td>gap between marker and label</td>
</tr>
<tr class="odd">
<td style="text-align: center;">mlabangle (<code>mlabang</code>)</td>
<td>angle of label</td>
</tr>
<tr class="even">
<td style="text-align: center;">mlabsize (<code>mlabs</code>)</td>
<td>size of label</td>
</tr>
<tr class="odd">
<td style="text-align: center;">mlabcolor (<code>mlabc</code>)</td>
<td>color and opacity of label</td>
</tr>
<tr class="even">
<td style="text-align: center;">mlabtextstyle (<code>mlabt</code>)</td>
<td>overall style of text</td>
</tr>
<tr class="odd">
<td style="text-align: center;">mlabstyle (<code>mlabsty</code>)</td>
<td>overall style of label</td>
</tr>
</tbody>
</table>
<h3 id="连线选项-connect_options">2.2.4 连线选项 <code>connect_options</code></h3>
<p>散点图的连线设置。</p>
<center>
Tab. 2-4 connect_options
</center>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">connect_options</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">connect (<code>c</code>)</td>
<td>how to connect points</td>
</tr>
<tr class="even">
<td style="text-align: center;">sort</td>
<td>how to order data before connecting</td>
</tr>
<tr class="odd">
<td style="text-align: center;">cmissing (<code>cmis</code>)</td>
<td>missing values are ignored</td>
</tr>
<tr class="even">
<td style="text-align: center;">lpattern (<code>l</code>)</td>
<td>line pattern (solid, dashed, etc.)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">lwidth (<code>lw</code>)</td>
<td>thickness of line</td>
</tr>
<tr class="even">
<td style="text-align: center;">lcolor (<code>lc</code>)</td>
<td>color and opacity of line</td>
</tr>
<tr class="odd">
<td style="text-align: center;">lalign (<code>la</code>)</td>
<td>line alignment (inside, outside, center)</td>
</tr>
<tr class="even">
<td style="text-align: center;">lstyle (<code>lsty</code>)</td>
<td>overall style of line</td>
</tr>
</tbody>
</table>
<ul>
<li><p>connect</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">connectstyle  Synonym     Description</span><br><span class="line">---------------------------------------------------------------</span><br><span class="line"> none            i        <span class="keyword">do</span> not connect</span><br><span class="line"> direct          <span class="keyword">l</span>        connect with straight lines</span><br><span class="line"> ascending       <span class="keyword">L</span>        direct, but only <span class="keyword">if</span> x[j+1] &gt; x[j]</span><br><span class="line"> stairstep       J        flat, then vertical</span><br><span class="line"> stepstair                vertical, then flat</span><br><span class="line">---------------------------------------------------------------</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="振荡选项-jitter_options">2.2.5 振荡选项 <code>jitter_options</code></h3>
<p>有时候，由于数据点太密集，甚至产生了重叠，使得在观察数据中的趋势时受到影响。这时，需要将这些数据点轻微地挪动位置，使得重合的数据点相互分开，在 <code>Stata</code> 中振荡选项 <code>jitter_options</code> 就是用来达到振荡数据点的目的的。一旦设定了振荡选项 <code>jitter(#)</code>，<code>scatter</code> 会在绘图前向数据中增加白噪声，选项中的 <code>#</code> 用来指定一个数字，表明振荡的程度占绘图区域的百分比。基本命令：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">scatter</span> mpg weight, jitter(8)</span><br></pre></td></tr></table></figure>
<p><img src="https://s3.ax1x.com/2021/03/18/62AcMn.md.png" /></p>
<center>
Fig. 2-1 振荡后结果
</center>
<h3 id="坐标选项-axis_choice_options">2.2.6 坐标选项 <code>axis_choice_options</code></h3>
<p>坐标选项 <code>axis_options</code>。主要包括：</p>
<ol type="1">
<li><code>axis_title_options</code>;</li>
<li><code>axis_label_options</code>;</li>
<li><code>axis_scale_options</code>;</li>
<li><code>axis_choice_options</code>;</li>
<li><code>axis_title_options</code></li>
</ol>
<p>坐标轴标题选项组 <code>axis_title_options</code> 用于设定坐标轴的标题，主要包括:</p>
<ul>
<li><code>ytitle(axis_title)</code>;</li>
<li><code>xtitle(axis_title)</code>;</li>
<li><code>ttitle(axis_title)</code>;</li>
<li><code>ztitle(axis_title)</code>;</li>
</ul>
<p><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">scatter</span> mpg price, ytitle(<span class="string">&quot;YYY&quot;</span>) xtitle(<span class="string">&quot;XXX&quot;</span>) <span class="comment">// <span class="doctag">note:</span> &#x27; ！= &quot;</span></span><br><span class="line"><span class="keyword">scatter</span> mpg price, ytitle(<span class="string">&quot;111YYY&quot;</span> <span class="string">&quot;222YYY2&quot;</span>) xtitle(<span class="string">&quot;111XXX&quot;</span> <span class="string">&quot;222XXX&quot;</span> <span class="string">&quot;333XXX&quot;</span>)</span><br></pre></td></tr></table></figure></p>
<ol start="6" type="1">
<li><code>axis_label_options</code></li>
</ol>
<p>坐标轴刻度选项组 <code>axis_label_options</code> 主要用于控制坐标轴的刻度和刻度的标识。主要包括:</p>
<p><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">axis_label_options                Description</span><br><span class="line">-------------------------------------------------------</span><br><span class="line">&#123;y|x|t|z&#125;<span class="keyword">label</span>(rule_or_values)    major ticks plus labels</span><br><span class="line">&#123;y|x|t|z&#125;tick(rule_or_values)     major ticks only</span><br><span class="line">&#123;y|x|t|z&#125;mlabel(rule_or_values)   minor ticks plus labels</span><br><span class="line">&#123;y|x|t|z&#125;mtick(rule_or_values)    minor ticks only</span><br><span class="line">-------------------------------------------------------</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p><code>rule</code> 的设定；</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">rule    Example    Description</span><br><span class="line">-------------------------------------------------------</span><br><span class="line">##      #6         approximately 6 nice values</span><br><span class="line">###     ##10       10-1=9 values between major ticks;</span><br><span class="line">           allowed with mlabel() and mtick() only</span><br><span class="line">#(#)#   -4(.5)3    specified <span class="keyword">range</span>: -4 to 3 <span class="keyword">in</span> steps of .5</span><br><span class="line">minmax  minmax     minimum and maximum values</span><br><span class="line">none    none       <span class="keyword">label</span> <span class="keyword">no</span> values</span><br><span class="line">.        .           skip the rule</span><br><span class="line">-------------------------------------------------------</span><br></pre></td></tr></table></figure></li>
<li><p><code>rules</code> 和 <code>numlists</code> 的设定；</p></li>
<li><p>子选项 <code>valuelable</code> 的使用；</p></li>
<li><p><code>alternate</code> 选项的设定；</p></li>
<li><p><code>grid</code> 和 <code>nogrid</code> 选项的设定。</p></li>
</ul>
<p><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">webuse</span> auto</span><br><span class="line"><span class="keyword">scatter</span> mpg weight, ylabel(#5) xlabel(#5)</span><br><span class="line"><span class="keyword">scatter</span> mpg weight, ylabel(10(5)45) xlabel(1500 2000 3000 4000 4500 5000)</span><br><span class="line"><span class="keyword">scatter</span> mpg weight, ymtick(#20, grid) xmtick(#20, grid gmax)</span><br></pre></td></tr></table></figure></p>
<ol start="7" type="1">
<li><code>axis_scale_option</code></li>
</ol>
<p>坐标量度选项 <code>axis_scale_option</code>，用于对坐标轴进行量度科刻画。</p>
<p><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">webuse</span> auto</span><br><span class="line"></span><br><span class="line"><span class="keyword">generate</span> ln_weight = <span class="built_in">log</span>(weight)</span><br><span class="line"><span class="keyword">scatter</span> mpg ln_weight</span><br><span class="line"></span><br><span class="line"><span class="keyword">scatter</span> mpg weight, xscale(<span class="keyword">log</span>)</span><br></pre></td></tr></table></figure></p>
<ol start="8" type="1">
<li><code>axis_choice_options</code></li>
</ol>
<p>坐标尺度选项组 <code>axis_choice_options</code>，尺度选项的主要功能在于决定坐标轴时采用正常的算术刻度、对数刻度还是反方向刻度，坐标轴的数值范围以及坐标线的显示。主要包括设定 <code>y</code> 轴的外观、<code>x</code> 轴的外观和设定 <code>t</code> 轴的外观。在设定的同时，还可以设定子选项的外观。</p>
<h3 id="twoway_options">2.2.7 twoway_options</h3>
<p>主要包含如下信息：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">twoway_options</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">added_line_options</td>
<td>draw lines at specified y or x values</td>
</tr>
<tr class="even">
<td style="text-align: center;">added_text_options</td>
<td>display text at specified (y,x) value</td>
</tr>
<tr class="odd">
<td style="text-align: center;">axis_options</td>
<td>labels, ticks, grids, log scales</td>
</tr>
<tr class="even">
<td style="text-align: center;">title_options</td>
<td>titles, subtitles, notes, captions</td>
</tr>
<tr class="odd">
<td style="text-align: center;">legend_options</td>
<td>legend explaining what means what</td>
</tr>
<tr class="even">
<td style="text-align: center;">scale(#)</td>
<td>resize text and markers</td>
</tr>
<tr class="odd">
<td style="text-align: center;">region_options</td>
<td>outlining, shading, aspect ratio</td>
</tr>
<tr class="even">
<td style="text-align: center;">aspect_option</td>
<td>constrain aspect ratio of plot region</td>
</tr>
<tr class="odd">
<td style="text-align: center;">scheme(schemename)</td>
<td>overall look</td>
</tr>
<tr class="even">
<td style="text-align: center;">play(recordingname)</td>
<td>play edits from recordingname</td>
</tr>
<tr class="odd">
<td style="text-align: center;">by(varlist, ...)</td>
<td>repeat for subgroups</td>
</tr>
<tr class="even">
<td style="text-align: center;">nodraw</td>
<td>suppress display of graph</td>
</tr>
<tr class="odd">
<td style="text-align: center;">name(name, ...)</td>
<td>specify name for graph</td>
</tr>
<tr class="even">
<td style="text-align: center;">saving(filename, ...)</td>
<td>save graph in file</td>
</tr>
<tr class="odd">
<td style="text-align: center;">advanced_options</td>
<td>difficult to explain</td>
</tr>
</tbody>
</table>
<ul>
<li><p><code>added_line_options</code></p>
<p>增加线选项 <code>added_line_options</code> 用于在二维图形上添加增加先，主要包括增加水平线，垂直线和特定的 <code>t</code> 轴上增加垂直线。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">xline(linearing), yline(linearing), tline(linearing)</span><br><span class="line"><span class="comment">// 其中 linearing 表示：numlist [, suboptions]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">scatter</span> mpg price, yline(10)</span><br><span class="line"><span class="keyword">scatter</span> mpg price, yline(10, lstyle(foreground))</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62AXdK.md.png" /></p>
<center>
<p>Fig.2-2 added_line_options</p>
</center>
<p>其中，<code>suboptions</code> 可以设定增加线的总样式、增加线的样式、增加线的粗细和增加线的颜色。</p></li>
<li><p><code>axis_options</code></p>
<p>轴选项包括：</p>
<ul>
<li><p><code>axis_title_options</code>;</p>
<p>轴线选择项 <code>yaxis(# [# ...])</code> 和 <code>xaxis(# [# ...])</code> 用来设定使用的是哪一个坐标，其中 <code>#</code> 取值为1到9，默认设置是 <code>yaxis(1)</code> 和 <code>xaxis(1)</code>，最常用的是对于 <code>y</code> 轴的选择，第一个 <code>y</code> 轴出现在图形的左侧，第二个 <code>y</code> 轴出现在图形的优策，而设定 <code>yaxis(12)</code> 将允许用户拥有两个相同的轴线。</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">twoway</span>(<span class="keyword">scatter</span> mpg weight)(<span class="keyword">scatter</span> price weight, yaxis(2))</span><br><span class="line"><span class="comment">// 二维图，等价于：</span></span><br><span class="line"><span class="keyword">scatter</span> mpg weight || <span class="keyword">scatter</span> price weight, yaxis(2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">scatter</span> mpg weight || <span class="keyword">scatter</span> price weight, yaxis(2) || ,  xlabel(#10) ytick(#10, axis(2)) ylabel(#8, axis(1))</span><br></pre></td></tr></table></figure>
<p>Result: <img src="https://s3.ax1x.com/2021/03/18/62AOZ6.md.png" /></p>
<center>
<p>Fig. 2-3 Example of pie figure</p>
</center></li>
<li><p><code>axis_label_options</code>;</p></li>
<li><p><code>axis_scale_options</code>;</p></li>
<li><p><code>axis_choice_options</code>。</p></li>
</ul></li>
<li><p><code>legend_options</code></p>
<p>当图形中包含多个组别的相似的内容时，<code>Stata</code> 将会生成图例。图例表示图形当中的不同符号对应着的内容，它使得读者能够轻松地读懂图中不同符号的含义。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">legend([contents] [location])</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> uslifeexp</span><br><span class="line"><span class="keyword">line</span> le year</span><br><span class="line"><span class="keyword">line</span> le_m le_f year <span class="comment">// default legend</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">line</span> le year, legend(<span class="keyword">on</span>)</span><br><span class="line"><span class="keyword">line</span> le_m le_f year, legend(off)</span><br><span class="line"></span><br><span class="line"><span class="keyword">label</span> <span class="keyword">var</span> le_m <span class="string">&quot;Males&quot;</span></span><br><span class="line"><span class="keyword">label</span> <span class="keyword">var</span> le_f <span class="string">&quot;Females&quot;</span></span><br><span class="line"><span class="keyword">line</span> le_m le_f year</span><br><span class="line"></span><br><span class="line"><span class="keyword">line</span> le_m le_f year, legend(<span class="keyword">label</span>(1 <span class="string">&quot;Males&quot;</span>) <span class="keyword">label</span>(2 <span class="string">&quot;Females&quot;</span>))</span><br><span class="line"><span class="keyword">scatter</span> le_m le_f year, c(<span class="keyword">l</span>)legend(<span class="keyword">label</span>(1 <span class="string">&quot;Males&quot;</span>) <span class="keyword">label</span>(2 <span class="string">&quot;Females&quot;</span>))</span><br><span class="line"><span class="comment">// c(l): 表示实现连线 connect(line)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">scatter</span> le_m le_f year, c(<span class="keyword">l</span>)legend(pos(5) ring(0) col(1) <span class="keyword">label</span>(1 <span class="string">&quot;Males&quot;</span>) <span class="keyword">label</span>(2 <span class="string">&quot;Females&quot;</span>))</span><br><span class="line"><span class="comment">// pos指时钟方位，ring(0) 表示离画图区域位置的距离。col指cols</span></span><br></pre></td></tr></table></figure></li>
<li><p><code>scale(#)</code></p>
<p><code>scale(#)</code> 选项设定一个数字以便调整整个图像包括文本、标记和线段的大小，可这个选项实际上是整个图形的放大镜或者缩小镜。</p>
<ul>
<li><code>scale(1)</code> ：默认设置，表示不改变图像大小；</li>
<li><code>scale(1.2)</code>：使整个图像增大20%可以设置；</li>
<li><code>scake(.8)</code>：为了使整个图像减少 20%，可以设置 。</li>
</ul>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">sysuse</span> lifeexp</span><br><span class="line"><span class="keyword">scatter</span> lexp lgnp, scale(1.3)</span><br></pre></td></tr></table></figure></li>
<li><p><code>by_options</code></p>
<p>设定选项 <code>by()</code> 后，<code>Stata</code> 会根据变量中的不同取值重复作图，因此 <code>by</code> 的依据往往是分类变量，比如性别、民族、国内国外等。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">by</span>(<span class="keyword">varlist</span> [, byopts])</span><br><span class="line"><span class="comment">// 其中，varlist是作图的根据变量，byopts是子选项关于by选项的设定</span></span><br></pre></td></tr></table></figure>
<ol type="1">
<li>选项 <code>total</code> 表示除了对每一个组别分别作图外，还要添加一个含有全部样本的图行； 2) 选项 <code>row(#)</code> 和 <code>cols(#)</code> 是相互替代的，指设定所有图行共排列 <code>#</code> 行或列。</li>
</ol>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> auto</span><br><span class="line"><span class="keyword">scatter</span> mpg weight, <span class="keyword">by</span>(foreign)</span><br><span class="line"><span class="keyword">scatter</span> mpg weight, <span class="keyword">by</span>(foreign, <span class="keyword">total</span>)</span><br><span class="line"><span class="keyword">scatter</span> mpg weight, <span class="keyword">by</span>(foreign, <span class="keyword">total</span> row(1))</span><br><span class="line"><span class="keyword">scatter</span> mpg weight, <span class="keyword">by</span>(foreign, <span class="keyword">total</span> title(<span class="string">&quot;test&quot;</span>))</span><br></pre></td></tr></table></figure>
<p>Result: <img src="https://s3.ax1x.com/2021/03/18/62Abs1.md.png" /></p>
<center>
<p>Fig.2-4 by_options</p>
</center></li>
<li><p><code>save_options</code></p>
<p><strong>图形保存选项：</strong></p>
<p>与处理数据文件一样，<code>Stata</code> 将本身生成的图形存储分为两种形式：一种是内存中的激活状态，另一种是存入硬盘的状态。在用户把当前文件存入硬盘之前，用户所绘制的图形均在内存中。用户可以选择是清楚或者存储，如果用户绘制另外一个图形，则自动清除之前保留在内存中的图形。基本语法： <figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">graph</span> <span class="keyword">describe</span></span><br><span class="line"><span class="keyword">graph</span> <span class="keyword">save</span> myfile, <span class="keyword">replace</span></span><br></pre></td></tr></table></figure> <strong>图形输出选项：</strong></p>
<p>为了使生成的图形与其他设备或者图形、文字处理软件相连接，<code>Stata</code> 还提供了图形输出的工具，包括将图形输出到打印设备上和将图形输出成为其他格式的文件。主要包括：</p>
<ol type="1">
<li>图形的打印 <code>graph print</code>；</li>
<li>存储为其他格式 <code>graph export newfilename.suffix</code>。</li>
</ol></li>
</ul>
<h3 id="点图">2.2.8 点图</h3>
<p>点图是一种散点图，其值在垂直方向上组合在一起（如直方图中的"合并"），而绘制的点在水平方向上分开。目的是在一个紧凑的图形中显示几个变量或组的所有数据。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">dotplot</span> <span class="keyword">varlist</span> [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> dotgr</span><br><span class="line"><span class="keyword">dotplot</span> g1r1-g1r10</span><br><span class="line"><span class="keyword">dotplot</span> g1r1-g1r10, title(<span class="string">&quot;Tumor volume, cu mm&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="标绘图">2.2.9 标绘图</h3>
<ul>
<li><p>曲线标绘图</p>
<p>曲线标绘图，就是其中的点用线段连接起来的散点图，和散点图一样，曲线标绘图的不同类型也属于 <code>Stata</code> 功能强大的 <code>graph twoway</code> 族命令。</p>
<p>散点图中控制添加坐标轴标签和标识的选项对曲线标绘图也起作用，新的选项可以控制曲线本身的特征。与散点图相比，曲线标绘图往往有不同的用法，如绘制描述随时间变化的变量。</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">[<span class="keyword">twoway</span>] <span class="keyword">line</span> <span class="keyword">varlist</span> [<span class="keyword">if</span>] [<span class="keyword">in</span>] [,options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> uslifeexp</span><br><span class="line"><span class="keyword">graph</span> <span class="keyword">twoway</span> <span class="keyword">line</span> le year</span><br><span class="line"><span class="comment">// twoway line le year</span></span><br><span class="line"><span class="comment">// line le year</span></span><br><span class="line"><span class="keyword">scatter</span> le year, msymbol(none) connect(<span class="keyword">l</span>)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62AjIO.md.png" /></p>
<center>
<p>Fig.2-5 曲线标绘图</p>
</center></li>
<li><p>连线标绘图</p>
<p>在曲线标绘图中，数据点是看不见的，只能看到连线，使用连线标绘图可以把图中的数据点加以标记。基本命令：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">twoway</span> connected <span class="keyword">varlist</span> [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, scatter_options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> uslifeexp</span><br><span class="line"><span class="keyword">twoway</span> connected le year</span><br><span class="line"><span class="keyword">scatter</span> le year, connect(<span class="keyword">l</span>)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62AxiD.md.png" /></p>
<center>
<p>Fig. 2-6 连线标绘图</p>
</center></li>
</ul>
<h3 id="拟合图">2.2.10 拟合图</h3>
<ul>
<li><p>一次拟合图形</p>
<p>一次拟合图形的绘制分两步：首先 <code>Stata</code> 使用 <code>yvar</code> 为因变量，<code>xvar</code> 为自变量进行一元线性回归，然后得到 <code>yvar</code> 的拟合值。比如说是 <code>hat</code>，然后使用 <code>hat</code> 对 <code>xvar</code> 做曲线标绘图，同时复合原始数据的散点。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">twoway</span> <span class="keyword">lfit</span> yvar xvar [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">scatter</span> mpg weight || <span class="keyword">lfit</span> mpg weight</span><br><span class="line"><span class="comment">// 等价于下述</span></span><br><span class="line"><span class="keyword">regress</span> mpg weight</span><br><span class="line"><span class="keyword">predict</span> fitted</span><br><span class="line"><span class="keyword">scatter</span> mpg weight || <span class="keyword">line</span> fitter weight</span><br></pre></td></tr></table></figure></li>
<li><p>二次拟合图形</p>
<p>二次拟合图形的绘制分两步：首先 <code>Stata</code> 使用 <code>yvar</code> 为因变量，<code>xvar</code> 和 <code>xvar</code> 的平方为自变量进行二元线性回归，得到 <code>yvar</code> 的拟合值如取名为 <code>hat</code>，然后使用 <code>hat</code> 对 <code>xvar</code> 做曲线标绘图，同时复合原始数据的散点图。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">twoway</span> qfit yvar xvar [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">scatter</span> mpg weight || <span class="keyword">lfit</span> mpg weight</span><br><span class="line"><span class="comment">// 原理类似于下述</span></span><br><span class="line"><span class="keyword">generate</span> <span class="keyword">tempvar</span> = weight^2</span><br><span class="line"><span class="keyword">regress</span> mpg weight <span class="keyword">tempvar</span></span><br><span class="line"><span class="keyword">predict</span> fitted</span><br><span class="line"><span class="keyword">scatter</span> mpg weight || <span class="keyword">line</span> fitted weight</span><br></pre></td></tr></table></figure></li>
<li><p><code>lowess</code> 拟合图形</p>
<p>命令 <code>lowess</code> 和 <code>graph twoway lowess</code> 皆可实现一种被称作 "<code>lowess</code> 修匀" 的非参数拟合图的绘制。由于具有可对拟合过程进行控制的选项，<code>lowess</code> 命令总的来说更为专业也更为强大。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">twoway</span> <span class="keyword">lowess</span> yvar xvar [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">scatter</span> mpg weight || <span class="keyword">lfit</span> mpg weight || <span class="keyword">lowess</span> mpg weight</span><br><span class="line"><span class="keyword">scatter</span> mpg weight || <span class="keyword">lfit</span> mpg weight || <span class="keyword">lowess</span> mpg weight||, <span class="keyword">by</span>(foreign)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="饼图">2.3 饼图</h2>
<h3 id="简介">2.3.1 简介</h3>
<p>基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">graph</span> pie varname [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight], over(varname) [options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> sales marketing research development</span><br><span class="line"></span><br><span class="line">         sales  marketing   research  develop~t</span><br><span class="line">  1\. 12 14 2 8</span><br><span class="line">  2\. end</span><br><span class="line"></span><br><span class="line"><span class="keyword">label</span> <span class="keyword">var</span> sales <span class="string">&quot;Sales&quot;</span></span><br><span class="line"><span class="keyword">label</span> <span class="keyword">var</span> marketing <span class="string">&quot;Marketing&quot;</span></span><br><span class="line"><span class="keyword">label</span> <span class="keyword">var</span> research <span class="string">&quot;Research&quot;</span></span><br><span class="line"><span class="keyword">label</span> <span class="keyword">var</span> develop  <span class="string">&quot;Development&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">graph</span> pie sales marketing research development, plabel(_all name, size(*1.5) color(white)) legend(off) plotregion(lstyle(none)) title(<span class="string">&quot;Expenditures, XYZ Corp.&quot;</span>) subtitle(<span class="string">&quot;2002&quot;</span>) <span class="keyword">note</span>(<span class="string">&quot;Source:  2002 Financia&gt; l Report (fictional data)&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Result: <img src="https://s3.ax1x.com/2021/03/18/62Aqqx.md.png" /></p>
<center>
Fig. 2-5 Example of pie figure
</center>
<h2 id="条形图">2.4 条形图</h2>
<h3 id="简介-1">2.4.1 简介</h3>
<p>条形图显示较为直观，可以显示众多的描述性统计量，同一个条形图中可以显示多个变量的统计量，比如均值、中位数、和、计数、标准差、最大值。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">graph</span> bar yvar [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options] <span class="comment">// 纵向</span></span><br><span class="line"><span class="keyword">graph</span> hbar yvars [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options] <span class="comment">// 横向</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">graph</span> bar mpg foreign</span><br></pre></td></tr></table></figure>
<h1 id="sample-related">3 Sample related</h1>
<h2 id="列联表-table">3.1 列联表 <code>table</code></h2>
<p><code>table</code> 命令可以用于生成一维到多维的列联表，表中不仅可以包含常见的频数，还可以包含任意其他变量的描述性统计量。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">table</span> rowvar [colvar [supercolvar]] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"><span class="comment">// 其中，`rowvar` 表示行变量，`colvar` 表示列变量，`supercolvar` 代表高阶的列变量。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">table</span> foreign rep78, c(<span class="keyword">mean</span> mpg) <span class="keyword">format</span>(%9.2f) center <span class="comment">// 居中并 format</span></span><br><span class="line"><span class="keyword">table</span> foreign rep78, c(<span class="keyword">mean</span> mpg) <span class="keyword">format</span>(%9.2f) center row col <span class="comment">// row和col表示添加汇总</span></span><br><span class="line"><span class="keyword">table</span> rep78, contents(<span class="keyword">n</span> mpg <span class="keyword">mean</span> mpg sd mpg <span class="keyword">median</span> mpg)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62EEo8.png" />
<center>
Fig. 列联表实例
</center>
<h2 id="列联表-tabulate">3.2 列联表 <code>tabulate</code></h2>
<p><code>tabulate</code> 命令主要用于生成一维或者二维的表格，对于二维表格还可以进行独立性检验。<code>tabulate</code> 的一维命令主要用于生成含有频数的一维表格。二维 <code>tabulate</code> 命令在生成二维表格的同时，可以计算多种独立性检验统计量和相关测量统计量，包括常用的 <code>Pearson's chi-squared</code>、<code>likelihood-ratio chi-squared</code>、<code>Cram's V</code>、<code>Fisher's exact test</code>、<code>Goodman and Kruskal's gamma</code>、 <code>Kendall's tau-b</code>。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">tabulate</span> <span class="keyword">varlist</span> [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, tab1_options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">tabulate</span> foreign, nolabel</span><br></pre></td></tr></table></figure>
<h2 id="样本-t-检验">3.3 样本 <code>t</code> 检验</h2>
<h3 id="单样本-t-检验">3.3.1 单样本 <code>t</code> 检验</h3>
<p>单样本检验的目的是比较样本均数所代表的未知总体均数 <span class="math inline">\(\mu\)</span> 和已知总体均数 <span class="math inline">\(\mu_0\)</span> 是否相等。其千题假设有散点：1) 已知一个总体均数；2) 可得到一个样本均数及该样本标准误；3) 样本来自正态或近似正态总体。计算公式为：</p>
<p><span class="math display">\[
t = \frac{\bar{X} - \mu_0}{s/\sqrt{n}}
\]</span></p>
<p>单样本检验步骤： 1. 建立假设，确定检验水准； 2. 计算统计量； 3. 确定 <span class="math inline">\(p\)</span> 值，得出结论。</p>
<p>基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ttest</span> varname  == # [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, level]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">ttest</span> mpg == 20</span><br><span class="line"><span class="keyword">ttest</span> mpg == 20, level(90)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62ArGQ.md.png" />
<center>
Fig. 单样本 t 检验
</center>
<h3 id="多样本-t-检验">3.3.2 多样本 <code>t</code> 检验</h3>
<p>多样本 <code>t</code> 检验分为两个正态总体的方差检验和两个正态总体的均值检验。基本语法：</p>
<ul>
<li><p>两个正态总体的方差检验:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">sdtest</span> varname1 == varname2 [<span class="keyword">if</span>] [<span class="keyword">in</span>], [, level(#)]</span><br><span class="line"><span class="keyword">sdtest</span> varname [<span class="keyword">if</span>] [<span class="keyword">in</span>], <span class="keyword">by</span>(groupvar) [level(#)] <span class="comment">// 借助分组</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> fuel</span><br><span class="line"><span class="keyword">sdtest</span> mpg1 == mpg2</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62EmWQ.md.png" /></p>
<center>
<p>Fig. 两个样本的方差检验</p>
</center>
<p>其中，<code>P</code> 值未落入拒绝域，即表明两个方差默认相同。</p></li>
<li><p>两个正态总体的均值检验：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ttest</span> varname1 == varname2 [<span class="keyword">if</span>] [<span class="keyword">in</span>] ,[, level(#)]</span><br><span class="line"><span class="keyword">ttest</span> varname [<span class="keyword">if</span>] [<span class="keyword">in</span>], <span class="keyword">by</span>(groupvar) [option] <span class="comment">// 借助分组</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> fuel3</span><br><span class="line"><span class="keyword">ttest</span> mpg, <span class="keyword">by</span>(treated)</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62EeJg.md.png" /></p>
<center>
<p>Fig. 两个样本的 t 检验</p>
</center></li>
</ul>
<h2 id="方差分析">3.4 方差分析</h2>
<h3 id="单因素方差分析">3.4.1 单因素方差分析</h3>
<p>单因素方差分析是指对单因素试验结果进行分析，检验因素对实验结果有无显著性影响的方法。单因素方差分析是两个样本平均数比较的引伸，它是用来检验多个平均数之间的差异，从而确定因素对实验结果有无显著性影响的一种统计方法。</p>
<p>单因素方差分析相关概念：1) 因素：影响研究对象的某一指标、变量。2) 水平：因素变化的各种状态或因素变化所分的等级或组别。3) 单因素实验：考虑的因素只有一个的试验叫单因素试验。基本命令：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">oneway</span> response_var factor_var [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> apple</span><br><span class="line"><span class="keyword">oneway</span> weight treatment, <span class="keyword">tabulate</span></span><br><span class="line"><span class="keyword">oneway</span> weight treated</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62Ayxs.md.png" />
<center>
Fig. 单因素方差分析
</center>
<h3 id="多因素方差分析">3.4.2 多因素方差分析</h3>
<p>多因素方差分析法是一种统计分析方法，可以用来分析两个因素的不同水平对结果是否有显著影响。以及两因素之间是否存在交互效应。一般运用双因素方差分析法，先对两个因素的不同水平的组合进行设计试验，要求每个组合下所得到的样本的含量是相同的。基本语法:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">anova</span> varname [termlist] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> systolic</span><br><span class="line"><span class="keyword">anova</span> systolic drug <span class="comment">// one-way anova</span></span><br><span class="line"><span class="keyword">anova</span> systolic drug disease <span class="comment">// two-way anova</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62ADPg.md.png" />
<center>
Fig. 多因素方差分析
</center>
<h3 id="协方差分析">3.4.3 协方差分析</h3>
<p>协方差分析将人为很难控制的控制因素作为协变量，并在排除协变量对观测变量影响的条件下，分析控制变量（可控）对观测变量的作用，从而更加准确地对控制因素进行评价。</p>
<p>协方差分析拓展了多因素方差分析，使之可以包含分类变量和连续变量的情况。当出现连续变量时，定义此变量，方差分析便可进行。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">anova</span> varname [termlist] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] c.(<span class="keyword">varlist</span>) [, options]</span><br><span class="line"><span class="comment">// c.(varlist) 指明该变量为连续变量，为指明则默认为分类变量。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">anova</span> drate region c.mage region#c.mage <span class="comment">// # 表示交互项</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62EMyn.md.png" />
<center>
Fig. 协方差分析
</center>
<h3 id="重复测量方差分析">3.4.4 重复测量方差分析</h3>
<p>在某些实验研究中，常常需要考虑时间因素对实验的影响，当需要对同一观察单位在不同时间重复进行多次测量，每个样本的测量数据之间存在相关性，因而不能简单地使用方差分析进行研究，而需要使用重复测量方差分析。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">anova</span> varname [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, repeated(varname)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> t43</span><br><span class="line"><span class="keyword">anova</span> <span class="keyword">score</span> person drug, repeated(drug)</span><br><span class="line"><span class="keyword">regress</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62EQLq.md.png" />
<center>
Fig. 重复测量方差分析
</center>
<h2 id="假设检验">3.5 假设检验</h2>
<h3 id="单个总体的假设检验分析">3.5.1 单个总体的假设检验分析</h3>
<p>单个总体的假设检验时利用某些检验统计量，对样本的均值方差进行检验。主要分为三种：一直方差、未知方差、未知期望。基本命令：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">input</span> kdqd</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        kdqd</span></span><br><span class="line"><span class="comment">1. 32.56</span></span><br><span class="line"><span class="comment">2. 29.66</span></span><br><span class="line"><span class="comment">3. 31.64</span></span><br><span class="line"><span class="comment">4. 20</span></span><br><span class="line"><span class="comment">5. 31.87</span></span><br><span class="line"><span class="comment">6. 31.03</span></span><br><span class="line"><span class="comment">7. end</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">replace</span> kdqd = 30 <span class="keyword">in</span> 4</span><br></pre></td></tr></table></figure>
<ul>
<li><p>正态分布，方差已知的均值检验</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">quietly</span> <span class="keyword">summarize</span></span><br><span class="line"><span class="keyword">scalar</span> z = (<span class="built_in">r</span>(<span class="keyword">mean</span>) - 32.5)/(1.1/<span class="built_in">sqrt</span>(6)) <span class="comment">// z 检验</span></span><br><span class="line"><span class="keyword">scalar</span> cri = <span class="built_in">invnormal</span>(1-0.05/2) <span class="comment">// 95% 置信度水平的临界值</span></span><br><span class="line"><span class="keyword">scalar</span> p = (1-<span class="built_in">normal</span>(<span class="built_in">abs</span>(z)))/2 <span class="comment">// p 值</span></span><br><span class="line"><span class="keyword">scalar</span> <span class="keyword">list</span> z cri p</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62E3wV.png" /></p>
<center>
<p>Fig. 方差已知的均值检验</p>
</center></li>
<li><p>正态分布，方差未知的均值检验</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ttest</span> varname == # [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, level(#)] <span class="comment">// 正态分布，方差未知的均值检验</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ttest</span> kdqd == 32.5</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62A2q0.md.png" /></p>
<center>
<p>Fig. 方差未知的均值检验</p>
</center></li>
<li><p>期望未知检验方差</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">sdtest</span> varname == # [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, level(#)] <span class="comment">// 期望未知检验方差。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">sdtest</span> kdqd == 1.1</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<p><img src="https://s3.ax1x.com/2021/03/18/62E8oT.md.png" /></p>
<center>
<p>Fig. 期望未知的方差检验</p>
</center></li>
</ul>
<h3 id="两个总体的假设检验">3.5.2 两个总体的假设检验</h3>
<p>在实际工作中，有时会用到两个正态总体的假设检验，两个正态中体的假设检验通常分为两种情况： 1. 均值（独立样本）：<span class="math inline">\(z\)</span> 检验（大样本）、<span class="math inline">\(t\)</span> 检验（小样本）。</p>
<p>基本语法：</p>
<p><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ttest</span> varname1 == varname2 [<span class="keyword">if</span>] [<span class="keyword">in</span>] [unequal, welch, level(#)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">ttest</span> mpg1 == mpg2, unpaired <span class="comment">// 非对称样本，数据并非针对同一个体</span></span><br></pre></td></tr></table></figure> Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62EYYF.md.png" />
<center>
Fig. 均值检验
</center>
<ol start="2" type="1">
<li>方差：<span class="math inline">\(F\)</span> 检验。</li>
</ol>
<p><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">sdtest</span> varname1 == varname2 [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, level(#)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> fuel</span><br><span class="line"><span class="keyword">sdtest</span> mpg1 == mpg2</span><br></pre></td></tr></table></figure> Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62EmWQ.md.png" />
<center>
Fig. 方差检验
</center>
<h2 id="最小二乘法分析">3.6 最小二乘法分析</h2>
<h3 id="小样本的普通最小二乘分析">3.6.1 小样本的普通最小二乘分析</h3>
<p>普通最小二乘估计方法 (Ordinary Least Square，简记为 <code>OLS</code>)，是单一方程线性回归模型最常用、最基本的估计方法。<code>OLS</code> 的基本思想就是通过让残差 <code>e</code> 的平方和最小，从而使得模型的估计称为可能。基本命令：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">regress</span> depvar [indepvar] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">regress</span> mpg weight foreign</span><br></pre></td></tr></table></figure>
<img src="https://s3.ax1x.com/2021/03/18/62EtW4.md.png" />
<center>
Fig. 小样本的 OLS
</center>
<h3 id="大样本的普通最小二乘分析">3.6.2 大样本的普通最小二乘分析</h3>
<p>大样本普通最小二乘估计方法 (<code>OLS</code>) 适应性更强。在大样本下，只要研究其渐近分布就可以了，而渐近分布比较容易推到。大样本 <code>OLS</code> 经常采用稳健标准差估计 (<code>robust</code>)。</p>
<p>稳健标准差是指其标准差对于模型中可能存在的异方差或自相关问题不敏感，基于稳健标准差计算的稳健 <code>t</code> 统计量仍然渐近服从 <code>t</code> 分布。基本命令：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">regress</span> depvar [indepvar] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, robust]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">generate</span> gpmw = ((1/mpg)/weight)*100*1000</span><br><span class="line"><span class="keyword">regress</span> gpmw foreign, <span class="keyword">vce</span>(robust)</span><br><span class="line"><span class="comment">// regress gpmw foreign, robust</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62EUSJ.md.png" />
<center>
Fig. 大样本的 OLS
</center>
<h3 id="约束回归">3.6.3 约束回归</h3>
<p>在做回归分析时，有时会希望某些变量的系数相同或满足某种关系。约束回归通常可以通过对变量进行变换实现。</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2
\]</span></p>
<p>基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">constraint</span> [define] # [exp = exp | coeflist]</span><br><span class="line"><span class="keyword">cnsreg</span> depvar indepvars [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] , constraints(constraints) [options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">constraint</span> 1 price = weight</span><br><span class="line"><span class="keyword">constraint</span> 2 displacement = weight</span><br><span class="line"><span class="keyword">cnsreg</span> mpg price weight foreign length, c(1) <span class="comment">// 使用第一个条件</span></span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62Eal9.md.png" />
<center>
Fig. 约束回归
</center>
<h3 id="非线性最小二乘法">3.6.4 非线性最小二乘法</h3>
<p>非线性最小二乘 (Nonlinear Least Square, <code>NLS</code>) 方法是一种以误差的平方和最小为准则来估计非线性静态模型参数的一种参数估计方法。通常情况下，非线性最小二乘方法没有解析解，一般使用数值方法求解。基本语法:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">nl</span> (depvar = &lt;sexp&gt;) [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"><span class="comment">// &lt;sexp&gt; is a substitutable expression;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// nl (y = &#123;alpha&#125; + &#123;beta&#125;*x^&#123;gamma=1&#125;)</span></span><br><span class="line"><span class="keyword">nl</span> (y = &#123;b0&#125; + &#123;b1&#125; / x), initial(b0 2 b1 3)</span><br></pre></td></tr></table></figure>
<h1 id="model-specification">4. Model specification</h1>
<h2 id="dummy-variables">4.1 Dummy variables</h2>
<p>对于定性数据，通常不能将其直接纳入模型中进行回归分析。需要进行虚拟变量进行处理。一般情况下，如果分类变量总供有 <code>N</code> 类，为了避免多重共线性的出现，通常引入 <code>N-1</code> 个虚拟变量。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">generate</span> varname = value <span class="comment">// 生成带初始值的虚拟变量</span></span><br></pre></td></tr></table></figure>
<h2 id="变量分组统计分析">4.2 变量分组统计分析</h2>
<p><code>statsby</code> 是对变量分组 (<code>bysort</code>) 进行统计分析 (<code>statstics</code>)。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">statsby</span> [exp_list] [, options]: command</span><br><span class="line"><span class="comment">// by(varlist) 用于设定分组变量，如公司代码、行业分类等</span></span><br><span class="line"><span class="comment">// [exp_list] 用于制定返回值。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">statsby</span> <span class="keyword">mean</span>=<span class="built_in">r</span>(<span class="keyword">mean</span>) sd=<span class="built_in">r</span>(sd) size=<span class="built_in">r</span>(<span class="keyword">N</span>), <span class="keyword">by</span>(rep78):  <span class="keyword">summarize</span> mpg</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62EdyR.md.png" />
<center>
Fig. statsby 分组统计
</center>
<h2 id="遗漏变量">4.3 遗漏变量</h2>
<p>遗漏变量属于解释变量选取错误的一种。因为某些数据难以获取，有时未获得的数据会降低模型的精度。可以通过遗漏变量进行处理。<code>Stata</code> 提供两种遗漏变量检验方法：<code>Link</code> 检验和 <code>Ramsey</code> 检验。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">linktest</span> [<span class="keyword">if</span>] [<span class="keyword">in</span>] [, cmd_options]</span><br><span class="line"><span class="keyword">estat</span> overtest [, rhs]</span><br></pre></td></tr></table></figure>
<h2 id="自变量熟练的选择">4.4 自变量熟练的选择</h2>
<p>在统计模型的设计过程中，通常希望模型简介简单。通常使用信息准则来确定解释变量的个数。常见的信息准则有：</p>
<ol type="1">
<li>赤池信息准则</li>
</ol>
<p>在衡量统计模型拟合优良性 (<code>Gooodness of fit</code>) 的一种标准。它建立在熵的概念基础上，可以权衡所估计模型的复杂度和此模型拟合数据的优良性。</p>
<ol start="2" type="1">
<li>贝叶斯信息准则</li>
</ol>
<p>是在不完全请报下，对部分未知的状态用主观概率估计，然后用贝叶斯公式对发生概率进行修正，最后再利用期望值和修正概率做出最优决策</p>
<p><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">estatic [, <span class="keyword">n</span>(#)]</span><br></pre></td></tr></table></figure></p>
<h2 id="极端数据的诊断与处理">4.5 极端数据的诊断与处理</h2>
<p>再全体观测值中，会有一些样本和总体样题距离较远，这些样本再回归中可能会对斜率或者截距的估计产生较大的影响。</p>
<p>在 <code>Stata</code> 中，如果解释变量过多或者是面板数据，绘图方式并不直观。通常使用 <code>leverage</code> 影响力方法判断该数据是否是极端数据。若数据的 <code>leverage</code> 影响力值高于平均值，则对回归系数影响较大，可能会产生极端数据的影响。</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">regress</span> price mpg weight foreign</span><br><span class="line"><span class="keyword">predict</span> lev, <span class="keyword">leverage</span> <span class="comment">// 计算所有观测值的 lev 值，计算数据诊断</span></span><br><span class="line"><span class="keyword">gsort</span> lev <span class="comment">// 降序排列</span></span><br><span class="line"><span class="keyword">sum</span> lev</span><br><span class="line"><span class="keyword">list</span> 1/3</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62EwO1.md.png" />
<center>
Fig. 极端数据诊断
</center>
<h2 id="多重共线性与逐步回归法">4.6 多重共线性与逐步回归法</h2>
<ul>
<li><p>多重共线性 (陈强，<span class="math inline">\(P_{171}\)</span>)</p>
<p>多重共线性问题，在多元线性回归分析中很常见。非常容易导致方程回归系数估计的标准误差变大，系数估计值的精度降低等。多重共线性的通常症状时，虽然整个回归方程的 <span class="math inline">\(\mathcal{R}^2\)</span> 较大、<span class="math inline">\(F\)</span> 检验也很显著，但单个系数的 <span class="math inline">\(t\)</span> 检验却不显著。</p>
<p>当确认模型存在多重共线性时，通常有两种解决方法来消除影响：1) 收集更多的数据，增大样本容量。2) 通过逐步分析回归改进模型的形式。</p></li>
<li><p>逐步回归法</p>
<p>逐步回归法的基本原理时分别拟合被解释变量，对于每一个解释变量的一元回归，并将各回归方程的拟合优度按照大小顺序排列，然后将拟合优度最大的解释变量作为基础变量，逐步将其他变量加入模型中，观测 <code>t</code> 值的变化。</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">stepwise</span> [, options] : command</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="异方差检验与处理-陈强p_132">4.7 异方差检验与处理 (陈强，<span class="math inline">\(P_{132}\)</span>)</h2>
<p>异方差，是指误差项 <span class="math inline">\(u\)</span> 对不同的的个体是不同的，即条件方差 <span class="math inline">\(Var(\varepsilon_i | X)\)</span> 依赖于 <span class="math inline">\(i\)</span>，而不是常数 <span class="math inline">\(\sigma^2\)</span>。 违反了球形误差的假设。异方差的检验通常有三种方法： 1. 较为直观地观察方法进行回归后画出残差图 <code>ecdplot varname</code> 2. BP 检验 <code>estat hettest, normal</code> 3. 怀特检验 <code>estat imtest, white</code></p>
<p>异方差的处理： 1. 稳健便准差 <code>OLS</code> 法 2. <code>GLS</code> 法（广义最小二乘法）</p>
<h2 id="内生性-陈强p_193">4.7 内生性 (陈强，<span class="math inline">\(P_{193}\)</span>)</h2>
<p><code>OLS</code> 能够成立的最重要条件是解释变量于扰动项不相关（同期外生性）。内生性指解释变量于扰动项相关。内生性通常来源于遗漏变量偏差、经典的测量误差问题和联立性（逆向因果）。如果出现内生性问题，通常解决办法是使用工具变量，利用二阶段最小二乘方法进行解决。基本语法:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">ivregress 2sls y [<span class="keyword">varlist</span> 1] (varlist2 = instlist) [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, option]</span><br></pre></td></tr></table></figure>
<h2 id="二值选择模型">4.8 二值选择模型</h2>
<h3 id="二值选择模型-陈强p_212">4.8.1 二值选择模型 (陈强，<span class="math inline">\(P_{212}\)</span>)</h3>
<p>当被解释的变量可选值只有两个的时候，可以建立二值选择模型进行分析问题。<code>Stata</code> 二值选择模型主要有 <code>Probit</code> 和 <code>Logit</code> 模型。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">logit</span> depvar [indepvars] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"><span class="keyword">probit</span> depvar [indepvars] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br></pre></td></tr></table></figure>
<h3 id="多指选择模型">4.8.2 多指选择模型</h3>
<p>当选择为多个且互相独立时，可以选用多值选择模型。比如，消费者选择不同品牌，旅游者选择不同的交通方式等。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">mlogit</span> depvar [indepvars] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"><span class="keyword">mprobit</span> depvar [indepvars] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br></pre></td></tr></table></figure>
<h3 id="排序选择模型">4.8.3 排序选择模型</h3>
<p>在因变量不止两种选择时，就要用到多元选择模型。多元离散选择问题普遍存在于经济生活中。例如：一个人面临多重职业选择，将可共选择的职业排队，用0，1，2，3 表示。影响选择的因素有不同职业的收入、发展前景和个人偏好等。所谓“排序”是指在各个选项之间有一定的顺序或级别种类。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ologit</span> depvar [indepvars] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"><span class="keyword">oprobit</span> depvar [indepvars] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br></pre></td></tr></table></figure>
<h3 id="条件-logit-模型">4.8.4 条件 Logit 模型</h3>
<p>面临多个选择时，选择的依据是个体的特点。但有时，在模型选择过程中，个体选择受外部因素影响，此时可以选用条件 <code>Logit</code> 模型，模型可以解决解释变量中存在的选择特征问题。基本问题：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">clogit</span> y x1 x2 [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] , <span class="built_in">group</span>(varname) [options]</span><br></pre></td></tr></table></figure>
<h3 id="嵌套-logit-模型">4.8.5 嵌套 Logit 模型</h3>
<p>在进行模型选择的时候，很多个体的选择是分层次的，下面层次的选择受到上面层次的限制，相同层次之间的选择具有替代性，层次之间的选择又不相关。这时可以选择嵌套 <code>Logit</code> 模型进行处理。嵌套 <code>Logit</code> 模型的参数估计方法有两种：一种是两阶段最大似然法；另一种是完全信息最大似然法。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">nlogitgen</span> newvar = alvar(bracnchlist) [, nolog]</span><br></pre></td></tr></table></figure>
<h2 id="主成分分析">4.9 主成分分析</h2>
<p>主成分分析是设法将原来众多具有一定相关性（比如 <span class="math inline">\(P\)</span> 个指标)，重新组合成一组新的互相无关的综合指标来代替原来的指标。在许多领域的研究与应用中，往往需要反映事物的多个变量进行大量的观测，收集大量数据以便进行分析寻找规律。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pca</span> <span class="keyword">varlist</span> [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">pca</span> price mpg rep78 weight</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62EBex.md.png" />
<center>
Fig. 主成分分析
</center>
<h1 id="时间序列">5 时间序列</h1>
<h2 id="时间序列的定义">5.1 时间序列的定义</h2>
<p>时间序列分析方法通常适用于多种领域，包括经济、气象、过程控制等。通常依据变量自身的变化规律，利用外推机制描述时间序列的变化。在使用时间序列数据进行分析前，通常需要定义时间变量，通过新的观测值，或者需要对时间序列进行预测。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">tsset</span> timevar [, option]</span><br><span class="line"><span class="comment">// tsset 定义时间变量；timevar 用于标识时间序列数据的变量名</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> idle2</span><br><span class="line"><span class="keyword">tsset</span> time</span><br><span class="line"><span class="keyword">generate</span> newm = tm(2003m6) + time - 1</span><br><span class="line"><span class="keyword">list</span> time newm 1/5</span><br><span class="line"><span class="keyword">format</span> newm %tm <span class="comment">// 将时间格式化为以月份显示</span></span><br></pre></td></tr></table></figure>
Result： <img src="https://s3.ax1x.com/2021/03/18/62EDw6.png" />
<center>
Fig. 时间序列
</center>
<ul>
<li><p>时间序列拓展</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">webuse</span> idle2</span><br><span class="line"><span class="keyword">generate</span> newm = tm(2003m6) + time - 1</span><br><span class="line"><span class="keyword">tsset</span> newm, monthly</span><br><span class="line"><span class="keyword">tsappend</span>, add(12) <span class="comment">// 时间序列拓展</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="时间序列图与白噪声">5.2 时间序列图与白噪声</h2>
<p>时间序列的相关性代表了信息，自相关函数和偏自相关函数可以直观观测信息度。同时，可以采用 <code>Q</code> 统计量来检验白噪声。基本语法:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">corrgram</span> varname [<span class="keyword">if</span>] [<span class="keyword">in</span>], [, corrgram_options]</span><br><span class="line"><span class="keyword">ac</span> varname [<span class="keyword">if</span>] [<span class="keyword">in</span>], [, ac_options] <span class="comment">// 自相关绘制</span></span><br><span class="line"><span class="keyword">pac</span> varname [<span class="keyword">if</span>] [<span class="keyword">in</span>], [pac_options] <span class="comment">// 偏自相关绘制</span></span><br><span class="line"><span class="keyword">wntestq</span> varname [<span class="keyword">if</span>] [<span class="keyword">in</span>], [, lags(#)] <span class="comment">// 白噪声</span></span><br></pre></td></tr></table></figure>
<h2 id="arima-模型">5.3 ARIMA 模型</h2>
<h3 id="arima-模型-1">5.3.1 <code>ARIMA</code> 模型</h3>
<p><code>ARIMA</code> 模型差分整合移动平均自回归模型，常用模型包括：自回归模型 (<code>AR</code>)、滑动平均模型 (<code>MA</code>)、自回归-滑动平均混合模型 (<code>ARMA</code>)、差分整合移动平均自回归莫i选哪个 (<code>ARIMA</code>)。基本语法:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">arima</span> depvar [indepvars], ar(<span class="keyword">numlist</span>) <span class="keyword">ma</span>(<span class="keyword">numlist</span>)</span><br><span class="line"><span class="keyword">arima</span> depvar, <span class="keyword">arima</span>(#p, #<span class="keyword">d</span>, #q)</span><br><span class="line"></span><br><span class="line"><span class="keyword">webuse</span> wpi1</span><br><span class="line"><span class="keyword">line</span> wpi t, yline(0)</span><br><span class="line"><span class="keyword">line</span> <span class="keyword">d</span>.wpi1 t, yline(0) <span class="comment">// 一阶差分</span></span><br></pre></td></tr></table></figure>
<h3 id="smarima-模型">5.3.2 <code>SMARIMA</code> 模型</h3>
<p>在某些时间序列中，存在明显的周期变化。这种周期是由于季节性变化（包括季度、月度、周度变化）或其他一些固有因素引起的。这类序列称为季节性序列。经济领域中，季节性时间序列更为常见。如季度时间序列、月度时间序列、周度时间序列等。基本语法:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">arima</span> depvar, <span class="keyword">arima</span>(#p, #<span class="keyword">d</span>, #q) sarima(#P, #<span class="keyword">D</span>, #Q, #s)</span><br></pre></td></tr></table></figure>
<h3 id="arimax-模型">5.3.3 <code>ARIMAX</code> 模型</h3>
<p><code>ARIMAX</code> 模型，分别是名称 <code>ARMA</code> 和 <code>ARIMA</code> 的扩展，<code>ARMAX</code> 和 <code>ARIMAX</code>。添加到末尾 <code>X</code> 代表“外源”。它表示建议添加一个单独的不同外部变量以帮助测量内生变量。基本语法:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">arima</span> depvar [indepvars] [<span class="keyword">if</span>] [<span class="keyword">in</span>] [weight] [, options]</span><br></pre></td></tr></table></figure>
<h2 id="自助法">5.3 自助法</h2>
<p>自助法 (<code>Bootstrap</code>) 是一种从给定训练样本集中有放回的均匀抽样。每当选中一个样本，它等可能地被再次选中并被再次添加到训练集中。自助法优点是不必对模型的数据生成过程做出假定。基本语法：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">bootstrap</span> exp_list [, options eform_option] : command</span><br><span class="line"></span><br><span class="line"><span class="keyword">sysuse</span> auto</span><br><span class="line"><span class="keyword">bootstrap</span>, reps(100) seed(123): <span class="keyword">regress</span> mpg weight gear foreign</span><br><span class="line"><span class="keyword">estat</span> <span class="keyword">bootstrap</span>, all</span><br></pre></td></tr></table></figure>
<p>Result:</p>
<img src="https://s3.ax1x.com/2021/03/18/62AWZV.md.png" />
<center>
Fig. Bootstrap 自举法
</center>
<h1 id="软件相关">6 软件相关</h1>
<h2 id="do-文件">6.1 do 文件</h2>
<p>快捷键：<code>ctrl</code> + <code>9</code></p>
<h2 id="注释">6.2 注释</h2>
<ol type="1">
<li>通过 <code>*</code> 声明一行注释</li>
<li>通过 <code>/*</code> 和 <code>*/</code> 进行注释</li>
<li>通过 <code>//</code> 注释</li>
<li>通过 <code>///</code> 注释</li>
</ol>
<h2 id="临时文件">6.3 临时文件</h2>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">tempvar</span> var1 var2 <span class="comment">// 临时变量</span></span><br><span class="line"><span class="keyword">tempname</span> ms1 ms2 <span class="comment">// 临时矩阵</span></span><br><span class="line"><span class="keyword">tempfile</span> file1 file2 <span class="comment">// 临时文件</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Class Notes</category>
        <category>Econometrics</category>
      </categories>
      <tags>
        <tag>Econometrics</tag>
      </tags>
  </entry>
</search>
